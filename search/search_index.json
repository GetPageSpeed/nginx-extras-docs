{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NGINX Extras Documentation","text":"<p>The NGINX Extras is the largest commercial collection of prebuilt dynamic NGINX modules on the Internet. Each module can be installed as a separate package.</p> <p>The major benefit of packaged installations is security, maintainability, and reproducibility. No longer you have to manually compile anything when you need to update NGINX or modules. An update is just a <code>dnf update</code> that takes seconds and no downtime whatsoever.</p> <p>We currently support all major RPM-based distros, including CentOS/RHEL, as well as Amazon Linux and the latest Fedora Linux.</p> <p>All RHEL derivatives like Oracle Linux, AlmaLinux, and Rocky Linux are supported as well.</p> <p>Due to the extensive nature of our collection, it's easy to get lost in all the goodies and new NGINX directives.</p> <p>This documentation site brings you each module's installation instructions and added directives in a single place. </p>"},{"location":"#getting-started","title":"Getting started","text":"<p>To verify packages' integrity before installation, install our GPG key.</p> <p>Install repository configuration</p> CentOS/RHEL/Rocky Linux/AlmaLinux 8+, Fedora Linux, Amazon Linux 2023+CentOS 7Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\namazon-linux-extras install epel\n</code></pre> <p>Once the repository configuration is installed, activate your subscription to the GetPageSpeed repository.</p> <p>Subscribed? Proceed with installing the modules to build your ultimate high-performance web stack.</p>"},{"location":"#install-nginx-modules","title":"Install NGINX modules","text":"<p>Thanks to the nature of dynamic modules, you can install just the modules you want instead of using bloatware NGINX installation. </p> <p>For example, to install NGINX and the Brotli module for it, run:</p> <pre><code>dnf -y install nginx nginx-module-brotli\n</code></pre> <p>Enable the module by adding the <code>load_module ...</code> directive that is shown after installation.</p> <p>In case you missed it, refer to the documentation of respective module and look for <code>load_module</code> directive required to enable it.</p> <p>To list available modules for installation, run:</p> <pre><code>sudo dnf list available | grep nginx-module\n</code></pre> <p>To install the recommended group of modules for performance and security, you may want to run:</p> <pre><code>sudo dnf -y groupinstall \"nginx extras recommended\"\n</code></pre> <p>This installs NGINX, and modules: PageSpeed, Brotli, Dynamic ETag, Immutable (performance); ModSecurity, Security Headers (security).</p>"},{"location":"#upgrading-modules","title":"Upgrading modules","text":"<p>New NGINX releases require upgrading its modules. Thanks to the repository, you don't need to worry about recompiling anything. We ship updated NGINX and module packages, and you can simply run <code>dnf upgrade</code> to get to the latest NGINX and module packages.</p> <p>After updating a module package, to actually apply it at runtime, you have to run the binary upgrade routine. This can be done like this:</p> <pre><code>service nginx upgrade\n</code></pre> <p>This ensures that NGINX loads the updated module(s).</p>"},{"location":"#complete-module-list","title":"Complete module list","text":"<p>Proceed to the Modules page to see all available modules and their documentation.</p>"},{"location":"angie/","title":"Angie","text":"<p>Angie is an efficient, powerful and scalable web server that was forked from NGINX by some of its former core devs,  with intention to extend functionality far beyond the original version.</p> <p>Angie is a drop-in replacement for nginx, so you can use the existing nginx configuration without major changes.</p>"},{"location":"angie/#installation-and-compatibility","title":"Installation and compatibility","text":"<p>NGINX Extras provide you with production-grade, SELinux compatible packages for Angie web server.</p> CentOS/RHEL 7 and Amazon Linux 2CentOS/RHEL 8, 9 and Fedora Linux, Amazon Linux 2023, etc. <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install yum-utils\nyum-config-manager --enable getpagespeed-extras-angie\nyum -y install angie\n</code></pre> <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install dnf-plugins-core\ndnf config-manager --enable getpagespeed-extras-angie\ndnf -y install angie\n</code></pre>"},{"location":"angie/#compatibility-notes","title":"Compatibility notes","text":"<p>Angie is based on the mainline NGINX branch but does not have 100% compatibility with NGINX ABI. In fact, it has runtime checks when loading a module compiled for NGINX to prevent the loading, to avoid unexpected problems.</p> <p>So for the time being, you can't use numerous module packages from NGINX Extras with Angie.</p>"},{"location":"angie/#angie-features","title":"Angie Features","text":"<p>Angie is a superset to standard NGINX distribution and includes a number of features not available elsewhere.</p> <p>Core advantages over nginx include the following:</p> <ul> <li>Supporting HTTP/3 for client connections, as well as for proxied server connections, with the ability to independently use different protocol versions (HTTP/1.x, HTTP/2, HTTP/3) on opposite sides.</li> <li>Simplifying configuration: the <code>location</code> directive can define several matching expressions at once, which enables combining blocks with shared settings.</li> <li>Exposing basic information about the web server, its configuration, as well as metrics of proxied servers, client connections, shared memory zones, and many other things via a RESTful API interface in JSON format.</li> <li>Exporting statistics in Prometheus format with customizable templates.</li> <li>Monitoring the server through the browser with the Console Light visual monitoring tool. See the online demo: https://console.angie.software/</li> <li>Automatically updating lists of proxied servers matching a domain name or retrieving such lists from SRV DNS records.</li> <li>Session binding mode, which directs all requests within one session to the same proxied server.</li> <li>Recommissioning upstream servers after a failure smoothly using the slow_start option of the server directive.</li> <li>Limiting the MP4 file transfer rate proportionally to its bitrate, thus reducing the bandwidth load.</li> <li>Extending authorization and balancing capabilities for the MQTT protocol with the mqtt_preread directive under stream.</li> <li>Pre-built binary packages for many popular third-party modules.</li> <li>Server- and client-side support for NTLS when using the TongSuo TLS library, enabled at build time.</li> </ul>"},{"location":"branches/","title":"NGINX Branches","text":"<p>NGINX is delivered by its creators in two distinct branches: stable and mainline.</p> <p>We support both. The default is stable. Both branches are actually stable, but represent different NGINX feature sets and compatibility levels.</p> <p>Which one is best for you? It depends.</p>"},{"location":"branches/#the-stable-nginx-branch","title":"The stable NGINX branch","text":"<p>When you set up GetPageSpeed repository on your system, you are able to install stable NGINX packages, by default.</p> <p>The stable branch has less moving parts, and NGINX itself is rarely updated on it. However, since it is not receiving frequent feature updates, it means there is less chances new bugs are introduced to it.</p>"},{"location":"branches/#the-mainline-nginx-branch","title":"The mainline NGINX branch","text":"<p>The mainline branch has frequent updates, and so you can expect more package updates, as the newer versions are released.</p> <p>While it does fix any issues found in the stable branch, it has the potential of bringing more issues via new features' code.</p> <p>The mainline NGINX has a higher chance of bringing backwards incompatible changes.</p>"},{"location":"branches/#recommendation","title":"Recommendation","text":"<p>Stick to the stable branch, unless you are very eager to try out a new feature, fix a severe security bug, and/or have the time to deal with potential (although rare) backwards incompatible changes.</p>"},{"location":"branches/#still-want-to-go-with-the-mainline","title":"Still want to go with the mainline?","text":"<p>You can install mainline NGINX module packages easily by enabling the <code>mainline</code> sub-repository:</p> <p>Enable the mainline repository</p> CentOS/RHEL/Rocky Linux/AlmaLinux 8+, Fedora Linux, Amazon Linux 2023+CentOS 7 or Amazon Linux 2 <pre><code>dnf -y install dnf-plugins-core\ndnf config-manager --enable getpagespeed-extras-mainline\n</code></pre> <pre><code>yum -y --disablerepo getpagespeed-extras install yum-utils\nyum-config-manager --enable getpagespeed-extras-mainline\n</code></pre> <p>Then <code>dnf upgrade</code> to ensure all the NGINX modules currently installed are switched to their mainline equivalent.</p> <p>Then install additional modules as usual, e.g.:</p> <pre><code>dnf -y install nginx-module-security\n</code></pre>"},{"location":"branches/#changed-your-mind-and-want-to-go-with-stable","title":"Changed your mind and want to go with stable?","text":"<p>For reasons mentioned above, you may want to downgrade to the stable branch:</p> <p>Disable the mainline repository</p> CentOS/RHEL/Rocky Linux/AlmaLinux 8+, Fedora Linux, Amazon Linux 2023+CentOS 7 or Amazon Linux 2 <pre><code>dnf -y install dnf-plugins-core\ndnf config-manager --disable getpagespeed-extras-mainline\ndnf -y downgrade \"nginx*\"\n</code></pre> <pre><code>yum-config-manager --disable getpagespeed-extras-mainline\nyum -y downgrade \"nginx*\"\n</code></pre>"},{"location":"integrity/","title":"Packages Integrity","text":"<p>Your package manager can verify packages before installation. To set this up, install our GPG key.</p>"},{"location":"integrity/#set-up-the-gpg-key-for-centosrhel-9-and-above","title":"Set up the GPG key for CentOS/RHEL 9 and above","text":"<pre><code>rpm --import https://extras.getpagespeed.com/RPM-GPG-KEY-GETPAGESPEED-2023\n</code></pre>"},{"location":"integrity/#set-up-the-gpg-key-for-other-distros","title":"Set up the GPG key for other distros","text":"<pre><code>rpm --import https://extras.getpagespeed.com/RPM-GPG-KEY-GETPAGESPEED\n</code></pre>"},{"location":"lua-scripting/","title":"Lua Scripting","text":"<p>NGINX can be empowered with the scripting power of the Lua language. You don't need to use Openresty for that. With our extensive collection of Lua library packages, you have something even better and in one place.</p> <p>GetPageSpeed = NGINX Plus + OpenResty + Lua libraries</p> <p>GetPageSpeed provides both Lua NGINX modules and Lua libraries to extend NGINX with Lua scripting capabilities.</p> <p>Simply install nginx-module-lua to extend NGINX with Lua scripting capability. And 100 (!) Lua libraries are available with separate easy-to-install packages.</p> <p>See the whole list below:</p> <p>title: \"NGINX Lua scripting by GetPageSpeed\" </p> <p>description: \"GetPageSpeed provides huge collection of Lua Resty package to empower your OpenResty-based setup.\"</p>"},{"location":"lua-scripting/#lua","title":"Lua","text":"<p>NGINX Lua Module is a high-level Lua API for Nginx. It allows scripting Nginx without touching the C code.</p> <p>NGINX Extras by GetPageSpeed = NGINX Plus + OpenResty + Lua libraries</p> <p>GetPageSpeed provides both Lua NGINX modules and Lua libraries to extend NGINX with Lua scripting capabilities.</p> <p>Multiple Lua library packages are made available by GetPageSpeed to build ultimate Nginx configurations, powered by Lua.</p> Package Name Description lua-resty-acme Automatic Let's Encrypt certificate serving and Lua implementation of ACMEv2 procotol lua-resty-ada LuaJIT FFI bindings to Ada \u2014 WHATWG-compliant and fast URL parser lua-resty-auto-ssl On the fly (and free) SSL registration and renewal inside nginx-module-lua/nginx with Let's Encrypt lua-resty-aws-auth Lua resty module to calculate AWS signature v4 authorization header lua-resty-aws-sdk Make api call to aws services lua-resty-balancer A generic consistent hash implementation for nginx-module-lua lua-resty-base-encoding A faster alternative to base64 encoding and provides missing base encoding for nginx-module-lua application lua-resty-cache Http cache to redis, can server stale response, and using \"lua-resty-lock\" only allow one request to populate a new cache lua-resty-checkups Manage NGINX upstreams in pure Lua lua-resty-consul-event Consul Events HTTP API Wrapper lua-resty-consul Library to interface with the consul HTTP API from nginx-module-lua lua-resty-core New FFI-based API for lua-nginx-module lua-resty-cors It's the implement of CORS on nginx-module-lua lua-resty-counter Lock-free counter for nginx-module-lua lua-resty-ctxdump Stash and apply the old ngx.ctx for avoiding being destoried after NGINX internal redirect happens lua-resty-dns-server Lua DNS server driver for nginx-module-lua lua-resty-dns DNS resolver for nginx-module-lua lua-resty-etcd Nonblocking Lua etcd driver library for nginx-module-lua lua-resty-exec Run external programs in nginx-module-lua without spawning a shell or blocking lua-resty-feishu-auth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-fileinfo LuaJIT FFI bindings to libmagic, magic number recognition library - tries to determine file types lua-resty-ftpclient Lua ftp client driver for nginx-module-lua based on the cosocket API lua-resty-global-throttle General purpose flow control with shared storage support lua-resty-healthcheck Healthcheck library for nginx-module-lua to validate upstream service status lua-resty-hmac HMAC functions for nginx-module-lua and LuaJIT lua-resty-hoedown LuaJIT FFI bindings to Hoedown, a standards compliant, fast, secure markdown processing library in C lua-resty-http2 The HTTP/2 Protocol (Client Side) Implementation for nginx-module-lua lua-resty-http Lua HTTP client cosocket driver for nginx-module-lua lua-resty-httpipe Lua HTTP client cosocket driver for nginx-module-lua, interfaces are more flexible lua-resty-hyperscan Hyperscan for nginx-module-lua lua-resty-influx Nginx-module-lua client for InfluxDB lua-resty-ini Ini parser for nginx-module-lua lua-resty-injection LuaJIT FFI bindings to libinjection (https://github.com/client9/libinjection) lua-resty-iputils Utility functions for working with IP addresses in nginx-module-lua lua-resty-jit-uuid Fast and dependency-free UUID library for LuaJIT/nginx-module-lua lua-resty-jq LuaJIT FFI bindings to jq lua-resty-jsonrpc-batch JSONRPC batch protocol module for nginx-module-lua lua-resty-jump-consistent-hash Consistent hash for nginx-module-lua lua-resty-jwt-verification JWT verification library for nginx-module-lua with JWKS integration lua-resty-jwt JWT For The Great nginx-module-lua lua-resty-kafka Lua kafka client driver for nginx-module-lua based on the cosocket API lua-resty-libcjson LuaJIT FFI-based cJSON library for nginx-module-lua lua-resty-libr3 High-performance path dispatching library base on libr3 for nginx-module-lua lua-resty-limit-rate Lua module for limiting request rate for nginx-module-lua, using the \"token bucket\" method lua-resty-limit-traffic Lua library for limiting and controlling traffic in nginx-module-lua lua-resty-lmdb Safe API for manipulating LMDB databases using nginx-module-lua lua-resty-locations Lua library implementing nginx style location uri matching lua-resty-lock Simple nonblocking lock API for nginx-module-lua based on shared memory dictionaries lua-resty-logger-socket Raw-socket-based Logger Library for NGINX (based on nginx-module-lua) lua-resty-lrucache Lua-land LRU Cache based on LuaJIT FFI lua-resty-macaroons LuaJIT FFI Bindings to libmacaroons \u2013 Macaroons are flexible authorization credentials that support decentralized delegation, attenuation, and verification lua-resty-mail A high-level, easy to use, and non-blocking email and SMTP library for nginx-module-lua lua-resty-maxminddb A Lua library for reading MaxMind's Geolocation database lua-resty-memcached Lua memcached client driver for nginx-module-lua based on the cosocket API lua-resty-mlcache Layered caching library for nginx-module-lua lua-resty-multiplexer Transparent port service multiplexer for stream subsystem lua-resty-murmurhash2 LuaJIT MurmurHash 2 bindings to NGINX / nginx-module-lua murmurhash2 implementation lua-resty-mysql Nonblocking Lua MySQL driver library for nginx-module-lua lua-resty-nettle LuaJIT FFI bindings for Nettle (a low-level cryptographic library) lua-resty-nsq Lua nsq client driver for nginx-module-lua based on the cosocket API lua-resty-ntlm Nginx ntlm module implemented by lua lua-resty-openidc OpenID Connect Relying Party and OAuth 2.0 Resource Server implementation in Lua for NGINX / nginx-module-lua lua-resty-openssl FFI-based OpenSSL binding for nginx-module-lua lua-resty-perf A small ngx resty lua library to benchmark memory and throughput of a function lua-resty-prettycjson Lua cJSON Pretty Formatter lua-resty-pubsub Lua Pubsub client driver for nginx-module-lua based on the cosocket API lua-resty-qless-web Port of Qless' web interface to nginx-module-lua environment lua-resty-qless Lua binding to Qless (Queue / Pipeline management) for nginx-module-lua / Redis lua-resty-rabbitmqstomp Opinionated Lua RabbitMQ client library for nginx-module-lua apps based on the cosocket API lua-resty-rack A simple and extensible HTTP server framework for nginx-module-lua lua-resty-radixtree Adaptive Radix Trees implemented in Lua / LuaJIT lua-resty-redis-connector Connection utilities for lua-resty-redis lua-resty-redis-ratelimit Limit the request processing rate between multiple NGINX instances backed by Redis lua-resty-redis-util Nginx-module-lua-resty-redis \u5c01\u88c5\u5de5\u5177\u7c7b lua-resty-redis Lua redis client driver for nginx-module-lua based on the cosocket API lua-resty-repl Interactive console (REPL) for nginx-module-lua and luajit code lua-resty-reqargs Read application/x-www-form-urlencoded, multipart/form-data, and application/json request args lua-resty-requests Yet Another HTTP library for nginx-module-lua - For human beings! lua-resty-riak Lua riak protocol buffer client driver for nginx-module-lua based on the cosocket API lua-resty-router Lua http router for nginx-module-lua lua-resty-rsa RSA encrypt/decrypt &amp; sign/verify for nginx-module-luaJIT lua-resty-scrypt LuaJIT FFI-based scrypt library for nginx-module-lua lua-resty-session Session library for nginx-module-lua \u2013 flexible and secure lua-resty-shell Lua module for nonblocking system shell command executions lua-resty-signal Lua library for killing or sending signals to UNIX processes lua-resty-smtp Send mail with NGINX lua-resty-snappy LuaJIT FFI bindings for Snappy, a fast compressor/decompressor (https://code.google.com/p/snappy/) lua-resty-sniproxy SNI Proxy based on stream-lua-nginx-module lua-resty-socket Automatic LuaSocket/cosockets compatibility module lua-resty-stats Is a statistical module for nginx base on nginx-module-lua, Statistical key and values are configurable, can use the nginx core's variables and this module's variables. The statistical result store in mongodb lua-resty-string String utilities and common hash functions for nginx-module-lua and LuaJIT lua-resty-t1k Lua implementation of the T1K protocol for Chaitin/SafeLine WAF lua-resty-tags A small DSL for building HTML documents lua-resty-tarantool Library for working with tarantool from nginx with the embedded Lua module or with nginx-module-lua lua-resty-template Templating Engine (HTML) for Lua and nginx-module-lua lua-resty-test Lua test frame for nginx-module-lua based on nginx-module-lua lua-resty-timer Extended timers for nginx-module-lua lua-resty-tlc General two level cache (lrucache + shared dict) lua-resty-tsort Performs a topological sort on input data lua-resty-txid Generate sortable, unique transaction or request IDs for nginx-module-lua/nginx lua-resty-upload Streaming reader and parser for http file uploading based on nginx-module-lua cosocket lua-resty-upstream-healthcheck Health Checker for NGINX Upstream Servers in Pure Lua lua-resty-upstream Upstream connection load balancing and failover module for nginx-module-lua lua-resty-uuid LuaJIT FFI bindings for libuuid, a DCE compatible Universally Unique Identifier library lua-resty-validation Validation Library (Input Validation and Filtering) for Lua and nginx-module-lua lua-resty-vhost Hostname matching library for nginx-module-lua lua-resty-waf High-performance WAF built on nginx-module-lua stack lua-resty-weauth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-websocket-proxy Reverse-proxying of websocket frames lua-resty-websocket WebSocket support for nginx-module-lua module lua-resty-woothee Woothee Lua-nginx-module-lua implementation lua-resty-worker-events Cross Worker Events for NGINX in Pure Lua lua-resty-xxhash LuaJIT FFI-bindings to xxHash, an Extremely fast non-cryptographic hash algorithm"},{"location":"lua/","title":"Lua","text":"<p>NGINX Lua Module is a high-level Lua API for Nginx. It allows scripting Nginx without touching the C code.</p> <p>NGINX Extras by GetPageSpeed = NGINX Plus + OpenResty + Lua libraries</p> <p>GetPageSpeed provides both Lua NGINX modules and Lua libraries to extend NGINX with Lua scripting capabilities.</p> <p>Multiple Lua library packages are made available by GetPageSpeed to build ultimate Nginx configurations, powered by Lua.</p> Package Name Description lua-resty-acme Automatic Let's Encrypt certificate serving and Lua implementation of ACMEv2 procotol lua-resty-ada LuaJIT FFI bindings to Ada \u2014 WHATWG-compliant and fast URL parser lua-resty-auto-ssl On the fly (and free) SSL registration and renewal inside nginx-module-lua/nginx with Let's Encrypt lua-resty-aws-auth Lua resty module to calculate AWS signature v4 authorization header lua-resty-aws-sdk Make api call to aws services lua-resty-balancer A generic consistent hash implementation for nginx-module-lua lua-resty-base-encoding A faster alternative to base64 encoding and provides missing base encoding for nginx-module-lua application lua-resty-cache Http cache to redis, can server stale response, and using \"lua-resty-lock\" only allow one request to populate a new cache lua-resty-checkups Manage NGINX upstreams in pure Lua lua-resty-consul-event Consul Events HTTP API Wrapper lua-resty-consul Library to interface with the consul HTTP API from nginx-module-lua lua-resty-core New FFI-based API for lua-nginx-module lua-resty-cors It's the implement of CORS on nginx-module-lua lua-resty-counter Lock-free counter for nginx-module-lua lua-resty-ctxdump Stash and apply the old ngx.ctx for avoiding being destoried after NGINX internal redirect happens lua-resty-dns-server Lua DNS server driver for nginx-module-lua lua-resty-dns DNS resolver for nginx-module-lua lua-resty-etcd Nonblocking Lua etcd driver library for nginx-module-lua lua-resty-exec Run external programs in nginx-module-lua without spawning a shell or blocking lua-resty-feishu-auth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-fileinfo LuaJIT FFI bindings to libmagic, magic number recognition library - tries to determine file types lua-resty-ftpclient Lua ftp client driver for nginx-module-lua based on the cosocket API lua-resty-global-throttle General purpose flow control with shared storage support lua-resty-healthcheck Healthcheck library for nginx-module-lua to validate upstream service status lua-resty-hmac HMAC functions for nginx-module-lua and LuaJIT lua-resty-hoedown LuaJIT FFI bindings to Hoedown, a standards compliant, fast, secure markdown processing library in C lua-resty-http2 The HTTP/2 Protocol (Client Side) Implementation for nginx-module-lua lua-resty-http Lua HTTP client cosocket driver for nginx-module-lua lua-resty-httpipe Lua HTTP client cosocket driver for nginx-module-lua, interfaces are more flexible lua-resty-hyperscan Hyperscan for nginx-module-lua lua-resty-influx Nginx-module-lua client for InfluxDB lua-resty-ini Ini parser for nginx-module-lua lua-resty-injection LuaJIT FFI bindings to libinjection (https://github.com/client9/libinjection) lua-resty-iputils Utility functions for working with IP addresses in nginx-module-lua lua-resty-jit-uuid Fast and dependency-free UUID library for LuaJIT/nginx-module-lua lua-resty-jq LuaJIT FFI bindings to jq lua-resty-jsonrpc-batch JSONRPC batch protocol module for nginx-module-lua lua-resty-jump-consistent-hash Consistent hash for nginx-module-lua lua-resty-jwt-verification JWT verification library for nginx-module-lua with JWKS integration lua-resty-jwt JWT For The Great nginx-module-lua lua-resty-kafka Lua kafka client driver for nginx-module-lua based on the cosocket API lua-resty-libcjson LuaJIT FFI-based cJSON library for nginx-module-lua lua-resty-libr3 High-performance path dispatching library base on libr3 for nginx-module-lua lua-resty-limit-rate Lua module for limiting request rate for nginx-module-lua, using the \"token bucket\" method lua-resty-limit-traffic Lua library for limiting and controlling traffic in nginx-module-lua lua-resty-lmdb Safe API for manipulating LMDB databases using nginx-module-lua lua-resty-locations Lua library implementing nginx style location uri matching lua-resty-lock Simple nonblocking lock API for nginx-module-lua based on shared memory dictionaries lua-resty-logger-socket Raw-socket-based Logger Library for NGINX (based on nginx-module-lua) lua-resty-lrucache Lua-land LRU Cache based on LuaJIT FFI lua-resty-macaroons LuaJIT FFI Bindings to libmacaroons \u2013 Macaroons are flexible authorization credentials that support decentralized delegation, attenuation, and verification lua-resty-mail A high-level, easy to use, and non-blocking email and SMTP library for nginx-module-lua lua-resty-maxminddb A Lua library for reading MaxMind's Geolocation database lua-resty-memcached Lua memcached client driver for nginx-module-lua based on the cosocket API lua-resty-mlcache Layered caching library for nginx-module-lua lua-resty-multiplexer Transparent port service multiplexer for stream subsystem lua-resty-murmurhash2 LuaJIT MurmurHash 2 bindings to NGINX / nginx-module-lua murmurhash2 implementation lua-resty-mysql Nonblocking Lua MySQL driver library for nginx-module-lua lua-resty-nettle LuaJIT FFI bindings for Nettle (a low-level cryptographic library) lua-resty-nsq Lua nsq client driver for nginx-module-lua based on the cosocket API lua-resty-ntlm Nginx ntlm module implemented by lua lua-resty-openidc OpenID Connect Relying Party and OAuth 2.0 Resource Server implementation in Lua for NGINX / nginx-module-lua lua-resty-openssl FFI-based OpenSSL binding for nginx-module-lua lua-resty-perf A small ngx resty lua library to benchmark memory and throughput of a function lua-resty-prettycjson Lua cJSON Pretty Formatter lua-resty-pubsub Lua Pubsub client driver for nginx-module-lua based on the cosocket API lua-resty-qless-web Port of Qless' web interface to nginx-module-lua environment lua-resty-qless Lua binding to Qless (Queue / Pipeline management) for nginx-module-lua / Redis lua-resty-rabbitmqstomp Opinionated Lua RabbitMQ client library for nginx-module-lua apps based on the cosocket API lua-resty-rack A simple and extensible HTTP server framework for nginx-module-lua lua-resty-radixtree Adaptive Radix Trees implemented in Lua / LuaJIT lua-resty-redis-connector Connection utilities for lua-resty-redis lua-resty-redis-ratelimit Limit the request processing rate between multiple NGINX instances backed by Redis lua-resty-redis-util Nginx-module-lua-resty-redis \u5c01\u88c5\u5de5\u5177\u7c7b lua-resty-redis Lua redis client driver for nginx-module-lua based on the cosocket API lua-resty-repl Interactive console (REPL) for nginx-module-lua and luajit code lua-resty-reqargs Read application/x-www-form-urlencoded, multipart/form-data, and application/json request args lua-resty-requests Yet Another HTTP library for nginx-module-lua - For human beings! lua-resty-riak Lua riak protocol buffer client driver for nginx-module-lua based on the cosocket API lua-resty-router Lua http router for nginx-module-lua lua-resty-rsa RSA encrypt/decrypt &amp; sign/verify for nginx-module-luaJIT lua-resty-scrypt LuaJIT FFI-based scrypt library for nginx-module-lua lua-resty-session Session library for nginx-module-lua \u2013 flexible and secure lua-resty-shell Lua module for nonblocking system shell command executions lua-resty-signal Lua library for killing or sending signals to UNIX processes lua-resty-smtp Send mail with NGINX lua-resty-snappy LuaJIT FFI bindings for Snappy, a fast compressor/decompressor (https://code.google.com/p/snappy/) lua-resty-sniproxy SNI Proxy based on stream-lua-nginx-module lua-resty-socket Automatic LuaSocket/cosockets compatibility module lua-resty-stats Is a statistical module for nginx base on nginx-module-lua, Statistical key and values are configurable, can use the nginx core's variables and this module's variables. The statistical result store in mongodb lua-resty-string String utilities and common hash functions for nginx-module-lua and LuaJIT lua-resty-t1k Lua implementation of the T1K protocol for Chaitin/SafeLine WAF lua-resty-tags A small DSL for building HTML documents lua-resty-tarantool Library for working with tarantool from nginx with the embedded Lua module or with nginx-module-lua lua-resty-template Templating Engine (HTML) for Lua and nginx-module-lua lua-resty-test Lua test frame for nginx-module-lua based on nginx-module-lua lua-resty-timer Extended timers for nginx-module-lua lua-resty-tlc General two level cache (lrucache + shared dict) lua-resty-tsort Performs a topological sort on input data lua-resty-txid Generate sortable, unique transaction or request IDs for nginx-module-lua/nginx lua-resty-upload Streaming reader and parser for http file uploading based on nginx-module-lua cosocket lua-resty-upstream-healthcheck Health Checker for NGINX Upstream Servers in Pure Lua lua-resty-upstream Upstream connection load balancing and failover module for nginx-module-lua lua-resty-uuid LuaJIT FFI bindings for libuuid, a DCE compatible Universally Unique Identifier library lua-resty-validation Validation Library (Input Validation and Filtering) for Lua and nginx-module-lua lua-resty-vhost Hostname matching library for nginx-module-lua lua-resty-waf High-performance WAF built on nginx-module-lua stack lua-resty-weauth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-websocket-proxy Reverse-proxying of websocket frames lua-resty-websocket WebSocket support for nginx-module-lua module lua-resty-woothee Woothee Lua-nginx-module-lua implementation lua-resty-worker-events Cross Worker Events for NGINX in Pure Lua lua-resty-xxhash LuaJIT FFI-bindings to xxHash, an Extremely fast non-cryptographic hash algorithm"},{"location":"lua_list/","title":"Lua list","text":"Package Name Description lua-resty-acme Automatic Let's Encrypt certificate serving and Lua implementation of ACMEv2 procotol lua-resty-ada LuaJIT FFI bindings to Ada \u2014 WHATWG-compliant and fast URL parser lua-resty-auto-ssl On the fly (and free) SSL registration and renewal inside nginx-module-lua/nginx with Let's Encrypt lua-resty-aws-auth Lua resty module to calculate AWS signature v4 authorization header lua-resty-aws-sdk Make api call to aws services lua-resty-balancer A generic consistent hash implementation for nginx-module-lua lua-resty-base-encoding A faster alternative to base64 encoding and provides missing base encoding for nginx-module-lua application lua-resty-cache Http cache to redis, can server stale response, and using \"lua-resty-lock\" only allow one request to populate a new cache lua-resty-checkups Manage NGINX upstreams in pure Lua lua-resty-consul-event Consul Events HTTP API Wrapper lua-resty-consul Library to interface with the consul HTTP API from nginx-module-lua lua-resty-core New FFI-based API for lua-nginx-module lua-resty-cors It's the implement of CORS on nginx-module-lua lua-resty-counter Lock-free counter for nginx-module-lua lua-resty-ctxdump Stash and apply the old ngx.ctx for avoiding being destoried after NGINX internal redirect happens lua-resty-dns-server Lua DNS server driver for nginx-module-lua lua-resty-dns DNS resolver for nginx-module-lua lua-resty-etcd Nonblocking Lua etcd driver library for nginx-module-lua lua-resty-exec Run external programs in nginx-module-lua without spawning a shell or blocking lua-resty-feishu-auth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-fileinfo LuaJIT FFI bindings to libmagic, magic number recognition library - tries to determine file types lua-resty-ftpclient Lua ftp client driver for nginx-module-lua based on the cosocket API lua-resty-global-throttle General purpose flow control with shared storage support lua-resty-healthcheck Healthcheck library for nginx-module-lua to validate upstream service status lua-resty-hmac HMAC functions for nginx-module-lua and LuaJIT lua-resty-hoedown LuaJIT FFI bindings to Hoedown, a standards compliant, fast, secure markdown processing library in C lua-resty-http2 The HTTP/2 Protocol (Client Side) Implementation for nginx-module-lua lua-resty-http Lua HTTP client cosocket driver for nginx-module-lua lua-resty-httpipe Lua HTTP client cosocket driver for nginx-module-lua, interfaces are more flexible lua-resty-hyperscan Hyperscan for nginx-module-lua lua-resty-influx Nginx-module-lua client for InfluxDB lua-resty-ini Ini parser for nginx-module-lua lua-resty-injection LuaJIT FFI bindings to libinjection (https://github.com/client9/libinjection) lua-resty-iputils Utility functions for working with IP addresses in nginx-module-lua lua-resty-jit-uuid Fast and dependency-free UUID library for LuaJIT/nginx-module-lua lua-resty-jq LuaJIT FFI bindings to jq lua-resty-jsonrpc-batch JSONRPC batch protocol module for nginx-module-lua lua-resty-jump-consistent-hash Consistent hash for nginx-module-lua lua-resty-jwt-verification JWT verification library for nginx-module-lua with JWKS integration lua-resty-jwt JWT For The Great nginx-module-lua lua-resty-kafka Lua kafka client driver for nginx-module-lua based on the cosocket API lua-resty-libcjson LuaJIT FFI-based cJSON library for nginx-module-lua lua-resty-libr3 High-performance path dispatching library base on libr3 for nginx-module-lua lua-resty-limit-rate Lua module for limiting request rate for nginx-module-lua, using the \"token bucket\" method lua-resty-limit-traffic Lua library for limiting and controlling traffic in nginx-module-lua lua-resty-lmdb Safe API for manipulating LMDB databases using nginx-module-lua lua-resty-locations Lua library implementing nginx style location uri matching lua-resty-lock Simple nonblocking lock API for nginx-module-lua based on shared memory dictionaries lua-resty-logger-socket Raw-socket-based Logger Library for NGINX (based on nginx-module-lua) lua-resty-lrucache Lua-land LRU Cache based on LuaJIT FFI lua-resty-macaroons LuaJIT FFI Bindings to libmacaroons \u2013 Macaroons are flexible authorization credentials that support decentralized delegation, attenuation, and verification lua-resty-mail A high-level, easy to use, and non-blocking email and SMTP library for nginx-module-lua lua-resty-maxminddb A Lua library for reading MaxMind's Geolocation database lua-resty-memcached Lua memcached client driver for nginx-module-lua based on the cosocket API lua-resty-mlcache Layered caching library for nginx-module-lua lua-resty-multiplexer Transparent port service multiplexer for stream subsystem lua-resty-murmurhash2 LuaJIT MurmurHash 2 bindings to NGINX / nginx-module-lua murmurhash2 implementation lua-resty-mysql Nonblocking Lua MySQL driver library for nginx-module-lua lua-resty-nettle LuaJIT FFI bindings for Nettle (a low-level cryptographic library) lua-resty-nsq Lua nsq client driver for nginx-module-lua based on the cosocket API lua-resty-ntlm Nginx ntlm module implemented by lua lua-resty-openidc OpenID Connect Relying Party and OAuth 2.0 Resource Server implementation in Lua for NGINX / nginx-module-lua lua-resty-openssl FFI-based OpenSSL binding for nginx-module-lua lua-resty-perf A small ngx resty lua library to benchmark memory and throughput of a function lua-resty-prettycjson Lua cJSON Pretty Formatter lua-resty-pubsub Lua Pubsub client driver for nginx-module-lua based on the cosocket API lua-resty-qless-web Port of Qless' web interface to nginx-module-lua environment lua-resty-qless Lua binding to Qless (Queue / Pipeline management) for nginx-module-lua / Redis lua-resty-rabbitmqstomp Opinionated Lua RabbitMQ client library for nginx-module-lua apps based on the cosocket API lua-resty-rack A simple and extensible HTTP server framework for nginx-module-lua lua-resty-radixtree Adaptive Radix Trees implemented in Lua / LuaJIT lua-resty-redis-connector Connection utilities for lua-resty-redis lua-resty-redis-ratelimit Limit the request processing rate between multiple NGINX instances backed by Redis lua-resty-redis-util Nginx-module-lua-resty-redis \u5c01\u88c5\u5de5\u5177\u7c7b lua-resty-redis Lua redis client driver for nginx-module-lua based on the cosocket API lua-resty-repl Interactive console (REPL) for nginx-module-lua and luajit code lua-resty-reqargs Read application/x-www-form-urlencoded, multipart/form-data, and application/json request args lua-resty-requests Yet Another HTTP library for nginx-module-lua - For human beings! lua-resty-riak Lua riak protocol buffer client driver for nginx-module-lua based on the cosocket API lua-resty-router Lua http router for nginx-module-lua lua-resty-rsa RSA encrypt/decrypt &amp; sign/verify for nginx-module-luaJIT lua-resty-scrypt LuaJIT FFI-based scrypt library for nginx-module-lua lua-resty-session Session library for nginx-module-lua \u2013 flexible and secure lua-resty-shell Lua module for nonblocking system shell command executions lua-resty-signal Lua library for killing or sending signals to UNIX processes lua-resty-smtp Send mail with NGINX lua-resty-snappy LuaJIT FFI bindings for Snappy, a fast compressor/decompressor (https://code.google.com/p/snappy/) lua-resty-sniproxy SNI Proxy based on stream-lua-nginx-module lua-resty-socket Automatic LuaSocket/cosockets compatibility module lua-resty-stats Is a statistical module for nginx base on nginx-module-lua, Statistical key and values are configurable, can use the nginx core's variables and this module's variables. The statistical result store in mongodb lua-resty-string String utilities and common hash functions for nginx-module-lua and LuaJIT lua-resty-t1k Lua implementation of the T1K protocol for Chaitin/SafeLine WAF lua-resty-tags A small DSL for building HTML documents lua-resty-tarantool Library for working with tarantool from nginx with the embedded Lua module or with nginx-module-lua lua-resty-template Templating Engine (HTML) for Lua and nginx-module-lua lua-resty-test Lua test frame for nginx-module-lua based on nginx-module-lua lua-resty-timer Extended timers for nginx-module-lua lua-resty-tlc General two level cache (lrucache + shared dict) lua-resty-tsort Performs a topological sort on input data lua-resty-txid Generate sortable, unique transaction or request IDs for nginx-module-lua/nginx lua-resty-upload Streaming reader and parser for http file uploading based on nginx-module-lua cosocket lua-resty-upstream-healthcheck Health Checker for NGINX Upstream Servers in Pure Lua lua-resty-upstream Upstream connection load balancing and failover module for nginx-module-lua lua-resty-uuid LuaJIT FFI bindings for libuuid, a DCE compatible Universally Unique Identifier library lua-resty-validation Validation Library (Input Validation and Filtering) for Lua and nginx-module-lua lua-resty-vhost Hostname matching library for nginx-module-lua lua-resty-waf High-performance WAF built on nginx-module-lua stack lua-resty-weauth \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1 lua-resty-websocket-proxy Reverse-proxying of websocket frames lua-resty-websocket WebSocket support for nginx-module-lua module lua-resty-woothee Woothee Lua-nginx-module-lua implementation lua-resty-worker-events Cross Worker Events for NGINX in Pure Lua lua-resty-xxhash LuaJIT FFI-bindings to xxHash, an Extremely fast non-cryptographic hash algorithm"},{"location":"modules/","title":"Modules","text":"<p>NGINX has superpowers and it has super strength. They are dynamic NGINX modules. GetPageSpeed makes them available for you in the form of easy-to-install packages.</p> Package Name Description nginx-module-accept-language NGINX Accept-Language module nginx-module-acme Automatic certificate management (ACMEv2) module for NGINX nginx-module-ajp Support AJP protocol proxy with NGINX nginx-module-array-var Array-typed variables for NGINX nginx-module-auth-digest Digest Authentication for NGINX nginx-module-auth-ldap LDAP Authentication module for NGINX nginx-module-auth-pam PAM authentication dynamic module for NGINX nginx-module-auth-totp Time-based one-time password (TOTP) authentication for NGINX nginx-module-aws-auth NGINX module to proxy to authenticated AWS services nginx-module-bot-verifier A search index bot verification module for NGINX nginx-module-brotli NGINX Brotli dynamic modules nginx-module-cache-purge NGINX Cache Purge module nginx-module-captcha NGINX Captcha Module nginx-module-cgi CGI support for NGINX nginx-module-combined-upstreams NGINX Combined Upstreams module nginx-module-concat HTTP Concatenation module for NGINX nginx-module-cookie-flag NGINX cookie flag module nginx-module-cookie-limit NGINX module to limit the number of malicious ip forged cookies nginx-module-coolkit NGINX CoolKit Module nginx-module-dav-ext NGINX WebDAV PROPFIND,OPTIONS,LOCK,UNLOCK support nginx-module-doh NGINX module for serving DNS-over-HTTPS (DOH) requests nginx-module-dynamic-etag NGINX module for adding ETag to dynamic content nginx-module-dynamic-limit-req NGINX module to dynamically lock IP and release it periodically nginx-module-echo nginx Echo module nginx-module-encrypted-session Encrypt and decrypt NGINX variable values nginx-module-execute NGINX Execute module nginx-module-f4fhds NGINX module for Adobe f4f format nginx-module-fancyindex NGINX Fancy Index module nginx-module-flv Media streaming server based on nginx-module-rtmp nginx-module-form-input NGINX form input module nginx-module-geoip2 NGINX GeoIP2 module nginx-module-geoip NGINX GeoIP dynamic modules nginx-module-google NGINX Module for Google Mirror creation nginx-module-graphite An NGINX module for collecting stats into Graphite nginx-module-headers-more NGINX Headers More dynamic module nginx-module-hmac-secure-link Alternative NGINX HMAC Secure Link module with support for OpenSSL hashes nginx-module-html-sanitize NGINX module to sanitize HTML 5 with whitelisted elements, attributes and CSS nginx-module-iconv NGINX iconv module nginx-module-image-filter NGINX image filter dynamic module nginx-module-immutable NGINX module for setting immutable caching on static assets nginx-module-ipscrub IP address anonymizer module for NGINX nginx-module-ipset-access NGINX ipset access module nginx-module-jpeg NGINX JPEG filter module nginx-module-js-challenge NGINX Javascript challenge module nginx-module-json-var NGINX JSON variables module nginx-module-json NGINX JSON module nginx-module-jwt NGINX JWT Module nginx-module-keyval Nginx module for the key-value store nginx-module-length-hiding NGINX Length Hiding Filter Module nginx-module-let NGINX let module nginx-module-limit-traffic-rate NGINX Limiting rate by given variables nginx-module-live-common Kaltura Media Framework Common NGINX Module nginx-module-log-sqlite SQLite logger module for NGINX nginx-module-log-zmq ZeroMQ logger module for NGINX nginx-module-lua Lua scripting support for NGINX nginx-module-markdown Markdown-to-html NGINX module nginx-module-memc Extended version of the standard NGINX memcached module nginx-module-naxsi NGINX Anti XSS &amp; SQL Injection module nginx-module-nchan Scalable, flexible pub/sub server for the modern web nginx-module-ndk Nginx Development Kit nginx-module-njs NGINX njs dynamic modules nginx-module-ntlm NTLM NGINX Module nginx-module-otel NGINX OpenTelemetry dynamic module nginx-module-pagespeed PageSpeed dynamic module for NGINX nginx-module-passenger Passenger module nginx-module-perl NGINX Perl dynamic module nginx-module-phantom-token Phantom Token NGINX Module nginx-module-pipelog NGINX pipelog module nginx-module-postgres PostgreSQL module for NGINX nginx-module-proxy-connect CONNECT method support in NGINX nginx-module-pta Period of Time Authentication module for NGINX nginx-module-push-stream NGINX push stream module nginx-module-rdns NGINX HTTP rDNS module nginx-module-redis-rate-limit Redis backed rate limit module for Nginx nginx-module-redis2 NGINX upstream module for the Redis 2.0 protocol nginx-module-rtmp NGINX RTMP module nginx-module-secure-token Secure token module for NGINX nginx-module-security-headers NGINX module for sending security headers nginx-module-security ModSecurity v3 Nginx Connector nginx-module-set-misc NGINX Set-Misc module nginx-module-shibboleth Shibboleth Auth Request module for NGINX nginx-module-slowfs NGINX SlowFS Cache Module nginx-module-small-light Dynamic image transformation module For NGINX nginx-module-spnego-http-auth Nginx module for HTTP SPNEGO auth nginx-module-srcache Transparent subrequest-based caching layout for arbitrary NGINX locations nginx-module-srt Nginx SRT Module nginx-module-statsd NGINX module for sending stats to statsd nginx-module-sticky NGINX sticky cookie module nginx-module-stream-lua Lua scripting support for NGINX streams nginx-module-stream-sts Nginx stream server traffic status core module nginx-module-stream-upsync NGINX module for syncing stream backends from consul or etcd nginx-module-sts Nginx stream server traffic status module nginx-module-substitutions String substitutions module for nginx nginx-module-sxg Signed HTTP Exchange(SXG) support for NGINX nginx-module-sysguard NGINX sysguard module nginx-module-testcookie NGINX testcookie robot mitigation module nginx-module-traffic-accounting Monitor the incoming and outgoing traffic metrics in realtime for NGINX nginx-module-ts NGINX MPEG-TS Live Module nginx-module-unbrotli Decompresses Brotli-encoded responses for clients that do not support it nginx-module-untar NGINX HTTP Untar Module nginx-module-upload NGINX module for handling file uploads nginx-module-upstream-fair The fair load balancer module for NGINX nginx-module-upstream-jdomain Asynchronous domain name resolution module for NGINX upstream nginx-module-upsync NGINX module for syncing upstreams from consul or etcd nginx-module-vod NGINX-based VOD Packager nginx-module-vts NGINX virtual host traffic status module nginx-module-waf A web application firewall module for NGINX nginx-module-wasm-wasmtime Nginx with WebAssembly powered by wasmtime nginx-module-webp NGINX WebP module nginx-module-xslt NGINX XSLT dynamic module nginx-module-xss Native cross-site scripting support in NGINX nginx-module-zip Streaming ZIP archiver for NGINX nginx-module-zstd NGINX module for the Zstandard compression"},{"location":"modules_list/","title":"Modules list","text":"Package Name Description nginx-module-accept-language NGINX Accept-Language module nginx-module-acme Automatic certificate management (ACMEv2) module for NGINX nginx-module-ajp Support AJP protocol proxy with NGINX nginx-module-array-var Array-typed variables for NGINX nginx-module-auth-digest Digest Authentication for NGINX nginx-module-auth-ldap LDAP Authentication module for NGINX nginx-module-auth-pam PAM authentication dynamic module for NGINX nginx-module-auth-totp Time-based one-time password (TOTP) authentication for NGINX nginx-module-aws-auth NGINX module to proxy to authenticated AWS services nginx-module-bot-verifier A search index bot verification module for NGINX nginx-module-brotli NGINX Brotli dynamic modules nginx-module-cache-purge NGINX Cache Purge module nginx-module-captcha NGINX Captcha Module nginx-module-cgi CGI support for NGINX nginx-module-combined-upstreams NGINX Combined Upstreams module nginx-module-concat HTTP Concatenation module for NGINX nginx-module-cookie-flag NGINX cookie flag module nginx-module-cookie-limit NGINX module to limit the number of malicious ip forged cookies nginx-module-coolkit NGINX CoolKit Module nginx-module-dav-ext NGINX WebDAV PROPFIND,OPTIONS,LOCK,UNLOCK support nginx-module-doh NGINX module for serving DNS-over-HTTPS (DOH) requests nginx-module-dynamic-etag NGINX module for adding ETag to dynamic content nginx-module-dynamic-limit-req NGINX module to dynamically lock IP and release it periodically nginx-module-echo nginx Echo module nginx-module-encrypted-session Encrypt and decrypt NGINX variable values nginx-module-execute NGINX Execute module nginx-module-f4fhds NGINX module for Adobe f4f format nginx-module-fancyindex NGINX Fancy Index module nginx-module-flv Media streaming server based on nginx-module-rtmp nginx-module-form-input NGINX form input module nginx-module-geoip2 NGINX GeoIP2 module nginx-module-geoip NGINX GeoIP dynamic modules nginx-module-google NGINX Module for Google Mirror creation nginx-module-graphite An NGINX module for collecting stats into Graphite nginx-module-headers-more NGINX Headers More dynamic module nginx-module-hmac-secure-link Alternative NGINX HMAC Secure Link module with support for OpenSSL hashes nginx-module-html-sanitize NGINX module to sanitize HTML 5 with whitelisted elements, attributes and CSS nginx-module-iconv NGINX iconv module nginx-module-image-filter NGINX image filter dynamic module nginx-module-immutable NGINX module for setting immutable caching on static assets nginx-module-ipscrub IP address anonymizer module for NGINX nginx-module-ipset-access NGINX ipset access module nginx-module-jpeg NGINX JPEG filter module nginx-module-js-challenge NGINX Javascript challenge module nginx-module-json-var NGINX JSON variables module nginx-module-json NGINX JSON module nginx-module-jwt NGINX JWT Module nginx-module-keyval Nginx module for the key-value store nginx-module-length-hiding NGINX Length Hiding Filter Module nginx-module-let NGINX let module nginx-module-limit-traffic-rate NGINX Limiting rate by given variables nginx-module-live-common Kaltura Media Framework Common NGINX Module nginx-module-log-sqlite SQLite logger module for NGINX nginx-module-log-zmq ZeroMQ logger module for NGINX nginx-module-lua Lua scripting support for NGINX nginx-module-markdown Markdown-to-html NGINX module nginx-module-memc Extended version of the standard NGINX memcached module nginx-module-naxsi NGINX Anti XSS &amp; SQL Injection module nginx-module-nchan Scalable, flexible pub/sub server for the modern web nginx-module-ndk Nginx Development Kit nginx-module-njs NGINX njs dynamic modules nginx-module-ntlm NTLM NGINX Module nginx-module-otel NGINX OpenTelemetry dynamic module nginx-module-pagespeed PageSpeed dynamic module for NGINX nginx-module-passenger Passenger module nginx-module-perl NGINX Perl dynamic module nginx-module-phantom-token Phantom Token NGINX Module nginx-module-pipelog NGINX pipelog module nginx-module-postgres PostgreSQL module for NGINX nginx-module-proxy-connect CONNECT method support in NGINX nginx-module-pta Period of Time Authentication module for NGINX nginx-module-push-stream NGINX push stream module nginx-module-rdns NGINX HTTP rDNS module nginx-module-redis-rate-limit Redis backed rate limit module for Nginx nginx-module-redis2 NGINX upstream module for the Redis 2.0 protocol nginx-module-rtmp NGINX RTMP module nginx-module-secure-token Secure token module for NGINX nginx-module-security-headers NGINX module for sending security headers nginx-module-security ModSecurity v3 Nginx Connector nginx-module-set-misc NGINX Set-Misc module nginx-module-shibboleth Shibboleth Auth Request module for NGINX nginx-module-slowfs NGINX SlowFS Cache Module nginx-module-small-light Dynamic image transformation module For NGINX nginx-module-spnego-http-auth Nginx module for HTTP SPNEGO auth nginx-module-srcache Transparent subrequest-based caching layout for arbitrary NGINX locations nginx-module-srt Nginx SRT Module nginx-module-statsd NGINX module for sending stats to statsd nginx-module-sticky NGINX sticky cookie module nginx-module-stream-lua Lua scripting support for NGINX streams nginx-module-stream-sts Nginx stream server traffic status core module nginx-module-stream-upsync NGINX module for syncing stream backends from consul or etcd nginx-module-sts Nginx stream server traffic status module nginx-module-substitutions String substitutions module for nginx nginx-module-sxg Signed HTTP Exchange(SXG) support for NGINX nginx-module-sysguard NGINX sysguard module nginx-module-testcookie NGINX testcookie robot mitigation module nginx-module-traffic-accounting Monitor the incoming and outgoing traffic metrics in realtime for NGINX nginx-module-ts NGINX MPEG-TS Live Module nginx-module-unbrotli Decompresses Brotli-encoded responses for clients that do not support it nginx-module-untar NGINX HTTP Untar Module nginx-module-upload NGINX module for handling file uploads nginx-module-upstream-fair The fair load balancer module for NGINX nginx-module-upstream-jdomain Asynchronous domain name resolution module for NGINX upstream nginx-module-upsync NGINX module for syncing upstreams from consul or etcd nginx-module-vod NGINX-based VOD Packager nginx-module-vts NGINX virtual host traffic status module nginx-module-waf A web application firewall module for NGINX nginx-module-wasm-wasmtime Nginx with WebAssembly powered by wasmtime nginx-module-webp NGINX WebP module nginx-module-xslt NGINX XSLT dynamic module nginx-module-xss Native cross-site scripting support in NGINX nginx-module-zip Streaming ZIP archiver for NGINX nginx-module-zstd NGINX module for the Zstandard compression"},{"location":"nginx-mod/","title":"NGINX-MOD","text":"<p>As you may know, our repository holds the latest stable NGINX and a vast array of dynamic modules for it. </p> <p>However, some performance-oriented folks are always looking for speeding up what's already fast - that is NGINX itself. </p> <p>There are some open-source patches for it, mainly by Cloudflare to improve things further.  To save trouble for many people relying on a manual compilation, we build this better patched NGINX as a package that is compatible with all the NGINX modules we have!  Its official name is NGINX-MOD.</p> <p>NGINX-MOD is based on the latest stable NGINX with the following additions:</p> <ul> <li>Seamless HTTP/3 Support: Experience faster and more reliable web connections with the cutting-edge HTTP/3 protocol.</li> <li>Enhanced HTTP/2 HPACK Compression: Boost your website\u2019s performance through optimized header compression, ensuring quicker data transfer.</li> <li>Dynamic TLS Record Management: Improve both security and speed with dynamically handled TLS records, adapting to your site\u2019s needs in real-time.</li> <li>Advanced Rate Limiting: Gain precise control over traffic with the extended <code>ngx_http_limit_req_module</code>, allowing you to set request limits on an hourly, daily, weekly, or yearly basis.</li> <li>Active Health Monitoring: Maintain high uptime and reliability with real-time health checks of your upstream servers. Learn More</li> <li>Enhanced Security Features: Protect your server information by disabling the display of the NGINX software name in both the Server: header and error pages.</li> <li>Secure SSL Proxying with <code>CONNECT</code> Method: Handle and proxy SSL requests using the <code>CONNECT</code> method, ensuring secure and efficient data transmission.</li> <li>Dark Mode Support: Automatic Dark Mode Support for NGINX error pages.</li> <li>Host header emulation for HTTP/3: The <code>$http_host</code> is initialized from authority, providing better compatibility with applications that rely on the <code>Host</code> header.</li> </ul> <p>Upgrade to GetPageSpeed today and take full advantage of these advanced NGINX-MOD features to optimize your website\u2019s performance, security, and reliability!</p> <p>More on those patches in the documentation below.</p>"},{"location":"nginx-mod/#how-to-install-nginx-mod","title":"How to install NGINX-MOD","text":"CentOS/RHEL 8+ and Fedora Linux, Amazon Linux 2023, etc.CentOS/RHEL 7Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install dnf-plugins-core\ndnf config-manager --disable getpagespeed-extras-mainline\ndnf config-manager --enable getpagespeed-extras-nginx-mod\ndnf -y install nginx-mod\nsystemctl enable --now nginx\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm\nyum -y install yum-utils\nyum-config-manager --disable getpagespeed-extras-mainline\nyum-config-manager --enable getpagespeed-extras-nginx-mod\nyum -y install nginx-mod\nsystemctl enable --now nginx\n</code></pre> <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \namazon-linux-extras install epel\nyum -y install yum-utils\nyum-config-manager --disable getpagespeed-extras-mainline\nyum-config-manager --enable getpagespeed-extras-nginx-mod\nyum -y install nginx-mod\nsystemctl enable --now nginx\n</code></pre>"},{"location":"nginx-mod/#how-to-switch-to-nginx-mod-from-our-regular-nginx","title":"How to switch to NGINX-MOD from our regular NGINX","text":"<p>If you were using our regular NGINX build, you can run a series of commands to upgrade to NGINX-MOD without affecting installed modules or configuration:</p> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm yum-utils\nyum-config-manager --disable getpagespeed-extras-mainline\nyum-config-manager --enable getpagespeed-extras-nginx-mod\nyum -y update nginx\nservice nginx upgrade\n</code></pre>"},{"location":"nginx-mod/#modules-for-nginx-mod","title":"Modules for NGINX-MOD","text":"<p>NGINX-MOD is fully compatible with over 50 NGINX module packages in our base repository. So you can install them as usual, for example:</p> <pre><code>dnf -y install nginx-module-pagespeed\n</code></pre>"},{"location":"nginx-mod/#active-health-checks","title":"Active Health Checks","text":""},{"location":"nginx-mod/#key-features-of-active-health-checks","title":"Key Features of Active Health Checks","text":"<ul> <li>Multi-Protocol Support: HTTP, TCP, SSL Hello, MySQL, AJP, FastCGI.  </li> <li>Customizable Checks: Interval, timeout, success/failure thresholds.  </li> <li>Status Dashboard: Real-time monitoring via HTML, CSV, or JSON.  </li> <li>Dynamic Adjustments: Mark servers up/down based on health checks.  </li> </ul>"},{"location":"nginx-mod/#configuration-basics-for-active-health-checks","title":"Configuration Basics for Active Health Checks","text":""},{"location":"nginx-mod/#example-http-health-check","title":"Example: HTTP Health Check","text":"<pre><code>http {\n  upstream backend {\n    server 192.168.1.10:80; \n    server 192.168.1.11:80;\n\n    # Health check configuration\n    check interval=5s rise=2 fall=3 timeout=4s type=http;\n    check_http_send \"GET /health HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\";\n    check_http_expect_alive http_2xx http_3xx;\n  }\n\n  server {\n    listen 80;\n    location / {\n      proxy_pass http://backend;\n    }\n\n    # Health status dashboard (restricted access)\n    location /status {\n      check_status html;\n      allow 10.0.0.0/8;  # Authorized IPs\n      deny all;\n      access_log off;\n    }\n  }\n}\n</code></pre>"},{"location":"nginx-mod/#explanation","title":"Explanation:","text":"<ul> <li><code>check</code>:  </li> <li><code>interval=5s</code>: Check every 5 seconds.  </li> <li><code>rise=2</code>: Mark server \"up\" after 2 consecutive successes.  </li> <li><code>fall=3</code>: Mark server \"down\" after 3 consecutive failures.  </li> <li><code>type=http</code>: Use HTTP checks.  </li> <li><code>check_http_send</code>: Custom HTTP request sent to upstream servers.  </li> <li><code>check_http_expect_alive</code>: Treat HTTP 2xx/3xx responses as healthy.  </li> <li><code>check_status</code>: Exposes a dashboard at <code>/status</code> in HTML format.  </li> </ul>"},{"location":"nginx-mod/#active-health-checks-directives-reference","title":"Active Health Checks Directives Reference","text":""},{"location":"nginx-mod/#core-directives","title":"Core Directives","text":"Directive Syntax Default Description <code>check</code> <code>interval=ms [fall=count] [rise=count] [timeout=ms] [type=protocol] [default_down=true\\|false] [port=number]</code> <code>interval=30s fall=5 rise=2 timeout=1s type=tcp default_down=true</code> Configures health check parameters. <code>check_http_send</code> <code>\"HTTP_REQUEST\"</code> <code>\"GET / HTTP/1.0\\r\\n\\r\\n\"</code> Custom HTTP request for <code>type=http</code> checks. <code>check_http_expect_alive</code> <code>http_2xx \\| http_3xx \\| ...</code> <code>http_2xx \\| http_3xx</code> HTTP status codes indicating a healthy server."},{"location":"nginx-mod/#advanced-directives","title":"Advanced Directives","text":"Directive Purpose <code>check_keepalive_requests</code> Number of requests per connection (default: <code>1</code>). <code>check_fastcgi_param</code> Custom FastCGI parameters for <code>type=fastcgi</code> checks. <code>check_shm_size</code> Shared memory size for health checks (default: <code>1M</code>)."},{"location":"nginx-mod/#active-health-check-types","title":"Active Health Check Types","text":""},{"location":"nginx-mod/#1-typehttp","title":"1. <code>type=http</code>","text":"<ul> <li>Usage: <pre><code>check type=http;\ncheck_http_send \"HEAD /health HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\";\ncheck_http_expect_alive http_200 http_302;\n</code></pre></li> <li>Response Codes: Configure acceptable statuses (e.g., <code>http_2xx</code>).  </li> </ul>"},{"location":"nginx-mod/#2-typetcp","title":"2. <code>type=tcp</code>","text":"<ul> <li>Simple TCP connection check: <pre><code>check interval=10s type=tcp;\n</code></pre></li> </ul>"},{"location":"nginx-mod/#3-typemysql","title":"3. <code>type=mysql</code>","text":"<ul> <li>Validates MySQL server availability: <pre><code>check type=mysql port=3306;\n</code></pre></li> </ul>"},{"location":"nginx-mod/#4-typefastcgi","title":"4. <code>type=fastcgi</code>","text":"<ul> <li>Custom FastCGI parameters: <pre><code>check type=fastcgi;\ncheck_fastcgi_param \"REQUEST_METHOD\" \"GET\";\ncheck_fastcgi_param \"SCRIPT_FILENAME\" \"index.php\";\n</code></pre></li> </ul>"},{"location":"nginx-mod/#status-page-setup","title":"Status Page Setup","text":""},{"location":"nginx-mod/#endpoint-configuration","title":"Endpoint Configuration","text":"<pre><code>location /status {\n  check_status [html|csv|json];  # Default: html\n  allow 192.168.1.0/24;         # Restrict access\n  deny all;\n}\n</code></pre>"},{"location":"nginx-mod/#query-parameters","title":"Query Parameters","text":"<ul> <li><code>format</code>: Override output format (e.g., <code>/status?format=json</code>).  </li> <li><code>status</code>: Filter servers by status (e.g., <code>/status?status=down</code>).  </li> </ul>"},{"location":"nginx-mod/#sample-outputs","title":"Sample Outputs","text":"<ul> <li>HTML: Interactive table with server status.  </li> <li>JSON: Machine-readable format for automation.  </li> <li>CSV: Simplified comma-separated values.  </li> </ul>"},{"location":"nginx-mod/#troubleshooting-best-practices-for-active-health-checks","title":"Troubleshooting &amp; Best Practices for Active Health Checks","text":""},{"location":"nginx-mod/#common-issues","title":"Common Issues","text":"<ol> <li>Shared Memory Exhausted:  </li> <li> <p>Fix: Increase <code>check_shm_size</code> in the <code>http</code> block: <pre><code>http {\n  check_shm_size 10M;  # Default: 1M\n}\n</code></pre></p> </li> <li> <p>False Positives/Negatives:  </p> </li> <li> <p>Adjust <code>rise</code>/<code>fall</code> thresholds and validate <code>check_http_send</code> requests.  </p> </li> <li> <p>Timeout Errors:  </p> </li> <li>Increase <code>timeout</code> if upstream servers respond slowly.  </li> </ol>"},{"location":"nginx-mod/#security-tips","title":"Security Tips","text":"<ul> <li>Restrict access to the <code>/status</code> endpoint using <code>allow</code>/<code>deny</code>.  </li> <li>Use HTTPS for the status page if sensitive data is exposed.  </li> </ul> <p>Active checks work seamlessly with <code>ip_hash</code>, <code>least_conn</code>, and third-party modules like <code>sticky</code> or <code>fair</code>.  </p>"},{"location":"nginx-mod/#ngx_http_limit_req_module-patch","title":"ngx_http_limit_req_module patch","text":"<p>Some NGINX users seek to define rate-limiting of once in a day for specific resources. This is not possible with stock NGINX. Our patch allows for a more fine-grained rate limit configuration. Examples:</p> <pre><code>limit_req_zone $binary_remote_addr zone=one:10m rate=1r/h; # 1 request per hour\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/d; # 1 request per day\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/w; # 1 request per week\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/M; # 1 request per month\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/Y; # 1 request per year\n</code></pre> <p>It is important to note, that your defined zone memory size should allow retaining old IP entries before the defined rate will apply.</p> <p>For example, you have defined a <code>10m</code> zone and <code>1r/d</code> for a particular resource. <code>10m</code> can store around 160,000 IP addresses. So if someone visits your rate-limited resource, and your traffic to it exceed 160K unique visitors within 24 hrs, then the same visitor can theoretically not be rate-limited within the same day, because information about his IP address will be evicted from memory after enough visitors visited the resource.</p> <p>This note applies to the stock module's configuration as well, but less so.</p> <p>So the rules of thumb are:</p> <ul> <li>You likely need to  increase memory zone, if your traffic is sufficient to be able to evict old IP addresses \"too early\"</li> <li>This is more appropriate for rate-limiting specific resources, not the whole website</li> </ul>"},{"location":"nginx-mod/#what-is-hpack-patch","title":"What is HPACK Patch","text":"<p>HPACK patch implements full HPACK in NGINX. In short, this allows for compressing HTTP headers</p>"},{"location":"nginx-mod/#what-is-the-connect-method-support","title":"What is the <code>CONNECT</code> method support","text":"<p>NGINX-MOD provides support for the <code>CONNECT</code> method request. This method is mainly used  to tunnel SSL requests through proxy servers. </p> <p>To enable and configure, please refer to the <code>proxy_connect</code> directives. </p>"},{"location":"nginx-mod/#configuration-directives-of-nginx-mod","title":"Configuration Directives of NGINX-MOD","text":"<p>There are some configuration directives in this build, which are not otherwise available in regular builds. Let's document them here.</p> <p>The following set of configuration directives are added by dynamic TLS records patch. </p>"},{"location":"nginx-mod/#ssl_dyn_rec_enable-onoff","title":"<code>ssl_dyn_rec_enable on|off</code>","text":"<p>Whether to enable dynamic TLS records.</p>"},{"location":"nginx-mod/#ssl_dyn_rec_size_lo","title":"<code>ssl_dyn_rec_size_lo</code>","text":"<p>The TLS record size to start with. Defaults to 1369 bytes (designed to fit the entire record in a single TCP segment: 1369 = 1500 - 40 (IPv6) - 20 (TCP) - 10 (Time) - 61 (Max TLS overhead)) ssl_dyn_rec_size_hi: the TLS record size to grow to. Defaults to 4229 bytes (designed to fit the entire record in 3 TCP segments)</p>"},{"location":"nginx-mod/#ssl_dyn_rec_threshold","title":"<code>ssl_dyn_rec_threshold</code>","text":"<p>The number of records to send before changing the record size.</p> <p>Because we build with the latest OpenSSL:</p>"},{"location":"nginx-mod/#ssl_protocols-sslv2-sslv3-tlsv1-tlsv11-tlsv12-tlsv13","title":"<code>ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3];</code>","text":"<p>Not a new directive. But since we build with the most recent stable OpenSSL, it allows for <code>TLSv1.3</code> value to be used.</p>"},{"location":"nginx-mod/#hiding-software-information","title":"Hiding software information","text":"<p>By default, NGINX only supports <code>server_tokens off;</code> which still yields <code>nginx</code> in the <code>Server:</code> header and in error pages. With NGINX-MOD, you can specify a new value <code>none</code>, which will cause NGINX to stop emission of its presence on the server:</p> <pre><code>server_tokens none;\n</code></pre>"},{"location":"nginx-mod/#verification","title":"Verification","text":"<p>To verify how you benefit from NGINX-MOD, you can run some tests.</p>"},{"location":"nginx-mod/#check-http2-headers-compression","title":"Check HTTP/2 headers compression","text":"<pre><code>yum install nghttp2\nh2load https://example.com -n 2 | tail -6 |head -1\n</code></pre> <p>Example output:</p> <p>traffic: 71.46KB (73170) total, 637B (637) headers (space savings 78.68%), 70.61KB (72304) data</p> <p>If you see 50% or more space savings, then it means that full HPACK compression is utilized.</p>"},{"location":"nginx-mod/#how-to-switch-back-to-stable-nginx","title":"How to switch back to stable NGINX","text":"<p>Going back to the stable package while preserving existing configuration:</p> <pre><code>yum-config-manager --disable getpagespeed-extras-nginx-mod\nMOD_PKGS=$(rpm -qa --queryformat '%{NAME}\\n' | grep nginx-mod | grep -v nginx-module)\nrpm --erase --justdb --nodeps ${MOD_PKGS}\nSTABLE_PKGS=$(echo ${MOD_PKGS} | sed 's@nginx-mod@nginx@g')\nyum -y install ${STABLE_PKGS}\nyum history sync\n</code></pre> <p>These commands will disable the NGINX-MOD repository and replace any <code>nginx-mod*</code> packages with their equivalents from the base repository, thus downgrading to stable NGINX.</p>"},{"location":"nginx-mod/#compatibility-notes","title":"Compatibility notes","text":"<ul> <li>NGINX-MOD is presently not compatible with the Plesk control panel</li> </ul>"},{"location":"plesk/","title":"Plesk","text":"<p>NGINX Extras ships with module packages for Plesk control panel.</p> <p>Please check the Plesk NGINX Extras page for more details.</p>"},{"location":"quic/","title":"HTTP/3 (QUIC)","text":"<p>HTTP/3 support in NGINX is provided in all of our NGINX packages.</p> <p>For information on how to enable QUIC in NGINX, see How to install NGINX with QUIC HTTP/3 support.</p>"},{"location":"tengine/","title":"Tengine","text":"<p>Tengine is a web server originated by Taobao, the largest e-commerce website in Asia. It is based on the Nginx HTTP  server and has many advanced features. Tengine has proven to be very stable and efficient on some of the top 100  websites in the world, including taobao.com and tmall.com.</p>"},{"location":"tengine/#installation-and-compatibility","title":"Installation and compatibility","text":"<p>NGINX Extras provide you with production-grade, SELinux compatible packages for Tengine web server.</p> CentOS/RHEL 7 and Amazon Linux 2CentOS/RHEL 8+, Fedora Linux <pre><code>sudo yum -y install https://extras.getpagespeed.com/release-latest.rpm\nsudo yum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm\nsudo yum -y install yum-utils\nsudo yum-config-manager --enable getpagespeed-extras-tengine\nsudo yum -y install tengine\n</code></pre> <pre><code>sudo dnf -y install https://extras.getpagespeed.com/release-latest.rpm \nsudo dnf -y install dnf-plugins-core\nsudo dnf config-manager --enable getpagespeed-extras-tengine\nsudo dnf -y install tengine\n</code></pre>"},{"location":"tengine/#compatibility-notes","title":"Compatibility notes","text":"<p>Since Tengine claims 100% compatibility with the stable NGINX branch, you can easily install all the numerous module packages from NGINX Extras to empower your Tengine furthermore, e.g. to add the  PageSpeed module. </p> <p>Commercial subscription for GetPageSpeed repository is required only to install NGINX modules for Tengine. You must provide the Tengine compatible NGINX version when installing modules, like so:</p> <pre><code>yum -y install 'nginx-module-pagespeed-1.22.1.*'\n</code></pre> <p>Here we specified to install <code>nginx-module-pagespeed</code> for NGINX 1.22.1, which is matching the current Tengine to NGINX binary compatibility.</p>"},{"location":"tengine/#tengine-features","title":"Tengine Features","text":"<ul> <li>All features of nginx 1.22.1 are inherited, i.e., it is 100% compatible with nginx.</li> <li>Support the CONNECT HTTP method for forward proxy.</li> <li>Support asynchronous OpenSSL, using hardware such as QAT for HTTPS acceleration.</li> <li>Enhanced operations monitoring, such as asynchronous log &amp; rollback, DNS caching, memory usage, etc.</li> <li>Support server_name in Stream module.</li> <li>More load balancing methods, e.g., consistent hashing, and session persistence.</li> <li>Input body filter support. It's quite handy to write Web Application Firewalls using this mechanism.</li> <li>Dynamic scripting language (Lua) support, which is very efficient and makes it easy to extend core functionalities.</li> <li>Limits retries for upstream servers (proxy, memcached, fastcgi, scgi, uwsgi).</li> <li>Includes a mechanism to support standalone processes.</li> <li>Protects the server in case system load or memory use goes too high.</li> <li>Multiple CSS or JavaScript requests can be combined into one request to reduce download time.</li> <li>Removes unnecessary white spaces and comments to reduce the size of a page.</li> <li>Proactive health checks of upstream servers can be performed.</li> <li>The number of worker processes and CPU affinities can be set automatically.</li> <li>The limit_req module is enhanced with whitelist support and more conditions are allowed in a single location.</li> <li>Enhanced diagnostic information makes it easier to troubleshoot errors.</li> <li>More user-friendly command lines, e.g., showing all compiled-in modules and supported directives.</li> <li>Expiration times can be specified for certain MIME types.</li> <li>Error pages can be reset to 'default'.</li> <li>...</li> </ul>"},{"location":"lua/acme/","title":"acme: Automatic Let's Encrypt certificate serving and Lua implementation of ACMEv2 procotol","text":""},{"location":"lua/acme/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/acme/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-acme\n</code></pre>"},{"location":"lua/acme/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-acme\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-acme v0.16.0  released on Sep 01 2025.</p> <p>Automatic Let's Encrypt certificate serving (RSA + ECC) and pure Lua implementation of the ACMEv2 protocol.</p> <p><code>http-01</code> and <code>tls-alpn-01</code> challenges are supported.</p> <p> </p> <p>\u7b80\u4f53\u4e2d\u6587</p>"},{"location":"lua/acme/#description","title":"Description","text":"<p>This library consists of two parts:</p> <ul> <li><code>resty.acme.autossl</code>: automatic lifecycle management of Let's Encrypt certificates</li> <li><code>resty.acme.client</code>: Lua implementation of ACME v2 protocol</li> </ul> <p>Install using opm:</p> <pre><code>opm install fffonion/lua-resty-acme\n</code></pre> <p>Alternatively, to install using luarocks:</p> <pre><code>luarocks install lua-resty-acme\n## manually install a luafilesystem\nluarocks install luafilesystem\n</code></pre> <p>Note you will need to manually install <code>luafilesystem</code> when using LuaRocks. This is made to maintain backward compatibility.</p> <p>This library uses an FFI-based openssl backend, which currently supports OpenSSL <code>1.1.1</code>, <code>1.1.0</code> and <code>1.0.2</code> series.</p>"},{"location":"lua/acme/#status","title":"Status","text":"<p>Production.</p>"},{"location":"lua/acme/#synopsis","title":"Synopsis","text":"<p>Create account private key and fallback certs:</p> <pre><code>## create account key\nopenssl genpkey -algorithm RSA -pkeyopt rsa_keygen_bits:4096 -out /etc/openresty/account.key\n## create fallback cert and key\nopenssl req -newkey rsa:2048 -nodes -keyout /etc/openresty/default.key -x509 -days 365 -out /etc/openresty/default.pem\n</code></pre> <p>Use the following example config:</p> <pre><code>events {}\n\nhttp {\n    resolver 8.8.8.8 ipv6=off;\n\n    lua_shared_dict acme 16m;\n\n    # required to verify Let's Encrypt API\n    lua_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;\n    lua_ssl_verify_depth 2;\n\n    init_by_lua_block {\n        require(\"resty.acme.autossl\").init({\n            -- setting the following to true\n            -- implies that you read and accepted https://letsencrypt.org/repository/\n            tos_accepted = true,\n            -- uncomment following for first time setup\n            -- staging = true,\n            -- uncomment following to enable RSA + ECC double cert\n            -- domain_key_types = { 'rsa', 'ecc' },\n            -- uncomment following to enable tls-alpn-01 challenge\n            -- enabled_challenge_handlers = { 'http-01', 'tls-alpn-01' },\n            account_key_path = \"/etc/openresty/account.key\",\n            account_email = \"youemail@youdomain.com\",\n            domain_whitelist = { \"example.com\" },\n        })\n    }\n\n    init_worker_by_lua_block {\n        require(\"resty.acme.autossl\").init_worker()\n    }\n\n    server {\n        listen 80;\n        listen 443 ssl;\n        server_name example.com;\n\n        # fallback certs, make sure to create them before hand\n        ssl_certificate /etc/openresty/default.pem;\n        ssl_certificate_key /etc/openresty/default.key;\n\n        ssl_certificate_by_lua_block {\n            require(\"resty.acme.autossl\").ssl_certificate()\n        }\n\n        location /.well-known {\n            content_by_lua_block {\n                require(\"resty.acme.autossl\").serve_http_challenge()\n            }\n        }\n    }\n}\n</code></pre> <p>When testing deployment, it's recommanded to uncomment the <code>staging = true</code> to allow an end-to-end test of your environment. This can avoid configuration failure result into too many requests that hits rate limiting on Let's Encrypt API.</p> <p>By default <code>autossl</code> only creates RSA certificates. To use ECC certificates or both, uncomment <code>domain_key_types = { 'rsa', 'ecc' }</code>. Note that multiple certificate chain is only supported by NGINX 1.11.0 or later.</p> <p>A certificate will be queued to create after Nginx seen request with such SNI, which might take tens of seconds to finish. During the meantime, requests with such SNI are responsed with the fallback certificate.</p> <p>Note that <code>domain_whitelist</code> or <code>domain_whitelist_callback</code> must be set to include your domain that you wish to server autossl, to prevent potential abuse using fake SNI in SSL handshake.</p> <p><code>domain_whitelist</code> defines a table that includes all domains should be included and the CN to be used to create cert for. Only a single <code>*</code> is allowed as a wildcard.</p> <pre><code>domain_whitelist = { \"domain1.com\", \"domain2.com\", \"domain3.com\", \"*.domain4.com\" },\n</code></pre>"},{"location":"lua/acme/#wildcard-certificates","title":"Wildcard certificates","text":"<p>To enable this library to create wildcard certificate, the following requirements must be met:</p> <ul> <li>The wildcard domain appear exactly as <code>*.somedomain.com</code> in <code>domain_whitelist</code>.</li> <li><code>dns-01</code> challenge is enabled and a dns provider that has <code>domains</code> matching the domain is configured.</li> </ul> <p>Otherwise a non-wildcard certificate will be created as fallback.</p> <p>By default, the wildcard domain <code>*.example.com</code> will appear in Common Name. When <code>wildcard_domain_in_san</code> is set to <code>true</code> however, a cert with Common Name <code>example.com</code> and Subject Alternate Name <code>*.example.com</code> will be created. Note both <code>*.example.com</code> and <code>example.com</code> should appear in <code>dns_provider_accounts</code>.</p>"},{"location":"lua/acme/#advanced-usage","title":"Advanced Usage","text":""},{"location":"lua/acme/#use-a-function-to-include-domains","title":"Use a function to include domains","text":"<p><code>domain_whitelist_callback</code> defines a function that accepts domain as parameter and return boolean to indicate if it should be included.</p> <p>To match a pattern in your domain name, for example all subdomains under <code>example.com</code>, use:</p> <pre><code>domain_whitelist_callback = function(domain, is_new_cert_needed)\n    return ngx.re.match(domain, [[\\.example\\.com$]], \"jo\")\nend\n</code></pre> <p>Furthermore, since checking domain whitelist is running in certificate phase. It's possible to use cosocket API here. Do note that this will increase the SSL handshake latency.</p> <pre><code>domain_whitelist_callback = function(domain, is_new_cert_needed)\n    -- send HTTP request\n    local http = require(\"resty.http\")\n    local res, err = httpc:request_uri(\"http://example.com\")\n    -- access the storage\n    local acme = require(\"resty.acme.autossl\")\n    local value, err = acme.storage:get(\"key\")\n    -- get cert from resty LRU cache\n    -- cached = { pkey, cert } or nil if cert is not in cache\n    local cached, staled, flags = acme.get_cert_from_cache(domain, \"rsa\")\n    -- do something to check the domain\n    -- return is_domain_included\nend}),\n</code></pre> <p><code>domain_whitelist_callback</code> function is provided with a second argument, which indicates whether the certificate is about to be served on incoming HTTP request (false) or new certificate is about to be requested (true). This allows to use cached values on hot path (serving requests) while fetching fresh data from storage for new certificates. One may also implement different logic, e.g. do extra checks before requesting new cert.</p>"},{"location":"lua/acme/#define-failure-cooloff-period","title":"Define failure cooloff period","text":"<p>In case of certificate request failure one may want to prevent ACME client to request another certificate immediatelly. By default, the cooloff period it is set to 300 seconds (5 minutes). It may be customized with <code>failure_cooloff</code> or with <code>failure_cooloff_callback</code> function, e.g. to implement exponential backoff.</p> <pre><code>    failure_cooloff_callback = function(domain, count)\n      if count == 1 then\n        return 600 -- 10 minutes\n      elseif count == 2 then\n        return 1800 -- 30 minutes\n      elseif count == 3 then\n        return 3600 -- 1 hour\n      elseif count == 4 then\n        return 43200 -- 12 hours\n      elseif count == 5 then\n        return 43200 -- 12 hours\n      else\n        return 86400 -- 24 hours\n      end\n    end\n</code></pre>"},{"location":"lua/acme/#tls-alpn-01-challenge","title":"tls-alpn-01 challenge","text":"<p>tls-alpn-01 challenge is currently supported on Openresty <code>1.15.8.x</code>, <code>1.17.8.x</code> and <code>1.19.3.x</code>.</p> Click to expand sample config <pre><code>events {}\n\nhttp {\n    resolver 8.8.8.8 ipv6=off;\n\n    lua_shared_dict acme 16m;\n\n    # required to verify Let's Encrypt API\n    lua_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;\n    lua_ssl_verify_depth 2;\n\n    init_by_lua_block {\n        require(\"resty.acme.autossl\").init({\n            -- setting the following to true\n            -- implies that you read and accepted https://letsencrypt.org/repository/\n            tos_accepted = true,\n            -- uncomment following for first time setup\n            -- staging = true,\n            -- uncomment folloing to enable RSA + ECC double cert\n            -- domain_key_types = { 'rsa', 'ecc' },\n            -- uncomment following to enable tls-alpn-01 challenge\n            enabled_challenge_handlers = { 'http-01', 'tls-alpn-01' },\n            account_key_path = \"/etc/openresty/account.key\",\n            account_email = \"youemail@youdomain.com\",\n            domain_whitelist = { \"example.com\" },\n            storage_adapter = \"file\",\n        })\n    }\n    init_worker_by_lua_block {\n        require(\"resty.acme.autossl\").init_worker()\n    }\n\n    server {\n        listen 80;\n        listen unix:/tmp/nginx-default.sock ssl;\n        # listen unix:/tmp/nginx-default.sock ssl proxy_protocol;\n        server_name example.com;\n\n        # set_real_ip_from unix:;\n        # real_ip_header proxy_protocol;\n\n        # fallback certs, make sure to create them before hand\n        ssl_certificate /etc/openresty/default.pem;\n        ssl_certificate_key /etc/openresty/default.key;\n\n        ssl_certificate_by_lua_block {\n            require(\"resty.acme.autossl\").ssl_certificate()\n        }\n\n        location /.well-known {\n            content_by_lua_block {\n                require(\"resty.acme.autossl\").serve_http_challenge()\n            }\n        }\n    }\n}\n\nstream {\n    init_worker_by_lua_block {\n        require(\"resty.acme.autossl\").init({\n            -- setting the following to true\n            -- implies that you read and accepted https://letsencrypt.org/repository/\n            tos_accepted = true,\n            -- uncomment following for first time setup\n            -- staging = true,\n            -- uncomment folloing to enable RSA + ECC double cert\n            -- domain_key_types = { 'rsa', 'ecc' },\n            -- uncomment following to enable tls-alpn-01 challenge\n            enabled_challenge_handlers = { 'http-01', 'tls-alpn-01' },\n            account_key_path = \"/etc/openresty/account.key\",\n            account_email = \"youemail@youdomain.com\",\n            domain_whitelist = { \"example.com\" },\n            storage_adapter = \"file\"\n        })\n        require(\"resty.acme.autossl\").init_worker()\n    }\n\n    map $ssl_preread_alpn_protocols $backend {\n        ~\\bacme-tls/1\\b unix:/tmp/nginx-tls-alpn.sock;\n        default unix:/tmp/nginx-default.sock;\n    }\n\n    server {\n            listen 443;\n            listen [::]:443;\n\n            ssl_preread on;\n            proxy_pass $backend;\n\n            # proxy_protocol on;\n    }\n\n    server {\n            listen unix:/tmp/nginx-tls-alpn.sock ssl;\n            # listen nix:/tmp/nginx-tls-alpn.sock ssl proxy_protocol;\n            ssl_certificate certs/default.pem;\n            ssl_certificate_key certs/default.key;\n\n            # requires --with-stream_realip_module\n            # set_real_ip_from unix:;\n\n            ssl_certificate_by_lua_block {\n                    require(\"resty.acme.autossl\").serve_tls_alpn_challenge()\n            }\n\n            content_by_lua_block {\n                    ngx.exit(0)\n            }\n    }\n}\n</code></pre> <p>In the above sample config, we set a http server and two stream server.</p> <p>The very front stream server listens for 443 port and route to different upstream based on client ALPN. The tls-alpn-01 responder listens on <code>unix:/tmp/nginx-tls-alpn.sock</code>. All normal https traffic listens on <code>unix:/tmp/nginx-default.sock</code>.</p> <pre><code>                                                [stream server unix:/tmp/nginx-tls-alpn.sock ssl]\n                                            Y /\n[stream server 443] --- ALPN is acme-tls ?\n                                            N \\\n                                                [http server unix:/tmp/nginx-default.sock ssl]\n</code></pre> <ul> <li>The config passed to <code>require(\"resty.acme.autossl\").init</code> in both subsystem should be kept same as possible.</li> <li><code>tls-alpn-01</code> challenge handler doesn't need any third party dependency.</li> <li>You can enable <code>http-01</code> and <code>tls-alpn-01</code> challenge handlers at the same time.</li> <li><code>http</code> and <code>stream</code> subsystem doesn't share shm, thus considering use a storage other than <code>shm</code>. If you must use <code>shm</code>, you will need to apply this patch.</li> </ul>"},{"location":"lua/acme/#dns-01-challenge","title":"dns-01 challenge","text":"<p>DNS-01 challenge is supported on lua-resty-acme &gt; 0.13.0. Currently, following DNS providers are supported:</p> <ul> <li><code>cloudflare</code>: Cloudflare</li> <li><code>dynv6</code>: Dynv6</li> <li><code>dnspod-intl</code>: Dnspod International (only Dnspod token is supported and use <code>id,token</code> in secret field)</li> </ul> <p>To read to how to extend a new DNS provider to work with <code>dns-01</code> challenge, see DNS provider.</p> <p>An example config to use <code>dns-01</code> challenge would be:</p> <pre><code>require(\"resty.acme.autossl\").init({\n  -- setting the following to true\n  -- implies that you read and accepted https://letsencrypt.org/repository/\n  tos_accepted = true,\n  -- uncomment following for first time setup\n  -- staging = true,\n  -- uncomment following to enable RSA + ECC double cert\n  -- domain_key_types = { 'rsa', 'ecc' },\n  -- do not set `http-01` or `tls-alpn-01` if you only plan to use dns-01.\n  enabled_challenge_handlers = { 'dns-01' },\n  account_key_path = \"/etc/openresty/account.key\",\n  account_email = \"youemail@youdomain.com\",\n  domain_whitelist = { \"example.com\", \"subdomain.anotherdomain.com\" },\n\n  dns_provider_accounts = {\n    {\n      name = \"cloudflare_prod\",\n      provider = \"cloudflare\",\n      secret = \"apikey of cloudflare\",\n      domains = { \"example.com\" },\n    },\n    {\n      name = \"dynv6_staging\",\n      provider = \"dynv6\",\n      secret = \"apikey of dynv6\",\n      domains = { \"*.anotherdomain.com\" },\n    },\n  },\n  -- uncomment following to create anotherdomain.com in CN and *.anotherdomain.com in SAN\n  -- wildcard_domain_in_san = true,\n})\n</code></pre> <p>By default, this library tries up to 5 minutes for DNS propagation. If the default TTL for dns provider is longer than that, user may want to tune up <code>challenge_start_delay</code> manually to wait longer.</p>"},{"location":"lua/acme/#restyacmeautossl","title":"resty.acme.autossl","text":"<p>A config table can be passed to <code>resty.acme.autossl.init()</code>, the default values are:</p> <pre><code>default_config = {\n  -- accept term of service https://letsencrypt.org/repository/\n  tos_accepted = false,\n  -- if using the let's encrypt staging API\n  staging = false,\n  -- the path to account private key in PEM format\n  account_key_path = nil,\n  -- the account email to register\n  account_email = nil,\n  -- number of certificate cache, per type\n  cache_size = 100,\n  domain_key_paths = {\n    -- the global domain RSA private key\n    rsa = nil,\n    -- the global domain ECC private key\n    ecc = nil,\n  },\n  -- the private key algorithm to use, can be one or both of\n  -- 'rsa' and 'ecc'\n  domain_key_types = { 'rsa' },\n  -- restrict registering new cert only with domain defined in this table\n  domain_whitelist = nil,\n  -- restrict registering new cert only with domain checked by this function\n  domain_whitelist_callback = nil,\n  -- interval to wait before retrying after failed certificate request\n  failure_cooloff = 300,\n  -- function that returns interval to wait before retrying after failed certificate request\n  failure_cooloff_callback = nil,\n  -- the threshold to renew a cert before it expires, in seconds\n  renew_threshold = 7 * 86400,\n  -- interval to check cert renewal, in seconds\n  renew_check_interval = 6 * 3600,\n  -- the store certificates\n  storage_adapter = \"shm\",\n  -- the storage config passed to storage adapter\n  storage_config = {\n    shm_name = 'acme',\n  },\n  -- the challenge types enabled\n  enabled_challenge_handlers = { 'http-01' },\n  -- time to wait before signaling ACME server to validate in seconds\n  challenge_start_delay = 0,\n  -- if true, the request to nginx waits until the cert has been generated and it is used right away\n  blocking = false,\n  -- if true, the certificate for domain not in whitelist will be deleted from storage\n  enabled_delete_not_whitelisted_domain = false,\n  -- the dict of dns providers, each provider should have following struct:\n  -- {\n  --   name = \"prod_account\",\n  --   provider = \"provider_name\", -- \"cloudflare\" or \"dynv6\"\n  --   secret  = \"the api key or token\",\n  --   domains = { \"example.com\", \"*.example.com\" }, -- the list of domains that can be used with this provider\n  -- }\n  dns_provider_accounts = {},\n  -- if enabled, wildcard domains like *.example.com will be created as SAN and CN will be example.com\n  wildcard_domain_in_san = false,\n}\n</code></pre> <p>If <code>account_key_path</code> is not specified, a new account key will be created everytime Nginx reloads configuration. Note this may trigger New Account rate limiting on Let's Encrypt API.</p> <p>If <code>domain_key_paths</code> is not specified, a new private key will be generated for each certificate (4096-bits RSA and 256-bits prime256v1 ECC). Note that generating such key will block worker and will be especially noticable on VMs where entropy is low.</p> <p>Pass config table directly to ACME client as second parameter. The following example demonstrates how to use a CA provider other than Let's Encrypt and also set the preferred chain.</p> <pre><code>resty.acme.autossl.init({\n    tos_accepted = true,\n    account_email = \"example@example.com\",\n  }, {\n    api_uri = \"https://acme.otherca.com/directory\",\n    preferred_chain = \"OtherCA PKI Root CA\",\n  }\n)\n</code></pre> <p>See also Storage Adapters below.</p> <p>When using distributed storage types, it's useful to bump up <code>challenge_start_delay</code> to allow changes in storage to propogate around. When <code>challenge_start_delay</code> is set to 0, no wait will be performed before start validating challenges.</p>"},{"location":"lua/acme/#autosslget_certkey","title":"autossl.get_certkey","text":"<p>syntax: certkey, err = autossl.get_certkey(domain, type?)</p> <p>Return the PEM-encoded certificate and private key for <code>domain</code> from storage. Optionally accepts a <code>type</code> parameter which can be <code>\"rsa\"</code> or <code>\"ecc\"</code>; if omitted, <code>type</code> will default to <code>\"rsa\"</code>.</p>"},{"location":"lua/acme/#restyacmeclient","title":"resty.acme.client","text":""},{"location":"lua/acme/#clientnew","title":"client.new","text":"<p>syntax: c, err = client.new(config)</p> <p>Create a ACMEv2 client.</p> <p>Default values for <code>config</code> are:</p> <pre><code>default_config = {\n  -- the ACME v2 API endpoint to use\n  api_uri = \"https://acme-v02.api.letsencrypt.org/directory\",\n  -- the account email to register\n  account_email = nil,\n  -- the account key in PEM format text\n  account_key = nil,\n  -- the account kid (as an URL)\n  account_kid = nil,\n  -- external account binding key id\n  eab_kid = nil,\n  -- external account binding hmac key, base64url encoded\n  eab_hmac_key = nil,\n  -- external account registering handler\n  eab_handler = nil,\n  -- storage for challenge\n  storage_adapter = \"shm\",\n  -- the storage config passed to storage adapter\n  storage_config = {\n    shm_name = \"acme\"\n  },\n  -- the challenge types enabled, selection of `http-01` and `tls-alpn-01`\n  enabled_challenge_handlers = {\"http-01\"},\n  -- select preferred root CA issuer's Common Name if appliable\n  preferred_chain = nil,\n  -- callback function that allows to wait before signaling ACME server to validate\n  challenge_start_callback = nil,\n  -- the dict of dns providers, each provider should have following struct:\n  dns_provider_accounts = {},\n}\n</code></pre> <p>If <code>account_kid</code> is omitted, user must call <code>client:new_account()</code> to register a new account. Note that when using the same <code>account_key</code>, <code>client:new_account()</code> will return the same <code>kid</code> that is previosuly registered.</p> <p>If CA requires External Account Binding, user can set <code>eab_kid</code> and <code>eab_hmac_key</code> to load an existing account, or set <code>account_email</code> and <code>eab_handler</code> to register a new account. <code>eab_hmac_key</code> must be base64 url encoded. In later case, user must call <code>client:new_account()</code> to register a new account. <code>eab_handler</code> must be an function that accepts account_email as parameter and returns <code>eab_kid</code>, <code>eab_hmac_key</code> and error if any.</p> <pre><code>eab_handler = function(account_email)\n  -- do something to register an account with account_email\n  -- if err then\n  --  return nil, nil, err\n  -- end\n  return eab_kid, eab_hmac_key\nend\n</code></pre> <p>The following CA provider's EAB handler is supported by lua-resty-acme and user doesn't need to implement their own <code>eab_handler</code>:</p> <ul> <li>ZeroSSL</li> </ul> <p><code>preferred_chain</code> is used to select a chain with matching Common Name in its root CA. For example, user can use use <code>\"ISRG Root X1\"</code> to force use the new default chain in Let's Encrypt. When no value is configured or the configured name is not found in any chain, the default chain will be used.</p> <p><code>challenge_start_callback</code> is a callback function to allow the client to wait before signalling ACME server to start validate challenge. It's useful in a distributed setup where challenges take time to propogate. <code>challenge_start_callback</code> accepts <code>challenge_type</code> and <code>challenge_token</code>. The client calls this function every second until it returns <code>true</code> indicating challenge should start; if this <code>challenge_start_callback</code> is not set, no wait will be performed.</p> <pre><code>challenge_start_callback = function(challenge_type, challenge_token)\n  -- do something here\n  -- if we are good\n  return true\nend\n</code></pre> <p>See also Storage Adapters below.</p>"},{"location":"lua/acme/#clientinit","title":"client:init","text":"<p>syntax: err = client:init()</p> <p>Initialize the client, requires availability of cosocket API. This function will login or register an account.</p>"},{"location":"lua/acme/#clientorder_certificate","title":"client:order_certificate","text":"<p>syntax: err = client:order_certificate(domain,...)</p> <p>Create a certificate with one or more domains. Note that wildcard domains are not supported as it can only be verified by dns-01 challenge.</p>"},{"location":"lua/acme/#clientserve_http_challenge","title":"client:serve_http_challenge","text":"<p>syntax: client:serve_http_challenge()</p> <p>Serve http-01 challenge. A common use case will be to put this as a content_by_* block for <code>/.well-known</code> path.</p>"},{"location":"lua/acme/#clientserve_tls_alpn_challenge","title":"client:serve_tls_alpn_challenge","text":"<p>syntax: client:serve_tls_alpn_challenge()</p> <p>Serve tls-alpn-01 challenge. See this section on how to use this handler.</p>"},{"location":"lua/acme/#storage-adapters","title":"Storage Adapters","text":"<p>Storage adapters are used in <code>autossl</code> or acme <code>client</code> to storage temporary or persistent data. Depending on the deployment environment, there're currently five storage adapters available to select from. To implement a custom storage adapter, please refer to this doc.</p>"},{"location":"lua/acme/#file","title":"file","text":"<p>Filesystem based storage. Sample configuration:</p> <p><pre><code>storage_config = {\n    dir = '/etc/openresty/storage',\n}\n</code></pre> If <code>dir</code> is omitted, the OS temporary directory will be used.</p> <p><code>luafilesystem</code> or <code>luafilesystem-ffi</code> is needed when using the <code>file</code> storage for renewal.</p>"},{"location":"lua/acme/#shm","title":"shm","text":"<p>Lua shared dict based storage. Note this storage is volatile between Nginx restarts (not reloads). Sample configuration:</p> <pre><code>storage_config = {\n    shm_name = 'dict_name',\n}\n</code></pre>"},{"location":"lua/acme/#redis","title":"redis","text":"<p>Redis based storage. The default config is:</p> <pre><code>storage_config = {\n    host = '127.0.0.1',\n    port = 6379,\n    database = 0,\n    -- Redis authentication key\n    auth = nil,\n    ssl = false,\n    ssl_verify = false,\n    ssl_server_name = nil,\n    -- namespace as a prefix of key\n    namespace = \"\",\n}\n</code></pre> <p>Redis &gt;= 2.6.12 is required as this storage requires SET EX.</p>"},{"location":"lua/acme/#vault","title":"vault","text":"<p>Hashicorp Vault based storage. Only KV V2 backend is supported. The default config is:</p> <pre><code>storage_config = {\n    host = '127.0.0.1',\n    port = 8200,\n    -- secrets kv prefix path\n    kv_path = \"acme\",\n    -- timeout in ms\n    timeout = 2000,\n    -- use HTTPS\n    https = false,\n    -- turn on tls verification\n    tls_verify = true\n    -- SNI used in request, default to host if omitted\n    tls_server_name = nil,\n    -- Auth Method, default to token, can be \"token\" or \"kubernetes\"\n    auth_method = \"token\"\n    -- Vault token\n    token = nil,\n    -- Vault's authentication path to use\n    auth_path =  \"kubernetes\",\n    -- The role to try and assign\n    auth_role = nil,\n    -- The path to the JWT\n    jwt_path = \"/var/run/secrets/kubernetes.io/serviceaccount/token\",\n    -- Vault namespace\n    namespace = nil,\n}\n</code></pre>"},{"location":"lua/acme/#support-for-different-auth-method","title":"Support for different auth method","text":"<ul> <li>Token: This is the default and allows to pass a literal \"token\" in the configuration</li> <li>Kubernetes: Via this method, one can utilize vault's built-in auth method for kubernetes   What this basically this is take the service account token and validates it has been signed by Kubernetes CA.   The major benefit here, is that config files don't expose your token anymore.</li> </ul> <p>The following configurations apply here:   <code>lua     -- Vault's authentication path to use     auth_path =  \"kubernetes\",     -- The role to try and assign     auth_role = nil,     -- The path to the JWT     jwt_path = \"/var/run/secrets/kubernetes.io/serviceaccount/token\",</code></p>"},{"location":"lua/acme/#consul","title":"consul","text":"<p>Hashicorp Consul based storage. The default config is:</p> <pre><code>storage_config = {\n    host = '127.0.0.1',\n    port = 8500,\n    -- kv prefix path\n    kv_path = \"acme\",\n    -- Consul ACL token\n    token = nil,\n    -- timeout in ms\n    timeout = 2000,\n}\n</code></pre>"},{"location":"lua/acme/#etcd","title":"etcd","text":"<p>etcd based storage. Right now only <code>v3</code> protocol is supported, and etcd server version should be &gt;= v3.4.0. The default config is:</p> <pre><code>storage_config = {\n    http_host = 'http://127.0.0.1:4001',\n    key_prefix = '',\n    timeout = 60,\n    ssl_verify = false,\n}\n</code></pre> <p>Etcd storage requires lua-resty-etcd library to installed. It can be manually installed with <code>opm install api7/lua-resty-etcd</code> or <code>luarocks install lua-resty-etcd</code>.</p>"},{"location":"lua/acme/#dns-providers","title":"DNS providers","text":"<p>TO create a custom DNS provider, follow these steps:</p> <ul> <li>Create a file like <code>route53.lua</code> under <code>lib/resty/acme/dns_provider</code></li> <li>Implement following function signature</li> </ul> <pre><code>function _M.new(token)\n  -- ... \n  return self\nend\n\nfunction _M:post_txt_record(fqdn, content)\n  return ok, err\nend\n\nfunction _M:delete_txt_record(fqdn)\n  return ok, err\nend\n</code></pre> <p>Where <code>token</code> is the apikey, <code>fqdn</code> is the DNS record name to set record, and <code>content</code> is the value of the record.</p>"},{"location":"lua/acme/#testing","title":"Testing","text":"<p>Setup e2e test environment by running <code>bash t/fixtures/prepare_env.sh</code>.</p> <p>Then run <code>cpanm install Test::Nginx::Socket</code> and then <code>prove -r t</code>.</p>"},{"location":"lua/acme/#see-also","title":"See Also","text":"<ul> <li>Automatic Certificate Management Environment (ACME)</li> <li>haproxytech/haproxy-lua-acme The ACME Lua implementation used in HAProxy.</li> <li>GUI/lua-resty-auto-ssl</li> <li>lua-resty-openssl</li> <li>Let's Encrypt API rate limits</li> </ul>"},{"location":"lua/acme/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-acme.</p>"},{"location":"lua/ada/","title":"ada: LuaJIT FFI bindings to Ada \u2014 WHATWG-compliant and fast URL parser","text":""},{"location":"lua/ada/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/ada/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-ada\n</code></pre>"},{"location":"lua/ada/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-ada\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-ada v1.1.0  released on Sep 03 2024.</p> <p>lua-resty-ada implements a LuaJIT FFI bindings to Ada \u2014 WHATWG-compliant and fast URL parser.</p>"},{"location":"lua/ada/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/ada/#synopsis","title":"Synopsis","text":"<pre><code>local ada = require(\"resty.ada\")\n\nlocal url = assert(ada.parse(\"https://www.7\u2011Eleven.com:1234/Home/../Privacy/Montr\u00e9al\"))\n\nprint(tostring(url))\n-- prints: https://www.xn--7eleven-506c.com:1234/Privacy/Montr%C3%A9al\n\nprint(tostring(url:clear_port())) -- there are many more methods\n-- prints: https://www.xn--7eleven-506c.com/Privacy/Montr%C3%A9al\n\nurl:free()\n-- explicitly frees the memory without waiting for the garbage collector\n\n-- There is also a static API\n\nprint(ada.get_href(\"https://www.7\u2011Eleven.com:1234/Home/../Privacy/Montr\u00e9al\"))\n-- prints: https://www.xn--7eleven-506c.com:1234/Privacy/Montr%C3%A9al\n\nprint(ada.clear_port(\"https://www.7\u2011Eleven.com:1234/Home/../Privacy/Montr\u00e9al\"))\n-- prints: https://www.xn--7eleven-506c.com/Privacy/Montr%C3%A9al\n</code></pre>"},{"location":"lua/ada/#api","title":"API","text":"<p>LDoc generated API docs can be viewed at bungle.github.io/lua-resty-ada.</p>"},{"location":"lua/ada/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-ada.</p>"},{"location":"lua/auto-ssl/","title":"auto-ssl: On the fly (and free) SSL registration and renewal inside nginx-module-lua/nginx with Let's Encrypt","text":""},{"location":"lua/auto-ssl/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/auto-ssl/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-auto-ssl\n</code></pre>"},{"location":"lua/auto-ssl/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-auto-ssl\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-auto-ssl v0.13.1  released on Oct 01 2019.</p> <p></p> <p>On the fly (and free) SSL registration and renewal inside OpenResty/nginx with Let's Encrypt.</p> <p>This OpenResty plugin automatically and transparently issues SSL certificates from Let's Encrypt (a free certificate authority) as requests are received. It works like:</p> <ul> <li>A SSL request for a SNI hostname is received.</li> <li>If the system already has a SSL certificate for that domain, it is immediately returned (with OCSP stapling).</li> <li>If the system does not yet have an SSL certificate for this domain, it issues a new SSL certificate from Let's Encrypt. Domain validation is handled for you. After receiving the new certificate (usually within a few seconds), the new certificate is saved, cached, and returned to the client (without dropping the original request).</li> </ul> <p>This uses the <code>ssl_certificate_by_lua</code> functionality in OpenResty 1.9.7.2+.</p> <p>By using lua-resty-auto-ssl to register SSL certificates with Let's Encrypt, you agree to the Let's Encrypt Subscriber Agreement.</p>"},{"location":"lua/auto-ssl/#status","title":"Status","text":"<p>Used in production (but the internal APIs might still be in flux).</p>"},{"location":"lua/auto-ssl/#create-etcresty-auto-ssl-and-make-sure-its-writable-by-whichever-user-your","title":"Create /etc/resty-auto-ssl and make sure it's writable by whichever user your","text":""},{"location":"lua/auto-ssl/#nginx-workers-run-as-in-this-example-www-data","title":"nginx workers run as (in this example, \"www-data\").","text":"<p>$ sudo mkdir /etc/resty-auto-ssl $ sudo chown www-data /etc/resty-auto-ssl <pre><code>Implement the necessary configuration inside your nginx config. Here is a minimal example:\n\n```nginx\nevents {\n  worker_connections 1024;\n}\n\nhttp {\n  # The \"auto_ssl\" shared dict should be defined with enough storage space to\n  # hold your certificate data. 1MB of storage holds certificates for\n  # approximately 100 separate domains.\n  lua_shared_dict auto_ssl 1m;\n  # The \"auto_ssl_settings\" shared dict is used to temporarily store various settings\n  # like the secret used by the hook server on port 8999. Do not change or\n  # omit it.\n  lua_shared_dict auto_ssl_settings 64k;\n\n  # A DNS resolver must be defined for OCSP stapling to function.\n  #\n  # This example uses Google's DNS server. You may want to use your system's\n  # default DNS servers, which can be found in /etc/resolv.conf. If your network\n  # is not IPv6 compatible, you may wish to disable IPv6 results by using the\n  # \"ipv6=off\" flag (like \"resolver 8.8.8.8 ipv6=off\").\n  resolver 8.8.8.8;\n\n  # Initial setup tasks.\n  init_by_lua_block {\n    auto_ssl = (require \"resty.auto-ssl\").new()\n\n    -- Define a function to determine which SNI domains to automatically handle\n    -- and register new certificates for. Defaults to not allowing any domains,\n    -- so this must be configured.\n    auto_ssl:set(\"allow_domain\", function(domain)\n      return true\n    end)\n\n    auto_ssl:init()\n  }\n\n  init_worker_by_lua_block {\n    auto_ssl:init_worker()\n  }\n\n  # HTTPS server\n  server {\n    listen 443 ssl;\n\n    # Dynamic handler for issuing or returning certs for SNI domains.\n    ssl_certificate_by_lua_block {\n      auto_ssl:ssl_certificate()\n    }\n\n    # You must still define a static ssl_certificate file for nginx to start.\n    #\n    # You may generate a self-signed fallback with:\n    #\n    # openssl req -new -newkey rsa:2048 -days 3650 -nodes -x509 \\\n    #   -subj '/CN=sni-support-required-for-valid-ssl' \\\n    #   -keyout /etc/ssl/resty-auto-ssl-fallback.key \\\n    #   -out /etc/ssl/resty-auto-ssl-fallback.crt\n    ssl_certificate /etc/ssl/resty-auto-ssl-fallback.crt;\n    ssl_certificate_key /etc/ssl/resty-auto-ssl-fallback.key;\n  }\n\n  # HTTP server\n  server {\n    listen 80;\n\n    # Endpoint used for performing domain verification with Let's Encrypt.\n    location /.well-known/acme-challenge/ {\n      content_by_lua_block {\n        auto_ssl:challenge_server()\n      }\n    }\n  }\n\n  # Internal server running on port 8999 for handling certificate tasks.\n  server {\n    listen 127.0.0.1:8999;\n\n    # Increase the body buffer size, to ensure the internal POSTs can always\n    # parse the full POST contents into memory.\n    client_body_buffer_size 128k;\n    client_max_body_size 128k;\n\n    location / {\n      content_by_lua_block {\n        auto_ssl:hook_server()\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"lua/auto-ssl/#configuration","title":"Configuration","text":"<p>Additional configuration options can be set on the <code>auto_ssl</code> instance that is created:</p>"},{"location":"lua/auto-ssl/#allow_domain","title":"<code>allow_domain</code>","text":"<p>Default: <code>function(domain, auto_ssl, ssl_options, renewal) return false end</code></p> <p>A function that determines whether the incoming domain should automatically issue a new SSL certificate.</p> <p>By default, resty-auto-ssl will not perform any SSL registrations until you define the <code>allow_domain</code> function. You may return <code>true</code> to handle all possible domains, but be aware that bogus SNI hostnames can then be used to trigger an indefinite number of SSL registration attempts (which will be rejected). A better approach may be to whitelist the allowed domains in some way.</p> <p>The callback function's arguments are:</p> <ul> <li><code>domain</code>: The domain of the incoming request.</li> <li><code>auto_ssl</code>: The current auto-ssl instance.</li> <li><code>ssl_options</code>: A table of optional configuration options that were passed to the <code>ssl_certificate</code> function. This can be used to customize the behavior on a per nginx <code>server</code> basis (see example in <code>request_domain</code>). Note, this option is not passed in when this function is called for renewals, so your function should handle that accordingly.</li> <li><code>renewal</code>: Boolean value indicating whether this function is being called during certificate renewal or not. When <code>true</code>, the <code>ssl_options</code> argument will not be present.</li> </ul> <p>When using the Redis storage adapter, you can access the current Redis connection inside the <code>allow_domain</code> callback by accessing <code>auto_ssl.storage.adapter:get_connection()</code>.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"allow_domain\", function(domain, auto_ssl, ssl_options, renewal)\n  return ngx.re.match(domain, \"^(example.com|example.net)$\", \"ijo\")\nend)\n</code></pre>"},{"location":"lua/auto-ssl/#dir","title":"<code>dir</code>","text":"<p>Default: <code>/etc/resty-auto-ssl</code></p> <p>The base directory used for storing configuration, temporary files, and certificate files (if using the <code>file</code> storage adapter). This directory must be writable by the user nginx workers run as.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"dir\", \"/some/other/location\")\n</code></pre>"},{"location":"lua/auto-ssl/#renew_check_interval","title":"<code>renew_check_interval</code>","text":"<p>Default: <code>86400</code></p> <p>How frequently (in seconds) all of the domains should be checked for certificate renewals. Defaults to checking every 1 day. Certificates will automatically be renewed if the expire in less than 30 days.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"renew_check_interval\", 172800)\n</code></pre>"},{"location":"lua/auto-ssl/#storage_adapter","title":"<code>storage_adapter</code>","text":"<p>Default: <code>resty.auto-ssl.storage_adapters.file</code> Options: <code>resty.auto-ssl.storage_adapters.file</code>, <code>resty.auto-ssl.storage_adapters.redis</code></p> <p>The storage mechanism used for persistent storage of the SSL certificates. File-based and redis-based storage adapters are supplied, but custom external adapters may also be specified (the value simply needs to be on the <code>lua_package_path</code>).</p> <p>The default storage adapter persists the certificates to local files. However, you may want to consider another storage adapter (like redis) for a couple reason:   - File I/O causes blocking in OpenResty which should be avoided for optimal performance. However, files are only read and written the first time a certificate is seen, and then things are cached in memory, so the actual amount of file I/O should be quite minimal.   - Local files won't work if the certificates need to be shared across multiple servers (for a load-balanced environment).</p> <p>Example:</p> <pre><code>auto_ssl:set(\"storage_adapter\", \"resty.auto-ssl.storage_adapters.redis\")\n</code></pre>"},{"location":"lua/auto-ssl/#redis","title":"<code>redis</code>","text":"<p>Default: <code>{ host = \"127.0.0.1\", port = 6379 }</code></p> <p>If the <code>redis</code> storage adapter is being used, then additional connection options can be specified on this table. Accepts the following options:</p> <ul> <li><code>host</code>: Host to connect to (defaults to <code>127.0.0.1</code>).</li> <li><code>port</code>: Port to connect to (defaults to <code>6379</code>).</li> <li><code>socket</code>: Instead of specifying <code>host</code> and <code>port</code> to connect to, a unix socket path can be given instead (in the format of <code>\"unix:/path/to/unix.sock\").</code></li> <li><code>connect_options</code>: Additional connection options to pass to the Redis <code>connect</code> function.</li> <li><code>auth</code>: Value to pass to the <code>AUTH</code> command.</li> <li><code>db</code>: The Redis database number used by lua-resty-auto-ssl to save certificates</li> <li><code>prefix</code>: Prefix all keys stored in Redis with this string.</li> </ul> <p>Example:</p> <pre><code>auto_ssl:set(\"redis\", {\n  host = \"10.10.10.1\"\n})\n</code></pre>"},{"location":"lua/auto-ssl/#request_domain","title":"<code>request_domain</code>","text":"<p>Default: <code>function(ssl, ssl_options) return ssl.server_name() end</code></p> <p>A function that determines the hostname of the request. By default, the SNI domain is used, but a custom function can be implemented to determine the domain name for non-SNI requests (by basing the domain on something that can be determined outside of SSL, like the port or IP address that received the request).</p> <p>The callback function's arguments are:</p> <ul> <li><code>ssl</code>: An instance of the <code>ngx.ssl</code> module.</li> <li><code>ssl_options</code>: A table of optional configuration options that were passed to the <code>ssl_certificate</code> function. This can be used to customize the behavior on a per nginx <code>server</code> basis.</li> </ul> <p>Example:</p> <p>This example, along with the accompanying nginx <code>server</code> blocks, will default to SNI domain names, but for non-SNI clients will respond with predefined hosts based on the connecting port. Connections to port 9000 will register and return a certificate for <code>foo.example.com</code>, while connections to port 9001 will register and return a certificate for <code>bar.example.com</code>. Any other ports will return the default nginx fallback certificate.</p> <pre><code>auto_ssl:set(\"request_domain\", function(ssl, ssl_options)\n  local domain, err = ssl.server_name()\n  if (not domain or err) and ssl_options and ssl_options[\"port\"] then\n    if ssl_options[\"port\"] == 9000 then\n      domain = \"foo.example.com\"\n    elseif ssl_options[\"port\"] == 9001 then\n      domain = \"bar.example.com\"\n    end\n  end\n\n  return domain, err\nend)\n</code></pre> <pre><code>server {\n  listen 9000 ssl;\n  ssl_certificate_by_lua_block {\n    auto_ssl:ssl_certificate({ port = 9000 })\n  }\n}\n\nserver {\n  listen 9001 ssl;\n  ssl_certificate_by_lua_block {\n    auto_ssl:ssl_certificate({ port = 9001 })\n  }\n}\n</code></pre>"},{"location":"lua/auto-ssl/#ca","title":"<code>ca</code>","text":"<p>Default: the default Let's Encrypt CA</p> <p>URL of the Let's Encrypt environment to use. Normally you should not set this, unless you want make us of Let's Encrypts staging environment.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"ca\", \"https://some-other-letsencrypt.org/directory\")\n</code></pre>"},{"location":"lua/auto-ssl/#hook_server_port","title":"<code>hook_server_port</code>","text":"<p>Default: 8999</p> <p>Internally we use a special server running on port 8999 for handling certificate tasks. The port used for this service may be changed here. Please note that you will also need to change it in your nginx configuration.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"hook_server_port\", 90)\n</code></pre>"},{"location":"lua/auto-ssl/#json_adapter","title":"<code>json_adapter</code>","text":"<p>Default: <code>resty.auto-ssl.json_adapters.cjson</code> Options: <code>resty.auto-ssl.json_adapters.cjson</code>, <code>resty.auto-ssl.json_adapters.dkjson</code></p> <p>The JSON adapter to use for encoding and decoding JSON. Defaults to using cjson, which is bundled with OpenResty installations and should probably be used in most cases. However, an adapter using the pure Lua dkjson can be used for environments where cjson may not be available (you will need to manually install the dkjson dependency via luarocks to use this adapter).</p> <p>cjson and dkjson json adapters are supplied, but custom external adapters may also be specified (the value simply needs to be on the <code>lua_package_path</code>).</p> <p>Example:</p> <pre><code>auto_ssl:set(\"json_adapter\", \"resty.auto-ssl.json_adapters.dkjson\")\n</code></pre>"},{"location":"lua/auto-ssl/#http_proxy_options","title":"<code>http_proxy_options</code>","text":"<p>Default: <code>nil</code></p> <p>Configure an HTTP proxy to use when making OCSP stapling requests. Accepts a table of options for lua-resty-http's <code>set_proxy_options</code>.</p> <p>Example:</p> <pre><code>auto_ssl:set(\"http_proxy_options\", {\n  http_proxy = \"http://localhost:3128\",\n})\n</code></pre>"},{"location":"lua/auto-ssl/#ssl_certificate-configuration","title":"<code>ssl_certificate</code> Configuration","text":"<p>The <code>ssl_certificate</code> function accepts an optional table of configuration options. These options can be used to customize and control the SSL behavior on a per nginx <code>server</code> basis. Some built-in options may control the default behavior of lua-resty-auto-ssl, but any other custom data can be given as options, which will then be passed along to the <code>allow_domain</code> and <code>request_domain</code> callback functions.</p> <p>Built-in configuration options:</p>"},{"location":"lua/auto-ssl/#generate_certs","title":"<code>generate_certs</code>","text":"<p>Default: true</p> <p>This variable can be used to disable generating certs on a per server block location.</p> <p>Example:</p> <pre><code>server {\n  listen 8443 ssl;\n  ssl_certificate_by_lua_block {\n    auto_ssl:ssl_certificate({ generate_certs = false })\n  }\n}\n</code></pre>"},{"location":"lua/auto-ssl/#advanced-lets-encrypt-configuration","title":"Advanced Let's Encrypt Configuration","text":"<p>Internally, lua-resty-auto-ssl uses dehydrated as it's Let's Encrypt client. If you'd like to adjust lower-level settings, like the private key size, public key algorithm, or your registration e-mail, these settings can be configured in a custom dehydrated configuration file.</p> <ul> <li>For a full list of supported options, see dehydrated's example config.</li> <li>Custom dehydrated configuration files can be placed inside the <code>/etc/resty-auto-ssl/letsencrypt/conf.d</code> directory by default (or adjust the path if you've changed the default lua-resty-auto-ssl <code>dir</code> setting).</li> </ul> <p>Example <code>/etc/resty-auto-ssl/letsencrypt/conf.d/custom.sh</code>:</p> <pre><code>KEYSIZE=\"4096\"\nKEY_ALGO=\"rsa\"\nCONTACT_EMAIL=\"foo@example.com\"\n</code></pre>"},{"location":"lua/auto-ssl/#precautions","title":"Precautions","text":"<ul> <li>Allowed Hosts: By default, resty-auto-ssl will not perform any SSL registrations until you define the <code>allow_domain</code> function. You may return <code>true</code> to handle all possible domains, but be aware that bogus SNI hostnames can then be used to trigger an indefinite number of SSL registration attempts (which will be rejected). A better approach may be to whitelist the allowed domains in some way.</li> <li>Untrusted Code: Ensure your OpenResty server where this is installed cannot execute untrusted code. The certificates and private keys have to be readable by the web server user, so it's important that this data is not compromised.</li> <li>File Storage: The default storage adapter persists the certificates to local files. However, you may want to consider another storage adapter (like redis) for a couple reason:</li> <li>File I/O causes blocking in OpenResty which should be avoided for optimal performance. However, files are only read and written the first time a certificate is seen, and then things are cached in memory, so the actual amount of file I/O should be quite minimal.</li> <li>Local files won't work if the certificates need to be shared across multiple servers (for a load-balanced environment).</li> </ul>"},{"location":"lua/auto-ssl/#development","title":"Development","text":"<p>After checking out the repo, Docker can be used to run the test suite:</p> <pre><code>$ docker-compose run --rm app make test\n</code></pre> <p>Tests can be found in the <code>spec</code> directory, and the test suite is implemented using busted.</p>"},{"location":"lua/auto-ssl/#release-process","title":"Release Process","text":"<p>To release a new version to LuaRocks:</p> <ul> <li>Ensure <code>CHANGELOG.md</code> is up to date.</li> <li>Move the rockspec file to the new version number (<code>git mv lua-resty-auto-ssl-X.X.X-1.rockspec lua-resty-auto-ssl-X.X.X-1.rockspec</code>), and update the <code>version</code> and <code>tag</code> variables in the rockspec file.</li> <li>Commit and tag the release (<code>git tag -a vX.X.X -m \"Tagging vX.X.X\" &amp;&amp; git push origin vX.X.X</code>).</li> <li>Run <code>make release VERSION=X.X.X</code>.</li> <li>Copy the CHANGELOG notes into a new GitHub Release.</li> </ul>"},{"location":"lua/auto-ssl/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-auto-ssl.</p>"},{"location":"lua/aws-auth/","title":"aws-auth: Lua resty module to calculate AWS signature v4 authorization header","text":""},{"location":"lua/aws-auth/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/aws-auth/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-aws-auth\n</code></pre>"},{"location":"lua/aws-auth/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-aws-auth\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-aws-auth v0.12  released on Jan 13 2017.</p> <p>Simple lua resty utilities to generate amazon v4 authorization and signature headers.</p>"},{"location":"lua/aws-auth/#usage","title":"Usage","text":"<pre><code>local aws_auth = require \"resty.aws-auth\"\nlocal config = {\n  aws_host       = \"email.us-east-1.amazonaws.com\",\n  aws_key        = \"AKIDEXAMPLE\",\n  aws_secret     = \"xxxsecret\",\n  aws_region     = \"us-east-1\",\n  aws_service    = \"ses\",\n  content_type   = \"application/x-www-form-urlencoded\",\n  request_method = \"POST\",\n  request_path   = \"/\",\n  request_body   = { hello=\"world\" } -- table of all request params\n}\n\nlocal aws = aws_auth:new(config)\n\n-- get the generated authorization header\n-- eg: AWS4-HMAC-SHA256 Credential=AKIDEXAMPLE/20150830/us-east-1/iam/aws4_request,\n---    SignedHeaders=content-type;host;x-amz-date, Signature=xxx\nlocal auth = aws:get_authorization_header()\n\n-- get the x-amz-date header\nlocal amz_date = aws:get_amz_date_header()\n</code></pre> <p>Add Authorization and x-amz-date header to ngx.req.headers</p> <pre><code>aws:set_ngx_auth_headers()\n</code></pre> <p>Reference Signing AWS With Signature V4 AWS service namespaces list AWS region and endpoints</p>"},{"location":"lua/aws-auth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-aws-auth.</p>"},{"location":"lua/aws-sdk/","title":"aws-sdk: Make api call to aws services","text":""},{"location":"lua/aws-sdk/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/aws-sdk/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-aws-sdk\n</code></pre>"},{"location":"lua/aws-sdk/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-aws-sdk\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-aws-sdk v0.1.0  released on Nov 22 2016.</p> <p>lua-resty-aws-sdk - a raw aws sdk generated from API specification</p>"},{"location":"lua/aws-sdk/#status","title":"Status","text":"<p>This library is not ready for production.</p>"},{"location":"lua/aws-sdk/#description","title":"Description","text":"<p>This Lua library provides basic aws request signing and creating feature. You can use this module with <code>proxy_pass</code>, or <code>lua-resty-http</code> or any other library you want.</p>"},{"location":"lua/aws-sdk/#synopsis","title":"Synopsis","text":"<pre><code>local lambda = require 'resty.aws.lambda'\nlocal cred = requrie 'resty.aws.cred'\nlocal json = require 'cjson'\n\nlocal c = cred.from_env()\nlocal l = lambda:new()\nlocal body = json.encode({\n  foo = 'bar'\n})\n\nlocal req = l:Invoke(c, {\n    FunctionName = 'test' \n    ['X-Amz-Client-Context'] = '&lt;some_base64_json_context&gt;'\n}, body)\n\n-- do something with req\n</code></pre>"},{"location":"lua/aws-sdk/#request-structure","title":"Request Structure","text":"<p>The <code>req</code> variable in the code above is just a data object which includes the following informations:</p> <ul> <li>headers - headers as a <code>{ { k, v } }</code> list</li> <li>hostname - the hostname which you can send the api request to</li> <li>port - the port, 443 only</li> <li>pathname - the pathname for the api</li> <li>method - the request method you can use to send the api request</li> <li>query - the query string as string</li> <li>body - the request body</li> </ul> <p>Because the aws sdk api only provides you data. You can build your own APIs on top of them. It doesn't care about which <code>http</code> library you use.</p>"},{"location":"lua/aws-sdk/#credentials","title":"Credentials","text":"<p>AWS credentials is a very important in the API request. So make sure you choose the right way to read and pass your credential to the request.</p> <p>In this library. It provides a module called <code>resty.aws.cred</code>. Which allows you get your credential from different places.</p> <p>The credential table will have a data structure which looks like this:</p> <pre><code>{\n  key = String,\n  secret = String,\n  session_token = ?String\n}\n</code></pre> <p>The session token is widly used in different places <code>iam/sts</code>. But is not a required field.</p>"},{"location":"lua/aws-sdk/#from_env","title":"<code>from_env</code>","text":"<p>This function will help you create a new credential table using <code>AWS_</code> related environment variables, the name of the variables are consist with <code>aws-cli</code>. </p> <ul> <li>AWS_ACCESS_KEY_ID</li> <li>AWS_SECRET_ACCESS_KEY</li> <li>AWS_SESSION_TOKEN</li> </ul> <pre><code>local c = require 'resty.aws.cred'\nlocal credential = c.from_env()\n</code></pre>"},{"location":"lua/aws-sdk/#from_iam","title":"<code>from_iam</code>","text":"<p>This function will help you create a new credential table using <code>iam</code> role which your related to the resource(ec2/ecs/..) you use. It simply sends http request to <code>169.254.169.254</code> to get the metadata informations. For more information about <code>iam</code> role and metadata. You need to check the AWS Document about it.</p> <pre><code>local c = require 'resty.aws.cred'\nlocal credential = c.from_iam('lambdainvoke')\n</code></pre>"},{"location":"lua/aws-sdk/#contribute","title":"Contribute","text":"<p>Service source files are generated using the <code>codegen/main.lua</code> file to create. All service file share the same format. And <code>botocore</code> as a submodule provides a nice API specification. We don't need to do the busywork to create lua api for every service manually. Instead, once we finish the code generation script. The <code>api-spec</code> + <code>codegen</code> will generate the code for us. So, don't change the code manually in the <code>lib/resty/aws</code> directory.</p>"},{"location":"lua/aws-sdk/#support-signature-methods","title":"Support signature methods","text":"<ul> <li>v4</li> </ul>"},{"location":"lua/aws-sdk/#implemented-services","title":"Implemented Services","text":"<ul> <li><code>resty.aws.lambda</code></li> <li><code>resty.aws.sqs</code></li> <li><code>resty.aws.sns</code></li> </ul>"},{"location":"lua/aws-sdk/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-aws-sdk.</p>"},{"location":"lua/balancer/","title":"balancer: A generic consistent hash implementation for nginx-module-lua","text":""},{"location":"lua/balancer/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/balancer/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-balancer\n</code></pre>"},{"location":"lua/balancer/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-balancer\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-balancer v0.5  released on May 24 2023.</p> <p>lua-resty-chash - A generic consistent hash implementation for OpenResty/LuaJIT</p> <p>lua-resty-roundrobin - A generic roundrobin implementation for OpenResty/LuaJIT</p>"},{"location":"lua/balancer/#status","title":"Status","text":"<p>This library is still under early development and is still experimental.</p>"},{"location":"lua/balancer/#description","title":"Description","text":"<p>This Lua library can be used with <code>balancer_by_lua*</code>.</p>"},{"location":"lua/balancer/#synopsis","title":"Synopsis","text":"<pre><code>    init_by_lua_block {\n        local resty_chash = require \"resty.chash\"\n        local resty_roundrobin = require \"resty.roundrobin\"\n        local resty_swrr = require \"resty.swrr\"\n\n        local server_list = {\n            [\"127.0.0.1:1985\"] = 2,\n            [\"127.0.0.1:1986\"] = 2,\n            [\"127.0.0.1:1987\"] = 1,\n        }\n\n        -- XX: we can do the following steps to keep consistency with nginx chash\n        local str_null = string.char(0)\n\n        local servers, nodes = {}, {}\n        for serv, weight in pairs(server_list) do\n            -- XX: we can just use serv as id when we doesn't need keep consistency with nginx chash\n            local id = string.gsub(serv, \":\", str_null)\n\n            servers[id] = serv\n            nodes[id] = weight\n        end\n\n        local chash_up = resty_chash:new(nodes)\n\n        package.loaded.my_chash_up = chash_up\n        package.loaded.my_servers = servers\n\n        local rr_up = resty_roundrobin:new(server_list)\n        package.loaded.my_rr_up = rr_up\n\n        local swrr_up = resty_swrr:new(server_list)\n        package.loaded.my_swrr_up = swrr_up\n    }\n\n    upstream backend_chash {\n        server 0.0.0.1;\n        balancer_by_lua_block {\n            local b = require \"ngx.balancer\"\n\n            local chash_up = package.loaded.my_chash_up\n            local servers = package.loaded.my_servers\n\n            -- we can balancer by any key here\n            local id = chash_up:find(ngx.var.arg_key)\n            local server = servers[id]\n\n            assert(b.set_current_peer(server))\n        }\n    }\n\n    upstream backend_rr {\n        server 0.0.0.1;\n        balancer_by_lua_block {\n            local b = require \"ngx.balancer\"\n\n            local rr_up = package.loaded.my_rr_up\n\n            -- Note that Round Robin picks the first server randomly\n            local server = rr_up:find()\n\n            assert(b.set_current_peer(server))\n        }\n    }\n\n    upstream backend_swrr {\n        server 0.0.0.1;\n        balancer_by_lua_block {\n            local b = require \"ngx.balancer\"\n\n            local swrr_up = package.loaded.my_swrr_up\n\n            -- Note that SWRR picks the first server randomly\n            local server = swrr_up:find()\n\n            assert(b.set_current_peer(server))\n        }\n    }\n\n    server {\n        location /chash {\n            proxy_pass http://backend_chash;\n        }\n\n        location /roundrobin {\n            proxy_pass http://backend_rr;\n        }\n\n        location /swrr {\n            proxy_pass http://backend_swrr;\n        }\n    }\n</code></pre>"},{"location":"lua/balancer/#methods","title":"Methods","text":"<p>Both <code>resty.chash</code>, <code>resty.roundrobin</code> and <code>resty.swrr</code> have the same apis.</p>"},{"location":"lua/balancer/#new","title":"new","text":"<p>syntax: <code>obj, err = class.new(nodes)</code></p> <p>Instantiates an object of this class. The <code>class</code> value is returned by the call <code>require \"resty.chash\"</code>.</p> <p>The <code>id</code> should be <code>table.concat({host, string.char(0), port})</code> like the nginx chash does, when we need to keep consistency with nginx chash.</p> <p>The <code>id</code> can be any string value when we do not need to keep consistency with nginx chash. The <code>weight</code> should be a non negative integer.</p> <pre><code>local nodes = {\n    -- id =&gt; weight\n    server1 = 10,\n    server2 = 2,\n}\n\nlocal resty_chash = require \"resty.chash\"\n\nlocal chash = resty_chash:new(nodes)\n\nlocal id = chash:find(\"foo\")\n\nngx.say(id)\n</code></pre>"},{"location":"lua/balancer/#reinit","title":"reinit","text":"<p>syntax: <code>obj:reinit(nodes)</code></p> <p>Reinit the chash obj with the new <code>nodes</code>.</p>"},{"location":"lua/balancer/#set","title":"set","text":"<p>syntax: <code>obj:set(id, weight)</code></p> <p>Set <code>weight</code> of the <code>id</code>.</p>"},{"location":"lua/balancer/#delete","title":"delete","text":"<p>syntax: <code>obj:delete(id)</code></p> <p>Delete the <code>id</code>.</p>"},{"location":"lua/balancer/#incr","title":"incr","text":"<p>syntax: <code>obj:incr(id, weight?)</code></p> <p>Increments weight for the <code>id</code> by the step value <code>weight</code>(default to 1).</p>"},{"location":"lua/balancer/#decr","title":"decr","text":"<p>syntax: <code>obj:decr(id, weight?)</code></p> <p>Decrease weight for the <code>id</code> by the step value <code>weight</code>(default to 1).</p>"},{"location":"lua/balancer/#find","title":"find","text":"<p>syntax: <code>id, index = obj:find(key)</code></p> <p>Find an id by the <code>key</code>, same key always return the same <code>id</code> in the same <code>obj</code>.</p> <p>The second return value <code>index</code> is the index in the chash circle of the hash value of the <code>key</code>.</p>"},{"location":"lua/balancer/#next","title":"next","text":"<p>syntax: <code>id, new_index = obj:next(old_index)</code></p> <p>If we have chance to retry when the first <code>id</code>(server) doesn't work well, then we can use <code>obj:next</code> to get the next <code>id</code>.</p> <p>The new <code>id</code> may be the same as the old one.</p>"},{"location":"lua/balancer/#performance","title":"Performance","text":"<p>There is a benchmark script <code>t/bench.lua</code>.</p> <p>I got the result when I run <code>make bench</code>:</p> <pre><code>chash new servers\n10000 times\nelasped: 0.61600017547607\n\nchash new servers2\n1000 times\nelasped: 0.77300000190735\n\nchash new servers3\n10000 times\nelasped: 0.66899991035461\n\nnew in func\n10000 times\nelasped: 0.62000012397766\n\nnew dynamic\n10000 times\nelasped: 0.75499987602234\n\nincr server3\n10000 times\nelasped: 0.19000029563904\n\nincr server1\n10000 times\nelasped: 0.33699989318848\n\ndecr server1\n10000 times\nelasped: 0.27300024032593\n\ndelete server3\n10000 times\nelasped: 0.037999868392944\n\ndelete server1\n10000 times\nelasped: 0.065000057220459\n\nset server1 9\n10000 times\nelasped: 0.26600003242493\n\nset server1 8\n10000 times\nelasped: 0.32000017166138\n\nset server1 1\n10000 times\nelasped: 0.56699991226196\n\nbase for find\n1000000 times\nelasped: 0.01800012588501\n\nfind\n1000000 times\nelasped: 0.9469997882843\n</code></pre>"},{"location":"lua/balancer/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> <li>the json lib for Lua and C: https://github.com/cloudflare/lua-resty-json</li> </ul>"},{"location":"lua/balancer/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-balancer.</p>"},{"location":"lua/base-encoding/","title":"base-encoding: A faster alternative to base64 encoding and provides missing base encoding for nginx-module-lua application","text":""},{"location":"lua/base-encoding/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/base-encoding/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-base-encoding\n</code></pre>"},{"location":"lua/base-encoding/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-base-encoding\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-base-encoding v1.3.0  released on Jul 21 2018.</p> <p>lua-resty-base-encoding - Faster alternative to base64 encoding and provides missing base encoding for OpenResty application</p> <p>All encoding are implemented in optimized C code with LuaJIT FFI binding.</p> <p>Most of the inner encoding implementations are from Nick Galbreath's stringencoders. The base32 encoding is implemented by myself, but also inspired from his art work.</p> <p>Build status: </p>"},{"location":"lua/base-encoding/#methods","title":"Methods","text":""},{"location":"lua/base-encoding/#encode_base2","title":"encode_base2","text":"<p><code>syntax: encoded = encode_base2(raw)</code></p> <p>Encode given string into base2 format(aka. bin format). Note that the input is string. Therefore, the <code>encode_base2</code> result of <code>1</code> is <code>00110001</code>, because the ascii value of <code>1</code> is 49, and the binary format of 49 is <code>00110001</code>. And don't forget that the output of <code>encode_base2</code> is a string instead of a binary number.</p>"},{"location":"lua/base-encoding/#decode_base2","title":"decode_base2","text":"<p><code>syntax: raw, err = decode_base2(encoded)</code></p> <p>Decode base2 format string into its raw value. If the given string is not valid base2 encoded, the <code>raw</code> will be <code>nil</code> and <code>err</code> will be <code>\"invalid input\"</code>. Any character in the input string which is not <code>1</code> will be considered as <code>0</code>. For example, <code>aa11aaa1</code> is equal to <code>00110001</code>. There is no RFC requires we should treat character not in <code>0</code> and <code>1</code> as invalid input, and check if a character is '0' or not will slow the performance down by 50%.</p>"},{"location":"lua/base-encoding/#encode_base16","title":"encode_base16","text":"<p><code>syntax: encoded = encode_base16(raw[, out_in_lowercase])</code></p> <p>Encode given string into base16 format(aka. hex/hexadecimal format). This method may be named <code>to_hex</code> or <code>encodeHex</code> in other languages. The default output letters are in <code>[0-9A-F]</code>. If you specify the <code>out_in_lowercase</code> to <code>true</code>, the output will be in <code>[0-9a-f]</code>.</p>"},{"location":"lua/base-encoding/#decode_base16","title":"decode_base16","text":"<p><code>syntax: raw, err = decode_base16(encoded)</code></p> <p>Decode base16 format(aka. hex/hexadecimal format) string into its raw value. This method may be named <code>from_hex</code> or <code>decodeHex</code> in other languages. If the given string is not valid base16 encoded, the <code>raw</code> will be <code>nil</code> and <code>err</code> will be <code>\"invalid input\"</code>. Letters in <code>[0-9a-fA-F]</code> are considered valid.</p>"},{"location":"lua/base-encoding/#encode_base32","title":"encode_base32","text":"<p><code>syntax: encoded = encode_base32(raw[, no_padding])</code></p> <p>Encode given string into base32 format with/without padding '='. The default value of <code>no_padding</code> is false.</p>"},{"location":"lua/base-encoding/#decode_base32","title":"decode_base32","text":"<p><code>syntax: raw, err = decode_base32(encoded)</code></p> <p>Decode base32 format string into its raw value. If the given string is not valid base32 encoded, the <code>raw</code> will be <code>nil</code> and <code>err</code> will be <code>\"invalid input\"</code>.</p>"},{"location":"lua/base-encoding/#encode_base32hex","title":"encode_base32hex","text":"<p><code>syntax: encoded = encode_base32hex(raw[, no_padding])</code></p> <p>Encode given string into base32hex format with/without padding '='. The default value of <code>no_padding</code> is false. For more info of base32hex format, see https://tools.ietf.org/html/rfc4648#section-7.</p>"},{"location":"lua/base-encoding/#decode_base32hex","title":"decode_base32hex","text":"<p><code>syntax: raw, err = decode_base32(encoded)</code></p> <p>Decode base32hex format string into its raw value. If the given string is not valid base32hex encoded, the <code>raw</code> will be <code>nil</code> and <code>err</code> will be <code>\"invalid input\"</code>. For more info of base32hex format, see https://tools.ietf.org/html/rfc4648#section-7.</p>"},{"location":"lua/base-encoding/#encode_base64","title":"encode_base64","text":""},{"location":"lua/base-encoding/#decode_base64","title":"decode_base64","text":""},{"location":"lua/base-encoding/#encode_base64url","title":"encode_base64url","text":""},{"location":"lua/base-encoding/#decode_base64url","title":"decode_base64url","text":"<p>Drop-in alternative to the official implementation in lua-resty-core. Read their official documentation instead. The encode method is 40% faster, and the decode method is 200% faster. Note that the implementation is endian and architecture dependent. Read the 'Must Read' section for more info.</p>"},{"location":"lua/base-encoding/#encode_base85","title":"encode_base85","text":"<p><code>syntax: encoded = encode_base85(raw)</code></p> <p>Encode given string into base85 format with/without padding '='. Note that there is not a standard but too many variants of so-called base85. This module's implementation should be compatiable with Go's encoding/ascii85 module (not in the level of API argument, but in the level of encode/decode rules).</p>"},{"location":"lua/base-encoding/#decode_base85","title":"decode_base85","text":"<p><code>syntax: raw, err = decode_base85(encoded)</code></p> <p>Decode base85 format string into its raw value. If the given string is not valid base85 encoded, the <code>raw</code> will be <code>nil</code> and <code>err</code> will be <code>\"invalid input\"</code>.</p>"},{"location":"lua/base-encoding/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-base-encoding.</p>"},{"location":"lua/cache/","title":"cache: Http cache to redis, can server stale response, and using \"lua-resty-lock\" only allow one request to populate a new cache","text":""},{"location":"lua/cache/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/cache/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-cache\n</code></pre>"},{"location":"lua/cache/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-cache\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-cache v1.0.0  released on Aug 07 2015.</p> <p>one lua library to work with srcache, can server stale response, and using \"lua-resty-lock\" only allow one request to populate a new cache.</p> <ol> <li>if the cache is missing, skip the srcache_fetch, and make single request to populate a new cache, the other request with same cache_key, just wait update cache success.</li> <li>always set the redis expires to (real expires time + stale time), so can find the stale data from reids.</li> <li>if get stale data from redis, just send stale data to client(using ngx.eof(), the client can close this connection.)</li> <li>and then make subrequest to populate a new cache (using lua-resty-lock, so only one request send to backend server).</li> </ol>"},{"location":"lua/cache/#synopsis","title":"Synopsis","text":"<pre><code>upstream www {\n    server 127.0.0.1:9999;\n}\nupstream redis {\n    server 127.0.0.1:6379;\n    keepalive 1024;\n}\nlua_shared_dict srcache_locks 1m;\nlocation /api {\n    set $cache_lock srcache_locks;\n    set $cache_ttl /redisttl;\n    set $cache_persist /redispersist;\n    set $cache_key \"$http_user_agent|$uri\";\n    set $cache_stale 100;\n    set $cache_lock_exptime 30;\n    set $cache_backend_lock_timeout 0.01;\n    set $cache_lock_timeout 3;\n    set $cache_lock_timeout_wait 0.06;\n    set $cache_skip_fetch \"X-Skip-Fetch\";\n    set_escape_uri $escaped_key $cache_key;\n\n    rewrite_by_lua_file /usr/local/openresty/lualib/resty/cache.lua;\n\n    if ($http_x_skip_fetch != TRUE){ srcache_fetch GET /redis $cache_key;}\n    srcache_store PUT /redis2 key=$escaped_key&amp;exptime=105;\n    add_header X-Cache $srcache_fetch_status;\n    add_header X-Store $srcache_store_status;\n    #echo hello world;\n    proxy_pass http://www;\n}\nlocation = /redisttl {\n    internal;\n    set_unescape_uri $key $arg_key;\n    set_md5 $key;\n    redis2_query ttl $key;\n    redis2_pass redis;\n}\nlocation = /redispersist {\n    internal;\n    set_unescape_uri $key $arg_key;\n    set_md5 $key;\n    redis2_query persist $key;\n    redis2_pass redis;\n}\nlocation = /redis {\n    internal;\n    set_md5 $redis_key $args;\n    redis_pass redis;\n}\nlocation = /redis2 {\n    internal;\n    set_unescape_uri $exptime $arg_exptime;\n    set_unescape_uri $key $arg_key;\n    set_md5 $key;\n    redis2_query set $key $echo_request_body;\n    redis2_query expire $key $exptime;\n    redis2_pass redis;\n}\n</code></pre>"},{"location":"lua/cache/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-cache.</p>"},{"location":"lua/checkups/","title":"checkups: Manage NGINX upstreams in pure Lua","text":""},{"location":"lua/checkups/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/checkups/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-checkups\n</code></pre>"},{"location":"lua/checkups/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-checkups\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-checkups v0.1  released on Feb 01 2019.</p> <p>lua-resty-checkups - Manage Nginx upstreams in pure ngx_lua</p>"},{"location":"lua/checkups/#status","title":"Status","text":"<p>Probably production ready in most cases, though not yet proven in the wild. Please check the issues list and let me know if you have any problems / questions.</p>"},{"location":"lua/checkups/#features","title":"Features","text":"<ul> <li>Periodically heartbeat to upstream servers</li> <li>Proactive and passive health check</li> <li>Dynamic upstream update</li> <li>Balance by weighted round-robin or consistent-hash</li> <li>Synchronize with Nginx upstream blocks</li> <li>Try clusters by levels or by keys</li> </ul>"},{"location":"lua/checkups/#synopsis","title":"Synopsis","text":"<pre><code>    -- config.lua\n\n    _M = {}\n\n    _M.global = {\n        checkup_timer_interval = 15,\n        checkup_shd_sync_enable = true,\n        shd_config_timer_interval = 1,\n    }\n\n    _M.ups1 = {\n        cluster = {\n            {\n                servers = {\n                    { host = \"127.0.0.1\", port = 4444, weight=10, max_fails=3, fail_timeout=10 },\n                }\n            },\n        },\n    }\n\n    return _M\n</code></pre> <pre><code>    -- nginx.conf\n\n    lua_shared_dict state 10m;\n    lua_shared_dict mutex 1m;\n    lua_shared_dict locks 1m;\n    lua_shared_dict config 10m;\n\n    server {\n        listen 12350;\n        return 200 12350;\n    }\n\n    server {\n        listen 12351;\n        return 200 12351;\n    }\n\n    init_by_lua_block {\n        local config = require \"config\"\n        local checkups = require \"resty.checkups.api\"\n        checkups.init(config)\n    }\n\n    init_worker_by_lua_block {\n        local config = require \"config\"\n        local checkups = require \"resty.checkups.api\"\n\n        checkups.prepare_checker(config)\n        checkups.create_checker()\n    }\n\n    server {\n        location = /12350 {\n            proxy_pass http://127.0.0.1:12350/;\n        }\n        location = /12351 {\n            proxy_pass http://127.0.0.1:12351/;\n        }\n\n        location = /t {\n            content_by_lua_block {\n                local checkups = require \"resty.checkups.api\"\n\n                local callback = function(host, port)\n                    local res = ngx.location.capture(\"/\" .. port)\n                    ngx.say(res.body)\n                    return 1\n                end\n\n                local ok, err\n\n                -- connect to a dead server, no upstream available\n                ok, err = checkups.ready_ok(\"ups1\", callback)\n                if err then ngx.say(err) end\n\n                -- add server to ups1\n                ok, err = checkups.update_upstream(\"ups1\", {\n                    {\n                        servers = {\n                            { host = \"127.0.0.1\", port = 12350, weight=10, max_fails=3, fail_timeout=10 },\n                        }\n                    },\n                })\n\n                if err then ngx.say(err) end\n                ngx.sleep(1)\n                ok, err = checkups.ready_ok(\"ups1\", callback)\n                if err then ngx.say(err) end\n                ok, err = checkups.ready_ok(\"ups1\", callback)\n                if err then ngx.say(err) end\n\n                -- add server to new upstream\n                ok, err = checkups.update_upstream(\"ups2\", {\n                        {\n                            servers = {\n                                { host=\"127.0.0.1\", port=12351 },\n                            }\n                        },\n                    })\n                if err then ngx.say(err) end\n                ngx.sleep(1)\n                ok, err = checkups.ready_ok(\"ups2\", callback)\n                if err then ngx.say(err) end\n\n                -- add server to ups2, reset rr state\n                ok, err = checkups.update_upstream(\"ups2\", {\n                        {\n                            servers = {\n                                { host = \"127.0.0.1\", port = 12350, weight=10, max_fails=3, fail_timeout=10 },\n                                { host = \"127.0.0.1\", port = 12351, weight=10, max_fails=3, fail_timeout=10 },\n                            }\n                        },\n                    })\n                if err then ngx.say(err) end\n                ngx.sleep(1)\n                ok, err = checkups.ready_ok(\"ups2\", callback)\n                if err then ngx.say(err) end\n                ok, err = checkups.ready_ok(\"ups2\", callback)\n                if err then ngx.say(err) end\n            }\n        }\n    }\n</code></pre> <p>A typical output of the <code>/t</code> location defined above is:</p> <pre><code>no servers available\n12350\n12350\n12351\n12350\n12351\n</code></pre>"},{"location":"lua/checkups/#configuration","title":"Configuration","text":""},{"location":"lua/checkups/#lua-configuration","title":"Lua configuration","text":"<p>Configuration file of checkups is a lua module consists of two parts, the global part and the cluster part.</p> <p>An example configuration file of checkups is shown below,</p> <pre><code>    -- config.lua\n\n    -- Here is the global part\n\n    _M = {}\n\n    _M.global = {\n        checkup_timer_interval = 15,\n        checkup_timer_overtime = 60,\n        default_heartbeat_enable = true,\n        checkup_shd_sync_enable = true,\n        shd_config_timer_interval = 1,\n    }\n\n\n    -- The rests parts are cluster configurations\n\n    _M.redis = {\n        enable = true,\n        typ = \"redis\",\n        timeout = 2,\n        read_timeout = 15,\n        send_timeout = 15,\n\n        protected = true,\n\n        cluster = {\n            {   -- level 1\n                    try = 2,\n                servers = {\n                    { host = \"192.168.0.1\", port = 6379, weight=10, max_fails=3, fail_timeout=10 },\n                    { host = \"192.168.0.2\", port = 6379, weight=10, max_fails=3, fail_timeout=10 },\n                }\n            },\n            {   -- level 2\n                servers = {\n                    { host = \"192.168.0.3\", port = 6379, weight=10, max_fails=3, fail_timeout=10 },\n                }\n            },\n        },\n    }\n\n    _M.api = {\n        enable = false,\n        typ = \"http\",\n            http_opts = {\n            query = \"GET /status HTTP/1.1\\r\\nHost: localhost\\r\\n\\r\\n\",\n            statuses = {\n                    [\"500\"] = false,\n                    [\"502\"] = false,\n                    [\"503\"] = false,\n                    [\"504\"] = false,\n            },\n        },\n\n        mode = \"hash\",\n\n        cluster = {\n            dc1 = {\n                servers = {\n                    { host = \"192.168.1.1\", port = 1234, weight=10, max_fails=3, fail_timeout=10 },\n                }\n            },\n            dc2 = {\n                servers = {\n                    { host = \"192.168.1.2\", port = 1234, weight=10, max_fails=3, fail_timeout=10 },\n                }\n            }\n        }\n    }\n\n    _M.ups_from_nginx = {\n        timeout = 2,\n\n        cluster = {\n            {   -- level 1\n                upstream = \"api.com\",\n            },\n            {   -- level 2\n                upstream = \"api.com\",\n                upstream_only_backup = true,\n            },\n        },\n    }\n\n    return _M\n</code></pre>"},{"location":"lua/checkups/#global-configurations","title":"global configurations","text":"<ul> <li><code>checkup_timer_interval</code>: Interval of sending heartbeats to backend servers. Default is <code>5</code>.</li> <li><code>checkup_timer_overtime</code>: Interval of checkups to expire the timer key. In most cases, you don't need to change this value. Default is <code>60</code>.</li> <li><code>default_heartbeat_enable</code>: Checkups will sent heartbeats to servers by default or not. Default is <code>true</code>.</li> <li><code>checkup_shd_sync_enable</code>: Create upstream syncer for each worker. If set to <code>false</code>, dynamic upstream will not work properly. Default is <code>true</code>.</li> <li><code>shd_config_timer_interval</code>: Interval of syncing upstream list from shared memory. Default is equal to <code>checkup_timer_interval</code>.</li> <li><code>ups_status_sync_enable</code>: If set to <code>true</code>, checkups will sync upstram status from checkups to Nginx upstream blocks. Default is <code>false</code>.</li> <li><code>ups_status_timer_interval</code>: Interval of syncing upstream status from checkups to Nginx upstream blocks.</li> </ul>"},{"location":"lua/checkups/#cluster-configurations","title":"Cluster configurations","text":"<ul> <li><code>skey</code>: <code>_M.xxxxx</code>. <code>xxxxx</code> is the <code>skey</code>(service key) of this Cluster.</li> <li><code>enable</code>: Enable or disable heartbeats to servers. Default is <code>true</code>.</li> <li><code>typ</code>: Cluster type, must be one of <code>general</code>, <code>redis</code>, <code>mysql</code>, <code>http</code>. Default is <code>general</code>.<ul> <li><code>general</code>: Heartbeat by TCP <code>sock:connect</code>.</li> <li><code>redis</code>: Heartbeat by redis <code>PING</code>. lua-resty-redis module is required.</li> <li><code>mysql</code>: Heartbeat by mysql <code>db:connect</code>. lua-resty-mysql module is required.</li> <li><code>http</code>: Heartbeat by HTTP request. You can setup customized HTTP request and response codes in <code>http_opts</code>.</li> </ul> </li> <li><code>timeout</code>: Connect timeout to upstream servers. Default is <code>5</code>.</li> <li><code>read_timeout</code>: Read timeout to upstream servers (not used during heartbeating). Default is equal to <code>timeout</code>.</li> <li><code>send_timeout</code>: Write timeout to upstream servers (not used during heartbeating). Default is equal to <code>timeout</code>.</li> <li> <p><code>http_opts</code>: HTTP heartbeat configurations. Only works for <code>typ=\"http\"</code>.</p> <ul> <li><code>query</code>: HTTP request to heartbeat.</li> <li><code>statuses</code>: If the code returned by server is set to <code>false</code>, then the server is considered to be failing.</li> </ul> </li> <li> <p><code>mode</code>: Balance mode. Can be set to <code>hash</code>, <code>url_hash</code> or <code>ip_hash</code>. Checkups will balance servers by <code>hash_key</code>, <code>ngx.var.uri</code> or <code>ngx.var.remote_addr</code>. Default is <code>wrr</code>.</p> </li> <li><code>protected</code>: If set to <code>true</code> and all the servers in the cluster are failing, checkups will not mark the last failing server as unavailable(<code>err</code>), instead, it will be marked as <code>unstable</code>(still available in next try). Default is <code>true</code>.</li> <li> <p><code>cluster</code>: You can configure multiple levels according to the cluster priority, at each level you can configure a cluster of <code>servers</code>. Checkups will try next level only when all the servers in the prior level are consitered unavailable.</p> <p>Instead of trying clusters by levels, you can configure checkups trying clusters by key(see <code>api</code> cluster above). Remember you should also pass extra argument like <code>opts.cluster_key={\"dc1\", \"dc2\"}</code> or <code>opts.cluster_key={3, 1, 2}</code> to checkups.read_ok to make checkups trying on the order of <code>dc1</code>, <code>dc2</code> or <code>level 3</code>, <code>level 1</code>, <code>level 2</code>. If you haven't passed <code>opts.cluster_key</code> to checkups.ready_ok, checkups will still try clusters by levels. As for the above <code>api</code> cluster, checkups will eventually return <code>no servers available</code>. * <code>try</code>: Retry count. Default is the number of servers. * <code>try_timeout</code>: Limits the time during which a request can be responsed, likewise nginx <code>proxy_next_upstream_timeout</code>. * <code>servers</code>: Configuration for <code>servers</code> are listed as follows,     * <code>weight</code>: Sets the weight of the server. Default is <code>1</code>.     * <code>max_fails</code>: Sets the number of unsuccessful attempts to communicate with the server that should happen in the duration set by the <code>fail_timeout</code> parameter. By default, the number of unsuccessful attempts is set to <code>0</code>, which disables the accounting of attempts. What is considered an unsuccessful attempt is defined by <code>http_opts.statuses</code> if <code>typ=\"http\"</code> or a <code>nil</code>/<code>false</code> returned by checkups.ready_ok. This options is only available in round-robin.     * <code>fail_timeout</code>: Sets the time during which the specified number of unsuccessful attempts to communicate with the server should happen to consider the server unavailable and the period of time the server will be considered unavailable. By default, the parameter is set to <code>10</code> seconds. This options is only available in round-robin.</p> <ul> <li><code>upstream</code>: Name of Nginx upstream blocks. Checkups will extract servers from Nginx conf's upstream blocks in prepare_checker. lua-upstream-nginx-module module is required.</li> <li><code>upstream_only_backup</code>: If set to <code>true</code>, checkups will only extract backup servers from Nginx upstream blocks.</li> </ul> </li> </ul>"},{"location":"lua/checkups/#nginx-configuration","title":"Nginx configuration","text":"<p>Add pathes of lua config file and checkups to <code>lua_package_path</code> and create lua shared dicts used by checkups. You should put these lines into <code>http</code> block of your Nginx config file.</p> <pre><code>lua_shared_dict state 10m;\nlua_shared_dict mutex 1m;\nlua_shared_dict locks 1m;\nlua_shared_dict config 10m;\n</code></pre> <p>If you use stream subsystem, you should put these lines into <code>stream</code> block of your Nginx config file.</p> <pre><code>lua_shared_dict stream_state 10m;\nlua_shared_dict stream_mutex 1m;\nlua_shared_dict stream_locks 1m;\nlua_shared_dict stream_config 10m;\n</code></pre>"},{"location":"lua/checkups/#api","title":"API","text":""},{"location":"lua/checkups/#init","title":"init","text":"<p>syntax: init(config)</p> <p>phase: init_by_lua</p> <p>Copy upstreams from <code>config.lua</code> to shdict, extract servers from Nginx upstream blocks and do some basic initialization.</p>"},{"location":"lua/checkups/#prepare_checker","title":"prepare_checker","text":"<p>syntax: prepare_checker(config)</p> <p>phase: init_worker_by_lua</p> <p>Copy configurations from <code>config.lua</code> to worker checkups, extract servers from Nginx upstream blocks and do some basic initialization.</p>"},{"location":"lua/checkups/#create_checker","title":"create_checker","text":"<p>syntax: create_checker()</p> <p>phase: init_worker_by_lua</p> <p>Create heartbeat timer and upstream sync timer. Only one heartbeat timer will be created among all the workers. It's highly recommended to call this method in <code>init_worker</code> phase.</p>"},{"location":"lua/checkups/#ready_ok","title":"ready_ok","text":"<p>syntax: res, err = ready_ok(skey, callback, opts?)</p> <p>phase: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>Select an available <code>peer</code> from cluster <code>skey</code> and call <code>callback(peer.host, peer.port, opts)</code>.</p> <p>The <code>opts</code> table accepts the following fields,</p> <ul> <li><code>cluster_key</code>: Try clusters by <code>cluster_key</code>. Checkups will try clusters on the order of <code>cluster_key</code>. <code>clusters_key</code> can be the name of the clusters or the level of the clusters. clusters eg: <code>{\"cluster_name_A\", \"name_B\", \"name_C\"}</code>. levels eg: <code>{3, 2, 1}</code>.</li> <li><code>hash_key</code>: Key used in <code>hash</code> balance mode. If not set, <code>ngx.var.uri</code> will be used.</li> <li><code>try</code>: Retry will be no more than <code>try</code> times.</li> <li><code>try_timeout</code>: Limits the time during which a request can be responsed, likewise nginx <code>proxy_next_upstream_timeout</code>.</li> </ul> <p>Returns what <code>callback</code> returns on success, or returns <code>nil</code> and a string describing the error otherwise.</p> <p>If <code>callback</code> returns <code>nil</code> or <code>false</code>, checkups will consider it to be a failed try and will retry <code>callback</code> with another peer. So, always remember not to return <code>nil</code> or <code>false</code> after a successful callback.</p>"},{"location":"lua/checkups/#select_peer","title":"select_peer","text":"<p>syntax: peer, err = select_peer(skey)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, balancer_by_lua</p> <p>Select an available peer from cluster <code>skey</code>.</p> <p>Return a table containing <code>host</code> and <code>port</code> of an available peer.</p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/checkups/#get_status","title":"get_status","text":"<p>syntax: status = get_status()</p> <p>phase: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>Return checkups status in <code>json</code> format.</p>"},{"location":"lua/checkups/#get_ups_timeout","title":"get_ups_timeout","text":"<p>syntax: connect_timeout, send_timeout, read_timeout = get_ups_timeout(skey)</p> <p>phase: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>Return timeout of cluster <code>skey</code>.</p>"},{"location":"lua/checkups/#feedback_status","title":"feedback_status","text":"<p>syntax: ok, err = feedback_status(skey, host, port, failed)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, balancer_by_lua.*</p> <p>Mark server <code>host:port</code> in cluster <code>skey</code> as failed(<code>true</code>) or available(<code>false</code>).</p> <p>Returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.</p>"},{"location":"lua/checkups/#update_upstream","title":"update_upstream","text":"<p>syntax: ok, err = update_upstream(skey, upstream)</p> <p>phase: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>Update cluster <code>skey</code>. <code>upstream</code> is in the same format as <code>cluster</code> in <code>config.lua</code>.</p> <p>Returns <code>true</code> on success, or returns <code>false</code> and a string describing the error otherwise.</p>"},{"location":"lua/checkups/#delete_upstream","title":"delete_upstream","text":"<p>syntax: ok, err = delete_upstream(skey)</p> <p>phase: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>Delete cluster <code>skey</code> from upstream list.</p> <p>Returns <code>true</code> on success, or returns <code>false</code> and a string describing the error otherwise.</p>"},{"location":"lua/checkups/#see-also","title":"See Also","text":"<ul> <li>lua-nginx-module</li> </ul>"},{"location":"lua/checkups/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-checkups.</p>"},{"location":"lua/consul-event/","title":"consul-event: Consul Events HTTP API Wrapper","text":""},{"location":"lua/consul-event/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/consul-event/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-consul-event\n</code></pre>"},{"location":"lua/consul-event/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-consul-event\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-consul-event v0.3.0  released on Jun 17 2019.</p> <p>Consul Events HTTP API Wrapper</p>"},{"location":"lua/consul-event/#overview","title":"Overview","text":"<p>This module provides an OpenResty client wrapper for the Consul Events API. This allows for OpenResty integration with Consul's custom user event mechanism, which can be used to build scripting infrastructure to do automated deploys, restart services, or perform any other orchestration action.</p> <p>This module leverages Consul's concept of blocking queries to watch for events broadcast on a given event name.</p>"},{"location":"lua/consul-event/#synopsis","title":"Synopsis","text":"<pre><code>local event = require \"resty.consul.event\"\n\nlocal e, err = event.new({\n  host = \"127.0.0.1\",\n  port = 8500,\n})\n\nif err then\n  ngx.log(ngx.ERR, err)\nend\n\ne:watch(\"foo\", function(event)\n  ngx.log(ngx.INFO, \"i got \", ngx.decode_base64(event.payload))\nend)\n</code></pre>"},{"location":"lua/consul-event/#usage","title":"Usage","text":""},{"location":"lua/consul-event/#new","title":"new","text":"<p><code>syntax: e, err = event.new(opts?)</code></p> <p>Instantiates a new watch object. <code>opts</code> may be a table with the following options: </p> <ul> <li><code>host</code>: String defining the Consul host</li> <li><code>port</code>: Number defining the Consul port</li> <li><code>timeout</code>: Number, in seconds, to pass to Consul blocking query API via the <code>wait</code> parameter. This value is also used to to define TCP layer timeouts, which are set higher than the application-layer timeout.</li> <li><code>ssl_verify</code>: Boolean defining whether to validate the TLS certificate presented by the remote Consul server.</li> <li><code>token</code>: String defining the Consul ACL token to send via the <code>X-Consul-Token</code> request header.</li> </ul>"},{"location":"lua/consul-event/#watch","title":"watch","text":"<p><code>syntax: e:watch(name, callback, initial_index, seen_ids)</code></p> <p>Watch the Consul events API for events broadcast under a given <code>name</code>, and execute the function <code>callback</code> . <code>callback</code> is passed a single parameter <code>event</code>, which contains the body of a single event as defined by the Consul Events API. Callback functions are wrapped in <code>pcall</code>, so it is safe to throw an error from within this function. Callback functions may return a single value but this value is largely meaningless; currently, this single value is logged as a debug entry.</p> <p>The values <code>initial_index</code> and <code>seen_ids</code> are optional, and can be used to initialize the watch against a certain state in the Consul events ring. <code>initial_index</code> is expected to be a string output by a previous <code>X-Consul-Index</code> header. <code>seen_ids</code> is expected to be a list of Consul Event ID values for whom callback events should not be executed. For example, the current state of the event buffer can be used to initialize a given watch:</p> <pre><code>local h = require(\"resty.http\").new()\n\n-- get the current events\nlocal res, err = h:request_uri(\"http://127.0.0.1:8500/v1/event/list?name=foo\")\nif err then\n  ngx.log(ngx.ERR, err)\nend\n\nlocal event = require \"resty.consul.event\"\n\nlocal e, err = event.new({\n  host = \"127.0.0.1\",\n  port = 8500,\n})\nif err then\n  ngx.log(ngx.ERR, err)\nend\n\nlocal l = {}\n\nfor _, e in ipairs(require(\"cjson\").decode(res.body)) do\n  table.insert(l, e.ID)\nend\n\nngx.timer.at(0, function()\n  e:watch(\n    \"foo\",\n    function(p) ngx.log(ngx.DEBUG, p.payload) end,\n    res.headers[\"X-Consul-Index\"],\n    l\n  )\nend)\n</code></pre> <p>Note: This body of this function runs in an infinite loop in order to watch the Consul events API indefinitely. As a result, it is strongly recommended to call this function inside a background timer generated via ngx.timer.at</p>"},{"location":"lua/consul-event/#testing","title":"Testing","text":"<p>A test suite for this repo is provided. Tests are written using Test::Nginx and executed with <code>prove</code>.</p> <p>To best test library behavior, the suite expects a Consul server to be running and accessible. By default, Consul is accessed at <code>127.0.0.1:8500</code>; the Consul host and port can be overriden by defining the environmental variables <code>TEST_NGINX_CONSUL_ADDR</code> and <code>TEST_NGINX_CONSUL_PORT</code>, respectively.</p>"},{"location":"lua/consul-event/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-consul-event.</p>"},{"location":"lua/consul/","title":"consul: Library to interface with the consul HTTP API from nginx-module-lua","text":""},{"location":"lua/consul/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/consul/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-consul\n</code></pre>"},{"location":"lua/consul/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-consul\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-consul v0.4.0  released on Aug 18 2021.</p> <p>Library to interface with the consul HTTP API from ngx_lua</p>"},{"location":"lua/consul/#overview","title":"Overview","text":"<p>Methods all return a lua-resty-http response object. The response body has been read and set to <code>res.body</code>, JSON decoded if the response has a <code>Content-Type</code> header of <code>Application/JSON</code>.</p> <p>All response headers are available at <code>res.headers</code>.</p> <p>The ACL Token parameter is always sent as the <code>X-Consul-Token</code> header rather than being included in the query string.</p> <p>If <code>wait</code> or <code>index</code> arguments are provided the request read timeout is extended appropriately. <code>wait</code> must be passed as a number of seconds, do not include <code>s</code> or any other unit string.</p> <pre><code>local resty_consul = require('resty.consul')\nlocal consul = resty_consul:new({\n        host            = \"127.0.0.1\",\n        port            = 8500,\n        connect_timeout = (60*1000), -- 60s\n        read_timeout    = (60*1000), -- 60s\n        default_args    = {\n            token = \"my-default-token\"\n        },\n        ssl             = false,\n        ssl_verify      = true,\n        sni_host        = nil,\n    })\n\nlocal res, err = consul:get('/agent/services')\nif not res then\n    ngx.log(ngx.ERR, err)\n    return\nend\n\nngx.print(res.status) -- 200\nlocal services = res.body -- JSON decoded response\n\n\nlocal res, err = consul:put('/agent/service/register', my_service_definition, { token = \"override-token\" })\nif not res then\n    ngx.log(ngx.ERR, err)\n    return\nend\n\nngx.print(res.status) -- 200\nngx.print(res.headers[\"X-Consul-Knownleader\"]) -- \"true\"\nlocal service_register_response = res.body -- JSON decoded response\n\n\nlocal res, err = consul:list_keys() -- Get all keys\nif not res then\n    ngx.log(ngx.ERR, err)\n    return\nend\n\nlocal keys = {}\nif res.status == 200 then\n    keys = res.body\nend\n\nfor _, key in ipairs(keys) do\n    local res, err = consul:get_key(key)\n    if not res then\n        ngx.log(ngx.ERR, err)\n        return\n    end\n\n    ngx.print(res.body[1].Value) -- Key value after base64 decoding\nend\n</code></pre>"},{"location":"lua/consul/#basic-methods","title":"Basic Methods","text":""},{"location":"lua/consul/#new","title":"new","text":"<p><code>syntax: client = consul:new(opts?)</code></p> <p>Create a new consul client. <code>opts</code> is a table setting the following options:</p> <ul> <li><code>host</code> Defaults to 127.0.0.1</li> <li><code>port</code> Defaults to 8500. Set to <code>0</code> if using a unix socket as <code>host</code>.</li> <li><code>connect_timeout</code> Connection timeout in ms. Defaults to 60s</li> <li><code>read_timeout</code> Read timeout in ms. Defaults to 60s</li> <li><code>default_args</code> Table of query string arguments to send with all requests (e.g. <code>token</code>) Defaults to empty</li> <li><code>ssl</code> Boolean, enable HTTPS requests. Default to <code>false</code>.</li> <li><code>ssl_verify</code> Boolean, verify SSL certificates. Defaults to <code>true</code>      = true,</li> <li><code>sni_host</code> Hostname to use when verifying SSL certs.</li> </ul>"},{"location":"lua/consul/#get","title":"get","text":"<p><code>syntax: res, err = consul:get(path, args?)</code></p> <p>Performs a GET request to the provided path. API Version is automatically prepended.</p> <p><code>args</code> is a table of query string parameters to add to the URI.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#put","title":"put","text":"<p><code>syntax: res, err = consul:put(path, body, args?)</code></p> <p>Performs a PUT request to the provided path. API Version is automatically prepended.</p> <p><code>args</code> is table of query string parameters to add to the URI.</p> <p>If <code>body</code> is a table or boolean value it is automatically json encoded before being sent.  Otherwise anything that lua-resty-http accepts as a body input is valid.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#delete","title":"delete","text":"<p><code>syntax: res, err = consul:delete(path, args?)</code></p> <p>Performs a GET request to the provided path. API Version is automatically prepended.</p> <p><code>args</code> is a table of query string parameters to add to the URI.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#get_client_body_reader","title":"get_client_body_reader","text":"<p>Proxy method to lua-resty-http</p>"},{"location":"lua/consul/#key-value-helpers","title":"Key Value Helpers","text":"<p>These methods automatically prepend <code>/v1/kv</code>, only the actual key should be passed. Base64 encoded values are automatically decoded.</p>"},{"location":"lua/consul/#get_key","title":"get_key","text":"<p><code>syntax: res, err = consul:get_key(key, args?)</code></p> <p>Retrieve a Consul KV key. Values are Base64 decoded.</p> <p><code>args</code> is a table of query string parameters to add to the URI.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#put_key","title":"put_key","text":"<p><code>syntax: res, err = consul:put_key(key, value, args?)</code></p> <p>Create or update a KV key.</p> <p><code>args</code> is table of query string parameters to add to the URI.</p> <p>If <code>value</code> is a table or boolean value it is automatically json encoded before being sent.  Otherwise anything that lua-resty-http accepts as a body input is valid.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#delete_1","title":"delete","text":"<p><code>syntax: res, err = consul:delete_key(key, args?)</code></p> <p>Delete a KV entry.</p> <p><code>args</code> is a table of query string parameters to add to the URI.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#list_keys","title":"list_keys","text":"<p><code>syntax: res, err = consul:list_keys(prefix?, args?)</code></p> <p>Retrieve all the keys in the KV strore. Optionally within a <code>prefix</code>.</p> <p><code>args</code> is a table of query string parameters to add to the URI.  <code>keys</code> is always set as a query string parameter with this method</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p>"},{"location":"lua/consul/#transaction-helper","title":"Transaction Helper","text":""},{"location":"lua/consul/#txn","title":"txn","text":"<p><code>syntax: res, err = consul:txn(payload, args?)</code></p> <p>Performs a <code>PUT</code> request  to the <code>/v1/txn</code> API endpoint with the provided payload.</p> <p><code>payload</code> can be provided as a Lua table, in which case <code>Value</code> keys will be automatically base64 encoded. Otherwise anything that lua-resty-http accepts as a body input is valid.</p> <p>Returns a lua-resty-http response object. On error returns <code>nil</code> and an error message.</p> <p>KV values in the response body are automatically base64 decoded.</p> <pre><code>local txn_payload = {\n    {\n        KV = {\n            Verb   = \"set\",\n            Key    = \"foo\",\n            Value  = \"bar\",\n        }\n    },\n    {\n        KV = {\n            Verb   = \"get\",\n            Key    = \"foobar\",\n        }\n    }\n}\n\nlocal consul = resty_consul:new()\n\nlocal res, err = consul:txn(txn_payload)\nif not res then\n    ngx.say(err)\n    return\nend\n\nngx.say(res.body.Results[2].KV.Value) -- \"bar\"\n</code></pre>"},{"location":"lua/consul/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-consul.</p>"},{"location":"lua/cookie/","title":"cookie: Lua library for HTTP cookie manipulations for nginx-module-lua","text":""},{"location":"lua/cookie/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following steps.</p>"},{"location":"lua/cookie/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install lua-resty-cookie\n</code></pre>"},{"location":"lua/cookie/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install lua5.1-resty-cookie\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-cookie v0.1.0  released on Jul 16 2015.</p> <p>lua-resty-cookie - This library parses HTTP Cookie header for Nginx and returns each field in the cookie.</p>"},{"location":"lua/cookie/#status","title":"Status","text":"<p>This library is production ready.</p>"},{"location":"lua/cookie/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua '\n                local ck = require \"resty.cookie\"\n                local cookie, err = ck:new()\n                if not cookie then\n                    ngx.log(ngx.ERR, err)\n                    return\n                end\n\n                -- get single cookie\n                local field, err = cookie:get(\"lang\")\n                if not field then\n                    ngx.log(ngx.ERR, err)\n                    return\n                end\n                ngx.say(\"lang\", \" =&gt; \", field)\n\n                -- get all cookies\n                local fields, err = cookie:get_all()\n                if not fields then\n                    ngx.log(ngx.ERR, err)\n                    return\n                end\n\n                for k, v in pairs(fields) do\n                    ngx.say(k, \" =&gt; \", v)\n                end\n\n                -- set one cookie\n                local ok, err = cookie:set({\n                    key = \"Name\", value = \"Bob\", path = \"/\",\n                    domain = \"example.com\", secure = true, httponly = true,\n                    expires = \"Wed, 09 Jun 2021 10:18:14 GMT\", max_age = 50,\n                    extension = \"a4334aebaec\"\n                })\n                if not ok then\n                    ngx.log(ngx.ERR, err)\n                    return\n                end\n\n                -- set another cookie, both cookies will appear in HTTP response\n                local ok, err = cookie:set({\n                    key = \"Age\", value = \"20\",\n                })\n                if not ok then\n                    ngx.log(ngx.ERR, err)\n                    return\n                end\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/cookie/#methods","title":"Methods","text":""},{"location":"lua/cookie/#new","title":"new","text":"<p><code>syntax: cookie_obj = cookie()</code></p> <p>Create a new cookie object for current request. You can get parsed cookie from client or set cookie to client later using this object.</p>"},{"location":"lua/cookie/#get","title":"get","text":"<p><code>syntax: cookie_val, err = cookie_obj:get(cookie_name)</code></p> <p>Get a single client cookie value. On error, returns <code>nil</code> and an error message.</p>"},{"location":"lua/cookie/#get_all","title":"get_all","text":"<p><code>syntax: fields, err = cookie_obj:get_all()</code></p> <p>Get all client cookie key/value pairs in a lua table. On error, returns <code>nil</code> and an error message.</p>"},{"location":"lua/cookie/#set","title":"set","text":"<pre><code>syntax: ok, err = cookie_obj:set({\n    key = \"Name\",\n    value = \"Bob\",\n    path = \"/\",\n    domain = \"example.com\",\n    secure = true, httponly = true,\n    expires = \"Wed, 09 Jun 2021 10:18:14 GMT\",\n    max_age = 50,\n    extension = \"a4334aebaec\"\n})\n</code></pre> <p>Set a cookie to client. This will add a new 'Set-Cookie' response header. <code>key</code> and <code>value</code> are required, all other fields are optional. If the same cookie (whole cookie string, e.g. \"Name=Bob; Expires=Wed, 09 Jun 2021 10:18:14 GMT; Max-Age=50; Domain=example.com; Path=/; Secure; HttpOnly;\") has already been setted, new cookie will be ignored.</p>"},{"location":"lua/cookie/#authors","title":"Authors","text":"<p>Jiale Zhi vipcalio@gmail.com, CloudFlare Inc.</p> <p>Yichun Zhang (agentzh) agentzh@gmail.com, CloudFlare Inc.</p>"},{"location":"lua/cookie/#copyright-and-license","title":"Copyright and License","text":"<p>This module is licensed under the BSD license.</p> <p>Copyright (C) 2013, by Jiale Zhi vipcalio@gmail.com, CloudFlare Inc.</p> <p>Copyright (C) 2013, by Yichun Zhang agentzh@gmail.com, CloudFlare Inc.</p> <p>All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ul> <li> <p>Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</p> </li> </ul> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"lua/cookie/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-cookie.</p>"},{"location":"lua/core/","title":"core: New FFI-based API for lua-nginx-module","text":""},{"location":"lua/core/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/core/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-core\n</code></pre>"},{"location":"lua/core/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-core\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-core v0.1.32  released on Oct 29 2025.</p> <p>lua-resty-core - New FFI-based Lua API for ngx_http_lua_module and/or ngx_stream_lua_module</p>"},{"location":"lua/core/#status","title":"Status","text":"<p>This library is production ready.</p>"},{"location":"lua/core/#synopsis","title":"Synopsis","text":"<p>This library is automatically loaded by default since OpenResty 1.15.8.1. This behavior can be disabled via the lua_load_resty_core directive, but note that the use of this library is vividly recommended, as its FFI implementation is both faster, safer, and more complete than the Lua C API of the ngx_lua module.</p> <p>If you are using an older version of OpenResty, you must load this library like so:</p> <pre><code>    # nginx.conf\n\n    http {\n        # you do NOT need to configure the following line when you\n        # are using the OpenResty bundle 1.4.3.9+.\n        init_by_lua_block {\n            require \"resty.core\"\n            collectgarbage(\"collect\")  -- just to collect any garbage\n        }\n\n        ...\n    }\n</code></pre>"},{"location":"lua/core/#description","title":"Description","text":"<p>This pure Lua library reimplements part of the ngx_lua module's Nginx API for Lua with LuaJIT FFI and installs the new FFI-based Lua API into the ngx. and ndk. namespaces used by the ngx_lua module.</p> <p>In addition, this Lua library implements any significant new Lua APIs of the ngx_lua module as proper Lua modules, like ngx.semaphore and ngx.balancer.</p> <p>The FFI-based Lua API can work with LuaJIT's JIT compiler. ngx_lua's default API is based on the standard Lua C API, which will never be JIT compiled and the user Lua code is always interpreted (slowly).</p> <p>Support for the new ngx_stream_lua_module has also begun.</p> <p>This library is shipped with the OpenResty bundle by default. So you do not really need to worry about the dependencies and requirements.</p>"},{"location":"lua/core/#prerequisites","title":"Prerequisites","text":"<p>WARNING This library is included with every OpenResty release. You should use the bundled version of this library in the particular OpenResty release you are using. Otherwise you may run into serious compatibility issues.</p> <ul> <li>LuaJIT 2.1 (for now, it is the v2.1 git branch in the official luajit-2.0 git repository: http://luajit.org/download.html )</li> <li>ngx_http_lua_module v0.10.25.</li> <li>ngx_stream_lua_module v0.0.13.</li> <li>lua-resty-lrucache</li> </ul>"},{"location":"lua/core/#api-implemented","title":"API Implemented","text":""},{"location":"lua/core/#restycorehash","title":"resty.core.hash","text":"<ul> <li>ngx.md5</li> <li>ngx.md5_bin</li> <li>ngx.sha1_bin</li> </ul>"},{"location":"lua/core/#restycorebase64","title":"resty.core.base64","text":"<ul> <li>ngx.encode_base64</li> <li>ngx.decode_base64</li> <li>ngx.decode_base64mime</li> </ul>"},{"location":"lua/core/#restycoreuri","title":"resty.core.uri","text":"<ul> <li>ngx.escape_uri</li> <li>ngx.unescape_uri</li> </ul>"},{"location":"lua/core/#restycoreregex","title":"resty.core.regex","text":"<ul> <li>ngx.re.match</li> <li>ngx.re.gmatch</li> <li>ngx.re.find</li> <li>ngx.re.sub</li> <li>ngx.re.gsub</li> </ul>"},{"location":"lua/core/#restycoreexit","title":"resty.core.exit","text":"<ul> <li>ngx.exit</li> </ul>"},{"location":"lua/core/#restycoreshdict","title":"resty.core.shdict","text":"<ul> <li>ngx.shared.DICT.get</li> <li>ngx.shared.DICT.get_stale</li> <li>ngx.shared.DICT.incr</li> <li>ngx.shared.DICT.set</li> <li>ngx.shared.DICT.safe_set</li> <li>ngx.shared.DICT.add</li> <li>ngx.shared.DICT.safe_add</li> <li>ngx.shared.DICT.replace</li> <li>ngx.shared.DICT.delete</li> <li>ngx.shared.DICT.ttl</li> <li>ngx.shared.DICT.expire</li> <li>ngx.shared.DICT.flush_all</li> <li>ngx.shared.DICT.free_space</li> <li>ngx.shared.DICT.capacity</li> </ul>"},{"location":"lua/core/#restycorevar","title":"resty.core.var","text":"<ul> <li>ngx.var.VARIABLE</li> </ul>"},{"location":"lua/core/#restycorectx","title":"resty.core.ctx","text":"<ul> <li>ngx.ctx</li> </ul>"},{"location":"lua/core/#get_ctx_table","title":"get_ctx_table","text":"<p>syntax: ctx = resty.core.ctx.get_ctx_table(ctx?)</p> <p>Similar to ngx.ctx but it accepts an optional <code>ctx</code> argument. It will use the <code>ctx</code> from caller instead of creating a new table when the <code>ctx</code> table does not exist.</p> <p>Notice: the <code>ctx</code> table will be used in the current request's whole life cycle. Please be very careful when you try to reuse the <code>ctx</code> table. You need to make sure there is no Lua code using or going to use the <code>ctx</code> table in the current request before you reusing the <code>ctx</code> table in some other place.</p>"},{"location":"lua/core/#restycorerequest","title":"resty.core.request","text":"<ul> <li>ngx.req.get_headers</li> <li>ngx.req.get_uri_args</li> <li>ngx.req.start_time</li> <li>ngx.req.get_method</li> <li>ngx.req.set_method</li> <li>ngx.req.set_header</li> <li>ngx.req.clear_header</li> </ul>"},{"location":"lua/core/#restycoreresponse","title":"resty.core.response","text":"<ul> <li>ngx.header.HEADER</li> </ul>"},{"location":"lua/core/#restycoremisc","title":"resty.core.misc","text":"<ul> <li>ngx.status</li> <li>ngx.is_subrequest</li> <li>ngx.headers_sent</li> <li>ngx.req.is_internal</li> </ul>"},{"location":"lua/core/#restycoretime","title":"resty.core.time","text":"<ul> <li>ngx.time</li> <li>ngx.now</li> <li>ngx.update_time</li> <li>ngx.localtime</li> <li>ngx.utctime</li> <li>ngx.cookie_time</li> <li>ngx.http_time</li> <li>ngx.parse_http_time</li> <li>monotonic_msec</li> <li>monotonic_time</li> </ul>"},{"location":"lua/core/#restycoreworker","title":"resty.core.worker","text":"<ul> <li>ngx.worker.exiting</li> <li>ngx.worker.pid</li> <li>ngx.worker.id</li> <li>ngx.worker.count</li> </ul>"},{"location":"lua/core/#restycorephase","title":"resty.core.phase","text":"<ul> <li>ngx.get_phase</li> </ul>"},{"location":"lua/core/#restycorendk","title":"resty.core.ndk","text":"<ul> <li>ndk.set_var</li> </ul>"},{"location":"lua/core/#restycoresocket","title":"resty.core.socket","text":"<ul> <li>socket.setoption</li> <li>socket.setclientcert</li> <li>socket.sslhandshake</li> </ul>"},{"location":"lua/core/#restycoreparam","title":"resty.core.param","text":"<ul> <li>ngx.arg (getter only)</li> </ul>"},{"location":"lua/core/#ngxsemaphore","title":"ngx.semaphore","text":"<p>This Lua module implements a semaphore API for efficient \"light thread\" synchronization, which can work across different requests (but not across nginx worker processes).</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxbalancer","title":"ngx.balancer","text":"<p>This Lua module implements for defining dynamic upstream balancers in Lua.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxssl","title":"ngx.ssl","text":"<p>This Lua module provides a Lua API for controlling SSL certificates, private keys, SSL protocol versions, and etc in NGINX downstream SSL handshakes.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxsslclienthello","title":"ngx.ssl.clienthello","text":"<p>This Lua module provides a Lua API for post-processing SSL client hello message for NGINX downstream SSL connections.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxsslsession","title":"ngx.ssl.session","text":"<p>This Lua module provides a Lua API for manipulating SSL session data and IDs for NGINX downstream SSL connections.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxre","title":"ngx.re","text":"<p>This Lua module provides a Lua API which implements convenience utilities for the <code>ngx.re</code> API.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxresp","title":"ngx.resp","text":"<p>This Lua module provides Lua API which could be used to handle HTTP response.</p> <p>See the documentation for this Lua module for more details.</p>"},{"location":"lua/core/#ngxpipe","title":"ngx.pipe","text":"<p>This module provides a Lua API to spawn processes and communicate with them in a non-blocking fashion.</p> <p>See the documentation for this Lua module for more details.</p> <p>This module was first introduced in lua-resty-core v0.1.16.</p>"},{"location":"lua/core/#ngxprocess","title":"ngx.process","text":"<p>This Lua module is used to manage the nginx process in Lua.</p> <p>See the documentation for this Lua module for more details.</p> <p>This module was first introduced in lua-resty-core v0.1.12.</p>"},{"location":"lua/core/#ngxerrlog","title":"ngx.errlog","text":"<p>This Lua module provides Lua API to capture and manage nginx error log messages.</p> <p>See the documentation for this Lua module for more details.</p> <p>This module was first introduced in lua-resty-core v0.1.12.</p>"},{"location":"lua/core/#ngxbase64","title":"ngx.base64","text":"<p>This Lua module provides Lua API to urlsafe base64 encode/decode.</p> <p>See the documentation for this Lua module for more details.</p> <p>This module was first introduced in lua-resty-core v0.1.14.</p>"},{"location":"lua/core/#caveat","title":"Caveat","text":"<p>If the user Lua code is not JIT compiled, then use of this library may lead to performance drop in interpreted mode. You will only observe speedup when you get a good part of your user Lua code JIT compiled.</p>"},{"location":"lua/core/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module#readme</li> <li>LuaJIT FFI: http://luajit.org/ext_ffi.html</li> </ul>"},{"location":"lua/core/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-core.</p>"},{"location":"lua/cors/","title":"cors: It's the implement of CORS on nginx-module-lua","text":""},{"location":"lua/cors/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/cors/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-cors\n</code></pre>"},{"location":"lua/cors/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-cors\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-cors v0.2.1  released on Oct 17 2016.</p> <p>lua-resty-cors</p>"},{"location":"lua/cors/#lua-resty-cors","title":"lua-resty-cors","text":"<p>It's the implement of CORS on OpenResty and  It backports the nginx-http-cors to OpenResty</p>"},{"location":"lua/cors/#status","title":"Status","text":"<p>Experimental</p>"},{"location":"lua/cors/#usage","title":"Usage","text":"<p>It shoule be placed on the nginx output header phase. In OpenResty it should be header_filter_by_lua*. The config shoule be like as the following:</p> <pre><code>http {\n      header_filter_by_lua_block {\n        local cors = require('lib.resty.cors');\n\n        cors.allow_host([==[.*\\.google\\.com]==])\n        cors.allow_host([==[.*\\.facebook\\.com]==])\n        cors.expose_header('x-custom-field1')\n        cors.expose_header('x-custom-field2')\n        cors.allow_method('GET')\n        cors.allow_method('POST')\n        cors.allow_method('PUT')\n        cors.allow_method('DELETE')\n        cors.allow_header('x-custom-field1')\n        cors.allow_header('x-custom-field2')\n        cors.max_age(7200)\n        cors.allow_credentials(false)\n\n        cors.run()\n    }\n}\n</code></pre>"},{"location":"lua/cors/#api","title":"API","text":""},{"location":"lua/cors/#allow_host","title":"allow_host","text":"<p><code>syntax: cors.allow_host(host)</code></p> <p>This will match the host from cors request then be added to the header Access-Control-Allow-Origin like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Allow-Origin: http://www.google.com\n</code></pre>"},{"location":"lua/cors/#expose_header","title":"expose_header","text":"<p><code>syntax: cors.expose_header(header)</code></p> <p>This will be added to the header Access-Control-Expose-Headers like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Expose-Headers: x-custom-field1,x-custom-field2\n</code></pre>"},{"location":"lua/cors/#allow_method","title":"allow_method","text":"<p><code>syntax: cors.allow_method(method)</code></p> <p>This will be added to the header Access-Control-Allow-Methods like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Allow-Methods:GET,POST,PUT\n</code></pre>"},{"location":"lua/cors/#allow_header","title":"allow_header","text":"<p><code>syntax: cors.allow_header(header)</code></p> <p>This will be added to the header Access-Control-Allow-Headers like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Allow-Headers:x-custom-field1,x-custom-field2\n</code></pre>"},{"location":"lua/cors/#max_age","title":"max_age","text":"<p><code>syntax: cors.max_age(age)</code></p> <p>This will be added to the header Access-Control-Max-Age like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Max-Age: 7200\n</code></pre>"},{"location":"lua/cors/#allow-credentials","title":"Allow-Credentials","text":"<p><code>syntax: cors.allow_credentials(true or false)</code></p> <p>This will be added to the header Access-Control-Allow-Credentials like as the following:</p> <pre><code>Request:\nOrigin: https://www.google.com\n\nResponse:\nAccess-Control-Allow-Credentials: true\n</code></pre>"},{"location":"lua/cors/#run","title":"run","text":"<p><code>syntax: cors.run()</code></p> <p>This is the entry for lua-resty-cors to run</p>"},{"location":"lua/cors/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-cors.</p>"},{"location":"lua/counter/","title":"counter: Lock-free counter for nginx-module-lua","text":""},{"location":"lua/counter/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/counter/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-counter\n</code></pre>"},{"location":"lua/counter/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-counter\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-counter v0.2.1  released on Apr 09 2020.</p> <p>lua-resty-counter - Lock-free counter for OpenResty.</p> <p> </p>"},{"location":"lua/counter/#description","title":"Description","text":"<p>When number of workers increase, the penalty of acquiring a lock becomes noticable. This library implements a lock-free counter that does incrementing operation in worker's Lua VM. Each worker then sync its local counter to a shared dict timely.</p>"},{"location":"lua/counter/#status","title":"Status","text":"<p>Production</p>"},{"location":"lua/counter/#api","title":"API","text":""},{"location":"lua/counter/#counternew","title":"counter.new","text":"<p>syntax: c, err = counter.new(shdict_name, sync_interval?)</p> <p>Create a new counter instance. Take first argument as the shared dict name in string. And an optional second argument as interval to sync local state to shared dict in number. If second argument is omitted, local counter will not be synced automatically, user are responsible to call <code>counter:sync</code> on each worker.</p>"},{"location":"lua/counter/#countersync","title":"counter.sync","text":"<p>syntax: ok = counter:sync()</p> <p>Sync current worker's local counter to shared dict. Not needed if a counter is created with <code>sync_interval</code> not set to <code>nil</code>.</p>"},{"location":"lua/counter/#counterincr","title":"counter.incr","text":"<p>syntax: counter:incr(key, step?)</p> <p>Increase counter of key <code>k</code> with a step of <code>step</code>. If <code>step</code> is omitted, it's default to <code>1</code>.</p>"},{"location":"lua/counter/#counterreset","title":"counter.reset","text":"<p>syntax: newval, err, forcible? = counter:reset(key, number)</p> <p>Reset the counter in shdict with a decrease of <code>number</code>. This function is a wrapper of <code>ngx.shared.DICT:incr(key, -number, number)</code>, please refer to lua-nginx-module doc for return values.</p>"},{"location":"lua/counter/#counterget","title":"counter.get","text":"<p>syntax: value = counter:get(key)</p> <p>Get the value of counter from shared dict.</p>"},{"location":"lua/counter/#counterget_keys","title":"counter.get_keys","text":"<p>syntax: keys = counter:get_keys(max_count?)</p> <p>Get the keys of counters in shared dict. This function is a wrapper of <code>ngx.shared.DICT:get_keys</code>, please refer to lua-nginx-module doc for return values.</p>"},{"location":"lua/counter/#see-also","title":"See Also","text":"<ul> <li>lua-nginx-module</li> </ul>"},{"location":"lua/counter/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-counter.</p>"},{"location":"lua/ctxdump/","title":"ctxdump: Stash and apply the old ngx.ctx for avoiding being destoried after NGINX internal redirect happens","text":""},{"location":"lua/ctxdump/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/ctxdump/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-ctxdump\n</code></pre>"},{"location":"lua/ctxdump/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-ctxdump\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-ctxdump v0.1  released on Jan 07 2021.</p> <p>lua-resty-ctxdump - stash and apply the ngx.ctx, avoiding being destoried after Nginx internal redirect happens.</p> <p></p>"},{"location":"lua/ctxdump/#status","title":"Status","text":"<p>Probably production ready in most cases, though not yet proven in the wild.  Please check the issues list and let me know if you have any problems / questions.</p>"},{"location":"lua/ctxdump/#synopsis","title":"Synopsis","text":"<pre><code>location /t1 {\n    set $ctx_ref = \"\";\n    content_by_lua_block {\n         local ctxdump = require \"resty.ctxdump\"\n         ngx.ctx = {\n             Date = \"Wed May  3 15:18:04 CST 2017\",\n             Site = \"unknown\"\n        }\n        ngx.var.ctx_ref = ctxdump.stash_ngx_ctx()\n        ngx.exec(\"/t2\")\n    }\n}\n\nlocation /t2 {\n    internal;\n    content_by_lua_block {\n         local ctxdump = require \"resty.ctxdump\"\n         ngx.ctx = {\n             Date = \"Wed May  3 15:18:04 CST 2017\",\n             Site = \"unknown\"\n        }\n        ngx.ctx = ctxdump.apply_ngx_ctx(ngx.var.ctx_ref)\n        ngx.say(\"Date: \" .. ngx.ctx[\"Date\"] .. \" Site: \" .. ngx.ctx[\"Site\"])\n    }\n}\n</code></pre>"},{"location":"lua/ctxdump/#methods","title":"Methods","text":""},{"location":"lua/ctxdump/#stash_ngx_ctx","title":"stash_ngx_ctx","text":"<p>syntax: ref = stash_ngx_ctx() phase: *init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*,     content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*,     ngx.timer.*, balancer_by_lua* </p> <p>Reference the <code>ngx.ctx</code>, returns an anchor(a new reference maintained by lua-resty-ctxdump).</p> <p>Note: <code>stash_ngx_ctx</code> and <code>apply_ngx_ctx</code> must be called in pairs, otherwise memory leak will happen! See apply_ngx_ctx.</p>"},{"location":"lua/ctxdump/#apply_ngx_ctx","title":"apply_ngx_ctx","text":"<p>syntax: old_ngx_ctx = apply_ngx_ctx(ref) phase: *init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*,     content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*,     ngx.timer.*, balancer_by_lua* </p> <p>fetch the old <code>ngx.ctx</code> with the anchor returns from <code>stash_ngx_ctx</code>. After that, the anchor will be out of work.</p> <p>Note: <code>stash_ngx_ctx</code> and <code>apply_ngx_ctx</code> must be called in pairs, otherwise memory leak will happen! See stash_ngx_ctx.</p>"},{"location":"lua/ctxdump/#see-also","title":"See Also","text":"<ul> <li>upyun-resty: https://github.com/upyun/upyun-resty</li> </ul>"},{"location":"lua/ctxdump/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-ctxdump.</p>"},{"location":"lua/dns-server/","title":"dns-server: Lua DNS server driver for nginx-module-lua","text":""},{"location":"lua/dns-server/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/dns-server/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-dns-server\n</code></pre>"},{"location":"lua/dns-server/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-dns-server\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-dns-server v0.2  released on Jul 23 2019.</p> <p>lua-resty-dns-server - Lua DNS server driver for the OpenResty</p>"},{"location":"lua/dns-server/#status","title":"Status","text":"<p>This library is still under early development and is still experimental.</p>"},{"location":"lua/dns-server/#description","title":"Description","text":"<p>This Lua library provies a DNS server driver for the ngx_lua nginx module:</p> <p>https://github.com/openresty/stream-lua-nginx-module/#readme</p>"},{"location":"lua/dns-server/#synopsis","title":"Synopsis","text":"<pre><code>stream {\n    server {\n        listen 53 udp;\n        content_by_lua_block {\n            local server = require 'resty.dns.server'\n            local sock, err = ngx.req.socket()\n            if not sock then\n                ngx.log(ngx.ERR, \"failed to get the request socket: \", err)\n                return ngx.exit(ngx.ERROR)\n            end\n\n            local req, err = sock:receive()\n            if not req then\n                ngx.log(ngx.ERR, \"failed to receive: \", err)\n                return ngx.exit(ngx.ERROR)\n            end\n\n            local dns = server:new()\n            local request, err = dns:decode_request(req)\n            if not request then\n                ngx.log(ngx.ERR, \"failed to decode request: \", err)\n\n                local resp = dns:encode_response()\n                local ok, err = sock:send(resp)\n                if not ok then\n                    ngx.log(ngx.ERR, \"failed to send: \", err)\n                    ngx.exit(ngx.ERROR)\n                end\n\n                return\n            end\n\n            local query = request.questions[1]\n            ngx.log(ngx.DEBUG, \"qname: \", query.qname, \" qtype: \", query.qtype)\n\n            local subnet = request.subnet[1]\n            if subnet then\n                ngx.log(ngx.DEBUG, \"subnet addr: \",  subnet.address, \" mask: \", subnet.mask, \" family: \", subnet.family)\n            end\n\n            local cname = \"sinacloud.com\"\n\n            if query.qtype == server.TYPE_CNAME or\n                query.qtype == server.TYPE_AAAA or query.qtype == server.TYPE_A then\n\n                local err = dns:create_cname_answer(query.qname, 600, cname)\n                if err then\n                    ngx.log(ngx.ERR, \"failed to create cname answer: \", err)\n                    return\n                end\n            else\n                dns:create_soa_answer(\"test.com\", 600, \"a.root-test.com\", \"vislee.test.com\", 1515161223, 1800, 900, 604800, 86400)\n            end\n\n            local resp = dns:encode_response()\n            local ok, err = sock:send(resp)\n            if not ok then\n                ngx.log(ngx.ERR, \"failed to send: \", err)\n                return\n            end\n        }\n    }\n\n    server {\n        listen 53;\n        content_by_lua_block {\n            local bit    = require 'bit'\n            local lshift = bit.lshift\n            local rshift = bit.rshift\n            local band   = bit.band\n            local byte   = string.byte\n            local char   = string.char\n            local server = require 'resty.dns.server'\n\n            local sock, err = ngx.req.socket()\n            if not sock then\n                ngx.log(ngx.ERR, \"failed to get the request socket: \", err)\n                return ngx.exit(ngx.ERROR)\n            end\n\n            local buf, err = sock:receive(2)\n            if not buf then\n                ngx.log(ngx.ERR, \"failed to receive: \", err)\n                return ngx.exit(ngx.ERROR)\n            end\n\n            local len_hi = byte(buf, 1)\n            local len_lo = byte(buf, 2)\n            local len = lshift(len_hi, 8) + len_lo\n            local data, err = sock:receive(len)\n            if not data then\n                ngx.log(ngx.ERR, \"failed to receive: \", err)\n                return ngx.exit(ngx.ERROR)\n            end\n\n            local dns = server:new()\n            local request, err = dns:decode_request(data)\n            if not request then\n                ngx.log(ngx.ERR, \"failed to decode dns request: \", err)\n                return\n            end\n\n            local query = request.questions[1]\n            ngx.log(ngx.DEBUG, \"qname: \", query.qname, \" qtype: \", query.qtype)\n\n            local subnet = request.subnet[1]\n            if subnet then\n                ngx.log(ngx.DEBUG, \"subnet addr: \",  subnet.address, \" mask: \", subnet.mask, \" family: \", subnet.family)\n            end\n\n            if query.qtype == server.TYPE_CNAME or query.qtype == server.TYPE_A then\n                dns:create_cname_answer(query.qname, 600, \"sinacloud.com\")\n            elseif query.qtype == server.TYPE_AAAA then\n                local resp_header, err = dns:create_response_header(server.RCODE_NOT_IMPLEMENTED)\n                resp_header.ra = 0\n            else\n                dns:create_soa_answer(\"test.com\", 600, \"a.root-test.com\", \"vislee.test.com\", 1515161223, 1800, 900, 604800, 86400)\n            end\n\n            local resp = dns:encode_response()\n            local len = #resp\n            local len_hi = char(rshift(len, 8))\n            local len_lo = char(band(len, 0xff))\n\n            local ok, err = sock:send({len_hi, len_lo, resp})\n            if not ok then\n                ngx.log(ngx.ERR, \"failed to send: \", err)\n                return\n            end\n            return\n        }\n    }\n}\n</code></pre>"},{"location":"lua/dns-server/#methods","title":"Methods","text":""},{"location":"lua/dns-server/#new","title":"new","text":"<p><code>syntax: s, err = class:new()</code></p> <p>Creates a dns.server object. Returns <code>nil</code> and an message string on error.</p>"},{"location":"lua/dns-server/#decode_request","title":"decode_request","text":"<p><code>syntax: request, err = s:decode_request(buf)</code></p> <p>Parse the DNS request.</p> <p>The request returned the lua table which takes some of the following fields:</p> <ul> <li> <p><code>header</code>: The <code>header</code> is also a lua table which usually takes some of the following fields:</p> <ul> <li><code>id</code> : The identifier assigned by the program that generates any kind of query.</li> <li><code>qr</code> : The field specifies whether this message is a query (<code>0</code>), or a response (<code>1</code>).</li> <li><code>opcode</code> : The field specifies kind of query in this message.</li> <li><code>tc</code> : The field specifies that this message was truncated due to length greater than that permitted on the transmission channel.</li> <li><code>rd</code> : Recursion Desired. If <code>RD</code> is set, it directs the name server to pursue the query recursively.</li> <li><code>rcode</code> : response code.</li> <li><code>qdcount</code> : The field specifying the number of entries in the question section.</li> </ul> </li> <li> <p><code>questions</code> : Each entry in the <code>questions</code> is also a lua table which takes some of the following:</p> <ul> <li><code>qname</code> : A domain name of query.</li> <li><code>qtype</code> : Specifies the type of the query.</li> <li><code>qclass</code> : Specifies the class of the query. Usually the field is <code>IN</code> for the Internet.</li> </ul> </li> </ul>"},{"location":"lua/dns-server/#create_a_answer","title":"create_a_answer","text":"<p><code>syntax: err = s:create_a_answer(name, ttl, ipv4)</code></p> <p>Create the A records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>ipv4</code></p> <p>The IPv4 address.</p> </li> </ul>"},{"location":"lua/dns-server/#create_aaaa_answer","title":"create_aaaa_answer","text":"<p><code>syntax: err = s:create_aaaa_answer(name, ttl, ipv6)</code></p> <p>Create the AAAA records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>ipv6</code></p> <p>The IPv6 address.</p> </li> </ul>"},{"location":"lua/dns-server/#create_cname_answer","title":"create_cname_answer","text":"<p><code>syntax: err = s:create_cname_answer(name, ttl, cname)</code></p> <p>Create the CNAME records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>cname</code></p> <p>The name for an alias.</p> </li> </ul>"},{"location":"lua/dns-server/#create_txt_answer","title":"create_txt_answer","text":"<p><code>syntax: err = s:create_txt_answer(name, ttl, txt)</code></p> <p>Create the txt records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>txt</code></p> <p>The text strings.</p> </li> </ul>"},{"location":"lua/dns-server/#create_ns_answer","title":"create_ns_answer","text":"<p><code>syntax: err = s:create_ns_answer(name, ttl, nsdname)</code></p> <p>Create the NS records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>nsdname</code></p> <p>The specifies a host which should be authoritative for the specified class and domain.</p> </li> </ul>"},{"location":"lua/dns-server/#create_soa_answer","title":"create_soa_answer","text":"<p><code>syntax: err = s:create_soa_answer(name, ttl, mname, rname, serial, refresh, retry, expire, minimum)</code></p> <p>Create the SOA records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>mname</code></p> <p>The the name server that was the original or primary source of data for this zone. * <code>rname</code></p> <p>The mailbox of the person responsible for this zone. * <code>serial</code></p> <p>The unsigned 32 bit version number of the original copy of the zone. * <code>refresh</code></p> <p>A 32 bit time interval before the zone should be refreshed. * <code>retry</code></p> <p>A 32 bit time interval that should elapse before a failed refresh should be retried. * <code>expire</code></p> <p>A 32 bit time value that specifies the upper limit on the time interval that can elapse before the zone is no longer authoritative. * <code>minimum</code></p> <p>The unsigned 32 bit minimum TTL field that should be exported with any RR from this zone.</p> </li> </ul>"},{"location":"lua/dns-server/#create_mx_answer","title":"create_mx_answer","text":"<p><code>syntax: err = s:create_mx_answer(name, ttl, preference, exchange)</code></p> <p>Create the MX records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>preference</code></p> <p>The preference of this mail exchange. * <code>exchange</code></p> <p>The mail exchange.</p> </li> </ul>"},{"location":"lua/dns-server/#create_srv_answer","title":"create_srv_answer","text":"<p><code>syntax: err = s:create_srv_answer(name, ttl, priority, weight, port, target)</code></p> <p>Create the SRV records. Returns <code>nil</code> or an message string on error. which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>priority</code></p> <p>The priority of this target host. * <code>weight</code></p> <p>The weight field specifies a relative weight for entries with the same priority. * <code>port</code></p> <p>The port on this target host of this service. * <code>target</code></p> <p>The domain name of the target host.</p> </li> </ul>"},{"location":"lua/dns-server/#create_response_header","title":"create_response_header","text":"<p><code>syntax: resp_header, err = s:create_response_header(rcode)</code></p>"},{"location":"lua/dns-server/#encode_response","title":"encode_response","text":"<p><code>syntax: resp = s:encode_response()</code></p> <p>Encode the DNS answers. Returns an message string on response or <code>nil</code>.</p>"},{"location":"lua/dns-server/#constants","title":"Constants","text":""},{"location":"lua/dns-server/#type_a","title":"TYPE_A","text":"<p>The <code>A</code> resource record type, equal to the decimal number <code>1</code>.</p>"},{"location":"lua/dns-server/#type_ns","title":"TYPE_NS","text":"<p>The <code>NS</code> resource record type, equal to the decimal number <code>2</code>.</p>"},{"location":"lua/dns-server/#type_cname","title":"TYPE_CNAME","text":"<p>The <code>CNAME</code> resource record type, equal to the decimal number <code>5</code>.</p>"},{"location":"lua/dns-server/#type_soa","title":"TYPE_SOA","text":"<p>The <code>SOA</code> resource record type, equal to the decimal number <code>6</code>.</p>"},{"location":"lua/dns-server/#type_mx","title":"TYPE_MX","text":"<p>The <code>MX</code> resource record type, equal to the decimal number <code>15</code>.</p>"},{"location":"lua/dns-server/#type_txt","title":"TYPE_TXT","text":"<p>The <code>TXT</code> resource record type, equal to the decimal number <code>16</code>.</p>"},{"location":"lua/dns-server/#type_aaaa","title":"TYPE_AAAA","text":"<p><code>syntax: typ = s.TYPE_AAAA</code></p> <p>The <code>AAAA</code> resource record type, equal to the decimal number <code>28</code>.</p>"},{"location":"lua/dns-server/#type_srv","title":"TYPE_SRV","text":"<p><code>syntax: typ = s.TYPE_SRV</code></p> <p>The <code>SRV</code> resource record type, equal to the decimal number <code>33</code>.</p> <p>See RFC 2782 for details.</p>"},{"location":"lua/dns-server/#type_any","title":"TYPE_ANY","text":"<p><code>syntax: typ = s.TYPE_ANY</code></p> <p>The all resource record type, equal to the decimal number <code>255</code>.</p>"},{"location":"lua/dns-server/#rcode_format_error","title":"RCODE_FORMAT_ERROR","text":""},{"location":"lua/dns-server/#rcode_not_implemented","title":"RCODE_NOT_IMPLEMENTED","text":""},{"location":"lua/dns-server/#see-also","title":"See Also","text":"<ul> <li>the stream-lua-nginx-module: https://github.com/openresty/stream-lua-nginx-module/#readme</li> <li>the lua-resty-dns library.</li> <li>this ngx_stream_ipdb_module library can support region resolution. </li> </ul>"},{"location":"lua/dns-server/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-dns-server.</p>"},{"location":"lua/dns/","title":"dns: DNS resolver for nginx-module-lua","text":""},{"location":"lua/dns/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/dns/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-dns\n</code></pre>"},{"location":"lua/dns/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-dns\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-dns v0.23  released on Aug 06 2023.</p> <p>lua-resty-dns - Lua DNS resolver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/dns/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/dns/#description","title":"Description","text":"<p>This Lua library provides a DNS resolver for the ngx_lua nginx module:</p> <p>https://github.com/openresty/lua-nginx-module/#readme</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.5.12 or OpenResty 1.2.1.11 is required.</p> <p>Also, the bit library is also required. If you're using LuaJIT 2.0 with ngx_lua, then the <code>bit</code> library is already available by default.</p> <p>Note that, this library is bundled and enabled by default in the OpenResty bundle.</p> <p>IMPORTANT: to be able to generate unique ids, the random generator must be properly seeded using <code>math.randomseed</code> prior to using this module.</p>"},{"location":"lua/dns/#synopsis","title":"Synopsis","text":"<pre><code>server {\n    location = /dns {\n        content_by_lua_block {\n            local resolver = require \"resty.dns.resolver\"\n            local r, err = resolver:new{\n                nameservers = {\"8.8.8.8\", {\"8.8.4.4\", 53} },\n                retrans = 5,  -- 5 retransmissions on receive timeout\n                timeout = 2000,  -- 2 sec\n                no_random = true, -- always start with first nameserver\n            }\n\n            if not r then\n                ngx.say(\"failed to instantiate the resolver: \", err)\n                return\n            end\n\n            local answers, err, tries = r:query(\"www.google.com\", nil, {})\n            if not answers then\n                ngx.say(\"failed to query the DNS server: \", err)\n                ngx.say(\"retry historie:\\n  \", table.concat(tries, \"\\n  \"))\n                return\n            end\n\n            if answers.errcode then\n                ngx.say(\"server returned error code: \", answers.errcode,\n                        \": \", answers.errstr)\n            end\n\n            for i, ans in ipairs(answers) do\n                ngx.say(ans.name, \" \", ans.address or ans.cname,\n                        \" type:\", ans.type, \" class:\", ans.class,\n                        \" ttl:\", ans.ttl)\n            end\n        }\n    }\n}\n</code></pre>"},{"location":"lua/dns/#methods","title":"Methods","text":""},{"location":"lua/dns/#new","title":"new","text":"<p><code>syntax: r, err = class:new(opts)</code></p> <p>Creates a dns.resolver object. Returns <code>nil</code> and a message string on error.</p> <p>It accepts a <code>opts</code> table argument. The following options are supported:</p> <ul> <li> <p><code>nameservers</code></p> <p>a list of nameservers to be used. Each nameserver entry can be either a single hostname string or a table holding both the hostname string and the port number. The nameserver is picked up by a simple round-robin algorithm for each <code>query</code> method call. This option is required. * <code>retrans</code></p> <p>the total number of times of retransmitting the DNS request when receiving a DNS response times out according to the <code>timeout</code> setting. Defaults to <code>5</code> times. When trying to retransmit the query, the next nameserver according to the round-robin algorithm will be picked up. * <code>timeout</code></p> <p>the time in milliseconds for waiting for the response for a single attempt of request transmission. note that this is ''not'' the maximal total waiting time before giving up, the maximal total waiting time can be calculated by the expression <code>timeout x retrans</code>. The <code>timeout</code> setting can also be changed by calling the <code>set_timeout</code> method. The default <code>timeout</code> setting is 2000 milliseconds, or 2 seconds. * <code>no_recurse</code></p> <p>a boolean flag controls whether to disable the \"recursion desired\" (RD) flag in the UDP request. Defaults to <code>false</code>. * <code>no_random</code></p> <p>a boolean flag controls whether to randomly pick the nameserver to query first, if <code>true</code> will always start with the first nameserver listed. Defaults to <code>false</code>.</p> </li> </ul>"},{"location":"lua/dns/#destroy","title":"destroy","text":"<p><code>syntax: r:destroy()</code></p> <p>Destroy the dns.resolver object by releasing all the internal occupied resources.</p>"},{"location":"lua/dns/#query","title":"query","text":"<p><code>syntax: answers, err, tries? = r:query(name, options?, tries?)</code></p> <p>Performs a DNS standard query to the nameservers specified by the <code>new</code> method, and returns all the answer records in an array-like Lua table. In case of errors, it will return <code>nil</code> and a string describing the error instead.</p> <p>If the server returns a non-zero error code, the fields <code>errcode</code> and <code>errstr</code> will be set accordingly in the Lua table returned.</p> <p>Each entry in the <code>answers</code> returned table value is also a hash-like Lua table which usually takes some of the following fields:</p> <ul> <li> <p><code>name</code></p> <p>The resource record name. * <code>type</code></p> <p>The current resource record type, possible values are <code>1</code> (<code>TYPE_A</code>), <code>5</code> (<code>TYPE_CNAME</code>), <code>28</code> (<code>TYPE_AAAA</code>), and any other values allowed by RFC 1035. * <code>address</code></p> <p>The IPv4 or IPv6 address in their textual representations when the resource record type is either <code>1</code> (<code>TYPE_A</code>) or <code>28</code> (<code>TYPE_AAAA</code>), respectively. Successive 16-bit zero groups in IPv6 addresses will not be compressed by default, if you want that, you need to call the <code>compress_ipv6_addr</code> static method instead. * <code>section</code></p> <p>The identifier of the section that the current answer record belongs to. Possible values are <code>1</code> (<code>SECTION_AN</code>), <code>2</code> (<code>SECTION_NS</code>), and <code>3</code> (<code>SECTION_AR</code>). * <code>cname</code></p> <p>The (decoded) record data value for <code>CNAME</code> resource records. Only present for <code>CNAME</code> records. * <code>ttl</code></p> <p>The time-to-live (TTL) value in seconds for the current resource record. * <code>class</code></p> <p>The current resource record class, possible values are <code>1</code> (<code>CLASS_IN</code>) or any other values allowed by RFC 1035. * <code>preference</code></p> <p>The preference integer number for <code>MX</code> resource records. Only present for <code>MX</code> type records. * <code>exchange</code></p> <p>The exchange domain name for <code>MX</code> resource records. Only present for <code>MX</code> type records. * <code>nsdname</code></p> <p>A domain-name which specifies a host which should be authoritative for the specified class and domain. Usually present for <code>NS</code> type records. * <code>rdata</code></p> <p>The raw resource data (RDATA) for resource records that are not recognized. * <code>txt</code></p> <p>The record value for <code>TXT</code> records. When there is only one character string in this record, then this field takes a single Lua string. Otherwise this field takes a Lua table holding all the strings. * <code>ptrdname</code></p> <p>The record value for <code>PTR</code> records.</p> </li> </ul> <p>This method also takes an optional <code>options</code> argument table, which takes the following fields:</p> <ul> <li> <p><code>qtype</code></p> <p>The type of the question. Possible values are <code>1</code> (<code>TYPE_A</code>), <code>5</code> (<code>TYPE_CNAME</code>), <code>28</code> (<code>TYPE_AAAA</code>), or any other QTYPE value specified by RFC 1035 and RFC 3596. Default to <code>1</code> (<code>TYPE_A</code>). * <code>authority_section</code></p> <p>When set to a true value, the <code>answers</code> return value includes the <code>Authority</code> section of the DNS response. Default to <code>false</code>. * <code>additional_section</code></p> <p>When set to a true value, the <code>answers</code> return value includes the <code>Additional</code> section of the DNS response. Default to <code>false</code>.</p> </li> </ul> <p>The optional parameter <code>tries</code> can be provided as an empty table, and will be returned as a third result. The table will be an array with the error message for each (if any) failed try.</p> <p>When data truncation happens, the resolver will automatically retry using the TCP transport mode to query the current nameserver. All TCP connections are short lived.</p>"},{"location":"lua/dns/#tcp_query","title":"tcp_query","text":"<p><code>syntax: answers, err = r:tcp_query(name, options?)</code></p> <p>Just like the <code>query</code> method, but enforce the TCP transport mode instead of UDP.</p> <p>All TCP connections are short lived.</p> <p>Here is an example:</p> <pre><code>    local resolver = require \"resty.dns.resolver\"\n\n    local r, err = resolver:new{\n        nameservers = { \"8.8.8.8\" }\n    }\n    if not r then\n        ngx.say(\"failed to instantiate resolver: \", err)\n        return\n    end\n\n    local ans, err = r:tcp_query(\"www.google.com\", { qtype = r.TYPE_A })\n    if not ans then\n        ngx.say(\"failed to query: \", err)\n        return\n    end\n\n    local cjson = require \"cjson\"\n    ngx.say(\"records: \", cjson.encode(ans))\n</code></pre>"},{"location":"lua/dns/#set_timeout","title":"set_timeout","text":"<p><code>syntax: r:set_timeout(time)</code></p> <p>Overrides the current <code>timeout</code> setting by the <code>time</code> argument in milliseconds for all the nameserver peers.</p>"},{"location":"lua/dns/#compress_ipv6_addr","title":"compress_ipv6_addr","text":"<p><code>syntax: compressed = resty.dns.resolver.compress_ipv6_addr(address)</code></p> <p>Compresses the successive 16-bit zero groups in the textual format of the IPv6 address.</p> <p>For example,</p> <pre><code>    local resolver = require \"resty.dns.resolver\"\n    local compress = resolver.compress_ipv6_addr\n    local new_addr = compress(\"FF01:0:0:0:0:0:0:101\")\n</code></pre> <p>will yield <code>FF01::101</code> in the <code>new_addr</code> return value.</p>"},{"location":"lua/dns/#expand_ipv6_addr","title":"expand_ipv6_addr","text":"<p><code>syntax: expanded = resty.dns.resolver.expand_ipv6_addr(address)</code></p> <p>Expands the successive 16-bit zero groups in the textual format of the IPv6 address.</p> <p>For example,</p> <pre><code>    local resolver = require \"resty.dns.resolver\"\n    local expand = resolver.expand_ipv6_addr\n    local new_addr = expand(\"FF01::101\")\n</code></pre> <p>will yield <code>FF01:0:0:0:0:0:0:101</code> in the <code>new_addr</code> return value.</p>"},{"location":"lua/dns/#arpa_str","title":"arpa_str","text":"<p><code>syntax: arpa_record = resty.dns.resolver.arpa_str(address)</code></p> <p>Generates the reverse domain name for PTR lookups for both IPv4 and IPv6 addresses. Compressed IPv6 addresses will be automatically expanded.</p> <p>For example,</p> <pre><code>    local resolver = require \"resty.dns.resolver\"\n    local ptr4 = resolver.arpa_str(\"1.2.3.4\")\n    local ptr6 = resolver.arpa_str(\"FF01::101\")\n</code></pre> <p>will yield <code>4.3.2.1.in-addr.arpa</code> for <code>ptr4</code> and <code>1.0.1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1.0.F.F.ip6.arpa</code> for <code>ptr6</code>.</p>"},{"location":"lua/dns/#reverse_query","title":"reverse_query","text":"<p><code>syntax: answers, err = r:reverse_query(address)</code></p> <p>Performs a PTR lookup for both IPv4 and IPv6 addresses. This function is basically a wrapper for the <code>query</code> command which uses the <code>arpa_str</code> command to convert the IP address on the fly.</p>"},{"location":"lua/dns/#constants","title":"Constants","text":""},{"location":"lua/dns/#type_a","title":"TYPE_A","text":"<p>The <code>A</code> resource record type, equal to the decimal number <code>1</code>.</p>"},{"location":"lua/dns/#type_ns","title":"TYPE_NS","text":"<p>The <code>NS</code> resource record type, equal to the decimal number <code>2</code>.</p>"},{"location":"lua/dns/#type_cname","title":"TYPE_CNAME","text":"<p>The <code>CNAME</code> resource record type, equal to the decimal number <code>5</code>.</p>"},{"location":"lua/dns/#type_soa","title":"TYPE_SOA","text":"<p>The <code>SOA</code> resource record type, equal to the decimal number <code>6</code>.</p>"},{"location":"lua/dns/#type_ptr","title":"TYPE_PTR","text":"<p>The <code>PTR</code> resource record type, equal to the decimal number <code>12</code>.</p>"},{"location":"lua/dns/#type_mx","title":"TYPE_MX","text":"<p>The <code>MX</code> resource record type, equal to the decimal number <code>15</code>.</p>"},{"location":"lua/dns/#type_txt","title":"TYPE_TXT","text":"<p>The <code>TXT</code> resource record type, equal to the decimal number <code>16</code>.</p>"},{"location":"lua/dns/#type_aaaa","title":"TYPE_AAAA","text":"<p><code>syntax: typ = r.TYPE_AAAA</code></p> <p>The <code>AAAA</code> resource record type, equal to the decimal number <code>28</code>.</p>"},{"location":"lua/dns/#type_srv","title":"TYPE_SRV","text":"<p><code>syntax: typ = r.TYPE_SRV</code></p> <p>The <code>SRV</code> resource record type, equal to the decimal number <code>33</code>.</p> <p>See RFC 2782 for details.</p>"},{"location":"lua/dns/#type_spf","title":"TYPE_SPF","text":"<p><code>syntax: typ = r.TYPE_SPF</code></p> <p>The <code>SPF</code> resource record type, equal to the decimal number <code>99</code>.</p> <p>See RFC 4408 for details.</p>"},{"location":"lua/dns/#class_in","title":"CLASS_IN","text":"<p><code>syntax: class = r.CLASS_IN</code></p> <p>The <code>Internet</code> resource record type, equal to the decimal number <code>1</code>.</p>"},{"location":"lua/dns/#section_an","title":"SECTION_AN","text":"<p><code>syntax: stype = r.SECTION_AN</code></p> <p>Identifier of the <code>Answer</code> section in the DNS response. Equal to decimal number <code>1</code>.</p>"},{"location":"lua/dns/#section_ns","title":"SECTION_NS","text":"<p><code>syntax: stype = r.SECTION_NS</code></p> <p>Identifier of the <code>Authority</code> section in the DNS response. Equal to the decimal number <code>2</code>.</p>"},{"location":"lua/dns/#section_ar","title":"SECTION_AR","text":"<p><code>syntax: stype = r.SECTION_AR</code></p> <p>Identifier of the <code>Additional</code> section in the DNS response. Equal to the decimal number <code>3</code>.</p>"},{"location":"lua/dns/#automatic-error-logging","title":"Automatic Error Logging","text":"<p>By default, the underlying ngx_lua module does error logging when socket errors happen. If you are already doing proper error handling in your own Lua code, then you are recommended to disable this automatic error logging by turning off ngx_lua's lua_socket_log_errors directive, that is,</p> <pre><code>    lua_socket_log_errors off;\n</code></pre>"},{"location":"lua/dns/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like <code>set_by_lua*</code>, <code>log_by_lua*</code>, and <code>header_filter_by_lua*</code> where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.dns.resolver</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see https://github.com/openresty/lua-nginx-module/#data-sharing-within-an-nginx-worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.dns.resolver</code> instance. You should always initiate <code>resty.dns.resolver</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/dns/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module/#readme</li> <li>the lua-resty-memcached library.</li> <li>the lua-resty-redis library.</li> <li>the lua-resty-mysql library.</li> </ul>"},{"location":"lua/dns/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-dns.</p>"},{"location":"lua/etcd/","title":"etcd: Nonblocking Lua etcd driver library for nginx-module-lua","text":""},{"location":"lua/etcd/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/etcd/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-etcd\n</code></pre>"},{"location":"lua/etcd/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-etcd\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-etcd v1.10.6  released on Apr 07 2024.</p> <p>lua-resty-etcd Nonblocking Lua etcd driver library for OpenResty, this module supports etcd API v3.</p> <p></p>"},{"location":"lua/etcd/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-etcd.</p>"},{"location":"lua/exec/","title":"exec: Run external programs in nginx-module-lua without spawning a shell or blocking","text":""},{"location":"lua/exec/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/exec/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-exec\n</code></pre>"},{"location":"lua/exec/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-exec\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-exec v3.0.3  released on Aug 22 2017.</p> <p>A small Lua module for executing processes. It's primarily intended to be used with OpenResty, but will work in regular Lua applications as well. When used with OpenResty, it's completely non-blocking (otherwise it falls back to using LuaSocket and does block).</p> <p>It's similar to (and inspired by) lua-resty-shell, the primary difference being this module uses sockexec, which doesn't spawn a shell - instead you provide an array of argument strings, which means you don't need to worry about shell escaping/quoting/parsing rules.</p> <p>Additionally, as of version 2.0.0, you can use <code>resty.exec.socket</code> to access a lower-level interface that allows two-way communication with programs. You can read and write to running applications!</p> <p>This requires your web server to have an active instance of sockexec running.</p>"},{"location":"lua/exec/#changelog","title":"Changelog","text":"<ul> <li><code>3.0.0</code></li> <li>new field returned: <code>unknown</code> - if this happens please send me a bug!</li> <li><code>2.0.0</code></li> <li>New <code>resty.exec.socket</code> module for using a duplex connection</li> <li><code>resty.exec</code> no longer uses the <code>bufsize</code> argument</li> <li><code>resty.exec</code> now accepts a <code>timeout</code> argument, specify in milliseconds, defaults to 60s</li> <li>This is a major revision, please test thoroughly before upgrading!</li> <li>No changelog before <code>2.0.0</code></li> </ul>"},{"location":"lua/exec/#restyexec-usage","title":"<code>resty.exec</code> Usage","text":"<pre><code>local exec = require'resty.exec'\nlocal prog = exec.new('/tmp/exec.sock')\n</code></pre> <p>Creates a new <code>prog</code> object, using <code>/tmp/exec.sock</code> for its connection to sockexec.</p> <p>From there, you can use <code>prog</code> in a couple of different ways:</p>"},{"location":"lua/exec/#ez-mode","title":"ez-mode","text":"<pre><code>local res, err = prog('uname')\n\n-- res = { stdout = \"Linux\\n\", stderr = nil, exitcode = 0, termsig = nil }\n-- err = nil\n\nngx.print(res.stdout)\n</code></pre> <p>This will run <code>uname</code>, with no data on stdin.</p> <p>Returns a table of output/error codes, with <code>err</code> set to any errors encountered.</p>"},{"location":"lua/exec/#setup-argv-beforehand","title":"Setup argv beforehand","text":"<pre><code>prog.argv = { 'uname', '-a' }\nlocal res, err = prog()\n\n-- res = { stdout = \"Linux localhost 3.10.18 #1 SMP Tue Aug 2 21:08:34 PDT 2016 x86_64 GNU/Linux\\n\", stderr = nil, exitcode = 0, termsig = nil }\n-- err = nil\n\nngx.print(res.stdout)\n</code></pre>"},{"location":"lua/exec/#setup-stdin-beforehand","title":"Setup stdin beforehand","text":"<pre><code>prog.stdin = 'this is neat!'\nlocal res, err = prog('cat')\n\n-- res = { stdout = \"this is neat!\", stderr = nil, exitcode = 0, termsig = nil }\n-- err = nil\n\nngx.print(res.stdout)\n</code></pre>"},{"location":"lua/exec/#call-with-explicit-argv-stdin-data-stdoutstderr-callbacks","title":"Call with explicit argv, stdin data, stdout/stderr callbacks","text":"<pre><code>local res, err = prog( {\n    argv = 'cat',\n    stdin = 'fun!',\n    stdout = function(data) print(data) end,\n    stderr = function(data) print(\"error:\", data) end\n} )\n\n-- res = { stdout = nil, stderr = nil, exitcode = 0, termsig = nil }\n-- err = nil\n-- 'fun!' is printed\n</code></pre> <p>Note: here <code>argv</code> is a string, which is fine if your program doesn't need any arguments.</p>"},{"location":"lua/exec/#setup-stdoutstderr-callbacks","title":"Setup stdout/stderr callbacks","text":"<p>If you set <code>prog.stdout</code> or <code>prog.stderr</code> to a function, it will be called for each chunk of stdout/stderr data received.</p> <p>Please note that there's no guarantees of stdout/stderr being a complete string, or anything particularly sensible for that matter!</p> <pre><code>prog.stdout = function(data)\n    ngx.print(data)\n    ngx.flush(true)\nend\n\nlocal res, err = prog('some-program')\n</code></pre>"},{"location":"lua/exec/#treat-timeouts-as-non-errors","title":"Treat timeouts as non-errors","text":"<p>By default, <code>sockexec</code> treats a timeout as an error. You can disable this by setting the object's <code>timeout_fatal</code> key to false. Examples:</p> <pre><code>-- set timeout_fatal = false on the prog objects\nprog.timeout_fatal = false\n\n-- or, set it at calltime:\nlocal res, err = prog({argv = {'cat'}, timeout_fatal = false})\n</code></pre>"},{"location":"lua/exec/#but-i-actually-want-a-shell","title":"But I actually want a shell!","text":"<p>Not a problem! You can just do something like:</p> <pre><code>local res, err = prog('bash','-c','echo $PATH')\n</code></pre> <p>Or if you want to run an entire script:</p> <pre><code>prog.stdin = script_data\nlocal res, err = prog('bash')\n\n-- this is roughly equivalent to running `bash &lt; script` on the CLI\n</code></pre>"},{"location":"lua/exec/#daemonizing-processes","title":"Daemonizing processes","text":"<p>I generally recommend against daemonizing processes - I think it's far better to use some kind of message queue and/or supervision system, so you can monitor processes, take actions on failure, and so on.</p> <p>That said, if you want to spin off some process, you could use <code>start-stop-daemon</code>, ie:</p> <pre><code>local res, err = prog('start-stop-daemon','--pidfile','/dev/null','--background','--exec','/usr/bin/sleep', '--start','--','10')\n</code></pre> <p>will spawn <code>sleep 10</code> as a detached background process.</p> <p>If you don't want to deal with <code>start-stop-daemon</code>, I have a small utility for spawning a background program called idgaf, ie:</p> <pre><code>local res, err = prog('idgaf','sleep','10')\n</code></pre> <p>This will basically accomplish the same thing <code>start-stop-daemon</code> does without requiring a billion flags.</p>"},{"location":"lua/exec/#restyexecsocket-usage","title":"<code>resty.exec.socket</code> Usage","text":"<pre><code>local exec_socket = require'resty.exec.socket'\n\n-- you can specify timeout in milliseconds, optional\nlocal client = exec_socket:new({ timeout = 60000 })\n\n-- every new program instance requires a new\n-- call to connect\nlocal ok, err = client:connect('/tmp/exec.sock')\n\n-- send program arguments, only accepts a table of\n-- arguments\nclient:send_args({'cat'})\n\n-- send data for stdin\nclient:send('hello there')\n\n-- receive data\nlocal data, typ, err = client:receive()\n\n-- `typ` can be one of:\n--    `stdout`   - data from the program's stdout\n--    `stderr`   - data from the program's stderr\n--    `exitcode` - the program's exit code\n--    `termsig`  - if terminated via signal, what signal was used\n\n-- if `err` is set, data and typ will be nil\n-- common `err` values are `closed` and `timeout`\nprint(string.format('Received %s data: %s',typ,data)\n-- will print 'Received stdout data: hello there'\n\nclient:send('hey this cat process is still running')\ndata, typ, err = client:receive()\nprint(string.format('Received %s data: %s',typ,data)\n-- will print 'Received stdout data: hey this cat process is still running'\n\nclient:send_close() -- closes stdin\ndata, typ, err = client:receive()\nprint(string.format('Received %s data: %s',typ,data)\n-- will print 'Received exitcode data: 0'\n\ndata, typ, err = client:receive()\nprint(err) -- will print 'closed'\n</code></pre>"},{"location":"lua/exec/#client-object-methods","title":"<code>client</code> object methods:","text":"<ul> <li><code>ok, err = client:connect(path)</code></li> </ul> <p>Connects via unix socket to the path given. If this is running in nginx, the <code>unix:</code> string will be prepended automatically.</p> <ul> <li><code>bytes, err = client:send_args(args)</code></li> </ul> <p>Sends a table of arguments to sockexec and starts the program.</p> <ul> <li><code>bytes, err = client:send_data(data)</code></li> </ul> <p>Sends <code>data</code> to the program's standard input</p> <ul> <li><code>bytes, err = client:send(data)</code></li> </ul> <p>Just a shortcut to <code>client:send_data(data)</code></p> <ul> <li><code>bytes, err = client:send_close()</code></li> </ul> <p>Closes the program's standard input. You can also send an empty string, like <code>client:send_data('')</code></p> <ul> <li><code>data, typ, err = client:receive()</code></li> </ul> <p>Receives data from the running process. <code>typ</code> indicates the type of data, which can be <code>stdout</code>, <code>stderr</code>, <code>termsig</code>, <code>exitcode</code></p> <p><code>err</code> is typically either <code>closed</code> or <code>timeout</code></p> <ul> <li><code>client:close()</code></li> </ul> <p>Forcefully closes the client connection</p> <ul> <li><code>client:getfd()</code></li> </ul> <p>A getfd method, useful if you want to monitor the underlying socket connection in a select loop</p>"},{"location":"lua/exec/#some-example-nginx-configs","title":"Some example nginx configs","text":"<p>Assuming you're running sockexec at <code>/tmp/exec.sock</code></p> <pre><code>$ sockexec /tmp/exec.sock\n</code></pre> <p>Then in your nginx config:</p> <pre><code>location /uname-1 {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        local data,err = prog('uname')\n        if(err) then\n            ngx.say(err)\n        else\n            ngx.say(data.stdout)\n        end\n    }\n}\nlocation /uname-2 {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        prog.argv = { 'uname', '-a' }\n        local data,err = prog()\n        if(err) then\n            ngx.say(err)\n        else\n            ngx.say(data.stdout)\n        end\n    }\n}\nlocation /cat-1 {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        prog.stdin = 'this is neat!'\n        local data,err = prog('cat')\n        if(err) then\n            ngx.say(err)\n        else\n            ngx.say(data.stdout)\n        end\n    }\n}\nlocation /cat-2 {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        local data,err = prog({argv = 'cat', stdin = 'awesome'})\n        if(err) then\n            ngx.say(err)\n        else\n            ngx.say(data.stdout)\n        end\n    }\n}\nlocation /slow-print {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        prog.stdout = function(v)\n            ngx.print(v)\n            ngx.flush(true)\n        end\n        prog('/usr/local/bin/slow-print')\n    }\n    # look in `/misc` of this repo for `slow-print`\n}\nlocation /shell {\n    content_by_lua_block {\n        local prog = require'resty.exec'.new('/tmp/exec.sock')\n        local data, err = prog('bash','-c','echo $PATH')\n        if(err) then\n            ngx.say(err)\n        else\n            ngx.say(data.stdout)\n        end\n    }\n}\n</code></pre>"},{"location":"lua/exec/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-exec.</p>"},{"location":"lua/feishu-auth/","title":"feishu-auth: \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1","text":""},{"location":"lua/feishu-auth/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/feishu-auth/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-feishu-auth\n</code></pre>"},{"location":"lua/feishu-auth/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-feishu-auth\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-feishu-auth v0.0.1  released on Aug 11 2021.</p> <p>\u9002\u7528\u4e8e OpenResty / ngx_lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1</p>"},{"location":"lua/feishu-auth/#_1","title":"\u4f7f\u7528","text":""},{"location":"lua/feishu-auth/#_2","title":"\u4e0b\u8f7d","text":"<pre><code>cd /path/to\ngit clone git@github.com:ledgetech/lua-resty-http.git\ngit clone git@github.com:SkyLothar/lua-resty-jwt.git\ngit clone git@github.com:k8scat/lua-resty-feishu-auth.git\n</code></pre>"},{"location":"lua/feishu-auth/#_3","title":"\u914d\u7f6e","text":"<pre><code>server {\n    access_by_lua_block {\n        local feishu_auth = require \"resty.feishu_auth\"\n        feishu_auth.app_id = \"\"\n        feishu_auth.app_secret = \"\"\n        feishu_auth.callback_uri = \"/feishu_auth_callback\"\n        feishu_auth.logout_uri = \"/feishu_auth_logout\"\n        feishu_auth.app_domain = \"feishu-auth.example.com\"\n\n        feishu_auth.jwt_secret = \"thisisjwtsecret\"\n\n        feishu_auth.ip_blacklist = {\"47.1.2.3\"}\n        feishu_auth.uri_whitelist = {\"/\"}\n        feishu_auth.department_whitelist = {\"0\"}\n\n        feishu_auth:auth()\n    }\n}\n</code></pre>"},{"location":"lua/feishu-auth/#_4","title":"\u914d\u7f6e\u8bf4\u660e","text":"<ul> <li><code>app_id</code> \u7528\u4e8e\u8bbe\u7f6e\u98de\u4e66\u4f01\u4e1a\u81ea\u5efa\u5e94\u7528\u7684 <code>App ID</code></li> <li><code>app_secret</code> \u7528\u4e8e\u8bbe\u7f6e\u98de\u4e66\u4f01\u4e1a\u81ea\u5efa\u5e94\u7528\u7684 <code>App Secret</code></li> <li><code>callback_uri</code> \u7528\u4e8e\u8bbe\u7f6e\u98de\u4e66\u7f51\u9875\u767b\u5f55\u540e\u7684\u56de\u8c03\u5730\u5740\uff08\u9700\u5728\u98de\u4e66\u4f01\u4e1a\u81ea\u5efa\u5e94\u7528\u7684\u5b89\u5168\u8bbe\u7f6e\u4e2d\u8bbe\u7f6e\u91cd\u5b9a\u5411 URL\uff09</li> <li><code>logout_uri</code> \u7528\u4e8e\u8bbe\u7f6e\u767b\u51fa\u5730\u5740</li> <li><code>app_domain</code> \u7528\u4e8e\u8bbe\u7f6e\u8bbf\u95ee\u57df\u540d\uff08\u9700\u548c\u4e1a\u52a1\u670d\u52a1\u7684\u8bbf\u95ee\u57df\u540d\u4e00\u81f4\uff09</li> <li><code>jwt_secret</code> \u7528\u4e8e\u8bbe\u7f6e JWT secret</li> <li><code>ip_blacklist</code> \u7528\u4e8e\u8bbe\u7f6e IP \u9ed1\u540d\u5355</li> <li><code>uri_whitelist</code> \u7528\u4e8e\u8bbe\u7f6e\u5730\u5740\u767d\u540d\u5355\uff0c\u4f8b\u5982\u9996\u9875\u4e0d\u9700\u8981\u767b\u5f55\u8ba4\u8bc1</li> <li><code>department_whitelist</code> \u7528\u4e8e\u8bbe\u7f6e\u90e8\u95e8\u767d\u540d\u5355\uff08\u5b57\u7b26\u4e32\uff09</li> </ul>"},{"location":"lua/feishu-auth/#_5","title":"\u5e94\u7528\u6743\u9650\u8bf4\u660e","text":"<ul> <li>\u83b7\u53d6\u90e8\u95e8\u57fa\u7840\u4fe1\u606f</li> <li>\u83b7\u53d6\u90e8\u95e8\u7ec4\u7ec7\u67b6\u6784\u4fe1\u606f</li> <li>\u4ee5\u5e94\u7528\u8eab\u4efd\u8bfb\u53d6\u901a\u8baf\u5f55</li> <li>\u83b7\u53d6\u7528\u6237\u7ec4\u7ec7\u67b6\u6784\u4fe1\u606f</li> <li>\u83b7\u53d6\u7528\u6237\u57fa\u672c\u4fe1\u606f</li> </ul>"},{"location":"lua/feishu-auth/#_6","title":"\u4f9d\u8d56\u6a21\u5757","text":"<ul> <li>lua-resty-http</li> <li>lua-resty-jwt</li> </ul>"},{"location":"lua/feishu-auth/#_7","title":"\u76f8\u5173\u9879\u76ee","text":"<ul> <li>lua-resty-weauth \u9002\u7528\u4e8e OpenResty / ngx_lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1</li> </ul>"},{"location":"lua/feishu-auth/#_8","title":"\u4f5c\u8005","text":"<p>K8sCat k8scat@gmail.com</p>"},{"location":"lua/feishu-auth/#_9","title":"\u5f00\u6e90\u534f\u8bae","text":"<p>MIT</p>"},{"location":"lua/feishu-auth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-feishu-auth.</p>"},{"location":"lua/fileinfo/","title":"fileinfo: LuaJIT FFI bindings to libmagic, magic number recognition library - tries to determine file types","text":""},{"location":"lua/fileinfo/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/fileinfo/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-fileinfo\n</code></pre>"},{"location":"lua/fileinfo/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-fileinfo\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-fileinfo v1.0  released on Oct 09 2014.</p> <p><code>lua-resty-fileinfo</code> is a file information library implementing LuaJIT bindings to <code>libmagic</code>.</p>"},{"location":"lua/fileinfo/#hello-world-with-lua-resty-fileinfo","title":"Hello World with lua-resty-fileinfo","text":"<pre><code>local fileinfo = require \"resty.fileinfo\"\nfileinfo\"a.txt\"\n</code></pre> <p>This will return string containing <code>ASCII text</code>. But there are other information available as well.</p>"},{"location":"lua/fileinfo/#lua-api","title":"Lua API","text":"<p>TBD</p>"},{"location":"lua/fileinfo/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-fileinfo.</p>"},{"location":"lua/ftpclient/","title":"ftpclient: Lua ftp client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/ftpclient/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/ftpclient/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-ftpclient\n</code></pre>"},{"location":"lua/ftpclient/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-ftpclient\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-ftpclient v1.1  released on Aug 07 2018.</p> <p>lua-resty-ftpclient - Lua ftp client driver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/ftpclient/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-ftpclient.</p>"},{"location":"lua/global-throttle/","title":"global-throttle: General purpose flow control with shared storage support","text":""},{"location":"lua/global-throttle/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/global-throttle/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-global-throttle\n</code></pre>"},{"location":"lua/global-throttle/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-global-throttle\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-global-throttle v0.2.0  released on Dec 30 2020.</p>"},{"location":"lua/global-throttle/#usage","title":"Usage","text":"<p>A generic, distributed throttling implementation for Openresty. It can be used to throttle any action let it be a request or a function call. Currently only approximate sliding window rate limiting is implemented.</p> <p>First require the module:</p> <pre><code>local global_throttle = require \"resty.global_throttle\"\n</code></pre> <p>After that you can create an instance of throttle like following where 100 is the limit that will be enforced per 2 seconds window. The third parameter tells the throttler what store provider it should use to store its internal statistics.</p> <pre><code>local memc_host = os.getenv(\"MEMCACHED_HOST\")\nlocal memc_port = os.getenv(\"MEMCACHED_PORT\")\n\n...\n\nlocal my_throttle, err = global_throttle.new(namespace, 10, 2, {\n  provider = \"memcached\",\n  host = memc_host,\n  port = memc_port,\n  connect_timeout = 15,\n  max_idle_timeout = 10000,\n  pool_size = 100,\n})\n</code></pre> <p>Finally you call following everytime before whatever it is you're throttling:</p> <pre><code>local estimated_final_count, desired_delay, err = my_throttle:process(\"identifier of whatever it is your are throttling\")\n</code></pre> <p>When <code>desired_delay</code> exists, it means the limit is exceeding and client should be throttled for <code>desired_delay</code> seconds.</p> <p>For more complete understanding of how to use this library, refer to <code>examples</code> directory.</p>"},{"location":"lua/global-throttle/#production-considerations","title":"Production considerations","text":"<ol> <li>Ensure you configure the connection pool size properly. Basically if your store (i.e memcached) can handle <code>n</code> concurrent connections and your NGINX has <code>m</code> workers, then the connection pool size should be configured as <code>n/m</code>. That is because the configured pool size is per NGINX worker. For example, if your store usually handles 1000 concurrent requests and you have 10 NGINX workers, then the connection pool size should be 100. Similarly if you have <code>p</code> different NGINX instances, then connection pool size should be <code>n/m/p</code>.</li> <li>Be careful when caching decisions based on <code>desired_delay</code>, sometimes it is too small that your cache can interpret it as 0 and cache indefinitely. Also caching for very little time probably does not add any benefit.</li> </ol>"},{"location":"lua/global-throttle/#contributions-and-development","title":"Contributions and Development","text":"<p>The library is designed to be extendable. Currently only approximate sliding window algorithm is implemented in <code>lib/resty/global_throttle/sliding_window.lua</code>. It can be used as a reference point to implement other algorithms.</p> <p>Storage providers are implemented in <code>lib/resty/global_throttle/store/</code>.</p>"},{"location":"lua/global-throttle/#references","title":"References","text":"<ul> <li>Cloudflare's blog post on approximate sliding window: https://blog.cloudflare.com/counting-things-a-lot-of-different-things/</li> </ul>"},{"location":"lua/global-throttle/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-global-throttle.</p>"},{"location":"lua/healthcheck/","title":"healthcheck: Healthcheck library for nginx-module-lua to validate upstream service status","text":""},{"location":"lua/healthcheck/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/healthcheck/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-healthcheck\n</code></pre>"},{"location":"lua/healthcheck/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-healthcheck\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-healthcheck v3.1.1  released on Nov 19 2025.</p> <p> </p> <p>A health check library for OpenResty.</p>"},{"location":"lua/healthcheck/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    lua_shared_dict test_shm 8m;\n    lua_shared_dict my_worker_events 8m;\n    init_worker_by_lua_block {\n\n        local we = require \"resty.worker.events\"\n        local ok, err = we.configure({\n            shm = \"my_worker_events\",\n            interval = 0.1\n        })\n        if not ok then\n            ngx.log(ngx.ERR, \"failed to configure worker events: \", err)\n            return\n        end\n\n        local healthcheck = require(\"resty.healthcheck\")\n        local checker = healthcheck.new({\n            name = \"testing\",\n            shm_name = \"test_shm\",\n            checks = {\n                active = {\n                    type = \"https\",\n                    http_path = \"/status\",\n                    healthy  = {\n                        interval = 2,\n                        successes = 1,\n                    },\n                    unhealthy  = {\n                        interval = 1,\n                        http_failures = 2,\n                    }\n                },\n            }\n        })\n\n        local ok, err = checker:add_target(\"127.0.0.1\", 8080, \"example.com\", false)\n\n        local handler = function(target, eventname, sourcename, pid)\n            ngx.log(ngx.DEBUG,\"Event from: \", sourcename)\n            if eventname == checker.events.remove\n                -- a target was removed\n                ngx.log(ngx.DEBUG,\"Target removed: \",\n                    target.ip, \":\", target.port, \" \", target.hostname)\n            elseif eventname == checker.events.healthy\n                -- target changed state, or was added\n                ngx.log(ngx.DEBUG,\"Target switched to healthy: \",\n                    target.ip, \":\", target.port, \" \", target.hostname)\n            elseif eventname ==  checker.events.unhealthy\n                -- target changed state, or was added\n                ngx.log(ngx.DEBUG,\"Target switched to unhealthy: \",\n                    target.ip, \":\", target.port, \" \", target.hostname)\n            else\n                -- unknown event\n            end\n        end\n    }\n}\n</code></pre>"},{"location":"lua/healthcheck/#description","title":"Description","text":"<p>This library supports performing active and passive health checks on arbitrary hosts.</p> <p>Control of the library happens via its programmatic API. Consumption of its events happens via the lua-resty-worker-events library.</p> <p>Targets are added using <code>checker:add_target(host, port)</code>. Changes in status (\"healthy\" or \"unhealthy\") are broadcasted via worker-events.</p> <p>Active checks are executed in the background based on the specified timer intervals.</p> <p>For passive health checks, the library receives explicit notifications via its programmatic API using functions such as <code>checker:report_http_status(host, port, status)</code>.</p> <p>See the online LDoc documentation for the complete API.</p>"},{"location":"lua/healthcheck/#history","title":"History","text":"<p>Versioning is strictly based on Semantic Versioning</p>"},{"location":"lua/healthcheck/#releasing-new-versions","title":"Releasing new versions:","text":"<ul> <li>update changelog below (PR's should be merged including a changelog entry)</li> <li>based on changelog determine new SemVer version</li> <li>create a new rockspec</li> <li>render the docs using <code>ldoc</code> (don't do this within PR's)</li> <li>commit as \"release x.x.x\" (do not include rockspec revision)</li> <li>tag the commit with \"x.x.x\" (do not include rockspec revision)</li> <li>push commit and tag</li> <li>upload rock to luarocks: <code>luarocks upload rockspecs/[name] --api-key=abc</code></li> </ul>"},{"location":"lua/healthcheck/#311-19-nov-2025","title":"3.1.1 (19-Nov-2025)","text":"<ul> <li>Fix: change default headers to empty table instead of an array to remove deprecation notice #174</li> </ul>"},{"location":"lua/healthcheck/#310-19-jun-2024","title":"3.1.0 (19-Jun-2024)","text":"<ul> <li>Feat: remove version check of resty.events #162</li> </ul>"},{"location":"lua/healthcheck/#302-16-may-2024","title":"3.0.2 (16-May-2024)","text":"<ul> <li>Fix: avoid creating multiple timers to run the same active check #157</li> </ul>"},{"location":"lua/healthcheck/#301-22-dec-2023","title":"3.0.1 (22-Dec-2023)","text":"<ul> <li>Fix: fix delay clean logic when multiple healthchecker was started #146</li> </ul>"},{"location":"lua/healthcheck/#300-12-oct-2023","title":"3.0.0 (12-Oct-2023)","text":"<ul> <li>Perf: optimize by localizing some functions #92 (backport)</li> <li>Fix: Generate fresh default http_statuses within new() #83 (backport)</li> </ul>"},{"location":"lua/healthcheck/#200-22-sep-2020","title":"2.0.0 (22-Sep-2020)","text":"<p>Note: Changes in this version has been discarded from current &amp; future development. Below you can see it's changelog but be aware that these changes might not be present in <code>3.y.z</code> unless they are explicitly stated in <code>3.y.z</code>, <code>1.6.3</code> or previous releases. Read more at: release 3.0.0 (#142) and chore(*): realign master branch to 3.0.0 release (#144)</p> <ul> <li>BREAKING: fallback for deprecated top-level field <code>type</code> is now removed   (deprecated since <code>0.5.0</code>) #56</li> <li>BREAKING: Bump <code>lua-resty-worker-events</code> dependency to <code>2.0.0</code>. This makes   a lot of the APIs in this library asynchronous as the worker events <code>post</code>   and <code>post_local</code> won't anymore call <code>poll</code> on a running worker automatically,   for more information, see:   https://github.com/Kong/lua-resty-worker-events#200-16-september-2020</li> <li>BREAKING: tcp_failures can no longer be 0 on http(s) checks (unless http(s)_failures   are also set to 0) #55</li> <li>feature: Added support for https_sni #49</li> <li>fix: properly log line numbers by using tail calls #29</li> <li>fix: when not providing a hostname, use IP #48</li> <li>fix: makefile; make install</li> <li>feature: added a status version field #54</li> <li>feature: add headers for probe request #54</li> <li>fix: exit early when reloading during a probe #47</li> <li>fix: prevent target-list from being nil, due to async behaviour #44</li> <li>fix: replace timer and node-wide locks with resty-timer, to prevent interval   skips #59</li> <li>change: added additional logging on posting events #25</li> <li>fix: do not run out of timers during init/init_worker when adding a vast   amount of targets #57</li> <li>fix: do not call on the module table, but use a method for locks. Also in   #57</li> </ul>"},{"location":"lua/healthcheck/#163-06-sep-2023","title":"1.6.3 (06-Sep-2023)","text":"<ul> <li>Feature: Added support for https_sni #49 (backport)</li> <li>Fix: Use OpenResty API for mTLS #99 (backport)</li> </ul>"},{"location":"lua/healthcheck/#162-17-nov-2022","title":"1.6.2 (17-Nov-2022)","text":"<ul> <li>Fix: avoid raising worker events for new targets that were marked for delayed   removal, i.e. targets that already exist in memory only need the removal flag   cleared when added back. #122</li> </ul>"},{"location":"lua/healthcheck/#161-25-jul-2022","title":"1.6.1 (25-Jul-2022)","text":"<ul> <li>Fix: improvements to ensure the proper securing of shared resources to avoid   race conditions and clearly report failure states.   #112,   #113,   #114.</li> <li>Fix: reduce the frequency of checking for unused targets, reducing the number   of locks created. #116</li> <li>Fix accept any lua-resty-events <code>0.1.x</code> release. #118</li> </ul>"},{"location":"lua/healthcheck/#160-27-jun-2022","title":"1.6.0 (27-Jun-2022)","text":"<ul> <li>Feature: introduce support to lua-resty-events   module in addition to lua-resty-worker-events   support. With this addition, the lua-resty-healthcheck luarocks package does   not require a specific event-sharing module anymore, but you are still   required to provide either lua-resty-worker-events or lua-resty-events.   #105</li> <li>Change: if available, lua-resty-healthcheck now uses <code>string.buffer</code>, the new LuaJIT's   serialization API. If it is unavailable, lua-resty-healthcheck fallbacks to   cjson.  #109</li> </ul>"},{"location":"lua/healthcheck/#153-14-nov-2022","title":"1.5.3 (14-Nov-2022)","text":"<ul> <li>Fix: avoid raising worker events for new targets that were marked for delayed   removal, i.e. targets that already exist in memory only need the removal flag   cleared when added back. #121</li> </ul>"},{"location":"lua/healthcheck/#152-07-jul-2022","title":"1.5.2 (07-Jul-2022)","text":"<ul> <li>Better handling of <code>resty.lock</code> failure modes, adding more checks to ensure the   lock is held before running critical code, and improving the decision whether a   function should be retried after a timeout trying to acquire a lock.   #113</li> <li>Increased logging for locked function failures.   #114</li> <li>The cleanup frequency of deleted targets was lowered, cutting the number of   created locks in a short period.   #116</li> </ul>"},{"location":"lua/healthcheck/#151-23-mar-2022","title":"1.5.1 (23-Mar-2022)","text":"<ul> <li>Fix: avoid breaking active health checks when adding or removing targets.   #93</li> </ul>"},{"location":"lua/healthcheck/#150-09-feb-2022","title":"1.5.0 (09-Feb-2022)","text":"<ul> <li>New option <code>checks.active.headers</code> supports one or more lists of values indexed by   header name. #87</li> <li>Introduce dealyed_clear() function, used to remove addresses after a time interval.   This function may be used when an address is being removed but may be added again   before the interval expires, keeping its health status.   #88</li> </ul>"},{"location":"lua/healthcheck/#143-31-mar-2022","title":"1.4.3 (31-Mar-2022)","text":"<ul> <li>Fix: avoid breaking active health checks when adding or removing targets.   #100</li> </ul>"},{"location":"lua/healthcheck/#142-29-jun-2021","title":"1.4.2 (29-Jun-2021)","text":"<ul> <li>Fix: prevent new active checks being scheduled while a health check is running.   #72</li> <li>Fix: remove event watcher when stopping an active health check.   #74; fixes Kong issue   #7406</li> </ul>"},{"location":"lua/healthcheck/#141-17-feb-2021","title":"1.4.1 (17-Feb-2021)","text":"<ul> <li>Fix: make sure that a single worker will actively check hosts' statuses.   #67</li> </ul>"},{"location":"lua/healthcheck/#140-07-jan-2021","title":"1.4.0 (07-Jan-2021)","text":"<ul> <li>Use a single timer to actively health check targets. This reduces the number   of timers used by health checkers, as they used to use two timers by each   target. #62</li> </ul>"},{"location":"lua/healthcheck/#130-17-jun-2020","title":"1.3.0 (17-Jun-2020)","text":"<ul> <li>Adds support to mTLS to active healthchecks. This feature  can be used adding   the fields <code>ssl_cert</code> and <code>ssl_key</code>, with certificate and key respectively,   when creating a new healthcheck object.   #41</li> </ul>"},{"location":"lua/healthcheck/#120-13-feb-2020","title":"1.2.0 (13-Feb-2020)","text":"<ul> <li>Adds <code>set_all_target_statuses_for_hostname</code>, which sets the targets for    all entries with a given hostname at once.</li> </ul>"},{"location":"lua/healthcheck/#112-19-dec-2019","title":"1.1.2 (19-Dec-2019)","text":"<ul> <li>Fix: when <code>ngx.sleep</code> API is not available (e.g. in the log phase) it is not    possible to lock using lua-resty-lock and any function that needs exclusive    access would fail. This fix adds a retry method that starts a new light    thread, which has access to <code>ngx.sleep</code>, to lock the critical path.    #37;</li> </ul>"},{"location":"lua/healthcheck/#111-14-nov-2019","title":"1.1.1 (14-Nov-2019)","text":"<ul> <li>Fix: fail when it is not possible to get exclusive access to the list of    targets. This fix prevents that workers get to an inconsistent state.    #34;</li> </ul>"},{"location":"lua/healthcheck/#110-30-sep-2019","title":"1.1.0 (30-Sep-2019)","text":"<ul> <li>Add support for setting the custom <code>Host</code> header to be used for active checks.</li> <li>Fix: log error on SSL Handshake failure    #28;</li> </ul>"},{"location":"lua/healthcheck/#100-05-jul-2019","title":"1.0.0 (05-Jul-2019)","text":"<ul> <li>BREAKING: all API functions related to hosts require a <code>hostname</code> argument    now. This way different hostnames listening on the same IP and ports    combination do not have an effect on each other.</li> <li>Fix: fix reporting active TCP probe successes    #20;    fixes issue #19</li> </ul>"},{"location":"lua/healthcheck/#061-04-apr-2019","title":"0.6.1 (04-Apr-2019)","text":"<ul> <li>Fix: set up event callback only after target list is loaded    #18;    fixes Kong issue #4453</li> </ul>"},{"location":"lua/healthcheck/#060-26-sep-2018","title":"0.6.0 (26-Sep-2018)","text":"<ul> <li>Introduce <code>checks.active.https_verify_certificate</code> field.    It is <code>true</code> by default; setting it to <code>false</code> disables certificate    verification in active healthchecks over HTTPS.</li> </ul>"},{"location":"lua/healthcheck/#050-25-jul-2018","title":"0.5.0 (25-Jul-2018)","text":"<ul> <li>Add support for <code>https</code> -- thanks @gaetanfl for the PR!</li> <li>Introduce separate <code>checks.active.type</code> and <code>checks.passive.type</code> fields;    the top-level <code>type</code> field is still supported as a fallback but is now    deprecated.</li> </ul>"},{"location":"lua/healthcheck/#042-23-may-2018","title":"0.4.2 (23-May-2018)","text":"<ul> <li>Fix <code>Host</code> header in active healthchecks</li> </ul>"},{"location":"lua/healthcheck/#041-21-may-2018","title":"0.4.1 (21-May-2018)","text":"<ul> <li>Fix internal management of healthcheck counters</li> </ul>"},{"location":"lua/healthcheck/#040-20-mar-2018","title":"0.4.0 (20-Mar-2018)","text":"<ul> <li>Correct setting of defaults in <code>http_statuses</code></li> <li>Type and bounds checking to <code>checks</code> table</li> </ul>"},{"location":"lua/healthcheck/#030-18-dec-2017","title":"0.3.0 (18-Dec-2017)","text":"<ul> <li>Disable individual checks by setting their counters to 0</li> </ul>"},{"location":"lua/healthcheck/#020-30-nov-2017","title":"0.2.0 (30-Nov-2017)","text":"<ul> <li>Adds <code>set_target_status</code></li> </ul>"},{"location":"lua/healthcheck/#010-27-nov-2017-initial-release","title":"0.1.0 (27-Nov-2017) Initial release","text":"<ul> <li>Initial upload</li> </ul>"},{"location":"lua/healthcheck/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-healthcheck.</p>"},{"location":"lua/hmac/","title":"hmac: HMAC functions for nginx-module-lua and LuaJIT","text":""},{"location":"lua/hmac/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/hmac/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-hmac\n</code></pre>"},{"location":"lua/hmac/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-hmac\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-hmac v0.6  released on May 31 2023.</p> <p>lua-resty-hmac - HMAC functions for ngx_lua and LuaJIT</p>"},{"location":"lua/hmac/#status","title":"Status","text":"<p>This library is still under active development and is considered production ready.</p>"},{"location":"lua/hmac/#description","title":"Description","text":"<p>This library requires an nginx build with OpenSSL, the ngx_lua module, and LuaJIT 2.0.</p>"},{"location":"lua/hmac/#synopsis","title":"Synopsis","text":"<pre><code>    # nginx.conf:\n\n    server {\n        location = /test {\n            content_by_lua_file conf/test.lua;\n        }\n    }\n\n    -- conf/test.lua:\n\n    local hmac = require \"resty.hmac\"\n\n    local hmac_sha1 = hmac:new(\"secret_key\", hmac.ALGOS.SHA1)\n    if not hmac_sha1 then\n        ngx.say(\"failed to create the hmac_sha1 object\")\n        return\n    end\n\n    local ok = hmac_sha1:update(\"he\")\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n    ok = hmac_sha1:update(\"llo\")\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n    local mac = hmac_sha1:final()  -- binary mac\n\n    local str = require \"resty.string\"\n    ngx.say(\"hmac_sha1: \", str.to_hex(mac))\n        -- output: \"hmac_sha1: aee4b890b574ea8fa4f6a66aed96c3e590e5925a\"\n\n    -- dont forget to reset after final!\n    if not hmac_sha1:reset() then\n        ngx.say(\"failed to reset hmac_sha1\")\n        return\n    end\n\n    -- short version\n    ngx.say(\"hmac_sha1: \", hmac_sha1:final(\"world\", true))\n        -- output: \"hmac_sha1: 4e9538f1efbe565c522acfb72fce6092ea6b15e0\"\n</code></pre>"},{"location":"lua/hmac/#methods","title":"Methods","text":"<p>To load this library,</p> <ol> <li>you need to specify this library's path in ngx_lua's lua_package_path directive. For example, <code>lua_package_path \"/path/to/lua-resty-hmac/lib/?.lua;;\";</code>.</li> <li>you use <code>require</code> to load the library into a local Lua variable:</li> </ol> <pre><code>    local hmac = require \"resty.hmac\"\n</code></pre>"},{"location":"lua/hmac/#new","title":"new","text":"<p><code>syntax: local hmac_sha256 = hmac:new(key [, hash_algorithm])</code></p> <p>Creates a new hmac instance. If failed, returns <code>nil</code>.</p> <p>The <code>key</code> argument specifies the key to use when calculating the message authentication code (MAC). <code>key</code> is a lua string which may contain printable characters or binary data.</p> <p>The <code>hash_algorithm</code> argument specifies which hashing algorithm to use (<code>hmac.ALGOS.MD5</code>, <code>hmac.ALGOS.SHA1</code>, <code>hmac.ALGOS.SHA256</code>, <code>hmac.ALGOS.SHA512</code>). The default value is <code>hmac.ALGOS.MD5</code>.</p>"},{"location":"lua/hmac/#update","title":"update","text":"<p><code>syntax: hmac_sha256:update(data)</code></p> <p>Updates the MAC calculation to include new data. If failed, returns <code>false</code>.</p> <p>The <code>data</code> argument specifies the additional data to include in the MAC. <code>data</code> is a lua string which may contain printable characters or binary data.</p>"},{"location":"lua/hmac/#final","title":"final","text":"<p><code>syntax: local mac = hmac_sha256:final([data, output_hex])</code></p> <p>Finalizes the MAC calculation and returns the final MAC value. If failed, returns <code>nil</code>. When <code>output_hex</code> is not <code>true</code> returns a lua string containing the raw, binary MAC. When <code>output_hex</code> is <code>true</code> returns a lua string containing the hexadecimal representation of the MAC.</p> <p>The <code>data</code> argument specifies the additional data to include in the MAC before finalizing the calculation. The default value is <code>nil</code>.</p> <p>The <code>output_hex</code> argument specifies wether the MAC should be returned as hex or binary. If <code>true</code> the MAC will be returned as hex. The default value is <code>false</code>.</p>"},{"location":"lua/hmac/#reset","title":"reset","text":"<p><code>syntax: hmac_sha256:reset()</code></p> <p>Resets the internal hmac context so it can be re-used to calculate a new MAC. If failed, returns <code>false</code>. If successful, the <code>key</code> and <code>hash_algorithm</code> remain the same but all other information is cleared.</p> <p>This MUST be called after <code>hmac_sha256:final()</code> in order to calculate a new MAC using the same hmac instance.</p>"},{"location":"lua/hmac/#prerequisites","title":"Prerequisites","text":"<ul> <li>LuaJIT 2.0+</li> <li>ngx_lua module</li> <li>lua-resty-string 0.8+</li> <li>OpenSSL 1.0.0+</li> </ul>"},{"location":"lua/hmac/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/hmac/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-hmac.</p>"},{"location":"lua/hoedown/","title":"hoedown: LuaJIT FFI bindings to Hoedown, a standards compliant, fast, secure markdown processing library in C","text":""},{"location":"lua/hoedown/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/hoedown/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-hoedown\n</code></pre>"},{"location":"lua/hoedown/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-hoedown\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-hoedown v0.91  released on Oct 09 2014.</p> <p><code>lua-resty-hoedown</code> is a Markdown, SmartyPants, buffer, and html and href/url escaping library implementing LuaJIT bindings to Hoedown.</p>"},{"location":"lua/hoedown/#hello-world-with-lua-resty-hoedown","title":"Hello World with lua-resty-hoedown","text":"<pre><code>local hoedown = require \"resty.hoedown\"\nhoedown[[\n## Are you ready for the truth?\n\nNow that there is the Tec-9, a crappy spray gun from South Miami.\nThis gun is advertised as the most popular gun in American crime.\nDo you believe that shit? It actually says that in the little book\nthat comes with it: the most popular gun in American crime. Like\nthey're actually proud of that shit.\n\n## I'm serious as a heart attack\n\nThe path of the righteous man is beset on all sides by the iniquities\nof the selfish and the tyranny of evil men. Blessed is he who, in the\nname of charity and good will, shepherds the weak through the valley\nof darkness, for he is truly his brother's keeper and the finder of\nlost children. And I will strike down upon thee with great vengeance\nand furious anger those who would attempt to poison and destroy My\nbrothers.\n]]\n</code></pre> <p>This will return string containing:</p> <pre><code>&lt;h1&gt;Are you ready for the truth?&lt;/h1&gt;\n\n&lt;p&gt;Now that there is the Tec-9, a crappy spray gun from South Miami.\nThis gun is advertised as the most popular gun in American crime.\nDo you believe that shit? It actually says that in the little book\nthat comes with it: the most popular gun in American crime. Like\nthey&amp;#39;re actually proud of that shit.&lt;/p&gt;\n\n&lt;h2&gt;I&amp;#39;m serious as a heart attack&lt;/h2&gt;\n\n&lt;p&gt;The path of the righteous man is beset on all sides by the iniquities\nof the selfish and the tyranny of evil men. Blessed is he who, in the\nname of charity and good will, shepherds the weak through the valley\nof darkness, for he is truly his brother&amp;#39;s keeper and the finder of\nlost children. And I will strike down upon thee with great vengeance\nand furious anger those who would attempt to poison and destroy My\nbrothers.&lt;/p&gt;\n</code></pre>"},{"location":"lua/hoedown/#lua-api","title":"Lua API","text":"<p>TBD</p>"},{"location":"lua/hoedown/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-hoedown.</p>"},{"location":"lua/http/","title":"http: Lua HTTP client cosocket driver for nginx-module-lua","text":""},{"location":"lua/http/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/http/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-http\n</code></pre>"},{"location":"lua/http/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-http\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-http v0.17.2  released on Feb 29 2024.</p> <p>Lua HTTP client cosocket driver for OpenResty / ngx_lua.</p>"},{"location":"lua/http/#status","title":"Status","text":"<p>Production ready.</p> <p></p>"},{"location":"lua/http/#features","title":"Features","text":"<ul> <li>HTTP 1.0 and 1.1</li> <li>SSL</li> <li>Streaming interface to the response body, for predictable memory usage</li> <li>Alternative simple interface for single-shot requests without a manual connection step</li> <li>Chunked and non-chunked transfer encodings</li> <li>Connection keepalives</li> <li>Request pipelining</li> <li>Trailers</li> <li>HTTP proxy connections</li> <li>mTLS (requires <code>ngx_lua_http_module</code> &gt;= v0.10.23)</li> </ul>"},{"location":"lua/http/#api","title":"API","text":"<ul> <li>new</li> <li>connect</li> <li>set_proxy_options</li> <li>set_timeout</li> <li>set_timeouts</li> <li>set_keepalive</li> <li>get_reused_times</li> <li>close</li> <li>request</li> <li>request_uri</li> <li>request_pipeline</li> <li>parse_uri</li> <li>get_client_body_reader</li> <li>Response<ul> <li>body_reader</li> <li>read_body</li> <li>read_trailers</li> </ul> </li> </ul>"},{"location":"lua/http/#deprecated","title":"Deprecated","text":"<p>These methods may be removed in future versions.</p> <ul> <li>connect_proxy</li> <li>ssl_handshake</li> <li>proxy_request</li> <li>proxy_response</li> </ul>"},{"location":"lua/http/#usage","title":"Usage","text":"<p>There are two basic modes of operation:</p> <ol> <li> <p>Simple single-shot requests which require no manual connection management but which buffer the entire response and leave the connection either closed or back in the connection pool.</p> </li> <li> <p>Streamed requests where the connection is established separately, then the request is sent, the body stream read in chunks, and finally the connection is manually closed or kept alive. This technique requires a little more code but provides the ability to discard potentially large response bodies on the Lua side, as well as pipelining multiple requests over a single connection.</p> </li> </ol>"},{"location":"lua/http/#single-shot-request","title":"Single-shot request","text":"<pre><code>local httpc = require(\"resty.http\").new()\n\n-- Single-shot requests use the `request_uri` interface.\nlocal res, err = httpc:request_uri(\"http://example.com/helloworld\", {\n    method = \"POST\",\n    body = \"a=1&amp;b=2\",\n    headers = {\n        [\"Content-Type\"] = \"application/x-www-form-urlencoded\",\n    },\n})\nif not res then\n    ngx.log(ngx.ERR, \"request failed: \", err)\n    return\nend\n\n-- At this point, the entire request / response is complete and the connection\n-- will be closed or back on the connection pool.\n\n-- The `res` table contains the expeected `status`, `headers` and `body` fields.\nlocal status = res.status\nlocal length = res.headers[\"Content-Length\"]\nlocal body   = res.body\n</code></pre>"},{"location":"lua/http/#streamed-request","title":"Streamed request","text":"<pre><code>local httpc = require(\"resty.http\").new()\n\n-- First establish a connection\nlocal ok, err, ssl_session = httpc:connect({\n    scheme = \"https\",\n    host = \"127.0.0.1\",\n    port = 8080,\n})\nif not ok then\n    ngx.log(ngx.ERR, \"connection failed: \", err)\n    return\nend\n\n-- Then send using `request`, supplying a path and `Host` header instead of a\n-- full URI.\nlocal res, err = httpc:request({\n    path = \"/helloworld\",\n    headers = {\n        [\"Host\"] = \"example.com\",\n    },\n})\nif not res then\n    ngx.log(ngx.ERR, \"request failed: \", err)\n    return\nend\n\n-- At this point, the status and headers will be available to use in the `res`\n-- table, but the body and any trailers will still be on the wire.\n\n-- We can use the `body_reader` iterator, to stream the body according to our\n-- desired buffer size.\nlocal reader = res.body_reader\nlocal buffer_size = 8192\n\nrepeat\n    local buffer, err = reader(buffer_size)\n    if err then\n        ngx.log(ngx.ERR, err)\n        break\n    end\n\n    if buffer then\n        -- process\n    end\nuntil not buffer\n\nlocal ok, err = httpc:set_keepalive()\nif not ok then\n    ngx.say(\"failed to set keepalive: \", err)\n    return\nend\n\n-- At this point, the connection will either be safely back in the pool, or closed.\n````\n\n## Connection\n\n## new\n\n`syntax: httpc, err = http.new()`\n\nCreates the HTTP connection object. In case of failures, returns `nil` and a string describing the error.\n\n## connect\n\n`syntax: ok, err, ssl_session = httpc:connect(options)`\n\nAttempts to connect to the web server while incorporating the following activities:\n\n- TCP connection\n- SSL handshake\n- HTTP proxy configuration\n\nIn doing so it will create a distinct connection pool name that is safe to use with SSL and / or proxy based connections, and as such this syntax is strongly recommended over the original (now deprecated) [TCP only connection syntax](#TCP-only-connect).\n\nThe options table has the following fields:\n\n* `scheme`: scheme to use, or nil for unix domain socket\n* `host`: target host, or path to a unix domain socket\n* `port`: port on target host, will default to `80` or `443` based on the scheme\n* `pool`: custom connection pool name. Option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsockconnect), except that the default will become a pool name constructed using the SSL / proxy properties, which is important for safe connection reuse. When in doubt, leave it blank!\n* `pool_size`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsockconnect)\n* `backlog`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsockconnect)\n* `proxy_opts`: sub-table, defaults to the global proxy options set, see [set\\_proxy\\_options](#set_proxy_options).\n* `ssl_reused_session`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake)\n* `ssl_verify`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake), except that it defaults to `true`.\n* `ssl_server_name`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake)\n* `ssl_send_status_req`: option as per [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake)\n* `ssl_client_cert`: will be passed to `tcpsock:setclientcert`. Requires `ngx_lua_http_module` &gt;= v0.10.23.\n* `ssl_client_priv_key`: as above.\n\n## set\\_timeout\n\n`syntax: httpc:set_timeout(time)`\n\nSets the socket timeout (in ms) for subsequent operations. See [set\\_timeouts](#set_timeouts) below for a more declarative approach.\n\n## set\\_timeouts\n\n`syntax: httpc:set_timeouts(connect_timeout, send_timeout, read_timeout)`\n\nSets the connect timeout threshold, send timeout threshold, and read timeout threshold, respectively, in milliseconds, for subsequent socket operations (connect, send, receive, and iterators returned from receiveuntil).\n\n## set\\_keepalive\n\n`syntax: ok, err = httpc:set_keepalive(max_idle_timeout, pool_size)`\n\nEither places the current connection into the pool for future reuse, or closes the connection. Calling this instead of [close](#close) is \"safe\" in that it will conditionally close depending on the type of request. Specifically, a `1.0` request without `Connection: Keep-Alive` will be closed, as will a `1.1` request with `Connection: Close`.\n\nIn case of success, returns `1`. In case of errors, returns `nil, err`. In the case where the connection is conditionally closed as described above, returns `2` and the error string `connection must be closed`, so as to distinguish from unexpected errors.\n\nSee [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsocksetkeepalive) for parameter documentation.\n\n## set\\_proxy\\_options\n\n`syntax: httpc:set_proxy_options(opts)`\n\nConfigure an HTTP proxy to be used with this client instance. The `opts` table expects the following fields:\n\n* `http_proxy`: an URI to a proxy server to be used with HTTP requests\n* `http_proxy_authorization`: a default `Proxy-Authorization` header value to be used with `http_proxy`, e.g. `Basic ZGVtbzp0ZXN0`, which will be overriden if the `Proxy-Authorization` request header is present.\n* `https_proxy`: an URI to a proxy server to be used with HTTPS requests\n* `https_proxy_authorization`: as `http_proxy_authorization` but for use with `https_proxy` (since with HTTPS the authorisation is done when connecting, this one cannot be overridden by passing the `Proxy-Authorization` request header).\n* `no_proxy`: a comma separated list of hosts that should not be proxied.\n\nNote that this method has no effect when using the deprecated [TCP only connect](#TCP-only-connect) connection syntax.\n\n## get\\_reused\\_times\n\n`syntax: times, err = httpc:get_reused_times()`\n\nSee [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsockgetreusedtimes).\n\n## close\n\n`syntax: ok, err = httpc:close()`\n\nSee [OpenResty docs](https://github.com/openresty/lua-nginx-module#tcpsockclose).\n\n## Requesting\n\n## request\n\n`syntax: res, err = httpc:request(params)`\n\nSends an HTTP request over an already established connection. Returns a `res` table or `nil` and an error message.\n\nThe `params` table expects the following fields:\n\n* `version`: The HTTP version number. Defaults to `1.1`.\n* `method`: The HTTP method string. Defaults to `GET`.\n* `path`: The path string. Defaults to `/`.\n* `query`: The query string, presented as either a literal string or Lua table..\n* `headers`: A table of request headers.\n* `body`: The request body as a string, a table of strings, or an iterator function yielding strings until nil when exhausted. Note that you must specify a `Content-Length` for the request body, or specify `Transfer-Encoding: chunked` and have your function implement the encoding. See also: [get\\_client\\_body\\_reader](#get_client_body_reader)).\n\nWhen the request is successful, `res` will contain the following fields:\n\n* `status`: The status code.\n* `reason`: The status reason phrase.\n* `headers`: A table of headers. Multiple headers with the same field name will be presented as a table of values.\n* `has_body`: A boolean flag indicating if there is a body to be read.\n* `body_reader`: An iterator function for reading the body in a streaming fashion.\n* `read_body`: A method to read the entire body into a string.\n* `read_trailers`: A method to merge any trailers underneath the headers, after reading the body.\n\nIf the response has a body, then before the same connection can be used for another request, you must read the body using `read_body` or `body_reader`.\n\n## request\\_uri\n\n`syntax: res, err = httpc:request_uri(uri, params)`\n\nThe single-shot interface (see [usage](#Usage)). Since this method performs an entire end-to-end request, options specified in the `params` can include anything found in both [connect](#connect) and [request](#request) documented above. Note also that fields `path`, and `query`, in `params` will override relevant components of the `uri` if specified (`scheme`, `host`, and `port` will always be taken from the `uri`).\n\nThere are 3 additional parameters for controlling keepalives:\n\n* `keepalive`: Set to `false` to disable keepalives and immediately close the connection. Defaults to `true`.\n* `keepalive_timeout`: The maximal idle timeout (ms). Defaults to `lua_socket_keepalive_timeout`.\n* `keepalive_pool`: The maximum number of connections in the pool. Defaults to `lua_socket_pool_size`.\n\nIf the request is successful, `res` will contain the following fields:\n\n* `status`: The status code.\n* `headers`: A table of headers.\n* `body`: The entire response body as a string.\n\n\n## request\\_pipeline\n\n`syntax: responses, err = httpc:request_pipeline(params)`\n\nThis method works as per the [request](#request) method above, but `params` is instead a nested table of parameter tables. Each request is sent in order, and `responses` is returned as a table of response handles. For example:\n\n```lua\nlocal responses = httpc:request_pipeline({\n    { path = \"/b\" },\n    { path = \"/c\" },\n    { path = \"/d\" },\n})\n\nfor _, r in ipairs(responses) do\n    if not r.status then\n        ngx.log(ngx.ERR, \"socket read error\")\n        break\n    end\n\n    ngx.say(r.status)\n    ngx.say(r:read_body())\nend\n</code></pre> <p>Due to the nature of pipelining, no responses are actually read until you attempt to use the response fields (status / headers etc). And since the responses are read off in order, you must read the entire body (and any trailers if you have them), before attempting to read the next response.</p> <p>Note this doesn't preclude the use of the streaming response body reader. Responses can still be streamed, so long as the entire body is streamed before attempting to access the next response.</p> <p>Be sure to test at least one field (such as status) before trying to use the others, in case a socket read error has occurred.</p>"},{"location":"lua/http/#response","title":"Response","text":""},{"location":"lua/http/#resbody_reader","title":"res.body_reader","text":"<p>The <code>body_reader</code> iterator can be used to stream the response body in chunk sizes of your choosing, as follows:</p> <pre><code>local reader = res.body_reader\nlocal buffer_size = 8192\n\nrepeat\n    local buffer, err = reader(buffer_size)\n    if err then\n        ngx.log(ngx.ERR, err)\n        break\n    end\n\n    if buffer then\n        -- process\n    end\nuntil not buffer\n</code></pre> <p>If the reader is called with no arguments, the behaviour depends on the type of connection. If the response is encoded as chunked, then the iterator will return the chunks as they arrive. If not, it will simply return the entire body.</p> <p>Note that the size provided is actually a maximum size. So in the chunked transfer case, you may get buffers smaller than the size you ask, as a remainder of the actual encoded chunks.</p>"},{"location":"lua/http/#resread_body","title":"res:read_body","text":"<p><code>syntax: body, err = res:read_body()</code></p> <p>Reads the entire body into a local string.</p>"},{"location":"lua/http/#resread_trailers","title":"res:read_trailers","text":"<p><code>syntax: res:read_trailers()</code></p> <p>This merges any trailers underneath the <code>res.headers</code> table itself. Must be called after reading the body.</p>"},{"location":"lua/http/#utility","title":"Utility","text":""},{"location":"lua/http/#parse_uri","title":"parse_uri","text":"<p><code>syntax: local scheme, host, port, path, query? = unpack(httpc:parse_uri(uri, query_in_path?))</code></p> <p>This is a convenience function allowing one to more easily use the generic interface, when the input data is a URI.</p> <p>As of version <code>0.10</code>, the optional <code>query_in_path</code> parameter was added, which specifies whether the querystring is to be included in the <code>path</code> return value, or separately as its own return value. This defaults to <code>true</code> in order to maintain backwards compatibility. When set to <code>false</code>, <code>path</code> will only include the path, and <code>query</code> will contain the URI args, not including the <code>?</code> delimiter.</p>"},{"location":"lua/http/#get_client_body_reader","title":"get_client_body_reader","text":"<p><code>syntax: reader, err = httpc:get_client_body_reader(chunksize?, sock?)</code></p> <p>Returns an iterator function which can be used to read the downstream client request body in a streaming fashion. You may also specify an optional default chunksize (default is <code>65536</code>), or an already established socket in place of the client request.</p> <p>Example:</p> <pre><code>local req_reader = httpc:get_client_body_reader()\nlocal buffer_size = 8192\n\nrepeat\n    local buffer, err = req_reader(buffer_size)\n    if err then\n        ngx.log(ngx.ERR, err)\n        break\n    end\n\n    if buffer then\n        -- process\n    end\nuntil not buffer\n</code></pre> <p>This iterator can also be used as the value for the body field in request params, allowing one to stream the request body into a proxied upstream request.</p> <pre><code>local client_body_reader, err = httpc:get_client_body_reader()\n\nlocal res, err = httpc:request({\n    path = \"/helloworld\",\n    body = client_body_reader,\n})\n</code></pre>"},{"location":"lua/http/#deprecated_1","title":"Deprecated","text":"<p>These features remain for backwards compatability, but may be removed in future releases.</p>"},{"location":"lua/http/#tcp-only-connect","title":"TCP only connect","text":"<p>The following versions of the <code>connect</code> method signature are deprecated in favour of the single <code>table</code> argument documented above.</p> <p><code>syntax: ok, err = httpc:connect(host, port, options_table?)</code></p> <p><code>syntax: ok, err = httpc:connect(\"unix:/path/to/unix.sock\", options_table?)</code></p> <p>NOTE: the default pool name will only incorporate IP and port information so is unsafe to use in case of SSL and/or Proxy connections. Specify your own pool or, better still, do not use these signatures.</p>"},{"location":"lua/http/#connect_proxy","title":"connect_proxy","text":"<p><code>syntax: ok, err = httpc:connect_proxy(proxy_uri, scheme, host, port, proxy_authorization)</code></p> <p>Calling this method manually is no longer necessary since it is incorporated within connect. It is retained for now for compatibility with users of the older TCP only connect syntax.</p> <p>Attempts to connect to the web server through the given proxy server. The method accepts the following arguments:</p> <ul> <li><code>proxy_uri</code> - Full URI of the proxy server to use (e.g. <code>http://proxy.example.com:3128/</code>). Note: Only <code>http</code> protocol is supported.</li> <li><code>scheme</code> - The protocol to use between the proxy server and the remote host (<code>http</code> or <code>https</code>). If <code>https</code> is specified as the scheme, <code>connect_proxy()</code> makes a <code>CONNECT</code> request to establish a TCP tunnel to the remote host through the proxy server.</li> <li><code>host</code> - The hostname of the remote host to connect to.</li> <li><code>port</code> - The port of the remote host to connect to.</li> <li><code>proxy_authorization</code> - The <code>Proxy-Authorization</code> header value sent to the proxy server via <code>CONNECT</code> when the <code>scheme</code> is <code>https</code>.</li> </ul> <p>If an error occurs during the connection attempt, this method returns <code>nil</code> with a string describing the error. If the connection was successfully established, the method returns <code>1</code>.</p> <p>There's a few key points to keep in mind when using this api:</p> <ul> <li>If the scheme is <code>https</code>, you need to perform the TLS handshake with the remote server manually using the <code>ssl_handshake()</code> method before sending any requests through the proxy tunnel.</li> <li>If the scheme is <code>http</code>, you need to ensure that the requests you send through the connections conforms to RFC 7230 and especially Section 5.3.2. which states that the request target must be in absolute form. In practice, this means that when you use <code>send_request()</code>, the <code>path</code> must be an absolute URI to the resource (e.g. <code>http://example.com/index.html</code> instead of just <code>/index.html</code>).</li> </ul>"},{"location":"lua/http/#ssl_handshake","title":"ssl_handshake","text":"<p><code>syntax: session, err = httpc:ssl_handshake(session, host, verify)</code></p> <p>Calling this method manually is no longer necessary since it is incorporated within connect. It is retained for now for compatibility with users of the older TCP only connect syntax.</p> <p>See OpenResty docs.</p>"},{"location":"lua/http/#proxy_request-proxy_response","title":"proxy_request / proxy_response","text":"<p>These two convenience methods were intended simply to demonstrate a common use case of implementing reverse proxying, and the author regrets their inclusion in the module. Users are encouraged to roll their own rather than depend on these functions, which may be removed in a subsequent release.</p>"},{"location":"lua/http/#proxy_request","title":"proxy_request","text":"<p><code>syntax: local res, err = httpc:proxy_request(request_body_chunk_size?)</code></p> <p>Performs a request using the current client request arguments, effectively proxying to the connected upstream. The request body will be read in a streaming fashion, according to <code>request_body_chunk_size</code> (see documentation on the client body reader below).</p>"},{"location":"lua/http/#proxy_response","title":"proxy_response","text":"<p><code>syntax: httpc:proxy_response(res, chunksize?)</code></p> <p>Sets the current response based on the given <code>res</code>. Ensures that hop-by-hop headers are not sent downstream, and will read the response according to <code>chunksize</code> (see documentation on the body reader above).</p>"},{"location":"lua/http/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-http.</p>"},{"location":"lua/http2/","title":"http2: The HTTP/2 Protocol (Client Side) Implementation for nginx-module-lua","text":""},{"location":"lua/http2/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/http2/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-http2\n</code></pre>"},{"location":"lua/http2/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-http2\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-http2 v1.0  released on Nov 20 2019.</p> <p>lua-resty-http2 - The HTTP/2 Protocol (Client Side) Implementation for OpenResty. Still Pending.</p> <p></p>"},{"location":"lua/http2/#status","title":"Status","text":"<p>This Lua module is currently considered experimental.</p>"},{"location":"lua/http2/#synopsis","title":"Synopsis","text":"<pre><code>local http2 = require \"resty.http2\"\n\nlocal host = \"127.0.0.1\"\nlocal port = 8080\nlocal sock = ngx.socket.tcp()\nlocal ok, err = sock:connect(host, port)\nif not ok then\n    ngx.log(ngx.ERR, \"failed to connect \", host, \":\", port, \": \", err)\n    return\nend\n\nlocal headers = {\n    { name = \":authority\", value = \"test.com\" },\n    { name = \":method\", value = \"GET\" },\n    { name = \":path\", value = \"/index.html\" },\n    { name = \":scheme\", value = \"http\" },\n    { name = \"accept-encoding\", value = \"gzip\" },\n    { name = \"user-agent\", value = \"example/client\" },\n}\n\nlocal on_headers_reach = function(ctx, headers)\n    -- Process the response headers\nend\n\nlocal on_data_reach = function(ctx, data)\n    -- Process the response body\nend\n\nlocal opts = {\n    ctx = sock,\n    recv = sock.receive,\n    send = sock.send,\n}\n\nlocal client, err = http2.new(opts)\nif not client then\n    ngx.log(ngx.ERR, \"failed to create HTTP/2 client: \", err)\n    return\nend\n\nlocal ok, err = client:request(headers, nil, on_headers_reach, on_data_reach)\nif not ok then\n    ngx.log(ngx.ERR, \"client:process() failed: \", err)\n    return\nend\n\nsock:close()\n</code></pre> <p>As a more formal exemplify, please read the util/example.lua.</p>"},{"location":"lua/http2/#description","title":"Description","text":"<p>This pure Lua library implements the client side HTTP/2 protocol, but not all details are covered, for example, the stream dependencies is maintained but never used.</p> <p>There are some inherent limitations which are not solved, however.</p> <p>Cannot be used over the SSL/TLS handshaked connections. The <code>tcpsock:sslhandshake</code> doesn't support the ALPN or NPN extensions, so currently only the plain connections can be used, the library will start HTTP/2 session with sending the connection preface, i.e. the string:</p> <pre><code>PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\n</code></pre> <p>This library provides a patch for the Application-Layer Protocol Negotiation. just uses this if you need.</p> <p>Only a HTTP request can be submitted. Currently the implemented APIs support for submitting just one HTTP request. PRs are welcome to solve this.</p> <p>HTTP/2 session reuse. The HTTP/2 protocol is designed as persistent, while the Cosocket object is binded to a specific HTTP request. One has to close the Cosocket object or set it alive before the request is over, this model is conflict with the reuse of HTTP/2 session, just a work-around way can solve this, see client:keepalive for the details.</p>"},{"location":"lua/http2/#api-implemented","title":"API Implemented","text":""},{"location":"lua/http2/#restyhttp2","title":"resty.http2","text":"<p>To load this module, just do this:</p> <pre><code>local http2 = require \"resty.http2\"\n</code></pre>"},{"location":"lua/http2/#http2new","title":"http2.new","text":"<p>syntax: local client, err = http2.new(opts)</p> <p>Creates a HTTP/2 client by specifying the options. In case of failure, <code>nil</code> and a error message string will be returned.</p> <p>The sole parameter <code>opts</code>, which is a Lua table, contains some fields:</p> <ul> <li> <p><code>recv</code>, a Lua function which is used to read bytes;</p> </li> <li> <p><code>send</code>, a Lua function which is used to send bytes;</p> </li> <li> <p><code>ctx</code>, an opaque data, acts as the callers' context;</p> </li> </ul> <p>The <code>recv</code> and <code>send</code> function will be called like:</p> <pre><code>local data, err = recv(ctx, size)\nlocal ok, err = send(ctx, data)\n</code></pre> <ul> <li> <p><code>preread_size</code>, a Lua number which influences the peer's initial send window size (advertise through the SETTINGS frame), default is <code>65535</code>;</p> </li> <li> <p><code>max_concurrent_stream</code>, a Lua number which limits the max concurrent streams in a HTTP/2 session, default is <code>128</code>;</p> </li> <li> <p><code>max_frame_size</code>, a Lua number which limits the max frame size that peer can send, default is <code>16777215</code>.</p> </li> <li> <p><code>key</code>, a Lua string which represents which cached HTTP/2 session the callers want to resue, if not found, new HTTP/2 session will be created. See client:keepalive for more details.</p> </li> </ul>"},{"location":"lua/http2/#clientacknowledge_settings","title":"client:acknowledge_settings","text":"<p>syntax: local ok, err = client:acknowledge_settings()</p> <p>Acknowledges peer's SETTINGS frame, settings will be applied automatically.</p> <p>In case of failure, <code>nil</code> and a Lua string will describes the error reason will be given.</p>"},{"location":"lua/http2/#clientrequest","title":"client:request","text":"<p>syntax: local ok, err = client:request(headers, body?, on_headers_reach, on_data_reach)</p> <p>Sends a HTTP request to peer,</p> <p>In case of failure, <code>nil</code> and a Lua string will describes the error reason will be given.</p> <p>the <code>headers</code>, should be a array-like Lua table represent the HTTP request headers, each entry is like <code>{ name = \"header1\", value = \"value1\" }</code>.</p> <p>It is worth noting that this library doesn't take care of the HTTP headers' semantics, so it's callers' responsibility to supply this, and callers should implement any necessary conversions, for example, <code>Host</code> should be converted to <code>:authority</code>. Also, the following headers will be ignored as they are CONNECTION specific.</p> <ul> <li><code>Connection</code></li> <li><code>Keep-Alive</code></li> <li><code>Proxy-Connection</code></li> <li><code>Upgrade</code></li> <li><code>Transfer-Encoding</code></li> </ul> <p>The <code>body</code>, can be a Lua string represents the HTTP request body. It also can be a Lua function to implement the stream-way uploading. When <code>body</code> is a Lua function, it will be called like:</p> <pre><code>local part_data, last, err = body(size)\n</code></pre> <p>In case of failure, <code>body</code> should provide the 3rd return value <code>err</code> to tell this library that some fatal errors happen, then this method will be aborted immediately, and a GOAWAY frame will be sent to peer with error code INTERNAL_ERROR.</p> <p>When all data has been generated, the 2nd return value <code>last</code> should be provided, and it's value must be <code>true</code>.</p> <p><code>on_headers_reach</code>, should be a Lua function, as a callback which will be called when complete HTTP response headers are received, it will be called like:</p> <pre><code>local abort = on_headers_reach(ctx, headers)\n</code></pre> <p>The 2nd parameter <code>headers</code> is a hash-like Lua table which represents the HTTP response headers received from peer.</p> <p><code>on_headers_reach</code> can decide whether aborts the HTTP/2 session by returning a boolean value <code>abort</code> to the library, the HTTP/2 session will be aborted if <code>on_headers_reach</code> returns a true value.</p> <p>The last parameter, <code>on_data_reach</code>, is a Lua function, acts as the callback which will be called when response body are received every time, it will be called like:</p> <pre><code>local abort = on_data_reach(ctx, data)\n</code></pre> <p>The 2nd parameter <code>data</code> is a Lua string represents the HTTP respose body received this time.</p> <p>The meaning of return value is same as the <code>on_headers_reach</code>.</p> <p>After this method returns, the HTTP/2 session is still alive, one can decide to close this session by calling client:close or going ahead to do something.</p>"},{"location":"lua/http2/#clientsend_request","title":"client:send_request","text":"<p>syntax: local stream, err = client:send_request(headers, body?)</p> <p>Sends the headers and body (if any) to peer.</p> <p>meanings of <code>headers</code> and <code>body</code> are same as the one in client:request.</p> <p>The corresponding created stream object will be given when this method returns.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#clientread_headers","title":"client:read_headers","text":"<p>syntax: local headers, err = client:read_headers(stream)</p> <p>Reads the response headers from peer, the parameter <code>stream</code> is the one created by client:send_request.</p> <p>The return headers is a hash-like Lua table which contains the whole HTTP response headers, which may contains some pesudo-headers like <code>\":status\"</code>, callers should do some transforms if necessary.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#clientread_body","title":"client:read_body","text":"<p>syntax: local body, err = client:read_body(stream)</p> <p>Reads a DATA frame from peer, the parameter <code>stream</code> is the one created by client:send_request.</p> <p>The return data is a Lua string which represents a piece of response body. Empty string will be given if the whole body were read done.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#clientclose","title":"client:close","text":"<p>syntax: local ok, err = client:close(code)</p> <p>Closes the current HTTP/2 session with the error code <code>code</code>.</p> <p>See resty.http2.error to learn the error codes.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#clientkeepalive","title":"client:keepalive","text":"<p>syntax: client:keepalive(key)</p> <p>Caches current HTTP/2 session for the reuse, note malformed HTTP/2 session will never be cached. The HTTP/2 session will detached from the connection, precisely, the current Cosocket object.</p> <p>The detached HTTP/2 session will be saved in an internal hash-like Lua table, the unique parameter <code>key</code> will be used to index this session when callers want to reuse it.</p> <p>After set this session as alive, callers should also set the Cosocket object as keepalive.</p> <p>There is an inherent limitation between the mapping of HTTP/2 session and the underlying connection. A HTTP/2 session can only be used in a TCP connection becasue it is stateful, if callers store the connection to a pool which caches multiple connections, the binding relations is lost, since which connection is picked to the Cosocket object is not sure, thereby which HTTP/2 session shall be matched is also unknown.</p> <p>This is no elegant way to solve this, unless the Cosocket model can assign an identifier to the underlying connection. Now what callers can do is use the single size connection pool to bypass this limitation, for example:</p> <pre><code>...\n\nsock:connect(host, port, { pool = \"h2\" })\n\n...\n\nsock:setkeepalive(75, 1)\nclient:keepalive(\"test\")\n</code></pre>"},{"location":"lua/http2/#restyhttp2protocol","title":"resty.http2.protocol","text":"<p>This module implements some low-level protocool-relevant APIs.</p> <p>To load this module, just do this:</p> <pre><code>local protocol = require \"resty.http2.protocol\"\n</code></pre>"},{"location":"lua/http2/#protocolsession","title":"protocol.session","text":"<p>syntax: local session, err = protocol.session(recv, send, ctx, preread_size?, max_concurrent_stream?, max_frame_size?)</p> <p>Creates a new HTTP/2 session, in case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p> <p>The meaning of every parameter is same as these described in http2.new.</p> <p>The initial SETTINGS frame and WINDOW_UPDATE frame will be sent before this function returns.</p>"},{"location":"lua/http2/#sessionadjust_window","title":"session:adjust_window","text":"<p>syntax: local ok = session:adjust_window(delta)</p> <p>Adjusts each streams send window size, stream will be reset if the altered send window size exceeds MAX_WINDOW_SIZE, in this case, <code>ok</code> will be <code>nil</code>.</p>"},{"location":"lua/http2/#sessionframe_queue","title":"session:frame_queue","text":"<p>syntax: session:frame_queue(frame)</p> <p>Appends <code>frame</code> to current session's output queue.</p>"},{"location":"lua/http2/#sessionflush_queue","title":"session:flush_queue","text":"<p>syntax: local ok, err = session:flush_queue()</p> <p>Packs and flushes the queueing frames, in case of failure, <code>nil</code> and a Lua string which described the error reason will be given.</p>"},{"location":"lua/http2/#sessionsubmit_request","title":"session:submit_request","text":"<p>syntax: local ok, err = session:submit_request(headers, no_body, priority?, pad?)</p> <p>Submits a HTTP request to the current HTTP/2 session, in case of failure, <code>nil</code> and a Lua string which described the error reason wil be given.</p> <p>Meaning of each parameter:</p> <ul> <li> <p><code>headers</code>, should be a hash-like Lua table represent the HTTP request headers, it is worth noting that this library doesn't take care of the HTTP headers' semantics, so it's callers' responsibility to supply this, and callers should transform any necessary pesudo headers. For example, <code>:authority</code> should be passed rather <code>Host</code>;</p> </li> <li> <p><code>no_body</code>, a boolean value, indicates whether this request has body. When it is true, the generated HEADERS frame will contains the END_HEADERS flag;</p> </li> <li> <p><code>priority</code>, a hash-like Lua table, which is used to define a custom stream dependencies:</p> </li> <li><code>priority.sid</code> represents the dependent stream identifier;</li> <li><code>priority.excl</code>, whether the new stream becomes the sole dependency of the   stream indicated by <code>priority.sid</code>;</li> <li> <p><code>priority.weight</code> defines weight of new stream;</p> </li> <li> <p><code>pad</code>, the padding data.</p> </li> </ul>"},{"location":"lua/http2/#sessionsubmit_window_update","title":"session:submit_window_update","text":"<p>syntax: local ok, err = session:submit_window_update(incr)</p> <p>Submits a WINDOW_UPDATE frame for the whole HTTP/2 session with an increment <code>incr</code>, in case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#sessionrecv_frame","title":"session:recv_frame","text":"<p>syntax: local frame, err = session:recv_frame()</p> <p>Receives a HTTP/2 frame, in case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p> <p>The corresponding action will be taken automatically, for example, GOAWAY frame will be sent if peer violates the HTTP/2 protocol conventions; WINDOW_UPDATE frame will be sent if peer's send window becomes too small.</p>"},{"location":"lua/http2/#sessionclose","title":"session:close","text":"<p>syntax: session:close(code?, debug_data?)</p> <p>Generates a GOAWAY frame with the error code <code>code</code> and debug data <code>debug_data</code>, the default error code is NO_ERROR and the debug_data is <code>nil</code>.</p> <p>Note this function just queues the GOAWAY frame to the output queue, callers should call <code>session:flush_queue</code> to really send the frames.</p>"},{"location":"lua/http2/#sessiondetach","title":"session:detach","text":"<p>syntax: session:detach()</p> <p>Detachs the current HTTP/2 session with the Cosocket object.</p>"},{"location":"lua/http2/#sessionattach","title":"session:attach","text":"<p>syntax: local ok, err = session:attach(recv, send, ctx)</p> <p>Attachs the current HTTP/2 session with a Cosocket object, in case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p> <p>The meanings of <code>recv</code>, <code>send</code> and <code>ctx</code> are same as these described in http.new.</p>"},{"location":"lua/http2/#restyhttp2stream","title":"resty.http2.stream","text":"<p>This module implements some low-level stream-relevant APIs.</p> <p>To load this module, just do this:</p> <pre><code>local h2_stream = require \"resty.http2.stream\"\n</code></pre>"},{"location":"lua/http2/#h2_streamnew","title":"h2_stream.new","text":"<p>syntax: local stream = h2_stream.new(sid, weight, session)</p> <p>Creates a new stream with the identifier <code>sid</code>, weight <code>weight</code> and the HTTP/2 session which it belongs.</p>"},{"location":"lua/http2/#h2_streamnew_root","title":"h2_stream.new_root","text":"<p>syntax: local root_stream = h2_stream.new_root(session)</p> <p>Creates the root stream with it's session.</p> <p>The root stream's identifier is <code>0x0</code> and is really a virtual stream which is used to manipulate the whole HTTP/2 session.</p>"},{"location":"lua/http2/#streamsubmit_headers","title":"stream:submit_headers","text":"<p>syntax: local ok, err = stream:submit_headers(headers, end_stream, priority?, pad?)</p> <p>Submits some HTTP headers to the stream.</p> <p>The first parameter <code>headers</code>, should be a hash-like Lua table represent the HTTP request headers, it is worth noting that this library doesn't take care of the HTTP headers' semantics, so it's callers' responsibility to supply this, and callers should transform any necessary pesudo headers. For example, <code>:authority</code> should be passed rather <code>Host</code>;</p> <p>The <code>end_stream</code> parameter should be a boolean value and is used to control whether the HEADERS frame should take the END_STREAM flag, basically callers can set it true if there is no request body need to send.</p> <p><code>priority</code> should be a hash-like Lua table (if any), which is used to define a custom stream dependencies:   * <code>priority.sid</code> represents the dependent stream identifier;   * <code>priority.excl</code>, whether the new stream becomes the sole dependency of the   stream indicated by <code>priority.sid</code>;   * <code>priority.weight</code> defines weight of new stream;</p> <p>The last parameter <code>pad</code>, represents the padding data.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the corresponding error will be given.</p>"},{"location":"lua/http2/#streamsubmit_data","title":"stream:submit_data","text":"<p>syntax: local ok, err = stream:submit_data(data, pad, last)</p> <p>Submits some request body to the stream, <code>data</code> should be a Lua string, with optional padding data.</p> <p>The last parameter <code>last</code> is indicated whether this is the last submittion, the current DATA frame will attach the END_STREAM flag if <code>last</code> is true.</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the corresponding error will be given.</p>"},{"location":"lua/http2/#streamsubmit_window_update","title":"stream:submit_window_update","text":"<p>syntax: local ok, err = session:submit_window_update(incr)</p> <p>Submits a WINDOW_UPDATE frame for the stream with an increment <code>incr</code>, in case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#streamset_dependency","title":"stream:set_dependency","text":"<p>syntax: stream:set_dependency(depend, excl)</p> <p>Sets current stream's dependencies to a stream with the identifier <code>depend</code>.</p> <p>The second parameter <code>excl</code>, indicates whether current stream will be the sole child of <code>depend</code>.</p> <p>When <code>depend</code> is absent, the target stream will be the root and <code>excl</code> will be treat as <code>false</code>.</p>"},{"location":"lua/http2/#streamrst","title":"stream:rst","text":"<p>syntax: stream:rst(code)</p> <p>Generates a RST_STREAM frame with the error code <code>code</code>. In the case of <code>code</code> is absent, the NO_ERROR code will be selected.</p> <p>Note this method just generates a RST_STREAM frame rather than send it, caller should send this frame by calling session:flush_queue.</p>"},{"location":"lua/http2/#restyhttp2frame","title":"resty.http2.frame","text":"<p>This module implements some low-level frame-relevant APIs.</p> <p>To load this module, just do this:</p> <pre><code>local h2_frame = require \"resty.http2.frame\"\n</code></pre>"},{"location":"lua/http2/#h2_frameheadernew","title":"h2_frame.header.new","text":"<p>syntax: local hd = h2_frame.header.new(length, typ, flags, id)</p> <p>Creates a frame header, with the payload length <code>length</code>, frame type <code>type</code> and takes <code>flags</code> as the frame flags, which belongs to the stream <code>id</code>.</p>"},{"location":"lua/http2/#h2_frameheaderpack","title":"h2_frame.header.pack","text":"<p>syntax: h2_frame.header.pack(hd, dst)</p> <p>Serializes the frame header <code>hd</code> to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p>"},{"location":"lua/http2/#h2_frameheaderunpack","title":"h2_frame.header.unpack","text":"<p>syntax: h2_frame.header.unpack(src)</p> <p>Deserializes a frame header from a Lua string <code>src</code>, the length of <code>src</code> must be at least 9 octets.</p>"},{"location":"lua/http2/#h2_frameprioritypack","title":"h2_frame.priority.pack","text":"<p>syntax: h2_frame.priority.pack(pf, dst)</p> <p>Serializes a PRIORITY frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>pf</code> must be a hash-like Lua table which contians:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>depend</code>, the dependent stream identifier</li> <li><code>excl</code>, specifies whether the current stream where this PRIORITY frame stays becomes the sole child of the stream identified by <code>depend</code>;</li> <li><code>weight</code>, assigns a new weight <code>weight</code> to current stream;</li> </ul>"},{"location":"lua/http2/#h2_framepriorityunpack","title":"h2_frame.priority.unpack","text":"<p>syntax: local ok, err = h2_frame.priority.unpack(pf, src, stream)</p> <p>Deserializes a PRIORITY frame from a Lua string <code>src</code>, the length of <code>src</code> must be at least the size specified in the <code>pf.header.length</code>.</p> <p>The <code>pf</code> should be a hash-like Lua table which already contains the current PRIORITY frame's header, i.e. <code>pf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current PRIORITY frame belongs.</p> <p>Corresponding actions will be taken automatically inside this method like building the new dependencies.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framerst_streampack","title":"h2_frame.rst_stream.pack","text":"<p>syntax: h2_frame.rst_stream.pack(rf, dst)</p> <p>Serializes a RST_STREAM frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>rf</code> must be a hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>error_code</code>, the error code;</li> </ul>"},{"location":"lua/http2/#h2_framerst_streamunpack","title":"h2_frame.rst_stream.unpack","text":"<p>syntax: h2_frame.rst_stream.unpack(rf, src, stream)</p> <p>Deserializes a RST_STREAM frame from a Lua string <code>src</code>. The length of <code>src</code> must be at least the size specified in the <code>rf.header.length</code>.</p> <p>The <code>rf</code> should be a hash-like Lua table which already contains the current RST_STREAM frame's header, i.e. <code>rf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current RST_STREAM frame belongs.</p> <p>Corresponding actions will be taken automatically inside this method like changing the stream's state.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framerst_streamnew","title":"h2_frame.rst_stream.new","text":"<p>syntax: local rf = h2_frame.rst_stream.new(error_code, sid)</p> <p>Creates a RST_STREAM frame with the error code <code>error_code</code>, which belongs to the stream <code>sid</code>.</p>"},{"location":"lua/http2/#h2_framesettingspack","title":"h2_frame.settings.pack","text":"<p>syntax: h2_frame.settings.pack(sf, dst)</p> <p>Serializes a SETTINGS frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>sf</code> must be a hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>item</code>, the specific settings, which should be a array-like Lua table, each element should be a hash-like Lua table:</li> <li><code>id</code>, the setting identifier, can be:<ul> <li>SETTINGS_ENABLE_PUSH (0x2)</li> <li>SETTINGS_MAX_CONCURRENT_STREAMS (0x3)</li> <li>SETTINGS_INITIAL_WINDOW_SIZE (0x4)</li> <li>SETTINGS_MAX_FRAME_SIZE (0x5)</li> </ul> </li> <li><code>value</code>, the corresponding setting value;</li> </ul>"},{"location":"lua/http2/#h2_framesettingsunpack","title":"h2_frame.settings.unpack","text":"<p>syntax: local ok, err = h2_frame.settings.unpack(sf, src, stream)</p> <p>Deserializes a SETTINGS frame from a Lua string <code>src</code>. The length of <code>src</code> must be at least the size specified in the <code>sf.header.length</code>.</p> <p>The <code>sf</code> should be a hash-like Lua table which already contains the current SETTINGS frame's header, i.e. <code>sf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current SETTINGS frame belongs (must be the root stream).</p> <p>Corresponding actions will be taken automatically inside this method like updating the HTTP/2 session settings value.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framesettingsnew","title":"h2_frame.settings.new","text":"<p>syntax: local sf = h2_frame.settings.new(flags, payload)</p> <p>Creates a SETTINGS frame with the flags <code>flags</code> and payload item <code>payload</code>.</p> <p>The <code>payload</code> should be a array-like Lua table, each element should be a hash-like Lua table:   * <code>id</code>, the setting identifier, can be:     * SETTINGS_ENABLE_PUSH (0x2)     * SETTINGS_MAX_CONCURRENT_STREAMS (0x3)     * SETTINGS_INITIAL_WINDOW_SIZE (0x4)     * SETTINGS_MAX_FRAME_SIZE (0x5)   * <code>value</code>, the corresponding setting value;</p>"},{"location":"lua/http2/#h2_framepingpack","title":"h2_frame.ping.pack","text":"<p>syntax: h2_frame.ping.pack(pf, dst)</p> <p>Serializes a PING frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>pf</code> must be a hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>opaque_data_hi</code>, highest 32 bits value of the corresponding ping data;</li> <li><code>opaque_data_lo</code>, lowest 32 bits value of the corresponding ping data;</li> </ul>"},{"location":"lua/http2/#h2_framepingunpack","title":"h2_frame.ping.unpack","text":"<p>syntax: local ok, err = h2_frame.ping.unpack(pf, src, stream)</p> <p>Deserializes a PING frame from a Lua string <code>src</code>. The length of <code>src</code> must be at least the size specified in the <code>sf.header.length</code>.</p> <p>The <code>pf</code> should be a hash-like Lua table which already contains the current PING frame's header, i.e. <code>pf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current PING frame belongs (must be the root stream).</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framegoawaypack","title":"h2_frame.goaway.pack","text":"<p>syntax: h2_frame.goaway.pack(gf, dst)</p> <p>Serializes a GOAWAY frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>gf</code> must be hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>last_stream_id</code>, the last peer-initialized stream identifier;</li> <li><code>error_code</code>, the error code;</li> <li><code>debug_data</code>, the debug data;</li> </ul>"},{"location":"lua/http2/#h2_framegoawayunpack","title":"h2_frame.goaway.unpack","text":"<p>syntax: local ok, err = h2_frame.goaway.unpack(gf, src, stream)</p> <p>Deserializes a GOAWAY frame from a Lua string <code>src</code>. The length of <code>src</code> must be at least the size specified in the <code>gf.header.length</code>.</p> <p>The <code>gf</code> should be a hash-like Lua table which already contains the current GOAWAY frame's heaer, i.e. <code>gf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current GOAWAY frame belongs (must be the root stream).</p> <p>In case of failure, <code>nil</code> and a Lua string which describes the error reason will be given.</p>"},{"location":"lua/http2/#h2_framegoawaynew","title":"h2_frame.goaway.new","text":"<p>syntax: local gf = h2_frame.goaway.new(last_sid, error_code, debug_data)</p> <p>Creates a GOAWAY frame with the last peer-initialized stream identifier <code>last_sid</code>, and error code <code>error_code</code>. Optionally, with the debug data <code>debug_data</code>.</p>"},{"location":"lua/http2/#h2_framewindow_updatepack","title":"h2_frame.window_update.pack","text":"<p>syntax: h2_frame.window_update.pack(wf, dst)</p> <p>Serializes a WINDOW_UPDATE frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>wf</code> must be hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>window_size_increment</code>, the window size increment;</li> </ul>"},{"location":"lua/http2/#h2_framewindow_updateunpack","title":"h2_frame.window_update.unpack","text":"<p>syntax: local ok, err = h2_frame.window_update.unpack(wf, src, stream)</p> <p>Deserializes a WINDOW_UPDATE frame from a Lua string <code>src</code>. The length of <code>src</code> must be at least the size specified in the <code>wf.header.length</code>.</p> <p>The <code>wf</code> should be a hash-like Lua table which already contains the current WINDOW_UPDATE frame's heaer, i.e. <code>wf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current WINDOW_UPDATE frame belongs.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framewindow_updatenew","title":"h2_frame.window_update.new","text":"<p>syntax: local wf = h2_frame.window_update.new(sid, window)</p> <p>Creates a WINDOW_UPDATE frame with the stream identifier <code>sid</code>, and enlarges the window size specified by <code>window</code>.</p>"},{"location":"lua/http2/#h2_frameheaderspack","title":"h2_frame.headers.pack","text":"<p>syntax: h2_frame.headers.pack(hf, dst)</p> <p>Serializes a HEADERS frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>hf</code> must be hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>pad</code>, the padding data;</li> <li><code>depend</code>, the dependent stream identifier;</li> <li><code>excl</code>, specifies whether the stream that current HEADERS frame belongs will become the sole child of the stream <code>depend</code>;</li> <li><code>weight</code>, specifies the weight of the stream that current HEADERS frame belongs.</li> <li><code>block_frags</code>, the plain HTTP headers (after the hpack compressing);</li> </ul>"},{"location":"lua/http2/#h2_frameheadersunpack","title":"h2_frame.headers.unpack","text":"<p>syntax: local ok,err = h2_frame.headers.unpack(hf, src, stream)</p> <p>Deserializes a HEADERS frame from the Lua string <code>src</code>, the length of <code>src</code> must be at least the size specified in the <code>hf.header.length</code></p> <p>The <code>hf</code> should be a hash-like Lua table which already contains the current HEADERS frame's heaer, i.e. <code>hf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current HEADER frame belongs.</p> <p>The corresponding action will be taken, for example, stream state transition will happens.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_frameheadersnew","title":"h2_frame.headers.new","text":"<p>syntax: local hf = h2_frame.headers.new(frags, pri?, pad?, end_stream, end_headers, sid)</p> <p>Creates a HEADERS frame which takes the block fragments <code>frags</code>.</p> <p>The parameter <code>pri</code> can be taken to specify the stream dependencies, <code>pri</code> should be a hash-like Lua table, which contains:</p> <ul> <li><code>sid</code>, the dependent stream identifier;</li> <li><code>excl</code>, whether the stream <code>sid</code> will be the sole child of dependent stream;</li> <li><code>weight</code>, defines the current stream's (specified by <code>sid</code>) weight ;</li> </ul> <p>The <code>pad</code> specifies the padding data, which is optional.</p> <p>When <code>end_stream</code> is true, current HEADERS frame will takes the END_STREAM flag, likewise, when <code>end_headers</code> is true, current HEADERS frame will takes the END_HEADERS flag.</p> <p>One should take care that if current HEADERS frame doesn't contain the whole headers, then one or more CONTINUATION frames must be followed according to the HTTP/2 procotol.</p>"},{"location":"lua/http2/#h2_framecontinuationpack","title":"h2_frame.continuation.pack","text":"<p>syntax: h2_frame.continuation.pack(cf, dst)</p> <p>Serializes a CONTINUATION frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>cf</code> must be hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>block_frags</code>, the plain HTTP headers (after the hpack compressing);</li> </ul>"},{"location":"lua/http2/#h2_framecontinuationunpack","title":"h2_frame.continuation.unpack","text":"<p>syntax: local ok, err = h2_frame.continuation.unpack(cf, src, stream)</p> <p>Deserializes a CONTINUATION frame from the Lua string <code>src</code>, the length of <code>src</code> must be at least the size specified in the <code>cf.header.length</code></p> <p>The <code>cf</code> should be a hash-like Lua table which already contains the current CONTINUATION frame's heaer, i.e. <code>cf.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current CONTINUATION frame belongs.</p> <p>The corresponding action will be taken, for example, stream state transition will happens.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framecontinuationnew","title":"h2_frame.continuation.new","text":"<p>syntax: local cf = h2_frame.continuation.new(frags, end_headers, sid)</p> <p>Creates a CONTINUATION frame which takes the block fragments <code>frags</code>.</p> <p>When <code>end_headers</code> is true, current CONTINUATION frame will takes the END_HEADERS flag.</p> <p>One should take care that if current CONTINUATION frame doesn't contain the whole headers, then one or more CONTINUATION frames must be followed according to the HTTP/2 procotol.</p> <p>The <code>sid</code> specifies the stream that current CONTINUATION frame belongs.</p>"},{"location":"lua/http2/#h2_framedatapack","title":"h2_frame.data.pack","text":"<p>syntax: h2_frame.data.pack(df, dst)</p> <p>Serializes a DATA frame to the destination <code>dst</code>. The <code>dst</code> must be a array-like Lua table.</p> <p>The <code>df</code> must be hash-like Lua table which contains:</p> <ul> <li><code>header</code>, the frame header;</li> <li><code>payload</code>, the HTTP request/response body;</li> </ul>"},{"location":"lua/http2/#h2_framedataunpack","title":"h2_frame.data.unpack","text":"<p>syntax: local ok, err = h2_frame.data.unpack(df, src, stream)</p> <p>Deserializes a DATA frame from the Lua string <code>src</code>, the length of <code>src</code> must be at least the size specified in the <code>df.header.length</code></p> <p>The <code>df</code> should be a hash-like Lua table which already contains the current DATA frame's heaer, i.e. <code>df.header</code>.</p> <p>The last parameter <code>stream</code> specifies the stream that current DATA frame belongs.</p> <p>The corresponding action will be taken, for example, stream state transition will happens.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#h2_framedatanew","title":"h2_frame.data.new","text":"<p>syntax: local df = h2_frame.data.new(payload, pad, last, sid)</p> <p>Creates a DATA frame which takes the payload <code>payload</code>.</p> <p>The <code>pad</code> specifies the padding data, which is optional.</p> <p>When <code>last</code> is true, current DATA frame will takes the END_STREAM flag.</p> <p>The <code>sid</code> specifies the stream that current DATA frame belongs.</p>"},{"location":"lua/http2/#h2_framepush_promiseunpack","title":"h2_frame.push_promise.unpack","text":"<p>syntax: local df = h2_frame.data.new(payload, pad, last, sid)</p> <p>Currently any incoming PUSH_PROMISE frame will be rejected.</p> <p>This method always returns <code>nil</code> and the error PROTOCOL_ERROR.</p>"},{"location":"lua/http2/#restyhttp2hpack","title":"resty.http2.hpack","text":"<p>This module implements some low-level HPACK APIs.</p> <p>To load this module, just do this:</p> <pre><code>local hpack = require \"resty.http2.hpack\"\n</code></pre>"},{"location":"lua/http2/#hpackencode","title":"hpack.encode","text":"<p>syntax: hpack.encode(src, dst, lower)</p> <p>Encodes the Lua string <code>src</code> to destination <code>dst</code>, the <code>dst</code> must be a array-like Lua table. Huffman codes will be tried firstly.</p> <p>The <code>lower</code> specifies whether current encoding operation is case-insensitive, default is <code>false</code>.</p>"},{"location":"lua/http2/#hpackindexed","title":"hpack.indexed","text":"<p>syntax: local v = hpack.indexed(index)</p> <p>Returns the index after using Indexed Header Field Representation.</p>"},{"location":"lua/http2/#hpackincr_indexed","title":"hpack.incr_indexed","text":"<p>syntax: local v = hpack.indexed(index)</p> <p>Returns the index after using Literal Header Field With Incremental Indexing.</p>"},{"location":"lua/http2/#hpacknew","title":"hpack.new","text":"<p>syntax: local h = hpack.new(size)</p> <p>Creates a hpack instance, since the HPACK decoding is stateful.</p> <p>The <code>size</code> represents the maximum hpack table size, default is 4096 bytes.</p> <p>The return value <code>h</code>, represents the HPACK instance. One of h's member is important, i.e. <code>h.cached</code>, which saves the whole header block fragments, and h:decode will analysis the data inside the <code>h.cached</code>.</p> <p>Currently the h2_frame.headers.unpack and h2_frame.continuation.unpack will push header block fragments to <code>h.cached</code>, once the block is complete, the decoding will be executed.</p>"},{"location":"lua/http2/#hinsert_entry","title":"h:insert_entry","text":"<p>syntax: local ok = h:insert_entry(header_name, header_value)</p> <p>Tries to insert a header entry with name <code>header_name</code> and value <code>header_value</code> to the HPACK dynamic table.</p> <p>The insertion maybe failed if this entry is too large. Necessary entry eviction will happen if the space is not enough.</p> <p>This method will return <code>true</code> if the insertion is successful or <code>false</code> if not.</p>"},{"location":"lua/http2/#hresize","title":"h:resize","text":"<p>syntax: local ok = h:resize(new_size)</p> <p>Adjusts the dynamic table size to <code>new_size</code>, currently the <code>new_size</code> cannot exceed <code>4096</code>, other the resize operation will be failed.</p> <p>When the dynamic table size is shrink, some entries will be evicted according the HPACK's rule.</p> <p>This method will return <code>true</code> if the resize operation is successful or <code>false</code> if not.</p>"},{"location":"lua/http2/#hdecode","title":"h:decode","text":"<p>syntax: local ok, err = h:decode(dst)</p> <p>Decodes the header block fragments inside <code>h.cached</code>, decoded headers will be saved in <code>dst</code>, a hash-like Lua table.</p> <p>In case of failure, <code>nil</code> and an error code will be given.</p>"},{"location":"lua/http2/#hget_indexed_header","title":"h:get_indexed_header","text":"<p>syntax: local entry = h:get_indexed_header(index)</p> <p>Returns the header entry according the index <code>index</code>.</p> <p>The return value will be <code>nil</code> if the index is invalid, otherwise, the <code>entry</code> will be hash-like Lua table with two items:</p> <ul> <li><code>entry.name</code>, the header name;</li> <li><code>entry.value</code>, the header value;</li> </ul>"},{"location":"lua/http2/#restyhttp2error","title":"resty.http2.error","text":"<p>This module implements some low-level error-relevant APIs.</p> <p>There many defined error codes, basically they are consistent with HTTP/2 protocol:</p> <ul> <li><code>h2_error.NO_ERROR</code></li> <li><code>h2_error.PROTOCOL</code></li> <li><code>h2_error.INTERNAL_ERROR</code></li> <li><code>h2_error.FLOW_CONTROL_ERROR</code></li> <li><code>h2_error.SETTINGS_TIMEOUT</code></li> <li><code>h2_error.STREAM_CLOSED</code></li> <li><code>h2_error.FRAME_SIZE_ERROR</code></li> <li><code>h2_error.REFUSED_STREAM</code></li> <li><code>h2_error.CANCEL</code></li> <li><code>h2_error.COMPRESSION_ERROR</code></li> <li><code>h2_error.CONNECT_ERROR</code></li> <li><code>h2_error.ENHANCE_YOUR_CALM</code></li> <li><code>h2_error.INADEQUATE_SECURITY</code></li> <li><code>h2_error.HTTP_1_1_REQUIRED</code></li> </ul> <p>And three custom error codes:</p> <ul> <li><code>h2_error.STREAM_PROTOCOL_ERROR</code>, stream level protocol error;</li> <li><code>h2_error.STREAM_FLOW_CONTROL_ERROR</code>, stream level flow control error;</li> <li><code>h2_error.STREAM_FRAME_SIZE_ERROR</code>, stream level frame size error;</li> </ul> <p>Stream level errors will not influence the whole connection but reset the current stream.</p> <p>To load this module, just do this:</p>"},{"location":"lua/http2/#h2_errorstrerror","title":"h2_error.strerror","text":"<p>syntax: local msg = h2_error.strerror(code)</p> <p>Returns a Lua string which describe the error code <code>code</code>, <code>\"unknown error\"</code> will be given if the error code is unknown.</p>"},{"location":"lua/http2/#h2_erroris_stream_error","title":"h2_error.is_stream_error","text":"<p>syntax: local ok = h2_error.is_stream_error(code)</p> <p>Judges whether the error code <code>code</code> is a stream-level error.</p>"},{"location":"lua/http2/#see-also","title":"See Also","text":"<ul> <li>upyun-resty: https://github.com/upyun/upyun-resty</li> <li>lua-resty-httpipe: https://github.com/timebug/lua-resty-httpipe</li> <li>lua-resty-requests: https://github.com/tokers/lua-resty-requests</li> </ul>"},{"location":"lua/http2/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-http2.</p>"},{"location":"lua/httpipe/","title":"httpipe: Lua HTTP client cosocket driver for nginx-module-lua, interfaces are more flexible","text":""},{"location":"lua/httpipe/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/httpipe/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-httpipe\n</code></pre>"},{"location":"lua/httpipe/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-httpipe\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-httpipe v0.5  released on Nov 25 2015.</p> <p>Lua HTTP client cosocket driver for OpenResty / ngx_lua.</p>"},{"location":"lua/httpipe/#status","title":"Status","text":"<p>Ready for testing. Probably production ready in most cases, though not yet proven in the wild. Please check the issues list and let me know if you have any problems / questions.</p>"},{"location":"lua/httpipe/#features","title":"Features","text":"<ul> <li>HTTP 1.0/1.1 and HTTPS</li> <li>Flexible interface design</li> <li>Streaming reader and uploads</li> <li>Chunked-encoding request / response body</li> <li>Sets the timeout for read and send operations</li> <li>Limit the maximum response body size</li> <li>Keepalive</li> </ul>"},{"location":"lua/httpipe/#synopsis","title":"Synopsis","text":"<pre><code>server {\n\n  listen 9090;\n\n  location /echo {\n    content_by_lua '\n      local raw_header = ngx.req.raw_header()\n\n      if ngx.req.get_method() == \"GET\" then\n          ngx.header[\"Content-Length\"] = #raw_header\n      end\n\n      ngx.req.read_body()\n      local body, err = ngx.req.get_body_data()\n\n      ngx.print(raw_header)\n      ngx.print(body)\n    ';\n  }\n\n  location /simple {\n    content_by_lua '\n      local httpipe = require \"resty.httpipe\"\n\n      local hp, err = httpipe:new()\n      if not hp then\n          ngx.log(ngx.ERR, \"failed to new httpipe: \", err)\n          return ngx.exit(503)\n      end\n\n      hp:set_timeout(5 * 1000) -- 5 sec\n\n      local res, err = hp:request(\"127.0.0.1\", 9090, {\n                                     method = \"GET\", path = \"/echo\" })\n      if not res then\n          ngx.log(ngx.ERR, \"failed to request: \", err)\n          return ngx.exit(503)\n      end\n\n      ngx.status = res.status\n\n      for k, v in pairs(res.headers) do\n          ngx.header[k] = v\n      end\n\n      ngx.say(res.body)\n    ';\n  }\n\n  location /generic {\n    content_by_lua '\n      local cjson = require \"cjson\"\n      local httpipe = require \"resty.httpipe\"\n\n      local hp, err = httpipe:new(10) -- chunk_size = 10\n      if not hp then\n          ngx.log(ngx.ERR, \"failed to new httpipe: \", err)\n          return ngx.exit(503)\n      end\n\n      hp:set_timeout(5 * 1000) -- 5 sec\n\n      local ok, err = hp:connect(\"127.0.0.1\", 9090)\n      if not ok then\n          ngx.log(ngx.ERR, \"failed to connect: \", err)\n          return ngx.exit(503)\n      end\n\n      local ok, err = hp:send_request{ method = \"GET\", path = \"/echo\" }\n      if not ok then\n          ngx.log(ngx.ERR, \"failed to send request: \", err)\n          return ngx.exit(503)\n      end\n\n      -- full streaming parser\n\n      while true do\n          local typ, res, err = hp:read()\n          if not typ then\n              ngx.say(\"failed to read: \", err)\n              return\n          end\n\n          ngx.say(\"read: \", cjson.encode({typ, res}))\n\n          if typ == 'eof' then\n              break\n          end\n      end\n    ';\n  }\n\n  location /advanced {\n    content_by_lua '\n      local httpipe = require \"resty.httpipe\"\n\n      local hp, err = httpipe:new()\n\n      hp:set_timeout(5 * 1000) -- 5 sec\n\n      local r0, err = hp:request(\"127.0.0.1\", 9090, {\n                                     method = \"GET\", path = \"/echo\",\n                                     stream = true })\n\n      -- from one http stream to another, just like a unix pipe\n\n      local pipe = r0.pipe\n\n      pipe:set_timeout(5 * 1000) -- 5 sec\n\n      --[[\n          local headers = {[\"Content-Length\"] = r0.headers[\"Content-Length\"]}\n          local r1, err = pipe:request(\"127.0.0.1\", 9090, {\n                                           method = \"POST\", path = \"/echo\",\n                                           headers = headers,\n                                           body = r0.body_reader })\n      --]]\n      local r1, err = pipe:request(\"127.0.0.1\", 9090, {\n                                       method = \"POST\", path = \"/echo\" })\n\n      ngx.status = r1.status\n\n      for k, v in pairs(r1.headers) do\n          ngx.header[k] = v\n      end\n\n      ngx.say(r1.body)\n    ';\n  }\n\n}\n</code></pre> <p>A typical output of the <code>/simple</code> location defined above is:</p> <pre><code>GET /echo HTTP/1.1\nHost: 127.0.0.1\nUser-Agent: Resty/HTTPipe-1.00\nAccept: */*\n</code></pre> <p>A typical output of the <code>/generic</code> location defined above is:</p> <pre><code>read: [\"statusline\",\"200\"]\nread: [\"header\",[\"Server\",\"openresty\\/1.5.12.1\",\"Server: openresty\\/1.5.12.1\"]]\nread: [\"header\",[\"Date\",\"Tue, 10 Jun 2014 07:29:57 GMT\",\"Date: Tue, 10 Jun 2014 07:29:57 GMT\"]]\nread: [\"header\",[\"Content-Type\",\"text\\/plain\",\"Content-Type: text\\/plain\"]]\nread: [\"header\",[\"Connection\",\"keep-alive\",\"Connection: keep-alive\"]]\nread: [\"header\",[\"Content-Length\",\"84\",\"Content-Length: 84\"]]\nread: [\"header_end\"]\nread: [\"body\",\"GET \\/echo \"]\nread: [\"body\",\"HTTP\\/1.1\\r\\n\"]\nread: [\"body\",\"Host: 127.\"]\nread: [\"body\",\"0.0.1\\r\\nUse\"]\nread: [\"body\",\"r-Agent: R\"]\nread: [\"body\",\"esty\\/HTTPi\"]\nread: [\"body\",\"pe-1.00\\r\\nA\"]\nread: [\"body\",\"ccept: *\\/*\"]\nread: [\"body\",\"\\r\\n\\r\\n\"]\nread: [\"body_end\"]\nread: [\"eof\"]\n</code></pre> <p>A typical output of the <code>/advanced</code> location defined above is:</p> <pre><code>POST /echo HTTP/1.1\nContent-Length: 84\nUser-Agent: Resty/HTTPipe-1.00\nAccept: */*\nHost: 127.0.0.1\n\nGET /echo HTTP/1.1\nHost: 127.0.0.1\nUser-Agent: Resty/HTTPipe-1.00\nAccept: */*\n</code></pre>"},{"location":"lua/httpipe/#connection","title":"Connection","text":""},{"location":"lua/httpipe/#new","title":"new","text":"<p><code>syntax: hp, err = httpipe:new(chunk_size?, sock?)</code></p> <p>Creates the httpipe object. In case of failures, returns <code>nil</code> and a string describing the error.</p> <p>The argument, <code>chunk_size</code>, specifies the buffer size used by cosocket reading operations. Defaults to <code>8192</code>.</p>"},{"location":"lua/httpipe/#connect","title":"connect","text":"<p><code>syntax: ok, err = hp:connect(host, port, options_table?)</code></p> <p><code>syntax: ok, err = hp:connect(\"unix:/path/to/unix.sock\", options_table?)</code></p> <p>Attempts to connect to the web server.</p> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p> <p>An optional Lua table can be specified as the last argument to this method to specify various connect options:</p> <ul> <li><code>pool</code> : Specifies a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template <code>&lt;host&gt;:&lt;port&gt;</code> or <code>&lt;unix-socket-path&gt;</code>.</li> </ul>"},{"location":"lua/httpipe/#set_timeout","title":"set_timeout","text":"<p><code>syntax: hp:set_timeout(time)</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the <code>connect</code> method.</p>"},{"location":"lua/httpipe/#ssl_handshake","title":"ssl_handshake","text":"<p><code>syntax: hp:ssl_handshake(reused_session?, server_name?, ssl_verify?)</code></p> <p>Does SSL/TLS handshake on the currently established connection.</p> <p>See more: http://wiki.nginx.org/HttpLuaModule#tcpsock:sslhandshake</p>"},{"location":"lua/httpipe/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = hp:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Attempts to puts the current connection into the ngx_lua cosocket connection pool.</p> <p>Note Normally, it will be called automatically after processing the request. In other words, we cannot release the connection back to the pool unless you consume all the data.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns 1. In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: times, err = hp:get_reused_times()</code></p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p>"},{"location":"lua/httpipe/#close","title":"close","text":"<p><code>syntax: ok, err = hp:close()</code></p> <p>Closes the current connection and returns the status.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/httpipe/#requesting","title":"Requesting","text":""},{"location":"lua/httpipe/#request","title":"request","text":"<p><code>syntax: res, err = hp:request(opts?)</code></p> <p><code>syntax: res, err = hp:request(host, port, opts?)</code></p> <p><code>syntax: res, err = hp:request(\"unix:/path/to/unix-domain.socket\", opts?)</code></p> <p>The <code>opts</code> table accepts the following fields:</p> <ul> <li><code>version</code>: Sets the HTTP version. Use <code>10</code> for HTTP/1.0 and <code>11</code> for HTTP/1.1. Defaults to <code>11</code>.</li> <li><code>method</code>: The HTTP method string. Defaults to <code>GET</code>.</li> <li><code>path</code>: The path string. Default to <code>/</code>.</li> <li><code>query</code>: Specifies query parameters. Accepts either a string or a Lua table.</li> <li><code>headers</code>: A table of request headers. Accepts a Lua table.</li> <li><code>body</code>: The request body as a string, or an iterator function.</li> <li><code>read_timeout</code>: Sets the timeout in milliseconds for network read operations specially.</li> <li><code>send_timeout</code>: Sets the timeout in milliseconds for network send operations specially.</li> <li><code>stream</code>: If set to <code>true</code>, return an iterable <code>res.body_reader</code> object instead of <code>res.body</code>.</li> <li><code>maxsize</code>: Sets the maximum size in bytes to fetch. A response body larger than this will cause the fucntion to return a <code>exceeds maxsize</code> error. Defaults to nil which means no limit.</li> <li><code>ssl_verify</code>: A Lua boolean value to control whether to perform SSL verification.</li> </ul> <p>When the request is successful, <code>res</code> will contain the following fields:</p> <ul> <li><code>res.status</code> (number): The resonse status, e.g. 200</li> <li><code>res.headers</code> (table): A Lua table with response headers.</li> <li><code>res.body</code> (string): The plain response body.</li> <li><code>res.body_reader</code> (function): An iterator function for reading the body in a streaming fashion.</li> <li><code>res.pipe</code> (httpipe): A new http pipe which use the current <code>body_reader</code> as input body by default.</li> </ul> <p>Note All headers (request and response) are noramlized for capitalization - e.g., Accept-Encoding, ETag, Foo-Bar, Baz - in the normal HTTP \"standard.\"</p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#request_uri","title":"request_uri","text":"<p><code>syntax: res, err = hp:request_uri(uri, opts?)</code></p> <p>The simple interface. Options supplied in the <code>opts</code> table are the same as in the generic interface, and will override components found in the uri itself.</p> <p>Returns a res object as same as <code>hp:request</code> method.</p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#resbody_reader","title":"res.body_reader","text":"<p>The <code>body_reader</code> iterator can be used to stream the response body in chunk sizes of your choosing, as follows:</p> <pre><code>local reader = res.body_reader\n\nrepeat\n  local chunk, err = reader(8192)\n  if err then\n    ngx.log(ngx.ERR, err)\n    break\n  end\n\n  if chunk then\n    -- process\n  end\nuntil not chunk\n</code></pre>"},{"location":"lua/httpipe/#send_request","title":"send_request","text":"<p><code>syntax: ok, err = hp:send_request(opts?)</code></p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#read_response","title":"read_response","text":"<p><code>syntax: local res, err = hp:read_response(callback?)</code></p> <p>The <code>callback</code> table accepts the following fields:</p> <ul> <li><code>header_filter</code>: A callback function for response headers filter</li> </ul> <pre><code>local res, err = hp:read_response{\n    header_filter = function (status, headers)\n        if status == 200 then\n            return 1\n        end\nend }\n</code></pre> <ul> <li><code>body_filter</code>: A callback function for response body filter</li> </ul> <pre><code>local res, err = hp:read_response{\n    body_filter = function (chunk)\n        ngx.print(chunk)\n    end\n}\n</code></pre> <p>Additionally there is no ability to stream the response body in this method. If the response is successful, res will contain the following fields: <code>res.status</code>, <code>res.headers</code>, <code>res.body</code>.</p> <p>Note When return true in callback function\uff0cfilter process will be interrupted.</p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#read","title":"read","text":"<p><code>syntax: local typ, res, err = hp:read()</code></p> <p>Streaming parser for the full response.</p> <p>The user just needs to call the read method repeatedly until a nil token type is returned. For each token returned from the read method, just check the first return value for the current token type. The token type can be <code>statusline</code>, <code>header</code>, <code>header_end</code>, <code>body</code>, <code>body_end</code> and <code>eof</code>. About the format of <code>res</code> value, please refer to the above example. For example, several body tokens holding each body data chunk, so <code>res</code> value is equal to the body data chunk.</p> <p>In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/httpipe/#eof","title":"eof","text":"<p><code>syntax: local eof = hp:eof()</code></p> <p>If return <code>true</code> indicating already consume all the data; Otherwise, the request there is still no end, you need call <code>hp:close</code> to close the connection forcibly.</p>"},{"location":"lua/httpipe/#utility","title":"Utility","text":""},{"location":"lua/httpipe/#parse_uri","title":"parse_uri","text":"<p><code>syntax: local scheme, host, port, path, args = unpack(hp:parse_uri(uri))</code></p> <p>This is a convenience function allowing one to more easily use the generic interface, when the input data is a URI.</p>"},{"location":"lua/httpipe/#get_client_body_reader","title":"get_client_body_reader","text":"<p><code>syntax: reader, err = hp:get_client_body_reader(chunk_size?)</code></p> <p>Returns an iterator function which can be used to read the downstream client request body in a streaming fashion. For example:</p> <pre><code>local req_reader = hp:get_client_body_reader()\n\nrepeat\n  local chunk, err = req_reader(8192)\n  if err then\n    ngx.log(ngx.ERR, err)\n    break\n  end\n\n  if chunk then\n    -- process\n  end\nuntil not chunk\n</code></pre> <p>This iterator can also be used as the value for the body field in request params, allowing one to stream the request body into a proxied upstream request.</p> <pre><code>local client_body_reader, err = hp:get_client_body_reader()\n\nlocal res, err = hp:request{\n   path = \"/helloworld\",\n   body = client_body_reader,\n}\n</code></pre>"},{"location":"lua/httpipe/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-httpipe.</p>"},{"location":"lua/hyperscan/","title":"hyperscan: Hyperscan for nginx-module-lua","text":""},{"location":"lua/hyperscan/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/hyperscan/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-hyperscan\n</code></pre>"},{"location":"lua/hyperscan/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-hyperscan\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-hyperscan v0.3  released on Apr 14 2022.</p> <p>lua-resty-hyperscan - Hyperscan for Openresty</p> <p>!!! Old Branch got too many callbacks problem, because luajit is not fully support CALLBACK. So we need a C wrapper to handle callbacks.</p>"},{"location":"lua/hyperscan/#_1","title":"Hyperscan for nginx-module-lua","text":""},{"location":"lua/hyperscan/#status","title":"Status","text":"<p>This library is under development so far.</p> <p>Support Block Mode and Vectored Mode now.</p>"},{"location":"lua/hyperscan/#_2","title":"Hyperscan for nginx-module-lua","text":""},{"location":"lua/hyperscan/#first-you-should-install-openresty","title":"first, you should install openresty","text":"<p>git clone git@github.com:LubinLew/lua-resty-hyperscan.git cd lua-resty-hyperscan make make install make test <pre><code>## \n\n## \n\n## Synopsis\n\nconfiguration example\n\n```lua\nuser  nobody;\nworker_processes  auto;\nerror_log logs/error.log error;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    access_log  logs/access.log;\n\n    init_by_lua_block {\n       local whs, err = require('hyperscan')\n        if not whs then\n            ngx.log(ngx.ERR, \"Failure:\", err)\n            return\n        end\n\n       -- new\n       local obj = whs.block_new(\"a-uniq-name\", true) -- true : enable debug mode\n\n       local patterns = {\n           {id = 1001, pattern = \"\\\\d3\",       flag = \"iu\"},\n           {id = 1002, pattern = \"\\\\s{3,5}\",   flag = \"u\"},\n           {id = 1003, pattern = \"[a-d]{2,7}\", flag = \"\"}\n       }\n\n        -- compile\n        ret, err = obj:compile(patterns)\n        if not ret then\n           ngx.log(ngx.ERR, \"hyperscan block compile failed, \", err)\n           return\n        end\n    }\n\n    server {\n        listen       80;\n        server_name  localhost;\n\n        location / {\n            content_by_lua_block {\n                local whs = require('hyperscan')\n                local obj = whs.block_get(\"a-uniq-name\")\n                -- scan\n                local ret, id, from, to = obj:scan(ngx.var.uri)\n                if ret then\n                    return ngx.print(\"[\", ngx.var.uri,\"] match: \", id, \" zone [\", from, \" - \", to, \").\\n\")\n                else\n                    return ngx.print(\"[\", ngx.var.uri, \"] not match any rule.\\n\")\n                end\n            }\n        }\n    }\n}\n</code></pre></p> <p>test cases:</p> <pre><code>$ curl http://localhost\n[/] not match any rule.\n\n$ curl http://localhost/131111111\n[/131111111] match: 1001 zone [0 - 3).\n\n$ curl \"http://localhost/      end\"\n[/      end] match: 1002 zone [0 - 4).\n\n$ curl http://localhost/aaaaaaa\n[/aaaaaaa] match: 1003 zone [0 - 3).\n</code></pre>"},{"location":"lua/hyperscan/#_3","title":"Hyperscan for nginx-module-lua","text":""},{"location":"lua/hyperscan/#methods","title":"Methods","text":"<p>way to load this library</p> <pre><code>local whs,err = require('hyperscan')\nif not whs then\n    ngx.log(ngx.ERR, \"reason: \", err)\nend\n</code></pre>"},{"location":"lua/hyperscan/#block_new","title":"block_new","text":"<p>Create a hyperscan instance for block mode.</p> <pre><code>local handle, err = whs.block_new(name, debug)\nif not handle then\n    ngx.log(ngx.ERR, \"reason: \", err)\nend\n</code></pre> Field Name Lua Type Description Parameter <code>name</code> string instance name, mainly for log <code>debug</code> boolean enable/disable write debug log to syslog Return\u00a0Value <code>handle</code> table/nil instance reference <code>err</code> string reason of failure"},{"location":"lua/hyperscan/#block_free","title":"block_free","text":"<p>Destroy a hyperscan instance for block mode.</p> <pre><code>whs.block_free(name)\n</code></pre>"},{"location":"lua/hyperscan/#block_get","title":"block_get","text":"<p>Get the instance\u00a0reference by name.</p> <pre><code>local handle = whs.block_get(name)\n</code></pre> Filed Name Lua Type Description Parameter <code>name</code> string instance name Return Value <code>handle</code> table/nil instance\u00a0reference"},{"location":"lua/hyperscan/#vector_new","title":"vector_new","text":"<p>Create a hyperscan instance for vector mode.</p> <pre><code>local handle, err = whs.vector_new(name, debug)\nif not handle then\n    ngx.log(ngx.ERR, \"reason: \", err)\nend\n</code></pre> Field Name Lua Type Description Parameter <code>name</code> string instance name, mainly for log <code>debug</code> boolean enable/disable write debug log to syslog Return\u00a0Value <code>handle</code> table/nil instance reference <code>err</code> string reason of failure"},{"location":"lua/hyperscan/#vector_free","title":"vector_free","text":"<p>Destroy a hyperscan instance for vector mode.</p> <pre><code>whs.vector_free(name)\n</code></pre>"},{"location":"lua/hyperscan/#vector_get","title":"vector_get","text":"<p>Get the instance\u00a0reference by name.</p> <pre><code>local handle = whs.vector_get(name)\n</code></pre> Filed Name Lua Type Description Parameter <code>name</code> string instance name Return Value <code>handle</code> table/nil instance\u00a0reference"},{"location":"lua/hyperscan/#handlecompile","title":"handle:compile","text":"<p>compile regular expression into a Hyperscan database.</p> <pre><code>--local handle = whs.block_new(name, debug)\nlocal ok, err = handle:compile(patterns)\nif not ok then\n    ngx.log(ngx.ERR, \"reason: \", err)\nend\n</code></pre> Field Name Lua Type Description parameter <code>patterns</code> table pattern list Return Value <code>ok</code> boolean success/failure <code>err</code> string reason of failure"},{"location":"lua/hyperscan/#pattern-list","title":"Pattern List","text":""},{"location":"lua/hyperscan/#example","title":"Example","text":"<pre><code>local patterns = {\n    {id = 1001, pattern = \"\\\\d3\",       flag = \"iu\"   },\n    {id = 1002, pattern = \"\\\\s{3,5}\",   flag = \"dmsu\" },\n    {id = 1003, pattern = \"[a-d]{2,7}\", flag = \"\"     }\n}\n</code></pre>"},{"location":"lua/hyperscan/#flags","title":"Flags","text":"Flag Hyperscan Value Description <code>'i'</code> HS_FLAG_CASELESS Set case-insensitive matching <code>'d'</code> HS_FLAG_DOTALL Matching a <code>.</code> will not exclude newlines. <code>'m'</code> HS_FLAG_MULTILINE Set multi-line anchoring. <code>'s'</code> HS_FLAG_SINGLEMATCH Set single-match only mode. <code>'e'</code> HS_FLAG_ALLOWEMPTY Allow expressions that can match against empty buffers. <code>'u'</code> HS_FLAG_UTF8 Enable UTF-8 mode for this expression. <code>'p'</code> HS_FLAG_UCP Enable Unicode property support for this expression. <code>'f'</code> HS_FLAG_PREFILTER Enable prefiltering mode for this expression. <code>'l'</code> HS_FLAG_SOM_LEFTMOST Enable leftmost start of match reporting. <code>'c'</code> HS_FLAG_COMBINATION Logical combination. <code>'q'</code> HS_FLAG_QUIET Don't do any match reporting."},{"location":"lua/hyperscan/#handlescan","title":"handle:scan","text":"<p>The actual pattern matching takes place for block-mode pattern databases.</p> <pre><code>--local handle = whs.block_get(name)\nlocal ok, id, from, to = handle:scan(data)\nif ok then\n    ngx.log(ngx.INFO, \"match success\", id, from, to)\nend\n</code></pre> <p>The actual pattern matching takes place for vector-mode pattern databases.</p> <pre><code>--local handle = whs.vector_get(name)\n--local data = {\"s\",\"s2\"}\n--local data = \"s\"\nlocal ok, id, dataindex, to = handle:scan(data)\nif ok then\n    ngx.log(ngx.INFO, \"match success\", id, from, to)\nend\n</code></pre> Field Name Lua Type Description Parameter <code>data</code> string/string[] string to be scanned(string[] only vector mode) Return Value <code>ok</code> boolean <code>ture</code> for match, <code>false</code> for not match <code>id</code> number match id <code>from</code> number match from byte arrary index(include itself) <code>to</code> number match end byte arrary index(exclude itself) <code>dataindex</code> number match data index(only vector mode)"},{"location":"lua/hyperscan/#handlefree","title":"handle:free","text":"<p>Destroy a hyperscan instance.</p> <pre><code>--local handle = whs.block_get(name)\nhandle:free()\n</code></pre>"},{"location":"lua/hyperscan/#_4","title":"Hyperscan for nginx-module-lua","text":""},{"location":"lua/hyperscan/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-hyperscan.</p>"},{"location":"lua/influx/","title":"influx: Nginx-module-lua client for InfluxDB","text":""},{"location":"lua/influx/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/influx/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-influx\n</code></pre>"},{"location":"lua/influx/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-influx\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-influx v0.2.1  released on Dec 27 2017.</p> <p>lua-resty-influx - OpenResty client writer for InfluxDB.</p>"},{"location":"lua/influx/#status","title":"Status","text":"<p>This library is in active development and is considered ready for production use.</p>"},{"location":"lua/influx/#description","title":"Description","text":"<p>This library provides an OpenResty interface to write data points to an InfluxDB server via UDP and HTTP interfaces. Object-based and buffering per-worker interfaces are provided.</p>"},{"location":"lua/influx/#synopsis","title":"Synopsis","text":"<p>Object interface:</p> <pre><code>http {\n    server {\n        access_by_lua_block {\n            local i = require \"resty.influx.object\"\n\n            local influx, err =i:new({\n                host = \"127.0.0.1\",\n                port = 8086,\n                proto = \"http\",\n                db = \"db\",\n                hostname = \"localhost\",\n                auth = \"user:password\",\n            })\n\n            if (not influx) then\n                ngx.say(err)\n                return\n            end\n\n            influx:set_measurement(\"foo\")\n            influx:add_tag(\"foo\", \"bar\")\n            influx:add_field(\"value\", 1)\n            influx:buffer()\n\n            -- add and buffer additional data points\n\n            local ok, err = influx:flush()\n\n            if (not ok) then\n                ngx.say(err)\n            end\n        }\n    }\n}\n</code></pre> <p>Buffering interface:</p> <pre><code>http {\n    init_worker_by_lua_block {\n        local ibuf = require \"resty.influx.buffer\"\n\n        local ok, err = ibuf.init({\n            host = \"127.0.0.1\",\n            port = 8089,\n            proto = \"udp\",\n        })\n\n        if (not ok) then\n            ngx.log(ngx.ERR, err)\n        end\n    }\n\n    server {\n        access_by_lua_block {\n            local ibuf = require \"resty.influx.buffer\"\n\n            ibuf.buffer({\n                measurement = \"foo\",\n                tags = {\n                    { foo = \"bar\" }\n                },\n                fields = {\n                    { value = 1 }\n                }\n            })\n        }\n\n        log_by_lua_block {\n            local ibuf = require \"resty.influx.buffer\"\n\n            ibuf.flush()\n        }\n    }\n}\n</code></pre>"},{"location":"lua/influx/#usage","title":"Usage","text":""},{"location":"lua/influx/#options","title":"Options","text":"<p>lua-resty-influx provides a pure object-based interface, as well as a buffering interface that stores data points per-worker, and then buffers asynchronously via <code>ngx.timer.at</code>. Creation of the buffering interface should be handled in the <code>init_worker_by_lua</code> phase via the <code>resty.influx.buffer.init</code> function; creation of the object-oriented interface should be handled in your appropriate phase handler via <code>resty.influx.object:new</code>. In both cases, the following options are available:</p>"},{"location":"lua/influx/#host","title":"host","text":"<p>Default: 127.0.0.1</p> <p>Sets the host to which <code>ngx.socket.udp</code> and <code>resty.http</code> will attempt to connect.</p>"},{"location":"lua/influx/#port","title":"port","text":"<p>Default: 8086</p> <p>Sets the port to which <code>ngx.socket.udp</code> and <code>resty.http</code> will attempt to connect. Defaults to <code>8086</code> as the default protocol is HTTP.</p>"},{"location":"lua/influx/#db","title":"db","text":"<p>Default: 'lua-resty-influx'</p> <p>Sets the db to which <code>resty.http</code> will attempt to connect. This option is ignored when <code>udp</code> is the configured protocol.</p>"},{"location":"lua/influx/#hostname","title":"hostname","text":"<p>Default: <code>host</code></p> <p>Sets the hostname to which <code>resty.http</code> will define the <code>Host</code> header for HTTP requests. By default, this is equal to the configured <code>host</code> option. This option is ignored when <code>udp</code> is the configured protocol.</p>"},{"location":"lua/influx/#proto","title":"proto","text":"<p>Default: http</p> <p>Sets the protocol by which <code>resty.influx</code> will connect to the remote server. Note that UDP can present a significant performance improvement, particularly when sending many small sets of data points, at the cost of error handling and authentication.</p>"},{"location":"lua/influx/#precision","title":"precision","text":"<p>Default: ms</p> <p>Sets the timestamp precision by which <code>resty.influx</code> will define timestamps. Currently, <code>ms</code>, <code>s</code>, and <code>none</code> are supported; when <code>none</code> is configured, no stamp will be sent as part of the line protocol message, and the remote Influx server will use nanosecond precision based on the server-local clock.</p>"},{"location":"lua/influx/#ssl","title":"ssl","text":"<p>Default: false</p> <p>Configures HTTP requests to perform a TLS handshake before sending data. This option is ignored when <code>udp</code> is the configured protocol.</p>"},{"location":"lua/influx/#auth","title":"auth","text":"<p>Default: ''</p> <p>Sets the username and password presented to remote HTTP(S). This value must be given as a single string in the format <code>user:password</code>. This option is ignored when <code>udp</code> is the configured protocol.</p>"},{"location":"lua/influx/#object-oriented-interface","title":"Object-Oriented Interface","text":"<p>The following methods are available via the object interface:</p>"},{"location":"lua/influx/#influxset_measurement","title":"influx:set_measurement","text":"<p>Syntax: influx:set_measurement(string)</p> <p>Sets the measurement for the data point associated with the current object.</p>"},{"location":"lua/influx/#influxadd_tag","title":"influx:add_tag","text":"<p>Syntax influx:add_tag(key, value)</p> <p>Adds a data point tag as a key-value pair. Keys and values are escaped according to (https://docs.influxdata.com/influxdb/v1.0/write_protocols/line_protocol_reference/).</p>"},{"location":"lua/influx/#influxadd_field","title":"influx:add_field","text":"<p>Syntax: influx:add_field(key, value)</p> <p>Add a data point field as a key-value pair. Fields and values are escaped according to (https://docs.influxdata.com/influxdb/v1.0/write_protocols/line_protocol_reference/). Integer values (number values appended with an <code>i</code>) are properly interpolated.</p>"},{"location":"lua/influx/#influxstamp","title":"influx:stamp","text":"<p>Syntax: influx:stamp(time?)</p> <p>Stamps the data point associated with the current object, with an optional arbitrary value (must be provided as a number); otherwise, this stamps the object with the appropriate value based on the precision specified via the options given to <code>new</code> for the object interface.</p>"},{"location":"lua/influx/#influxclear","title":"influx:clear","text":"<p>Syntax influx:clear()</p> <p>Clears the measurement, tags, and fields on the data point associated with the current object. Note that this is called internally when <code>buffer</code> or  <code>write</code> are called.</p>"},{"location":"lua/influx/#influxbuffer","title":"influx:buffer","text":"<p>Syntax: local ok, err = influx:buffer()</p> <p>Buffer the contents of the data point associated with the current object for later flushing. Returns true on success; otherwise, returns false and a string describing the error (such as invalid conditions under which to buffer).</p>"},{"location":"lua/influx/#influxflush","title":"influx:flush","text":"<p>Syntax: local ok, err = influx:flush()</p> <p>Flushes all buffered data points associated with the current object. Returns true on success; otherwise, returns false and a string describing the error (such as leftover data waiting to be buffered, or no available buffered data points).</p>"},{"location":"lua/influx/#influxwrite","title":"influx:write","text":"<p>Syntax local ok, err = inflush:write()</p> <p>Writes the data point associated with the current object, without clearing the existing object buffer. This is essentially shorthand for calling <code>buffer</code> and <code>flush</code> on a single data point. Note that previously buffered data points still remain in the buffer, and must be sent out via <code>flush</code> if desired.</p>"},{"location":"lua/influx/#buffering-interface","title":"Buffering Interface","text":"<p>The following functions are available via the buffering interface:</p>"},{"location":"lua/influx/#influxbuffer_1","title":"influx.buffer","text":"<p>Syntax: influx.buffer(data_table)</p> <p>Buffers a new data point in the per-worker process buffer. <code>data_table</code> must be a table that contains the following keys:</p> <ul> <li><code>measurement</code>: String denoting the measurement of the data point</li> <li><code>tags</code>: Integer-indexed table containing tables of key-value pairs denoting the tag elements. See the synopsis for examples.</li> <li><code>fields</code>: Integer-indexed table containing tables of key-value pairs denoting the field elements. See the synopsis for examples.</li> </ul> <p>Note that currently the timestamp is automatically set with <code>ms</code> precision.</p>"},{"location":"lua/influx/#influxflush_1","title":"influx.flush","text":"<p>Syntax influx.flush()</p> <p>Write all data points buffered in the current worker process to the configured influx host. Returns true on success; otherwise, returns false and a string describing the error from <code>ngx.timer.at</code>.</p> <p>This operation returns immediately and runs asynchronously</p>"},{"location":"lua/influx/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-influx.</p>"},{"location":"lua/ini/","title":"ini: Ini parser for nginx-module-lua","text":""},{"location":"lua/ini/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/ini/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-ini\n</code></pre>"},{"location":"lua/ini/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-ini\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-ini v0.1  released on May 31 2016.</p> <p>lua-resty-ini - Lua ini parser</p>"},{"location":"lua/ini/#status","title":"Status","text":"<p>This library is still under early development and is still experimental.</p>"},{"location":"lua/ini/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/ini/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-ini.</p>"},{"location":"lua/injection/","title":"injection: LuaJIT FFI bindings to libinjection (https://github.com/client9/libinjection)","text":""},{"location":"lua/injection/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/injection/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-injection\n</code></pre>"},{"location":"lua/injection/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-injection\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-injection v1.0  released on Sep 15 2016.</p> <p>LuaJIT FFI bindings to libinjection (https://github.com/client9/libinjection) \u2014 SQL / SQLI / XSS tokenizer parser analyzer.</p>"},{"location":"lua/injection/#synopsis","title":"Synopsis","text":"<pre><code>local injection = require \"resty.injection\"\n\n-- Print version of libinjection\nprint(injection.version)\n\n-- Testing SQL injection detection\nprint(injection.sql(\"test; DROP users;\"))\nprint(injection.sql(\"test\"))\nprint(injection.sql(\"test&lt;script&gt;&lt;/script&gt;\"))\n\n-- Testing Cross-Site Scripting injection detection\nprint(injection.xss(\"test; DROP users;\"))\nprint(injection.xss(\"test\"))\nprint(injection.xss(\"test&lt;script&gt;&lt;/script&gt;\"))\n</code></pre> <p>The above would output something similar to this:</p> <pre><code>3.9.1\ntrue    n;Tn;\nfalse\nfalse\nfalse\nfalse\ntrue\n</code></pre> <p>The second line contains fingerprint of the injection.</p>"},{"location":"lua/injection/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-injection.</p>"},{"location":"lua/iputils/","title":"iputils: Utility functions for working with IP addresses in nginx-module-lua","text":""},{"location":"lua/iputils/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/iputils/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-iputils\n</code></pre>"},{"location":"lua/iputils/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-iputils\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-iputils v0.3.0  released on Mar 28 2017.</p> <p>Collection of utility functions for working with IP addresses.</p>"},{"location":"lua/iputils/#overview","title":"Overview","text":"<pre><code>init_by_lua_block {\n  local iputils = require(\"resty.iputils\")\n  iputils.enable_lrucache()\n  local whitelist_ips = {\n      \"127.0.0.1\",\n      \"10.10.10.0/24\",\n      \"192.168.0.0/16\",\n  }\n\n  -- WARNING: Global variable, recommend this is cached at the module level\n  -- https://github.com/openresty/lua-nginx-module#data-sharing-within-an-nginx-worker\n  whitelist = iputils.parse_cidrs(whitelist_ips)\n}\n\naccess_by_lua_block {\n    local iputils = require(\"resty.iputils\")\n    if not iputils.ip_in_cidrs(ngx.var.remote_addr, whitelist) then\n      return ngx.exit(ngx.HTTP_FORBIDDEN)\n    end\n}\n</code></pre>"},{"location":"lua/iputils/#methods","title":"Methods","text":""},{"location":"lua/iputils/#enable_lrucache","title":"enable_lrucache","text":"<p><code>syntax: ok, err = iputils.enable_lrucache(size?)</code></p> <p>Creates a global lrucache object for caching ip2bin lookups.</p> <p>Size is optional and defaults to 4000 entries (~1MB per worker)</p> <p>Calling this repeatedly will reset the cache</p>"},{"location":"lua/iputils/#ip2bin","title":"ip2bin","text":"<p><code>syntax: bin_ip, bin_octets = iputils.ip2bin(ip)</code></p> <p>Returns the binary representation of an IPv4 address and a table containing the binary representation of each octet</p> <p>Returns <code>nil</code> and and error message for bad IPs</p>"},{"location":"lua/iputils/#parse_cidr","title":"parse_cidr","text":"<p><code>syntax: lower, upper = iputils.parse_cidr(cidr)</code></p> <p>Returns a binary representation of the lowest (network) and highest (broadcast) addresses of an IPv4 network.</p>"},{"location":"lua/iputils/#parse_cidrs","title":"parse_cidrs","text":"<p><code>syntax: parsed = iputils.parse_cidrs(cidrs)</code></p> <p>Takes a table of CIDR format IPV4 networks and returns a table of tables containg the lower and upper addresses.</p> <p>If an invalid network is in the table an error is logged and the other networks are returned</p>"},{"location":"lua/iputils/#ip_in_cidrs","title":"ip_in_cidrs","text":"<p><code>syntax: bool, err = iputils.ip_in_cidrs(ip, cidrs)</code></p> <p>Takes a string IPv4 address and a table of parsed CIDRs (e.g. from <code>iputils.parse_cidrs</code>).</p> <p>Returns a <code>true</code> or <code>false</code> if the IP exists within any of the specified networks.</p> <p>Returns <code>nil</code> and an error message with an invalid IP</p>"},{"location":"lua/iputils/#binip_in_cidrs","title":"binip_in_cidrs","text":"<p><code>syntax: bool, err = iputils.binip_in_cidrs(bin_ip, cidrs)</code></p> <p>Takes a nginx binary IPv4 address (e.g. <code>ngx.var.binary_remote_addr</code>) and a table of parsed CIDRs (e.g. from <code>iputils.parse_cidrs</code>).</p> <p>This method is much faster than <code>ip_in_cidrs()</code> if the IP being checked is already available as a binary representation.</p> <p>Returns a <code>true</code> or <code>false</code> if the IP exists within any of the specified networks.</p> <p>Returns <code>nil</code> and an error message with an invalid IP</p>"},{"location":"lua/iputils/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-iputils.</p>"},{"location":"lua/jit-uuid/","title":"jit-uuid: Fast and dependency-free UUID library for LuaJIT/nginx-module-lua","text":""},{"location":"lua/jit-uuid/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jit-uuid/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jit-uuid\n</code></pre>"},{"location":"lua/jit-uuid/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jit-uuid\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jit-uuid v0.0.7  released on Dec 16 2017.</p> <p>[![Module Version][badge-version-image]][luarocks-resty-jit-uuid] [![Coverage Status][badge-coveralls-image]][badge-coveralls-url]</p> <p>A pure LuaJIT (no dependencies) UUID library tuned for performance.</p>"},{"location":"lua/jit-uuid/#motivation","title":"Motivation","text":"<p>This module is aimed at being a free of dependencies, performant and complete UUID library for LuaJIT and ngx_lua.</p> <p>Unlike FFI and C bindings, it does not depend on libuuid being available in your system. On top of that, it performs better than most (all?) of the generators it was benchmarked against, FFI bindings included.</p> <p>Finally, it provides additional features such as UUID v3/v4/v5 generation and UUID validation.</p> <p>See the Benchmarks section for comparisons between other UUID libraries for Lua/LuaJIT.</p>"},{"location":"lua/jit-uuid/#usage","title":"Usage","text":"<p>LuaJIT: <pre><code>local uuid = require 'resty.jit-uuid'\n\nuuid.seed()        ---&gt; automatic seeding with os.time(), LuaSocket, or ngx.time()\n\nuuid()             ---&gt; v4 UUID (random)\nuuid.generate_v4() ---&gt; v4 UUID\n\nuuid.generate_v3() ---&gt; v3 UUID (name-based with MD5)\nuuid.generate_v5() ---&gt; v5 UUID (name-based with SHA-1)\n\nuuid.is_valid()    ---&gt; true/false (automatic JIT PCRE or Lua patterns)\n</code></pre></p> <p>OpenResty: <pre><code>http {\n    init_worker_by_lua_block {\n        local uuid = require 'resty.jit-uuid'\n        uuid.seed() -- very important!\n    }\n\n    server {\n        location / {\n            content_by_lua_block {\n                local uuid = require 'resty.jit-uuid'\n                ngx.say(uuid())\n            }\n        }\n    }\n}\n</code></pre></p> <p>Note: when generating v4 (random) UUIDs in ngx_lua, it is very important that you seed this module in the <code>init_worker</code> phase. If you do not, your workers will generate identical UUID sequences, which could lead to serious issues in your application. The seeding requirement also applies in uses outside of ngx_lua, although seeding is less delicate in such cases. Additionally, you should be weary about the usage of the <code>lua_code_cache</code> directive: if Lua code cache is disabled, all sequences of UUIDs generated during subsequent requests will be identical, unless this module is seeded for every request. Just like disabling Lua code cache, such behavior would be considered an ngx_lua anti-pattern and you should avoid it.</p>"},{"location":"lua/jit-uuid/#documentation","title":"Documentation","text":"<p>Documentation is available online at http://thibaultcha.github.io/lua-resty-jit-uuid/.</p>"},{"location":"lua/jit-uuid/#benchmarks","title":"Benchmarks","text":"<p>This module has been carefully benchmarked on each step of its implementation to ensure the best performance for OpenResty and plain LuaJIT. For example, UUID validation will use JIT PCRE over Lua patterns when possible.</p> <p>The <code>bench.lua</code> file provides benchmarks of UUID generation for several popular UUID libraries.</p> <p>Run <code>make bench</code> to run them: <pre><code>LuaJIT 2.1.0-beta1 with 1e+06 UUIDs\nUUID v4 (random) generation\n1. resty-jit-uuid   took:   0.064228s    0%\n2. FFI binding      took:   0.093374s   +45%\n3. C binding        took:   0.220542s   +243%\n4. Pure Lua         took:   2.051905s   +3094%\n\nUUID v3 (name-based and MD5) generation if supported\n1. resty-jit-uuid   took:   1.306127s\n\nUUID v5 (name-based and SHA-1) generation if supported\n1. resty-jit-uuid   took:   4.834929s\n\nUUID validation if supported (set of 70% valid, 30% invalid)\n1. resty-jit-uuid (JIT PCRE enabled)    took:   0.223060s\n2. FFI binding                          took:   0.256580s\n3. resty-jit-uuid (Lua patterns)        took:   0.444174s\n</code></pre></p> <ul> <li>FFI binding: https://github.com/bungle/lua-resty-uuid</li> <li>C binding: https://github.com/Mashape/lua-uuid</li> <li>Pure Lua: https://github.com/Tieske/uuid</li> <li>resty-jit-uuid: this module (base reference for generation % comparison)</li> </ul> <p>Note: UUID validation performance in ngx_lua (JIT PCRE) can be greatly improved by enabling lua-resty-core.</p>"},{"location":"lua/jit-uuid/#contributions","title":"Contributions","text":"<p>Suggestions improving this module's or the benchmarks' performance (of any benchmarked library) are particularly appreciated.</p>"},{"location":"lua/jit-uuid/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jit-uuid.</p>"},{"location":"lua/jq/","title":"jq: LuaJIT FFI bindings to jq","text":""},{"location":"lua/jq/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jq/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jq\n</code></pre>"},{"location":"lua/jq/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jq\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jq v0.2.0  released on Jun 06 2025.</p> <p>lua-resty-jq is a small LuaJIT FFI wrapper to jq</p>"},{"location":"lua/jq/#hello-world-with-lua-resty-jq","title":"Hello World with lua-resty-jq","text":"<pre><code>-- &lt;example-input&gt; from https://api.github.com/repos/stedolan/jq/commits?per_page=5\nlocal jq = require \"resty.jq\".new()\n\njq:compile(\"[ .[] | {message: .commit.message, name: .commit.committer.name} ]\")\nlocal output = jq:filter(&lt;example-input&gt;)\n\nprint(output)\n\njq:teardown()\n</code></pre> <p>Running the above code will output (or similar):</p> <pre><code>[\n  {\n    \"message\": \"Add some missing code quoting to the manual\",\n    \"name\": \"William Langford\"\n  },\n  {\n    \"message\": \"Reduce allocation on string multiplication\",\n    \"name\": \"William Langford\"\n  },\n  {\n    \"message\": \"Fix multiple string multiplication\",\n    \"name\": \"William Langford\"\n  },\n  {\n    \"message\": \"Fix error handling in strftime\",\n    \"name\": \"William Langford\"\n  },\n  {\n    \"message\": \"Makefile: prepend srcdir to jq.1.prebuilt to fix out of source compilation\",\n    \"name\": \"William Langford\"\n  }\n]\n</code></pre>"},{"location":"lua/jq/#new","title":"new","text":"<p><code>syntax: jq, err = require(\"resty.jq\").new()</code></p> <p>Allocates a <code>libjq</code> context.</p>"},{"location":"lua/jq/#teardown","title":"teardown","text":"<p><code>syntax: jq:teardown()</code></p> <p>Destroys the <code>libjq</code> context, freeing resources.</p>"},{"location":"lua/jq/#compile","title":"compile","text":"<p><code>syntax: ok, err = jq:compile(program)</code></p> <p>Returns <code>true</code> if the program was compiled, otherwise <code>nil</code> and the error <code>compilation failed</code>.</p> <p>Note it is not currently possible to inspect details of the compilation error. If in doubt, try your program in the CLI <code>jq</code>.</p>"},{"location":"lua/jq/#filter","title":"filter","text":"<p><code>syntax: res, err = jq:filter(data, options)</code></p> <p>Filters <code>data</code> using the previously compiled program. The <code>options</code> table can contain flags which alter the behaviour of the filter, similar to a subset of the CLI options to <code>jq</code>:</p> <ul> <li><code>compact_output</code>: Returns output in a compact form without additional   spacing, and with each JSON object on a single line. Defaults to <code>true</code>. Set to <code>false</code> for \"pretty\" output.</li> <li><code>raw_output</code>: Outputs as raw strings, not JSON quoted. Default is <code>false</code>.</li> <li><code>join_output</code>: As <code>raw_output</code> but in addition does not output newline   separators. Default is <code>false</code>.</li> <li><code>ascii_output</code>: jq usually outputs non-ASCII Unicode codepoints as UTF-8,   even if the input specified them as escape sequences (like \"\\u03bc\"). Using this option, you can force jq to produce pure ASCII output with every non-ASCII character replaced with the equivalent escape sequence. Default is <code>false</code>.</li> <li><code>sort_keys</code>: Output the fields of each object with the keys in sorted order.   Default is <code>false</code>.</li> <li><code>table_output</code>: Returns a sequence-like table of encoded results instead of     concatenating them into a single string. Default is <code>false</code>.</li> </ul> <p>Additionally, <code>filter()</code> takes a table as an optional 3rd argument. When supplied, this table will be used to store results instead of creating a new table for each call to <code>filter()</code>:</p> <pre><code>local buf = {}\nlocal res, err = jq:filter(data, nil, buf)\nfor _, elem in ipairs(buf) do\n  -- ...\nend\n</code></pre> <p>Doing so implies <code>options.table_output = true</code>, so this option must be explicitly set to <code>false</code> in order to receive a string result:</p> <pre><code>local buf = {}\nlocal res, err = jq:filter(data, { table_output = false }, buf)\nprint(res)\n</code></pre> <p>NOTE: <code>filter()</code> adds a trailing <code>nil</code> to the table such that the length operator (<code>#buf</code>) and <code>ipairs(buf)</code> return accurate results after execution, but it does not clear the table. Callers must clear the table themselves if desired.</p>"},{"location":"lua/jq/#see-also","title":"See Also","text":"<ul> <li>lua-jq</li> </ul>"},{"location":"lua/jq/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jq.</p>"},{"location":"lua/jsonrpc-batch/","title":"jsonrpc-batch: JSONRPC batch protocol module for nginx-module-lua","text":""},{"location":"lua/jsonrpc-batch/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jsonrpc-batch/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jsonrpc-batch\n</code></pre>"},{"location":"lua/jsonrpc-batch/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jsonrpc-batch\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jsonrpc-batch v0.0.1  released on Jul 15 2015.</p> <p>The Lua-Openresty implementation of JSON-RPC 2.0 Batch Request (http://www.jsonrpc.org/specification#batch).</p> <p>The batch request is non-blocking and proceeded paralelly because this module makes use of location.capture_multi of ngx_lua. So the performance is high while the implementation is simple.</p> <p>This module parses a batch request, validate it, and makes multi subrequest to upstream servers. Note that you must have a upstream JSON-RPC server as you like, but upstream servers need not apply for JSON-RPC batch request.</p>"},{"location":"lua/jsonrpc-batch/#synopsis","title":"Synopsis","text":""},{"location":"lua/jsonrpc-batch/#basic-usage","title":"Basic Usage","text":"<pre><code>server {\n    location /api {\n        # jsonrpc endpoint\n    }\n    location /api/batch {\n        lua_need_request_body on;\n\n        content_by_lua '\n            local jsonrpc_batch = require \"resty.jsonrpc.batch\"\n            client = jsonrpc_batch:new()\n            local res, err = client:batch_request({\n                path    = \"/api\",\n                request = ngx.var.request_body,\n            })\n            if err then\n                ngx.exit(500)\n            end\n            ngx.say(res)\n        ';\n    }\n}\n</code></pre>"},{"location":"lua/jsonrpc-batch/#advanced-usage","title":"Advanced Usage","text":"<pre><code>http {\n\n    init_by_lua '\n        local jsonrpc_batch = require \"resty.jsonrpc.batch\"\n        client = jsonrpc_batch.new({\n            -- make limitation to batch request array size\n            max_batch_array_size = 10,\n            -- for logging upstream response time\n            before_subrequest = function(self, ctx, req)\n                ctx.start_at = ngx.now()\n            end,\n            after_subrequest = function(self, ctx, resps, req)\n                ngx.var.jsonrpc_upstream_response_time = ngx.now() - ctx.start_at\n            end,\n        })\n    ';\n\n    server {\n        set $jsonrpc_upstream_response_time  -;\n\n        location ~ /api/method/.* {\n            # jsonrpc endpoint\n        }\n\n        location /api/batch {\n            lua_need_request_body on;\n\n            content_by_lua '\n                local res, err = client:batch_request({\n                    -- you can change the endpoint per request\n                    path = function(self, ctx, req)\n                        return \"/api/method/\" .. req.method\n                    end,\n                    request  = ngx.var.request_body,\n                });\n                if err then\n                    ngx.log(ngx.CRIT, err);\n                    ngx.exit(500);\n                end\n                ngx.say(res);\n            ';\n        }\n    }\n}\n</code></pre>"},{"location":"lua/jsonrpc-batch/#methods","title":"Methods","text":""},{"location":"lua/jsonrpc-batch/#new","title":"new","text":"<p><code>usage:client = jsonrpc_batch:new(options)</code></p> <p>The options argument is a Lua table holding the following keys:</p> <ul> <li><code>max_batch_array_size</code> [Int]</li> </ul> <p>Set limitation to json array size of batch request .   When a request whose json array size is over the limit comes, <code>request</code> method returns a invalid error json.</p> <p>The default value is <code>nil</code> (no limit).</p> <ul> <li><code>allow_single_request</code> [Bool]</li> </ul> <p>This module can accept not only batch requests, but also single requests (no batch requests) . For example, <code>{\"id\":1, \"jsonrpc\": \"2.0\", \"params\": {}, \"method\": \"hoge\"}</code> is a single request.</p> <p>If <code>allow_single_request</code> is set to be <code>false</code>, a single request results to a invalid error json.</p> <p>The default value is <code>true</code>. * <code>before_subrequest</code> [Function <code>function(self, ctx)</code>]</p> <pre><code>Specify the callback function fired just before throw subrequests.  `ctx` argument is a [Context](#Context) Object.\n\nFor example, you can set nginx variable (`ngx.var`) for logging subrequests, and you can manipulate request parameters dynamically.\n</code></pre> <ul> <li> <p><code>after_subrequest</code> [Function <code>function(self, ctx)</code>]</p> <p>Specify the callback function fired just after throw subrequests. <code>ctx</code> argument is a Context Object.</p> <p>For example, we can set nginx variable (<code>ngx.var</code>) for logging subrequest results, and we can manipulate subrequest responses dynamically.</p> </li> </ul>"},{"location":"lua/jsonrpc-batch/#request","title":"request","text":"<pre><code>usage:\nres, err = client:request({\n    path = \"/api\",\n    request = ###jsonrpc request json###,\n})\n</code></pre> <p>Decode request json and separate it, and make subrequest parallely to specified <code>path</code>. It returns response json(<code>res</code>) which is generated by all the subrequest 's response json. <code>err</code> is set error message when lua script occurs an error.</p> <p>It can accept following parameters.</p> <ul> <li> <p><code>request</code> [String] (requried)</p> <p>A request JSON.</p> </li> <li> <p><code>path</code> [String or Function <code>function(self, ctx, req)</code>] (required)</p> <p>Subrequest path like <code>\"/api\"</code>.</p> <p>The type can be Function which decides path for each subrequest dynamically.</p> <p><code>ctx</code> argument is a Context Object.</p> <p><code>req</code> argument is a single request json included by batch request json array. like <code>{\"id\":1, \"jsonrpc\": \"2.0\", \"params\": {\"user_id\": 1}, \"method\": \"getUser\"}</code>.</p> <p>To give one example, we can use this function for separating api endpoints by JSON-RPC method, and we can throw original request path information to subrequest.</p> <p>Following configuration exmaple is that there are two endpoints, and dispatch batch requests to endpoints by jsonrpc method. Besides, endpoints have own API version as path prefix.</p> </li> </ul> <pre><code>    location ~ ^/(\\d+\\.\\d+)/getUser$ {\n        # jsonrpc endpoint 1\n    }\n\n    location ~ ^/(\\d+\\.\\d+)/updateUser$ {\n        # jsonrpc endppoint 2\n    }\n\n    location ~ ^/(\\d+\\.\\d+)/batch$ {\n        set $version $1;\n        lua_need_request_body on;\n        content_by_lua {\n            local res, err = client:batch_request({\n                path = function(self, ctx, req)\n                    return \"/\" .. ngx.var.version  .. \"/\" .. req.method\n                end,\n                request = ngx.var.request_body,\n            });\n            if err then\n              ngx.log(ngx.CRIT, err);\n              ngx.exit(500);\n              return;\n            end\n        };\n    }\n</code></pre> <ul> <li> <p><code>method</code> (string) optional</p> <p>Specify HTTP method using by subrequests. The default value is <code>ngx.HTTP_POST</code>.</p> </li> </ul>"},{"location":"lua/jsonrpc-batch/#object","title":"Object","text":""},{"location":"lua/jsonrpc-batch/#context","title":"Context","text":"<p><code>before_subrequest</code>, <code>after_subrequest</code>, and <code>path</code> callback functions has Context object in arguments. Context object includes information of requests and subrequest responses, so which value it has or not changes by the request proccess.</p> <p>Context object is a lua table, and has following keys.</p> <ul> <li><code>path</code> [String or Function]</li> </ul> <p>Specified by <code>request</code> method as <code>path</code>.</p> <ul> <li><code>method</code> [String]</li> </ul> <p>Specified by <code>request</code> method as <code>method</code>.</p> <ul> <li><code>raw_request</code> [String]</li> </ul> <p>request json specified by <code>request</code> method as <code>request</code>.</p> <ul> <li><code>request</code> [Table]</li> </ul> <p>lua table generated by decoding <code>raw_request</code> json.</p> <ul> <li><code>is_batch</code> [Bool]</li> </ul> <p>The request json is single request or batch request.</p> <ul> <li>subreq_reqs [Table]</li> </ul> <p>The array of subrequests parameters.   This is the arguments of <code>ngx.location.capture_multi</code>.</p> <ul> <li>subreq_resps [Table]</li> </ul> <p>The array of subrequests responses.   This is the response of <code>ngx.location.capture_multi</code>.</p>"},{"location":"lua/jsonrpc-batch/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jsonrpc-batch.</p>"},{"location":"lua/jump-consistent-hash/","title":"jump-consistent-hash: Consistent hash for nginx-module-lua","text":""},{"location":"lua/jump-consistent-hash/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jump-consistent-hash/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jump-consistent-hash\n</code></pre>"},{"location":"lua/jump-consistent-hash/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jump-consistent-hash\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jump-consistent-hash v0.1.4  released on May 09 2016.</p> <p>A simple implementation of this paper.</p>"},{"location":"lua/jump-consistent-hash/#features","title":"Features","text":"<ul> <li>small memory footprint and fast</li> <li>consistence is maintained through servers' updating</li> </ul>"},{"location":"lua/jump-consistent-hash/#usage","title":"Usage","text":"<ul> <li> <p>you can use the basic jchash module to do consistent-hash <pre><code>local jchash = require \"resty.chash.jchash\"\n\nlocal buckets = 8\nlocal id = jchash.hash_short_str(\"random key\", buckets)\n</code></pre></p> </li> <li> <p>or you can use the wrapping module <code>resty.chash.server</code> to consistent-hash a list of servers <pre><code>local jchash_server = require \"resty.chash.server\"\n\nlocal my_servers = {\n    { \"127.0.0.1\", 80, 1},   -- {addr, port, weight} weight can be left out if it's 1\n    { \"127.0.0.2\", 80 },\n    { \"127.0.0.3\", 80 }\n}\n\nlocal cs, err = jchash_server.new(my_servers)\nlocal uri = ngx.var.uri\nlocal svr = cs:lookup(uri)\nlocal addr = svr[1]\nlocal port = svr[2]\n\n-- now you can use the ngx.balancer to do some consistent LB\n\n-- you can even update the servers list, and still maintain the consistence, eg.\nlocal my_new_servers = {\n    { \"127.0.0.2\", 80 },\n    { \"127.0.0.3\", 80 },\n    { \"127.0.0.4\", 80 }\n}\n\ncs:update_servers(my_new_servers)\nsvr = cs:lookup(uri)   -- if the server was 127.0.0.2, then it stays the same,\n                       -- as we only update the 127.0.0.4.\n\n-- what's more, consistence is maintained even the number of servers changes! eg.\nlocal my_less_servers = {\n    { \"127.0.0.2\", 80 },\n    { \"127.0.0.3\", 80 }\n}\ncs:update_servers(my_less_servers)\nsvr = cs:lookup(uri)   -- if the server was 127.0.0.2, then it stays the same,\n                       -- if the server was 127.0.0.4, then it has 50% chance to be\n                       -- 127.0.0.3 or 127.0.0.4\n\ncs:update_servers(my_new_servers)\nsvr = cs:lookup(uri)   -- if the server was 127.0.0.2, then it has 66% chance to stay the same\n</code></pre></p> </li> </ul>"},{"location":"lua/jump-consistent-hash/#test","title":"Test","text":"<pre><code>make test\n</code></pre>"},{"location":"lua/jump-consistent-hash/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jump-consistent-hash.</p>"},{"location":"lua/jwt-verification/","title":"jwt-verification: JWT verification library for nginx-module-lua with JWKS integration","text":""},{"location":"lua/jwt-verification/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jwt-verification/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jwt-verification\n</code></pre>"},{"location":"lua/jwt-verification/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jwt-verification\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jwt-verification v0.7.0  released on Oct 30 2025.</p> <p>JWT verification library for OpenResty.</p> <p> </p>"},{"location":"lua/jwt-verification/#description","title":"Description","text":"<p>JWT verification library for OpenResty.</p> <p>The project's goal is to be a modern and slimmer replacement for lua-resty-jwt with built-in support for JWKS.</p> <p>This project does not provide JWT manipulation or creation features: you can only verify/decrypt tokens.</p>"},{"location":"lua/jwt-verification/#status","title":"Status","text":"<p>Feature complete and fully working.</p> <p>API is stable and breaking changes will follow SEMVER. Will tag 1.0 relatively soon.</p>"},{"location":"lua/jwt-verification/#library-non-goals","title":"Library non-goals","text":"<ul> <li>JWT creation/modification</li> <li>Feature complete for the sake of RFCs completeness.</li> <li>Senseless and unsafe RFCs features (e.g. alg none) won't be implemented.</li> </ul>"},{"location":"lua/jwt-verification/#differences-from-lua-resty-jwt","title":"Differences from lua-resty-jwt","text":"<p>Main differences are: - No JWT manipulation of any kind (you can only decrypt/verify them) - Simpler internal structure reliant on more recent lua-resty-openssl and OpenSSL versions. - Supports different JWE algorithms (see tables above). - Automatic JWT verification given JWKS HTTP endpoint.</p> <p>If any of the points above are a problem, or you need compatibility with older OpenResty versions, I recommend sticking with lua-resty-jwt.</p>"},{"location":"lua/jwt-verification/#types","title":"Types","text":"<p>Types and null checks are provided with extensive use of EmmyLua annotations.</p> <p>IDEs plugin integrations for EmmyLua: - Idea - VSCode</p> <p>The file <code>ngx.d.lua</code> in the project's root provides some <code>ngx</code> stubs.</p>"},{"location":"lua/jwt-verification/#supported-features","title":"Supported features","text":"<ul> <li>JWS verification: with symmetric or asymmetric keys.</li> <li>JWE decryption: with symmetric or asymmetric keys.</li> <li>Asymmetric keys format supported:</li> <li>PEM</li> <li>DER</li> <li>JWK</li> <li>JWT claims validation.</li> <li>Automatic JWKS fetching and JWT validation.</li> <li>optional caching strategies.</li> <li>Nested JWTs (JWS in JWE)</li> </ul>"},{"location":"lua/jwt-verification/#jws-verification","title":"JWS Verification","text":"Claims Implemented alg jku jwk kid x5u x5c x5t x5t#S256 typ cty crit alg Implemented JOSE Implementation Requirements Requirements HS256 Required HS384 Optional HS512 Optional RS256 Recommended RS384 Optional RS512 Optional ES256 Recommended+ ES384 Optional ES512 Optional PS256 Optional PS384 Optional PS512 Optional none Optional EdDSA Deprecated ES256K Optional Ed25519 Optional *OpenSSL 3.0+ Ed448 Optional"},{"location":"lua/jwt-verification/#jwe-decryption","title":"JWE Decryption","text":"Claims Implemented alg enc zip jku jwk kid x5u x5c x5t x5t#S256 typ cty crit kty Implemented JOSE Implementation Requirements EC Recommended+ RSA Required oct Required OKP Optional alg Implemented JOSE Implementation Requirements Requirements RSA1_5 Recommended- RSA-OAEP Recommended+ RSA-OAEP-256 Optional RSA-OAEP-384 Optional RSA-OAEP-512 Optional A128KW Recommended *OpenSSL 3.0+ A192KW Optional *OpenSSL 3.0+ A256KW Recommended *OpenSSL 3.0+ dir Recommended ECDH-ES Recommended+ ECDH-ES+A128KW Recommended *OpenSSL 3.0+ ECDH-ES+A192KW Optional *OpenSSL 3.0+ ECDH-ES+A256KW Recommended *OpenSSL 3.0+ A128GCMKW Optional A192GCMKW Optional A256GCMKW Optional PBES2-HS256+A128KW Optional PBES2-HS384+A192KW Optional PBES2-HS512+A256KW Optional <p>*The first official release of OpenResty including OpenSSL 3.0+ is OpenResty 1.27.1.1 which shipped with OpenSSL 3.0.15 (Yes, the godawful slow OpenSSL 3.0 series...).</p> <p>So, please, go with OpenResty 1.27.1.2 as a minimum, which shipped with OpenSSL 3.4.1.</p> enc Implemented JOSE Implementation Requirements A128CBC-HS256 Required A192CBC-HS384 Optional A256CBC-HS512 Required A128GCM Recommended A192GCM Optional A256GCM Recommended"},{"location":"lua/jwt-verification/#jwks-retrieval-cache-strategies","title":"JWKS retrieval cache strategies","text":"Cache Strategy Implemented no cache local (shared_dict)"},{"location":"lua/jwt-verification/#jwt-verification-usage","title":"JWT verification usage","text":""},{"location":"lua/jwt-verification/#jwtdecode_header_unsafe","title":"jwt.decode_header_unsafe","text":"<p>syntax: header, err = jwt.decode_header_unsafe(token)</p> <p>Read a jwt header and convert it to a lua table.</p> <p>Important: this method does not validate JWT signature! Only use if you need to inspect the token's header without having to perform the full validation.</p> <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE3MTY2NDkwNzJ9._MwFdsBPSyci9iARpoAaulReGcn1q7mKiPZjR2JDvdY\"\nlocal header, err = jwt.decode_header_unsafe(token)\nif not header then\n    return nil, \"malformed jwt: \" .. err\nend\nprint(\"alg: \" .. header.alg) -- alg: HS256\n</code></pre>"},{"location":"lua/jwt-verification/#jwtverify","title":"jwt.verify","text":"<p>syntax: decoded_token, err = jwt.verify(token, secret, options?)</p> <p>Validate a JWS token and convert it to a lua table.</p> <p>The optional parameter <code>options</code> can be passed to configure the token validator. Valid fields are: - <code>valid_signing_algorithms</code> (dict | nil): a dict containing allowed <code>alg</code> claims used to validate the JWT. - <code>typ</code> (string | nil): if non-null, ensure JWT claim <code>typ</code> matches the passed value. - <code>issuer</code> (string | nil): if non-null, ensure JWT claim <code>iss</code> matches the passed value. - <code>audiences</code> (string | table | nil): if non-null, ensure JWT claim <code>aud</code> matches one of the supplied values. - <code>subject</code> (string | nil): if non-null, ensure JWT claim <code>sub</code> matches the passed value. - <code>jwtid</code> (string | nil): if non-null, ensure JWT claim <code>jti</code> matches the passed value. - <code>ignore_not_before</code> (bool): If true, the JWT claim <code>nbf</code> will be ignored. - <code>ignore_expiration</code> (bool): If true, the JWT claim <code>exp</code> will be ignored. - <code>current_unix_timestamp</code> (datetime | nil): the JWT <code>nbf</code> and <code>exp</code> claims will be validated against this timestamp. If null,   will use the current datetime supplied by <code>ngx.time()</code>. - <code>timestamp_skew_seconds</code> (int): How many seconds of leeway can the library use to check token expiration against current   time. Useful when clocks are not always exactly synchronized. Setting this value too high may pose security issues. <p>Default values for <code>options</code> fields: <pre><code>local verify_default_options = {\n    valid_signing_algorithms = {\n        [\"HS256\"]=\"HS256\", [\"HS384\"]=\"HS384\", [\"HS512\"]=\"HS512\",\n        [\"RS256\"]=\"RS256\", [\"RS384\"]=\"RS384\", [\"RS512\"]=\"RS512\",\n        [\"ES256\"]=\"ES256\", [\"ES384\"]=\"ES384\", [\"ES512\"]=\"ES512\",\n        [\"PS256\"]=\"PS256\", [\"PS384\"]=\"PS384\", [\"PS512\"]=\"PS512\",\n        [\"ES256K\"]=\"ES256K\", [\"Ed25519\"]=\"Ed25519\", [\"Ed448\"]=\"Ed448\",\n    },\n    typ = nil,\n    issuer = nil,\n    audiences = nil,\n    subject = nil,\n    jwtid = nil,\n    ignore_not_before = false,\n    ignore_expiration = false,\n    current_unix_timestamp = nil,\n    timestamp_skew_seconds = 1,\n}\n</code></pre></p> <p>Minimal example with symmetric keys: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE3MTY2NTUwMTV9.NuEhIzUuufJgPZ8CmCPnD4Vrw7EnTyWD8bGtYCwuDZ0\"\nlocal decoded_token, err = jwt.verify(token, \"superSecretKey\")\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- HS256\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p> <p>Minimal example with asymmetric keys: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE3MTY2Njg2Mzd9.H6PE-zLizMMqefx8DG4X5glVjyxR9UNT225Tq2yufHhu4k9K0IGttpykjMCG8Ck_4Qt2ezEWIgoiWhSn1rv_zwxe7Pv-B09fDs7h1hbASi5MZ0YVAmK9ID1RCKM_NTBEnPLot_iopKZRj2_J5F7lvXwJDZSzEAFJZdrgjKeBS4saDZAv7SIL9Nk75rdhgY-RgRwsjmTYSksj7eioRJJLHifrMnlQDbdrBD5_Qk5tD6VPcssO-vIVBUAYrYYTa7M7A_v47UH84zDtzNYBbk9NrDbyq5-tYs0lZwNhIX8t-0VAxjuCyrrGZvv8_O01pdi90kQmntFIbaiDiD-1WlGcGA\"\nlocal decoded_token, err = jwt.verify(token, \"-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvXFhNyhFWuWtFSJqfOAw\\np42lLIn9kB9oaciiKgNAYZ8SYw5t9Fo+Zh7IciVijn+cVS2/aoBNg2HhfdYgfpQ/\\nsb6jwbRqFMln2GmG+X2aJ2wXMJ/QfxrPFdO9L36bAEwkubUTYXwgMSm1KqWRN8xX\\n+oBu+dbyzw7iUbrmw0ybzXKZLJvetCvmt0reU5TvdwoczOWFBSKeYnzBrC6hISD8\\n8TYDJ4tiw1EWVOupQGqgel0KjC7iwdIYi7PROn6/1MMnF48zlBbT/7/zORj84Z/y\\nDnmxZu1MQ07kHqXDRYumSfCerg5Xw5vde7Tz8O0TWtaYV3HJXNa0VpN5OI3L4y7P\\nhwIDAQAB\\n-----END PUBLIC KEY-----\")\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- RS256\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p> <p>Examples with custom <code>options</code>: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE3MTY2NTUwMTV9.NuEhIzUuufJgPZ8CmCPnD4Vrw7EnTyWD8bGtYCwuDZ0\"\nlocal decoded_token, err = jwt.verify(token, \"superSecretKey\", {\n    valid_signing_algorithms = {[\"HS256\"]=\"HS256\", [\"HS384\"]=\"HS384\", [\"HS512\"]=\"HS512\"}, -- only allow HS family algs\n    audiences = {\"user\", \"admin\"}, -- `aud` must be one of the following\n    ignore_not_before = true -- ignore `nbf` claim (not recommended)\n})\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- HS256\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p>"},{"location":"lua/jwt-verification/#jwtdecrypt","title":"jwt.decrypt","text":"<p>syntax: decoded_token, err = jwt.decrypt(token, secret, options?)</p> <p>Decrypt and validate a JWE token and convert it to a lua table.</p> <p>The optional parameter <code>options</code> can be passed to configure the token validator. Valid fields are: - <code>valid_encryption_alg_algorithms</code> (dict | nil): a dict containing allowed <code>alg</code> claims used to decrypt the JWT. - <code>valid_encryption_enc_algorithms</code> (dict | nil): a dict containing allowed <code>enc</code> claims used to decrypt the JWT. - <code>typ</code> (string | nil): if non-null, ensure JWT claim <code>typ</code> matches the passed value. - <code>issuer</code> (string | nil): if non-null, ensure JWT claim <code>iss</code> matches the passed value. - <code>audiences</code> (string | table | nil): if non-null, ensure JWT claim <code>aud</code> matches one of the supplied values. - <code>subject</code> (string | nil): if non-null, ensure JWT claim <code>sub</code> matches the passed value. - <code>jwtid</code> (string | nil): if non-null, ensure JWT claim <code>jti</code> matches the passed value. - <code>ignore_not_before</code> (bool): If true, the JWT claim <code>nbf</code> will be ignored. - <code>ignore_expiration</code> (bool): If true, the JWT claim <code>exp</code> will be ignored. - <code>current_unix_timestamp</code> (datetime | nil): the JWT <code>nbf</code> and <code>exp</code> claims will be validated against this timestamp. If null,   will use the current datetime supplied by <code>ngx.time()</code>. - <code>timestamp_skew_seconds</code> (int): How many seconds of leeway can the library use to check token expiration against current   time. Useful when clocks are not always exactly synchronized. Setting this value too high may pose security issues. - <code>allow_nested_jwt</code> (bool): Allows verification of jwts containing another jwt (aka nested jwts or jwt-in-jwt). This is opt-in   as default since the claims to validate are always inside the innermost jwt and WILL NOT be automatically validated. It's up   to you to recursively validate the inner jwts returned as a string in the <code>payload</code> field by this lib. A nested   jwt MUST contain the <code>cty</code> header key set to <code>JWT</code> to be recognized as such. <p>Default values for <code>options</code> fields: <pre><code>local decrypt_default_options = {\n    valid_encryption_alg_algorithms = {\n        [\"RSA-OAEP\"]=\"RSA-OAEP\",\n        [\"RSA-OAEP-256\"]=\"RSA-OAEP-256\", [\"RSA-OAEP-384\"]=\"RSA-OAEP-384\", [\"RSA-OAEP-512\"]=\"RSA-OAEP-512\",\n        [\"A128KW\"]=\"A128KW\", [\"A192KW\"]=\"A192KW\", [\"A256KW\"]=\"A256KW\",\n        [\"dir\"]=\"dir\",\n        [\"ECDH-ES\"]=\"ECDH-ES\",\n        [\"ECDH-ES+A128KW\"]=\"ECDH-ES+A128KW\",\n        [\"ECDH-ES+A192KW\"]=\"ECDH-ES+A192KW\",\n        [\"ECDH-ES+A256KW\"]=\"ECDH-ES+A256KW\",\n    },\n    valid_encryption_enc_algorithms = {\n        [\"A128CBC-HS256\"]=\"A128CBC-HS256\",\n        [\"A192CBC-HS384\"]=\"A192CBC-HS384\",\n        [\"A256CBC-HS512\"]=\"A256CBC-HS512\",\n        [\"A128GCM\"]=\"A128GCM\",\n        [\"A192GCM\"]=\"A192GCM\",\n        [\"A256GCM\"]=\"A256GCM\",\n    },\n    typ = nil,\n    issuer = nil,\n    audiences = nil,\n    subject = nil,\n    jwtid = nil,\n    ignore_not_before = false,\n    ignore_expiration = false,\n    current_unix_timestamp = nil,\n    timestamp_skew_seconds = 1,\n    allow_nested_jwt = false,\n}\n</code></pre></p> <p>Minimal example with symmetric keys: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJBMTI4S1ciLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.zAIq7qVAEO-eCG6gOdd3ld8_IHzeq3UlaWLHF2IDn6nNUuHh5n_i4w.5CM864cgiBgFPwluW4ViRg.mUeX7zHDVNsXhys0XO5S4w.t3yAR_HU0GDTEyCbpRa6BQ\"\nlocal decoded_token, err = jwt.decrypt(token, \"superSecretKey12\")\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- A128KW\nprint(decoded_token.header.enc) -- A128CBC-HS256\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p> <p>Minimal example with asymmetric keys in PEM format: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJFQ0RILUVTK0ExMjhLVyIsImVuYyI6IkEyNTZHQ00iLCJlcGsiOnsieCI6IkFJdkVhSzVKZGl6d1I5ZFMzRUN2Y0dKMGNHWXNFejdpYWJwRUp1bE0tWDAiLCJjcnYiOiJYMjU1MTkiLCJrdHkiOiJPS1AifX0.QFfmPVYjk1PoyhE7elaDgUdUGGeAECLo7jB4ghq_8MIRXV3VKO1yAA.XITF2apHB5roeUsx.08T0gALwkb6Wibr2Og.IJoh3U_tspnMx_mWelRT5g\"\nlocal decoded_token, err = jwt.decrypt(token, \"-----BEGIN PRIVATE KEY-----\\nMC4CAQAwBQYDK2VuBCIEIMCxXl/FEuh3pGo1Z++QRs2vudqkGd63mK0Js0f6y+55\\n-----END PRIVATE KEY-----\", nil)\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- ECDH-ES+A128KW\nprint(decoded_token.header.enc) -- A256GCM\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p> <p>Examples with custom <code>options</code>: <pre><code>local jwt = require(\"resty.jwt-verification\")\n\nlocal token = \"eyJhbGciOiJBMTI4S1ciLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.zAIq7qVAEO-eCG6gOdd3ld8_IHzeq3UlaWLHF2IDn6nNUuHh5n_i4w.5CM864cgiBgFPwluW4ViRg.mUeX7zHDVNsXhys0XO5S4w.t3yAR_HU0GDTEyCbpRa6BQ\"\nlocal decoded_token, err = jwt.decrypt(token, \"superSecretKey12\", {\n    valid_encryption_alg_algorithms = {[\"A128KW\"]=\"A128KW\"}, -- only allow A128KW family algs (requires OpenSSL 3.0+)\n    valid_encryption_enc_algorithms = {[\"A128CBC-HS256\"]=\"A128CBC-HS256\"}, -- only allow A128CBC family encs\n    audiences = {\"user\", \"admin\"}, -- `aud` must be one of the following\n    ignore_not_before = true -- ignore `nbf` claim (not recommended)\n})\nif not decoded_token then\n    return nil, \"invalid jwt: \" .. err\nend\nprint(decoded_token.header.alg) -- A128KW\nprint(decoded_token.header.enc) -- A128CBC-HS256\nprint(decoded_token.payload.foo) -- bar\n</code></pre></p>"},{"location":"lua/jwt-verification/#jwks-verification-usage","title":"JWKS verification usage","text":"<p>The <code>resty.jwt-verification-jwks</code> module implements automatic JWKS retrieval from an HTTP endpoint and subsequent JWT validation with fetched keys.</p> <p>The <code>resty.jwt-verification-jwks-cache-*</code> modules implement optional JWKS caching strategies. Only one caching strategy can be enabled at a time; if none are enabled, the JWKS endpoint will be called once for every JWT to validate.</p>"},{"location":"lua/jwt-verification/#jwksinit","title":"jwks.init","text":"<p>syntax: ok, err = jwks.init(cache_strategy?)</p> <p>Initialize the jwks module and optionally specify a caching strategy.</p> <p>This function must be called only once and preferably in the <code>init_by_lua_file</code> section.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\n-- initalize without cache\nlocal ok, err = jwks.init(nil)\nif not ok then\n    ngx.say(\"Error initializing jwks module: \", err)\nend\n\n-- or ...\n\n-- initalize with local cache based on openresty shared mem dict.\n-- add this in the `http` section of your nginx config: `lua_shared_dict resty_jwt_verification_cache_jwks 10m;`\n-- see https://openresty-reference.readthedocs.io/en/latest/Lua_Nginx_API/#ngxshareddict\nlocal jwks_cache_local = require(\"resty.jwt-verification-jwks-cache-local\")\nlocal ok, err = jwks.init(jwks_cache_local)\nif not ok then\n    ngx.say(\"Error initializing jwks module: \", err)\nend\n</code></pre> <p>You can implement your own cache and pass it in the init method instead. Here's an example how:</p> <pre><code>local my_cache = {}\n\n---Get cached entry string for key.\n---@param key string Cache key.\n---@return string|nil value Return cached result as string if present, nil otherwise.\nfunction my_cache.get(key)\n    -- TODO\nend\n\n---Cache data under key until expiry.\n---@param key string Cache key.\n---@param value string Cache value.\n---@param expiry integer Cache entry expiry in seconds.\n---@return boolean|nil ok true on success\n---@return string|nil err nil on success, error message otherwise.\nfunction my_cache.setex(key, value, expiry)\n    -- TODO\nend\n\nlocal ok, err = jwks.init(my_cache)\nif not ok then\n    ngx.say(\"Error initializing jwks module: \", err)\nend\n</code></pre>"},{"location":"lua/jwt-verification/#jwksset_http_timeouts_ms","title":"jwks.set_http_timeouts_ms","text":"<p>syntax: jwks.set_http_timeouts_ms(connect, send, read)</p> <p>Set HTTP client timeouts in milliseconds used for fetching JWKS.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\njwks.set_http_timeouts_ms(5000, 5000, 5000)\n</code></pre>"},{"location":"lua/jwt-verification/#jwksset_http_ssl_verify","title":"jwks.set_http_ssl_verify","text":"<p>syntax: jwks.set_http_ssl_verify(enabled)</p> <p>Enable/disable TLS verification used by HTTP client for fetching JWKS.</p> <p>By default, all TLS certificates are verified. If the JWKS endpoint is using self-signed certificates, either add the respective root CA to the OS certs store or disable certificates verification with this endpoint (it's unsafe).</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\njwks.set_http_ssl_verify(false)\n</code></pre>"},{"location":"lua/jwt-verification/#jwksset_cache_ttl","title":"jwks.set_cache_ttl","text":"<p>syntax: jwks.set_http_ssl_verify(enabled)</p> <p>Change the default cache TTL. Default value is 12 hours.</p> <p>Note: The cache ttl can only be used when the jwks module has been initialized with a cache. See how to enable caching.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\njwks.set_cache_ttl(2 * 3600) -- 2h\n</code></pre>"},{"location":"lua/jwt-verification/#jwksfetch_jwks","title":"jwks.fetch_jwks","text":"<p>syntax: payload, err = jwks.fetch_jwks(endpoint)</p> <p>Manually fetch JWKS from HTTP endpoint; the returned payload, in case of success, is the HTTP response body as string: No check is performed whatsoever whether the payload contains JWKS or something else.</p> <p>If a caching strategy has been enabled, the endpoint will try to fetch it from the cache first. After a cache miss and successful JWKS retrieval via HTTP, the cache will be updated with the result.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\npayload, err = jwks.fetch_jwks(\"https://www.googleapis.com/oauth2/v3/certs\")\nif payload == nil then\n    print(\"failed fetching JWKS: \", err)\n    return\nend\nprint(payload) -- '{\"keys\":[{\"alg\":\"RS256\",\"e\":\"AQAB\",\"kid\":\"882503a5fd56e9f734dfba5c50d7bf48db284ae9\",\"kty\":\"RSA\",\"n\":\"woRUr445_ODXrFeynz5L208aJkABOKQHEzbfGM_V1ijkYZWZKY0PXKPP_wRKcE4C6OyjDNd5gHh3dF5QsVhVDZCfR9QjTf94o4asngrHzdOcfQ0pZIvzu_vzaVG82VGLM-2rKQp8uz06A6TbUzbIv9wQ8wQpYDIdujNkLqL22Mkb2drPxm9Y9I05PmVdkkvAbu4Q_KRJWxykOigHp-hVBmpYS2P3xuX56gM7ZRcXXJKKUfrGel4nDhSIAAD1wBNcVVgKbb0TYfZmVpRSCji_b6JHjqYhYjUasdotYJzWl7quAFsN_X_4j-cHZ30OS81j--OiIxWpL11y1kcbE0u-Dw\",\"use\":\"sig\"},{\"n\":\"m7GlcF1ExRB4braT7sDnZvlY3wpqX9krkVRqcVA-m43FWFYBtuSpd-lc0EV8R8TO180y0tSgJc7hviI1IBJQlNa7XkjVGhY0ZFUp5rTpC45QbA9Smo4CLa5HQIf-69rkkovjFNMuDQvNiYCgRPLyRjmQbN2uHl4fU3hhf5qFqKTKo7eLCZiEMjrOkTXziA7xJJigUGe-ab8U-AXNH1fnCbejzHEIxL0eUG_4r4xddImOxETDO5T65AQCeqs7vtYos2xq5SLFuaUsithRQ-IMm3OlcVhMjBYt6uvGS6IdMjKon4wThCxEqAEXg0nahiGjnQCW176SNF152__TOjQVwQ\",\"alg\":\"RS256\",\"kty\":\"RSA\",\"use\":\"sig\",\"kid\":\"8e8fc8e556f7a76d08d35829d6f90ae2e12cfd0d\",\"e\":\"AQAB\"}]}'\n</code></pre>"},{"location":"lua/jwt-verification/#jwksverify_jwt_with_jwks","title":"jwks.verify_jwt_with_jwks","text":"<p>syntax: jwt, err = jwks.verify_jwt_with_jwks(jwt_token, jwks_endpoint, jws_options?)</p> <p>Given a signed jwt_token as a string, verify its signature with JWKS provided by the HTTP service found at jwks_endpoint.</p> <p>On success, the verified JWT is returned as a lua table, otherwise nil and an error are returned.</p> <p>The optional parameter <code>jws_options</code> can be passed to configure the token validator when calling jwt.verify after having successfully fetched the JWKS. See jwt.verify respective docs for more info about which options can be passed.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\njwt, err = jwks.verify_jwt_with_jwks(\"&lt;MY_JWT&gt;\", \"http://myservice:8888/.well-known/jwks.json\", nil)\nif jwt == nil then\n    print(\"failed verifying jwt: \", err)\n    return\nend\nprint(jwt.header.alg)\nprint(tostring(jwt.payload))\n</code></pre>"},{"location":"lua/jwt-verification/#jwksdecrypt_jwt_with_jwks","title":"jwks.decrypt_jwt_with_jwks","text":"<p>syntax: jwt, err = jwks.decrypt_jwt_with_jwks(jwt_token, jwks_endpoint, jwe_options?)</p> <p>Given an encrypted jwt_token as a string, decrypt it with JWKS provided by the HTTP service found at jwks_endpoint.</p> <p>On success, the decrypted JWT is returned as a lua table, otherwise nil and an error are returned.</p> <p>The optional parameter <code>jwe_options</code> can be passed to configure the token validator when calling jwt.decrypt after having successfully fetched the JWKS. See jwt.decrypt respective docs for more info about which options can be passed.</p> <pre><code>local jwks = require(\"resty.jwt-verification-jwks\")\n\njwt, err = jwks.decrypt_jwt_with_jwks(\"&lt;MY_JWT&gt;\", \"http://myservice:8888/.well-known/jwks.json\", nil)\nif jwt == nil then\n    print(\"failed decrypting jwt: \", err)\n    return\nend\nprint(jwt.header.alg)\nprint(jwt.header.enc)\nprint(tostring(jwt.payload))\n</code></pre>"},{"location":"lua/jwt-verification/#rfcs-used-as-reference","title":"RFCs used as reference","text":"<ul> <li>RFC 7515 JSON Web Signature (JWS)</li> <li>RFC 7516 JSON Web Encryption (JWE)</li> <li>RFC 7517 JSON Web Key (JWK)</li> <li>RFC 7518 JSON Web Algorithms (JWA)</li> <li>RFC 7519 JSON Web Token (JWT)</li> <li>RFC 7520 Examples of Protecting Content Using JSON Object Signing and Encryption (JOSE)</li> <li>IANA JOSE assignments</li> </ul>"},{"location":"lua/jwt-verification/#run-tests","title":"Run tests","text":""},{"location":"lua/jwt-verification/#setup","title":"Setup","text":"<p>Install test suit: <pre><code>sudo cpan Test::Nginx\n</code></pre></p> <p>Install openresty: see https://openresty.org/en/linux-packages.html</p>"},{"location":"lua/jwt-verification/#run","title":"Run","text":"<pre><code>export PATH=/usr/local/openresty/nginx/sbin:$PATH\nprove -r t\n</code></pre>"},{"location":"lua/jwt-verification/#run-benchmarks","title":"Run benchmarks","text":"<p>The testsuite <code>Test::Nginx</code> has built-in benchmarking integration with weighttp.</p>"},{"location":"lua/jwt-verification/#increase-sysctl-limits","title":"Increase <code>sysctl</code> limits","text":"<p>If you plant to stress test the library, you may need to increase system limits.</p> <pre><code>cat &gt; /etc/sysctl.d/openresty-benchmarks.conf &lt;&lt; EOF\nnet.ipv4.ip_local_port_range=2048 65535\n\nnet.ipv4.tcp_tw_reuse=1\n\nnet.core.netdev_max_backlog=2000\nnet.ipv4.tcp_max_syn_backlog=2048\nEOF\n\n## apply changes\nsudo sysctl -p /etc/sysctl.d/openresty-benchmarks.conf\n</code></pre>"},{"location":"lua/jwt-verification/#launch-tests","title":"Launch tests","text":"<p>I've created some pseudo-real world scenarios inside the <code>benchmarks</code> folder.</p> <pre><code>## for more info about syntax: https://openresty.gitbooks.io/programming-openresty/content/testing/test-modes.html\nexport TEST_NGINX_BENCHMARK='50000 10'\nprove -r ./benchmarks\n</code></pre> <p>By default, only 1 nginx worker and 1 CPU core will be used to perform the benchmarks. To increase the worker limits, change the <code>workers(1);</code> directive inside the <code>.t</code> files and re-run the benchmark.</p>"},{"location":"lua/jwt-verification/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jwt-verification.</p>"},{"location":"lua/jwt/","title":"jwt: JWT For The Great nginx-module-lua","text":""},{"location":"lua/jwt/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/jwt/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-jwt\n</code></pre>"},{"location":"lua/jwt/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-jwt\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-jwt v0.1.11  released on Jul 11 2017.</p> <p>lua-resty-jwt - JWT for ngx_lua and LuaJIT</p> <p>Attention  the hmac lib used here is lua-resty-hmac, not the one in luarocks.</p>"},{"location":"lua/jwt/#status","title":"Status","text":"<p>This library is under active development but is considered production ready.</p>"},{"location":"lua/jwt/#description","title":"Description","text":"<p>This library requires an nginx build with OpenSSL, the ngx_lua module, the LuaJIT 2.0, the lua-resty-hmac, and the lua-resty-string,</p>"},{"location":"lua/jwt/#synopsis","title":"Synopsis","text":"<pre><code>    # nginx.conf:\n\n    server {\n        default_type text/plain;\n        location = /verify {\n            content_by_lua '\n                local cjson = require \"cjson\"\n                local jwt = require \"resty.jwt\"\n\n                local jwt_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\" ..\n                    \".eyJmb28iOiJiYXIifQ\" ..\n                    \".VAoRL1IU0nOguxURF2ZcKR0SGKE1gCbqwyh8u2MLAyY\"\n                local jwt_obj = jwt:verify(\"lua-resty-jwt\", jwt_token)\n                ngx.say(cjson.encode(jwt_obj))\n            ';\n        }\n        location = /sign {\n            content_by_lua '\n                local cjson = require \"cjson\"\n                local jwt = require \"resty.jwt\"\n\n                local jwt_token = jwt:sign(\n                    \"lua-resty-jwt\",\n                    {\n                        header={typ=\"JWT\", alg=\"HS256\"},\n                        payload={foo=\"bar\"}\n                    }\n                )\n                ngx.say(jwt_token)\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/jwt/#methods","title":"Methods","text":"<p>To load this library,</p> <ol> <li>you need to specify this library's path in ngx_lua's lua_package_path directive. For example, <code>lua_package_path \"/path/to/lua-resty-jwt/lib/?.lua;;\";</code>.</li> <li>you use <code>require</code> to load the library into a local Lua variable:</li> </ol> <pre><code>    local jwt = require \"resty.jwt\"\n</code></pre>"},{"location":"lua/jwt/#sign","title":"sign","text":"<p><code>syntax: local jwt_token = jwt:sign(key, table_of_jwt)</code></p> <p>sign a table_of_jwt to a jwt_token.</p> <p>The <code>alg</code> argument specifies which hashing algorithm to use (<code>HS256</code>, <code>HS512</code>, <code>RS256</code>).</p>"},{"location":"lua/jwt/#sample-of-table_of_jwt","title":"sample of table_of_jwt","text":"<pre><code>{\n    \"header\": {\"typ\": \"JWT\", \"alg\": \"HS512\"},\n    \"payload\": {\"foo\": \"bar\"}\n}\n</code></pre>"},{"location":"lua/jwt/#verify","title":"verify","text":"<p><code>syntax: local jwt_obj = jwt:verify(key, jwt_token [, claim_spec [, ...]])</code></p> <p>verify a jwt_token and returns a jwt_obj table.  <code>key</code> can be a pre-shared key (as a string), or a function which takes a single parameter (the value of <code>kid</code> from the header) and returns either the pre-shared key (as a string) for the <code>kid</code> or <code>nil</code> if the <code>kid</code> lookup failed.  This call will fail if you try to specify a function for <code>key</code> and there is no <code>kid</code> existing in the header.</p> <p>See Verification for details on the format of <code>claim_spec</code> parameters.</p>"},{"location":"lua/jwt/#load-verify","title":"load &amp; verify","text":"<pre><code>syntax: local jwt_obj = jwt:load_jwt(jwt_token)\nsyntax: local verified = jwt:verify_jwt_obj(key, jwt_obj [, claim_spec [, ...]])\n</code></pre> <p>verify = load_jwt +  verify_jwt_obj</p> <p>load jwt, check for kid, then verify it with the correct key</p>"},{"location":"lua/jwt/#sample-of-jwt_obj","title":"sample of jwt_obj","text":"<pre><code>{\n    \"raw_header\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\",\n    \"raw_payload: \"eyJmb28iOiJiYXIifQ\",\n    \"signature\": \"wrong-signature\",\n    \"header\": {\"typ\": \"JWT\", \"alg\": \"HS256\"},\n    \"payload\": {\"foo\": \"bar\"},\n    \"verified\": false,\n    \"valid\": true,\n    \"reason\": \"signature mismatched: wrong-signature\"\n}\n</code></pre>"},{"location":"lua/jwt/#sign-jwe","title":"sign-jwe","text":"<p><code>syntax: local jwt_token = jwt:sign(key, table_of_jwt)</code></p> <p>sign a table_of_jwt to a jwt_token.</p> <p>The <code>alg</code> argument specifies which hashing algorithm to use for encrypting key (<code>dir</code>). The <code>enc</code> argument specifies which hashing algorithm to use for encrypting payload (<code>A128CBC-HS256</code>, <code>A256CBC-HS512</code>)</p>"},{"location":"lua/jwt/#sample-of-table_of_jwt_1","title":"sample of table_of_jwt","text":"<pre><code>{\n    \"header\": {\"typ\": \"JWE\", \"alg\": \"dir\", \"enc\":\"A128CBC-HS256\"},\n    \"payload\": {\"foo\": \"bar\"}\n}\n</code></pre>"},{"location":"lua/jwt/#verification","title":"Verification","text":"<p>Both the <code>jwt:load</code> and <code>jwt:verify_jwt_obj</code> functions take, as additional parameters, any number of optional <code>claim_spec</code> parameters.  A <code>claim_spec</code> is simply a lua table of claims and validators.  Each key in the <code>claim_spec</code> table corresponds to a matching key in the payload, and the <code>validator</code> is a function that will be called to determine if the claims are met.</p> <p>The signature of a <code>validator</code> function is:</p> <pre><code>function(val, claim, jwt_json)\n</code></pre> <p>Where <code>val</code> is the value of the claim from the <code>jwt_obj</code> being tested (or nil if it doesn't exist in the object's payload), <code>claim</code> is the name of the claim that is being verified, and <code>jwt_json</code> is a json-serialized representation of the object that is being verified.  If the function has no need of the <code>claim</code> or <code>jwt_json</code>, parameters, they may be left off.</p> <p>A <code>validator</code> function returns either <code>true</code> or <code>false</code>.  Any <code>validator</code> MAY raise an error, and the validation will be treated as a failure, and the error that was raised will be put into the reason field of the resulting object.  If a <code>validator</code> returns nothing (i.e. <code>nil</code>), then the function is treated to have succeeded - under the assumption that it would have raised an error if it would have failed.</p> <p>A special claim named <code>__jwt</code> can be used such that if a <code>validator</code> function exists for it, then the <code>validator</code> will be called with a deep clone of the entire parsed jwt object as the value of <code>val</code>.  This is so that you can write verifications for an entire object that may depend on one or more claims.</p> <p>Multiple <code>claim_spec</code> tables can be specified to the <code>jwt:load</code> and <code>jwt:verify_jwt_obj</code> - and they will be executed in order.  There is no guarantee of the execution order of individual <code>validators</code> within a single <code>claim_spec</code>.  If a <code>claim_spec</code> fails, then any following <code>claim_specs</code> will NOT be executed.</p>"},{"location":"lua/jwt/#sample-claim_spec","title":"sample <code>claim_spec</code>","text":"<pre><code>{\n    sub = function(val) return string.match(\"^[a-z]+$\", val) end,\n    iss = function(val)\n        for _, value in pairs({ \"first\", \"second\" }) do\n            if value == val then return true end\n        end\n        return false\n    end,\n    __jwt = function(val, claim, jwt_json)\n        if val.payload.foo == nil or val.payload.bar == nil then\n            error(\"Need to specify either 'foo' or 'bar'\")\n        end\n    end\n}\n</code></pre>"},{"location":"lua/jwt/#jwt-validators","title":"JWT Validators","text":"<p>A library of helpful <code>validator</code> functions exists at <code>resty.jwt-validators</code>.  You can use this library by including: <pre><code>local validators = require \"resty.jwt-validators\"\n</code></pre></p> <p>The following functions are currently defined in the validator library.  Those marked with \"(opt)\" means that the same function exists named <code>opt_&lt;name&gt;</code> which takes the same parameters.  The \"opt\" version of the function will return <code>true</code> if the key does not exist in the payload of the jwt_object being verified, while the \"non-opt\" version of the function will return false if the key does not exist in the payload of the jwt_object being verified.</p>"},{"location":"lua/jwt/#validatorschain","title":"<code>validators.chain(...)</code>","text":"<p>Returns a validator that chains the given functions together, one after another - as long as they keep passing their checks.</p>"},{"location":"lua/jwt/#validatorsrequiredchain_function","title":"<code>validators.required(chain_function)</code>","text":"<p>Returns a validator that returns <code>false</code> if a value doesn't exist.  If the value exists and a <code>chain_function</code> is specified, then the value of <code>chain_function(val, claim, jwt_json)</code> will be returned, otherwise, <code>true</code> will be returned.  This allows for specifying that a value is both required and it must match some additional check.</p>"},{"location":"lua/jwt/#validatorsrequire_one_ofclaim_keys","title":"<code>validators.require_one_of(claim_keys)</code>","text":"<p>Returns a validator which errors with a message if NONE of the given claim keys exist.  It is expected that this function is used against a full jwt object.  The claim_keys must be a non-empty table of strings.</p>"},{"location":"lua/jwt/#validatorscheckcheck_val-check_function-name-check_type-opt","title":"<code>validators.check(check_val, check_function, name, check_type)</code> (opt)","text":"<p>Returns a validator that checks if the result of calling the given <code>check_function</code> for the tested value and <code>check_val</code> returns true.  The value of <code>check_val</code> and <code>check_function</code> cannot be nil.  The optional <code>name</code> is used for error messages and defaults to \"check_value\".  The optional <code>check_type</code> is used to make sure that the check type matches and defaults to <code>type(check_val)</code>.  The first parameter passed to check_function will never be nil.  If the <code>check_function</code> raises an error, that will be appended to the error message.</p>"},{"location":"lua/jwt/#validatorsequalscheck_val-opt","title":"<code>validators.equals(check_val)</code> (opt)","text":"<p>Returns a validator that checks if a value exactly equals (using <code>==</code>) the given check_value. The value of <code>check_val</code> cannot be nil.</p>"},{"location":"lua/jwt/#validatorsmatchespattern-opt","title":"<code>validators.matches(pattern)</code> (opt)","text":"<p>Returns a validator that checks if a value matches the given pattern (using <code>string.match</code>).  The value of <code>pattern</code> must be a string.</p>"},{"location":"lua/jwt/#validatorsany_ofcheck_values-check_function-name-check_type-table_type-opt","title":"<code>validators.any_of(check_values, check_function, name, check_type, table_type)</code> (opt)","text":"<p>Returns a validator which calls the given <code>check_function</code> for each of the given <code>check_values</code> and the tested value.  If any of these calls return <code>true</code>, then this function returns <code>true</code>.  The value of <code>check_values</code> must be a non-empty table with all the same types, and the value of <code>check_function</code> must not be <code>nil</code>.  The optional <code>name</code> is used for error messages and defaults to \"check_values\".  The optional <code>check_type</code> is used to make sure that the check type matches and defaults to <code>type(check_values[1])</code> - the table type.</p>"},{"location":"lua/jwt/#validatorsequals_any_ofcheck_values-opt","title":"<code>validators.equals_any_of(check_values)</code> (opt)","text":"<p>Returns a validator that checks if a value exactly equals any of the given <code>check_values</code>.</p>"},{"location":"lua/jwt/#validatorsmatches_any_ofpatterns-opt","title":"<code>validators.matches_any_of(patterns)</code> (opt)","text":"<p>Returns a validator that checks if a value matches any of the given <code>patterns</code>.</p>"},{"location":"lua/jwt/#validatorscontains_any_ofcheck_valuesname-opt","title":"<code>validators.contains_any_of(check_values,name)</code> (opt)","text":"<p>Returns a validator that checks if a value of expected type <code>string</code> exists in any of the given <code>check_values</code>.  The value of <code>check_values</code>must be a non-empty table with all the same types.  The optional name is used for error messages and defaults to <code>check_values</code>.</p>"},{"location":"lua/jwt/#validatorsgreater_thancheck_val-opt","title":"<code>validators.greater_than(check_val)</code> (opt)","text":"<p>Returns a validator that checks how a value compares (numerically, using <code>&gt;</code>) to a given <code>check_value</code>.  The value of <code>check_val</code> cannot be <code>nil</code> and must be a number.</p>"},{"location":"lua/jwt/#validatorsgreater_than_or_equalcheck_val-opt","title":"<code>validators.greater_than_or_equal(check_val)</code> (opt)","text":"<p>Returns a validator that checks how a value compares (numerically, using <code>&gt;=</code>) to a given <code>check_value</code>.  The value of <code>check_val</code> cannot be <code>nil</code> and must be a number.</p>"},{"location":"lua/jwt/#validatorsless_thancheck_val-opt","title":"<code>validators.less_than(check_val)</code> (opt)","text":"<p>Returns a validator that checks how a value compares (numerically, using <code>&lt;</code>) to a given <code>check_value</code>.  The value of <code>check_val</code> cannot be <code>nil</code> and must be a number.</p>"},{"location":"lua/jwt/#validatorsless_than_or_equalcheck_val-opt","title":"<code>validators.less_than_or_equal(check_val)</code> (opt)","text":"<p>Returns a validator that checks how a value compares (numerically, using <code>&lt;=</code>) to a given <code>check_value</code>.  The value of <code>check_val</code> cannot be <code>nil</code> and must be a number.</p>"},{"location":"lua/jwt/#validatorsis_not_before-opt","title":"<code>validators.is_not_before()</code> (opt)","text":"<p>Returns a validator that checks if the current time is not before the tested value within the system's leeway.  This means that: <pre><code>val &lt;= (system_clock() + system_leeway).\n</code></pre></p>"},{"location":"lua/jwt/#validatorsis_not_expired-opt","title":"<code>validators.is_not_expired()</code> (opt)","text":"<p>Returns a validator that checks if the current time is not equal to or after the tested value within the system's leeway.  This means that: <pre><code>val &gt; (system_clock() - system_leeway).\n</code></pre></p>"},{"location":"lua/jwt/#validatorsis_at-opt","title":"<code>validators.is_at()</code> (opt)","text":"<p>Returns a validator that checks if the current time is the same as the tested value within the system's leeway.  This means that: <pre><code>val &gt;= (system_clock() - system_leeway) and val &lt;= (system_clock() + system_leeway).\n</code></pre></p>"},{"location":"lua/jwt/#validatorsset_system_leewayleeway","title":"<code>validators.set_system_leeway(leeway)</code>","text":"<p>A function to set the leeway (in seconds) used for <code>is_not_before</code> and <code>is_not_expired</code>.  The default is to use <code>0</code> seconds</p>"},{"location":"lua/jwt/#validatorsset_system_clockclock","title":"<code>validators.set_system_clock(clock)</code>","text":"<p>A function to set the system clock used for <code>is_not_before</code> and <code>is_not_expired</code>.  The default is to use <code>ngx.now</code></p>"},{"location":"lua/jwt/#sample-claim_spec-using-validators","title":"sample <code>claim_spec</code> using validators","text":"<pre><code>local validators = require \"resty.jwt-validators\"\nlocal claim_spec = {\n    sub = validators.opt_matches(\"^[a-z]+$),\n    iss = validators.equals_any_of({ \"first\", \"second\" }),\n    __jwt = validators.require_one_of({ \"foo\", \"bar\" })\n}\n</code></pre>"},{"location":"lua/jwt/#legacytimeframe-options","title":"Legacy/Timeframe options","text":"<p>In order to support code which used previous versions of this library, as well as to simplify specifying timeframe-based <code>claim_specs</code>, you may use in place of any single <code>claim_spec</code> parameter a table of <code>validation_options</code>.  The parameter should be expressed as a key/value table. Each key of the table should be picked from the following list.</p> <p>When using legacy <code>validation_options</code>, you MUST ONLY specify these options.  That is, you cannot mix legacy <code>validation_options</code> with other <code>claim_spec</code> validators.  In order to achieve that, you must specify multiple options to the <code>jwt:load</code>/<code>jwt:verify_jwt_obj</code> functions.</p> <ul> <li> <p><code>lifetime_grace_period</code>: Define the leeway in seconds to account for clock skew between the server that generated the jwt and the server validating it. Value should be zero (<code>0</code>) or a positive integer.</p> <ul> <li> <p>When this validation option is specified, the process will ensure that the jwt contains at least one of the two <code>nbf</code> or <code>exp</code> claim and compare the current clock time against those boundaries. Would the jwt be deemed as expired or not valid yet, verification will fail.</p> </li> <li> <p>When none of the <code>nbf</code> and <code>exp</code> claims can be found, verification will fail.</p> </li> <li> <p><code>nbf</code> and <code>exp</code> claims are expected to be expressed in the jwt as numerical values. Wouldn't that be the case, verification will fail.</p> </li> <li> <p>Specifying this option is equivalent to calling:   <pre><code>validators.set_system_leeway(leeway)\n</code></pre></p> </li> </ul> <p>and specifying as a <code>claim_spec</code>:   <pre><code>{\n  __jwt = validators.require_one_of({ \"nbf\", \"exp\" }),\n  nbf = validators.opt_is_not_before(),\n  exp = validators.opt_is_not_expired()\n}\n</code></pre></p> </li> <li> <p><code>require_nbf_claim</code>: Express if the <code>nbf</code> claim is optional or not. Value should be a boolean.</p> <ul> <li> <p>When this validation option is set to <code>true</code> and no <code>lifetime_grace_period</code> has been specified, a zero (<code>0</code>) leeway is implied.</p> </li> <li> <p>Specifying this option is equivalent to specifying as a <code>claim_spec</code>:   <pre><code>{\n  nbf = validators.is_not_before(),\n}\n</code></pre></p> </li> </ul> </li> <li> <p><code>require_exp_claim</code>: Express if the <code>exp</code> claim is optional or not. Value should be a boolean.</p> <ul> <li> <p>When this validation option is set to <code>true</code> and no <code>lifetime_grace_period</code> has been specified, a zero (<code>0</code>) leeway is implied.</p> </li> <li> <p>Specifying this option is equivalent to specifying as a <code>claim_spec</code>:   <pre><code>{\n  exp = validators.is_not_expired(),\n}\n</code></pre></p> </li> </ul> </li> <li> <p><code>valid_issuers</code>: Whitelist the vetted issuers of the jwt. Value should be a array of strings.</p> <ul> <li> <p>When this validation option is specified, the process will compare the jwt <code>iss</code> claim against the list of valid issuers. Comparison is done in a case sensitive manner. Would the jwt issuer not be found in the whitelist, verification will fail.</p> </li> <li> <p><code>iss</code> claim is expected to be expressed in the jwt as a string. Wouldn't that be the case, verification will fail.</p> </li> <li> <p>Specifying this option is equivalent to specifying as a <code>claim_spec</code>:   <pre><code>{\n  iss = validators.equals_any_of(valid_issuers),\n}\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"lua/jwt/#sample-of-validation_options-usage","title":"sample of validation_options usage","text":"<pre><code>local jwt_obj = jwt:verify(key, jwt_token,\n    {\n        lifetime_grace_period = 120,\n        require_exp_claim = true,\n        valid_issuers = { \"my-trusted-issuer\", \"my-other-trusteed-issuer\" }\n    }\n)\n</code></pre>"},{"location":"lua/jwt/#examples","title":"Examples","text":"<ul> <li>JWT Auth With Query and Cookie</li> <li>JWT Auth With KID and Store Your Key in Redis</li> </ul>"},{"location":"lua/jwt/#testing-with-docker","title":"Testing With Docker","text":"<pre><code>./ci script\n</code></pre>"},{"location":"lua/jwt/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/jwt/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-jwt.</p>"},{"location":"lua/kafka/","title":"kafka: Lua kafka client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/kafka/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/kafka/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-kafka\n</code></pre>"},{"location":"lua/kafka/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-kafka\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-kafka v0.23  released on Nov 03 2023.</p> <p>lua-resty-kafka - Lua kafka client driver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/kafka/#status","title":"Status","text":"<p>This library is still under early development and is still experimental.</p>"},{"location":"lua/kafka/#description","title":"Description","text":"<p>This Lua library is a Kafka client driver for the ngx_lua nginx module:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.9.3 or openresty 1.4.3.7 is required, and unfortunately only LuaJIT supported (<code>--with-luajit</code>).</p> <p>Note for <code>ssl</code> connections at least ngx_lua 0.9.11 or openresty 1.7.4.1 is required, and unfortunately only LuaJIT supported (<code>--with-luajit</code>).</p>"},{"location":"lua/kafka/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua '\n                local cjson = require \"cjson\"\n                local client = require \"resty.kafka.client\"\n                local producer = require \"resty.kafka.producer\"\n\n                local broker_list = {\n                    {\n                        host = \"127.0.0.1\",\n                        port = 9092,\n\n                        -- optional auth\n                        sasl_config = {\n                            mechanism = \"PLAIN\",\n                            user = \"USERNAME\",\n                            password = \"PASSWORD\",\n                        },\n                    },\n                }\n\n                local key = \"key\"\n                local message = \"halo world\"\n\n                -- usually we do not use this library directly\n                local cli = client:new(broker_list)\n                local brokers, partitions = cli:fetch_metadata(\"test\")\n                if not brokers then\n                    ngx.say(\"fetch_metadata failed, err:\", partitions)\n                end\n                ngx.say(\"brokers: \", cjson.encode(brokers), \"; partitions: \", cjson.encode(partitions))\n\n\n                -- sync producer_type\n                local p = producer:new(broker_list)\n\n                local offset, err = p:send(\"test\", key, message)\n                if not offset then\n                    ngx.say(\"send err:\", err)\n                    return\n                end\n                ngx.say(\"send success, offset: \", tonumber(offset))\n\n                -- this is async producer_type and bp will be reused in the whole nginx worker\n                local bp = producer:new(broker_list, { producer_type = \"async\" })\n\n                local ok, err = bp:send(\"test\", key, message)\n                if not ok then\n                    ngx.say(\"send err:\", err)\n                    return\n                end\n\n                ngx.say(\"send success, ok:\", ok)\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/kafka/#modules","title":"Modules","text":""},{"location":"lua/kafka/#restykafkaclient","title":"resty.kafka.client","text":"<p>To load this module, just do this</p> <pre><code>    local client = require \"resty.kafka.client\"\n</code></pre>"},{"location":"lua/kafka/#methods","title":"Methods","text":""},{"location":"lua/kafka/#new","title":"new","text":"<p><code>syntax: c = client:new(broker_list, client_config)</code></p> <p>The <code>broker_list</code> is a list of broker, like the below</p> <p><pre><code>[\n    {\n        \"host\": \"127.0.0.1\",\n        \"port\": 9092,\n\n        // optional auth\n        \"sasl_config\": {\n            //support mechanism: PLAIN\u3001SCRAM-SHA-256\u3001SCRAM-SHA-512\n            \"mechanism\": \"PLAIN\",\n            \"user\": \"USERNAME\",\n            \"password\": \"PASSWORD\"\n        }\n    }\n]\n</code></pre> * <code>sasl_config</code></p> <p>support mechanism: PLAIN\u3001SCRAM-SHA-256\u3001SCRAM-SHA-512.</p> <p>warn:SCRAM-SHA-256\u3001SCRAM-SHA-512 need install lua-resty-jit-uuid and lua-resty-openssl</p> <p>An optional <code>client_config</code> table can be specified. The following options are as follows:</p> <p>client config</p> <ul> <li> <p><code>socket_timeout</code></p> <p>Specifies the network timeout threshold in milliseconds. SHOULD lagrer than the <code>request_timeout</code>.</p> </li> <li> <p><code>keepalive_timeout</code></p> <p>Specifies the maximal idle timeout (in milliseconds) for the keepalive connection.</p> </li> <li> <p><code>keepalive_size</code></p> <p>Specifies the maximal number of connections allowed in the connection pool for per Nginx worker.</p> </li> <li> <p><code>refresh_interval</code></p> <p>Specifies the time to auto refresh the metadata in milliseconds. Then metadata will not auto refresh if is nil.</p> </li> <li> <p><code>ssl</code></p> <p>Specifies if client should use ssl connection. Defaults to false. See: https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake</p> </li> <li> <p><code>ssl_verify</code></p> <p>Specifies if client should perform SSL verification. Defaults to false. See: https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake</p> </li> <li> <p><code>resolver</code></p> <p>Specifies a function to host resolving, which returns a string of IP or <code>nil</code>, to override system default host resolver. Default <code>nil</code>, no resolving performed. Example <code>function(host) if host == \"some_host\" then return \"10.11.12.13\" end end</code></p> </li> </ul>"},{"location":"lua/kafka/#fetch_metadata","title":"fetch_metadata","text":"<p><code>syntax: brokers, partitions = c:fetch_metadata(topic)</code></p> <p>In case of success, return the all brokers and partitions of the <code>topic</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/kafka/#refresh","title":"refresh","text":"<p><code>syntax: brokers, partitions = c:refresh()</code></p> <p>This will refresh the metadata of all topics which have been fetched by <code>fetch_metadata</code>. In case of success, return all brokers and all partitions of all topics. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/kafka/#choose_api_version","title":"choose_api_version","text":"<p><code>syntax: api_version = c:choose_api_version(api_key, min_version, max_version)</code></p> <p>This helps the client to select the correct version of the <code>api_key</code> corresponding to the API.</p> <p>When <code>min_version</code> and <code>max_version</code> are provided, it will act as a limit and the selected versions in the return value will not exceed their limits no matter how high or low the broker supports the API version. When they are not provided, it will follow the range of versions supported by the broker.</p> <p>Tip: The version selection strategy is to choose the maximum version within the allowed range.</p>"},{"location":"lua/kafka/#restykafkaproducer","title":"resty.kafka.producer","text":"<p>To load this module, just do this</p> <pre><code>    local producer = require \"resty.kafka.producer\"\n</code></pre>"},{"location":"lua/kafka/#methods_1","title":"Methods","text":""},{"location":"lua/kafka/#new_1","title":"new","text":"<p><code>syntax: p = producer:new(broker_list, producer_config?, cluster_name?)</code></p> <p>It's recommend to use async producer_type.</p> <p><code>broker_list</code> is the same as in <code>client</code></p> <p>An optional options table can be specified. The following options are as follows:</p> <p><code>socket_timeout</code>, <code>keepalive_timeout</code>, <code>keepalive_size</code>, <code>refresh_interval</code>, <code>ssl</code>, <code>ssl_verify</code>  are the same as in <code>client_config</code></p> <p>producer config, most like in http://kafka.apache.org/documentation.html#producerconfigs</p> <ul> <li> <p><code>producer_type</code></p> <p>Specifies the <code>producer.type</code>. \"async\" or \"sync\"</p> </li> <li> <p><code>request_timeout</code></p> <p>Specifies the <code>request.timeout.ms</code>. Default <code>2000 ms</code></p> </li> <li> <p><code>required_acks</code></p> <p>Specifies the <code>request.required.acks</code>, SHOULD NOT be zero. Default <code>1</code>.</p> </li> <li> <p><code>max_retry</code></p> <p>Specifies the <code>message.send.max.retries</code>. Default <code>3</code>.</p> </li> <li> <p><code>retry_backoff</code></p> <p>Specifies the <code>retry.backoff.ms</code>. Default <code>100</code>.</p> </li> <li> <p><code>api_version</code></p> <p>Specifies the produce API version. Default <code>0</code>. If you use Kafka 0.10.0.0 or higher, <code>api_version</code> can use <code>0</code>, <code>1</code> or <code>2</code>. If you use Kafka 0.9.x, <code>api_version</code> should be <code>0</code> or <code>1</code>. If you use Kafka 0.8.x, <code>api_version</code> should be <code>0</code>.</p> </li> <li> <p><code>partitioner</code></p> <p>Specifies the partitioner that choose partition from key and partition num. <code>syntax: partitioner = function (key, partition_num, correlation_id) end</code>, the correlation_id is an auto increment id in producer. Default partitioner is:</p> <pre><code>local function default_partitioner(key, num, correlation_id)\n    local id = key and crc32(key) or correlation_id\n    -- partition_id is continuous and start from 0\n    return id % num\nend\n</code></pre> </li> </ul> <p>buffer config ( only work <code>producer_type</code> = \"async\" )</p> <ul> <li> <p><code>flush_time</code></p> <p>Specifies the <code>queue.buffering.max.ms</code>. Default <code>1000</code>.</p> </li> <li> <p><code>batch_num</code></p> <p>Specifies the <code>batch.num.messages</code>. Default <code>200</code>.</p> </li> <li> <p><code>batch_size</code></p> <p>Specifies the <code>send.buffer.bytes</code>. Default <code>1M</code>(may reach 2M). Be careful, SHOULD be smaller than the <code>socket.request.max.bytes / 2 - 10k</code> config in kafka server.</p> </li> <li> <p><code>max_buffering</code></p> <p>Specifies the <code>queue.buffering.max.messages</code>. Default <code>50,000</code>.</p> </li> <li> <p><code>error_handle</code></p> <p>Specifies the error handle, handle data when buffer send to kafka error. <code>syntax: error_handle = function (topic, partition_id, message_queue, index, err, retryable) end</code>, the failed messages in the message_queue is like <code>{ key1, msg1, key2, msg2 }</code>, <code>key</code> in the message_queue is empty string <code>\"\"</code> even if orign is <code>nil</code>. <code>index</code> is the message_queue length, should not use <code>#message_queue</code>. when <code>retryable</code> is <code>true</code> that means kafka server surely not committed this messages, you can safely retry to send; and else means maybe, recommend to log to somewhere.</p> </li> <li> <p><code>wait_on_buffer_full</code></p> <p>Specifies whether to wait when the buffer queue is full, Default <code>false</code>. When buffer queue is full, if option passed <code>true</code>,  will use semaphore wait function to block coroutine until timeout or buffer queue has reduced, Otherwise, return \"buffer overflow\" error with <code>false</code>. Notice, it could not be used in those phases which do not support yields, i.e. log phase.</p> </li> <li> <p><code>wait_buffer_timeout</code></p> <p>Specifies the max wait time when buffer is full, Default <code>5</code> seconds.</p> </li> </ul> <p>Not support compression now.</p> <p>The third optional <code>cluster_name</code> specifies the name of the cluster, default <code>1</code> (yeah, it's number). You can Specifies different names when you have two or more kafka clusters. And this only works with <code>async</code> producer_type.</p>"},{"location":"lua/kafka/#send","title":"send","text":"<p><code>syntax: ok, err = p:send(topic, key, message)</code></p> <ol> <li> <p>In sync model</p> <p>In case of success, returns the offset ( cdata: LL ) of the current broker and partition. In case of errors, returns <code>nil</code> with a string describing the error.</p> </li> <li> <p>In async model</p> <p>The <code>message</code> will write to the buffer first. It will send to the kafka server when the buffer exceed the <code>batch_num</code>, or every <code>flush_time</code> flush the buffer.</p> <p>It case of success, returns <code>true</code>. In case of errors, returns <code>nil</code> with a string describing the error (<code>buffer overflow</code>).</p> </li> </ol>"},{"location":"lua/kafka/#offset","title":"offset","text":"<p><code>syntax: sum, details = p:offset()</code></p> <pre><code>Return the sum of all the topic-partition offset (return by the ProduceRequest api);\nand the details of each topic-partition\n</code></pre>"},{"location":"lua/kafka/#flush","title":"flush","text":"<p><code>syntax: ok = p:flush()</code></p> <p>Always return <code>true</code>.</p>"},{"location":"lua/kafka/#restykafkabasic-consumer","title":"resty.kafka.basic-consumer","text":"<p>To load this module, just do this</p> <pre><code>    local bconsumer = require \"resty.kafka.basic-consumer\"\n</code></pre> <p>This module is a minimalist implementation of a consumer, providing the <code>list_offset</code> API for querying by time or getting the start and end offset and the <code>fetch</code> API for getting messages in a topic.</p> <p>In a single call, only the information of a single partition in a single topic can be fetched, and batch fetching is not supported for now. The basic consumer does not support the consumer group related API, so you need to fetch the message after getting the offset through the <code>list_offset</code> API, or your service can manage the offset itself.</p>"},{"location":"lua/kafka/#methods_2","title":"Methods","text":""},{"location":"lua/kafka/#new_2","title":"new","text":"<p><code>syntax: c = bconsumer:new(broker_list, client_config)</code></p> <p>The <code>broker_list</code> is a list of broker, like the below</p> <pre><code>[\n    {\n        \"host\": \"127.0.0.1\",\n        \"port\": 9092,\n\n        // optional auth\n        \"sasl_config\": {\n            \"mechanism\": \"PLAIN\",\n            \"user\": \"USERNAME\",\n            \"password\": \"PASSWORD\"\n        }\n    }\n]\n</code></pre> <p>An optional <code>client_config</code> table can be specified. The following options are as follows:</p> <p>client config</p> <ul> <li> <p><code>socket_timeout</code></p> <p>Specifies the network timeout threshold in milliseconds. SHOULD lagrer than the <code>request_timeout</code>.</p> </li> <li> <p><code>keepalive_timeout</code></p> <p>Specifies the maximal idle timeout (in milliseconds) for the keepalive connection.</p> </li> <li> <p><code>keepalive_size</code></p> <p>Specifies the maximal number of connections allowed in the connection pool for per Nginx worker.</p> </li> <li> <p><code>refresh_interval</code></p> <p>Specifies the time to auto refresh the metadata in milliseconds. Then metadata will not auto refresh if is nil.</p> </li> <li> <p><code>ssl</code></p> <p>Specifies if client should use ssl connection. Defaults to false. See: https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake</p> </li> <li> <p><code>ssl_verify</code></p> <p>Specifies if client should perform SSL verification. Defaults to false. See: https://github.com/openresty/lua-nginx-module#tcpsocksslhandshake</p> </li> <li> <p><code>isolation_level</code>     This setting controls the visibility of transactional records. See: https://kafka.apache.org/protocol.html</p> </li> <li> <p><code>client_rack</code></p> <p>Rack ID of the consumer making this request. See: https://kafka.apache.org/protocol.html</p> </li> </ul>"},{"location":"lua/kafka/#list_offset","title":"list_offset","text":"<p><code>syntax: offset, err = c:list_offset(topic, partition, timestamp)</code></p> <p>The parameter timestamp can be a UNIX timestamp or a constant defined in <code>resty.kafka.protocol.consumer</code>, <code>LIST_OFFSET_TIMESTAMP_LAST</code>, <code>LIST_OFFSET_TIMESTAMP_FIRST</code>, <code>LIST_OFFSET_TIMESTAMP_MAX</code>, used to get the initial and latest offsets, etc., semantics with the ListOffsets API in Apache Kafka. See: https://kafka.apache.org/protocol.html#The_Messages_ListOffsets</p> <p>In case of success, return the offset of the specified case. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/kafka/#fetch","title":"fetch","text":"<p><code>syntax: result, err = c:fetch(topic, partition, offset)</code></p> <p>In case of success, return the following <code>result</code> of the specified case. In case of errors, returns <code>nil</code> with a string describing the error.</p> <p>The <code>result</code> will contain more information such as the messages:</p> <ul> <li> <p><code>records</code></p> <p>The table containing the content of the message.</p> </li> <li> <p><code>errcode</code></p> <p>The error code of Fetch API. See: https://kafka.apache.org/protocol.html#protocol_error_codes</p> </li> <li> <p><code>high_watermark</code></p> <p>The high watermark of Fetch API. See: https://kafka.apache.org/protocol.html#The_Messages_Fetch</p> </li> <li> <p><code>last_stable_offset</code></p> <p>The last stable offset of Fetch API. Content depends on the API version, maybe nil. See: https://kafka.apache.org/protocol.html#The_Messages_Fetch that response API version above v4</p> </li> <li> <p><code>log_start_offset</code></p> <p>The log start offset of Fetch API. Content depends on the API version, maybe nil. See: https://kafka.apache.org/protocol.html#The_Messages_Fetch that response API version above v5</p> </li> <li> <p><code>aborted_transactions</code></p> <p>The aborted transactions of Fetch API. Content depends on the API version, maybe nil. See: https://kafka.apache.org/protocol.html#The_Messages_Fetch that response API version above v4</p> </li> <li> <p><code>preferred_read_replica</code></p> <p>The preferred read replica of Fetch API. Content depends on the API version, maybe nil. See: https://kafka.apache.org/protocol.html#The_Messages_Fetch that response API version above v11</p> </li> </ul>"},{"location":"lua/kafka/#errors","title":"Errors","text":"<p>When you call the modules provided in this library, you may get some errors. Depending on the source, they can be divided into the following categories.</p> <ul> <li> <p>Network errors: such as connection rejected, connection timeout, etc. You need to check the connection status of each service in your environment.</p> </li> <li> <p>Metadata-related errors: such as Metadata or ApiVersion data cannot be retrieved properly; the specified topic or partition does not exist, etc. You need to check the Kafka Broker and client configuration.</p> </li> <li> <p>Error returned by Kafka: sometimes Kafka will include err_code data in the response data, When this problem occurs, the <code>err</code> in the return value looks like this <code>OFFSET_OUT_OF_RANGE</code>, all uppercase characters, and separated by underscores, and in the current library we provide a error list of mappings corresponding to the textual descriptions. To learn more about these errors, see the descriptions in the Kafka documentation.</p> </li> </ul>"},{"location":"lua/kafka/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> <li>the kafka protocol: https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol</li> <li>the lua-resty-redis library</li> <li>the lua-resty-logger-socket library</li> <li>the sarama</li> </ul>"},{"location":"lua/kafka/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-kafka.</p>"},{"location":"lua/libcjson/","title":"libcjson: LuaJIT FFI-based cJSON library for nginx-module-lua","text":""},{"location":"lua/libcjson/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/libcjson/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-libcjson\n</code></pre>"},{"location":"lua/libcjson/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-libcjson\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-libcjson v1.4  released on Jul 04 2016.</p> <p><code>lua-resty-libcjson</code> is a LuaJIT FFI-based cJSON library (tested with OpenResty too).</p>"},{"location":"lua/libcjson/#lua-api","title":"Lua API","text":""},{"location":"lua/libcjson/#mixed-jsondecodevalue","title":"mixed json.decode(value)","text":"<p>Decodes JSON value or structure (JSON array or object), and returns either Lua <code>table</code> or some simple value (e.g. <code>boolean</code>, <code>string</code>, <code>number</code>, <code>nil</code> or <code>json.null</code> (when running in context of OpenResty the <code>json.null</code> is the same as <code>ngx.null</code>).</p>"},{"location":"lua/libcjson/#example","title":"Example","text":"<pre><code>local json = require \"resty.libcjson\"\nlocal obj = json.decode \"{}\"       -- table (with obj.__jsontype == \"object\")\nlocal arr = json.decode \"[]\"       -- table (with arr.__jsontype == \"array\")\nlocal nbr = json.decode \"1\"        -- 1\nlocal bln = json.decode \"true\"     -- true\nlocal str = json.decode '\"test\"'   -- \"test\"\nlocal str = json.decode '\"\"'       -- \"\"\nlocal num = json.decode(5)         -- 5\nlocal num = json.decode(math)      -- math\nlocal num = json.decode(json.null) -- json.null\nlocal nul = json.decode \"null\"     -- json.null\nlocal nul = json.decode \"\"         -- nil\nlocal nul = json.decode(nil)       -- nil\nlocal nul = json.decode()          -- nil\n</code></pre> <p>Nested JSON structures are parsed as nested Lua tables.</p>"},{"location":"lua/libcjson/#string-jsonencodevalue-formatted","title":"string json.encode(value, formatted)","text":"<p>Encodes Lua value or table, and returns equivalent JSON value or structure as a string. Optionally you may pass <code>formatted</code> argument with value of <code>false</code> to get unformatted JSON string as output.</p>"},{"location":"lua/libcjson/#example_1","title":"Example","text":"<pre><code>local json = require \"resty.libcjson\"\nlocal str = json.encode{}                              -- \"[]\"\nlocal str = json.encode(setmetatable({}, json.object)) -- \"{}\"\nlocal str = json.encode(1)                             -- \"1\"\nlocal str = json.encode(1.1)                           -- \"1.100000\"\nlocal str = json.encode \"test\"                         -- '\"test\"'\nlocal str = json.encode \"\"                             -- '\"\"'\nlocal str = json.encode(false)                         -- \"false\"\nlocal str = json.encode(nil)                           -- \"null\"\nlocal str = json.encode(json.null)                     -- \"null\"\nlocal str = json.encode()                              -- \"null\"\nlocal str = json.encode{ a = \"b\" }                     -- '{ \"a\": \"b\" }'\nlocal str = json.encode{ \"a\", b = 1 }                  -- '{ \"1\": \"a\", \"b\": 1 }'\nlocal str = json.encode{ 1, 1.1, \"a\", \"\", false }      -- '[1, 1.100000, \"a\", \"\", false]' \n</code></pre> <p>Nested Lua tables are encoded as nested JSON structures (JSON objects or arrays).</p>"},{"location":"lua/libcjson/#about-json-arrays-and-object-encoding-and-decoding","title":"About JSON Arrays and Object Encoding and Decoding","text":"<p>See this comment: https://github.com/bungle/lua-resty-libcjson/issues/1#issuecomment-38567447.</p>"},{"location":"lua/libcjson/#benchmarks","title":"Benchmarks","text":"<p>About 190 MB citylots.json:</p> <pre><code>## Lua cJSON\nDecoding Time: 5.882825\nEncoding Time: 4.902301\n## lua-resty-libcjson\nDecoding Time: 6.409872\nEncoding Time: (takes forever)\n</code></pre>"},{"location":"lua/libcjson/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-libcjson.</p>"},{"location":"lua/libr3/","title":"libr3: High-performance path dispatching library base on libr3 for nginx-module-lua","text":""},{"location":"lua/libr3/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/libr3/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-libr3\n</code></pre>"},{"location":"lua/libr3/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-libr3\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-libr3 v1.2  released on Sep 30 2019.</p> <p>This is Lua-Openresty implementation library base on FFI for libr3.</p> <p></p>"},{"location":"lua/libr3/#status","title":"Status","text":"<p>This repository is an experimental.</p>"},{"location":"lua/libr3/#synopsis","title":"Synopsis","text":"<pre><code> location / {\n     content_by_lua_block {\n         -- r3 router\n         local r3 = require(\"resty.r3\").new();\n         local encode_json = require(\"cjson.safe\").encode\n\n         function foo(params) -- foo handler\n             ngx.say(\"foo: \", encode_json(params))\n         end\n\n         -- routing\n         r3:get(\"/foo/{id}/{name}\", foo)\n\n         -- don't forget!!!\n         r3:compile()\n\n         -- dispatch\n         local ok = r3:dispatch(\"/foo/a/b\", ngx.req.get_method())\n         if not ok then\n             ngx.exit(404)\n         end\n     }\n }\n</code></pre>"},{"location":"lua/libr3/#methods","title":"Methods","text":""},{"location":"lua/libr3/#new","title":"new","text":"<p><code>syntax: r3, err = r3router:new()</code></p> <p>Creates a r3 object. In case of failures, returns <code>nil</code> and a string describing the error.</p> <p><code>syntax: r3, err = r3router:new(routes)</code></p> <p>The routes is a array table, like <code>{ {...}, {...}, {...} }</code>, Each element in the array is a route, which is a hash table.</p> <p>The attributes of each element may contain these: * <code>path</code>: client request uri. * <code>handler</code>: Lua callback function. * <code>host</code>: optional, client request host, not only supports normal domain name, but also supports wildcard name, both <code>foo.com</code> and <code>*.foo.com</code> are valid. * <code>remote_addr</code>: optional, client remote address like <code>192.168.1.100</code>, and we can use CIDR format, eg <code>192.168.1.0/24</code>. * <code>methods</code>: optional, It's an array table, we can put one or more method names together. Here is the valid method name: \"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\", \"HEAD\", \"OPTIONS\".</p> <p>Example:</p> <pre><code>-- foo handler\nfunction foo(params)\n    ngx.say(\"foo: \", require(\"cjson\").encode(params))\nend\n\nlocal r3route = require \"resty.r3\"\nlocal r3 = r3route.new({\n        {\n            path = [[/foo/{:\\w+}/{:\\w+}\"]],\n            method = {\"GET\"},\n            handler = foo\n        },\n        {\n            path = [[/bar/{:\\w+}/{:\\w+}]],\n            host = \"*.bar.com\",\n            handler = foo\n        },\n        {\n            path = [[/alice/{:\\w+}/{:\\w+}]],\n            remote_addr = \"192.168.1.0/24\",\n            handler = foo\n        },\n        {\n            path = [[/bob/{:\\w+}/{:\\w+}]],\n            method = {\"GET\"},\n            host = \"*.bob.com\",\n            remote_addr = \"192.168.1.0/24\",\n            handler = foo\n        },\n    })\n</code></pre>"},{"location":"lua/libr3/#insert_route","title":"insert_route","text":"<p><code>syntax: r3, err = r3:insert_route(path, callback, opts)</code></p> <ul> <li><code>path</code>: Client request uri.</li> <li><code>callback</code>: Lua callback function.</li> </ul> <p><code>opts</code> is optional argument, it is a Lua table. * <code>method</code>: It's an array table, we can put one or more method names together. * <code>host</code>: optional, client request host, not only supports normal domain name, but also supports wildcard name, both <code>foo.com</code> and <code>*.foo.com</code> are valid. * <code>remote_addr</code>: optional, client remote address like <code>192.168.1.100</code>, and we can use CIDR format, eg <code>192.168.1.0/24</code>.</p> <pre><code>-- route\nlocal function foo(params)\n    ngx.say(\"foo\")\nend\n\nlocal r3route = require \"resty.r3\"\nlocal r3 = r3route.new()\n\nr3:insert_route(\"/a\", foo)\nr3:insert_route(\"/b\", foo, {method = {\"GET\"}})\n</code></pre>"},{"location":"lua/libr3/#add-router","title":"add router","text":"<p>BTW, we can add a router by specifying a lowercase method name.</p> <p>Valid method name list: <code>get</code>, <code>post</code>, <code>put</code>, <code>delete</code>, <code>patch</code>, <code>head</code>, <code>options</code>.</p> <pre><code>-- route\nlocal function foo(params)\n    ngx.say(\"foo\")\nend\n\nr3:get(\"/a\", foo)\nr3:post(\"/b\", foo)\nr3:put(\"/c\", foo)\nr3:delete(\"/d\", foo)\n</code></pre>"},{"location":"lua/libr3/#compile","title":"compile","text":"<p><code>syntax: r3:compile()</code></p> <p>It compiles our route paths into a prefix tree (trie). You must compile after adding all routes, otherwise it may fail to match.</p>"},{"location":"lua/libr3/#dispatch","title":"dispatch","text":"<p><code>syntax: ok = r3:dispatch(path, method)</code></p> <ul> <li><code>path</code>: client request uri.</li> <li><code>method</code>: method name of client request.</li> </ul> <p><code>syntax: ok = r3:dispatch(path, opts)</code></p> <ul> <li><code>path</code>: client request uri.</li> <li><code>opts</code>: a Lua tale<ul> <li><code>method</code>: optional, method name of client request.</li> <li><code>host</code>: optional, client request host, not only supports normal domain name, but also supports wildcard name, both <code>foo.com</code> and <code>*.foo.com</code> are valid.</li> <li><code>remote_addr</code>: optional, client remote address like <code>192.168.1.100</code>, and we can use CIDR format, eg <code>192.168.1.0/24</code>.</li> </ul> </li> </ul> <p>Dispatchs the path to the controller by <code>method</code>, <code>path</code> and <code>host</code>.</p> <pre><code>local ok = r3:dispatch(ngx.var.uri, ngx.req.get_method())\n</code></pre>"},{"location":"lua/libr3/#dispatch2","title":"dispatch2","text":"<p><code>syntax: ok = r3:dispatch2(param_tab, path, method)</code></p> <p><code>syntax: ok = r3:dispatch2(param_tab, path, opts)</code></p> <p>Basically the same as <code>dispatch</code>, support for passing in a <code>table</code> object to store parsing parameters, makes it easier to reuse lua table.</p>"},{"location":"lua/libr3/#ubuntu","title":"Ubuntu","text":"<p>sudo apt-get install check libpcre3 libpcre3-dev build-essential libtool \\     automake autoconf pkg-config</p>"},{"location":"lua/libr3/#centos-7","title":"CentOS 7","text":"<p>sodu yum install gcc gcc-c++ git make automake autoconf pcre pcre-devel \\     libtool pkgconfig    <pre><code>### Compile and install\n</code></pre> sudo make install ```</p>"},{"location":"lua/libr3/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-libr3.</p>"},{"location":"lua/limit-rate/","title":"limit-rate: Lua module for limiting request rate for nginx-module-lua, using the \"token bucket\" method","text":""},{"location":"lua/limit-rate/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/limit-rate/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-limit-rate\n</code></pre>"},{"location":"lua/limit-rate/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-limit-rate\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-limit-rate v0.1  released on Oct 25 2018.</p> <p>lua-resty-limit-rate - Lua module for limiting request rate for OpenResty/ngx_lua, using the \"token bucket\" method.</p>"},{"location":"lua/limit-rate/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    lua_shared_dict my_limit_rate_store 100m;\n    lua_shared_dict my_locks 100k;\n\n    server {\n        location / {\n            access_by_lua_block {\n                local limit_rate = require \"resty.limit.rate\"\n\n                local lim, err = limit_rate.new(\"my_limit_rate_store\", 500, 10, 3, 200, {\n                    lock_enable = true, -- use lua-resty-lock\n                    locks_shdict_name = \"my_locks\",\n                })\n\n                if not lim then\n                    ngx.log(ngx.ERR,\n                            \"failed to instantiate a resty.limit.rate object: \", err)\n                    return ngx.exit(500)\n                end\n\n                -- the following call must be per-request.\n                -- here we use the remote (IP) address as the limiting key\n                local key = ngx.var.binary_remote_addr\n                local delay, err = lim:incoming(key, true)\n                -- local delay, err = lim:take(key, 1, ture)\n                if not delay then\n                    if err == \"rejected\" then\n                        return ngx.exit(503)\n                    end\n                    ngx.log(ngx.ERR, \"failed to take token: \", err)\n                    return ngx.exit(500)\n                end\n\n                if delay &gt;= 0.001 then\n                    -- the 2nd return value holds the current avail tokens number\n                    -- of requests for the specified key\n                    local avail = err\n\n                    ngx.sleep(delay)\n                end\n            }\n\n            # content handler goes here. if it is content_by_lua, then you can\n            # merge the Lua code above in access_by_lua into your content_by_lua's\n            # Lua handler to save a little bit of CPU time.\n        }\n\n        location /take_available {\n            access_by_lua_block {\n                local limit_rate = require \"resty.limit.rate\"\n\n                -- global 20r/s 6000r/5m\n                local lim_global = limit_rate.new(\"my_limit_rate_store\", 100, 6000, 2, nil, {\n                    lock_enable = true,\n                    locks_shdict_name = \"my_locks\",\n                })\n\n                if not lim_global then\n                    return ngx.exit(500)\n                end\n\n                -- single 2r/s 600r/5m\n                local lim_single = limit_rate.new(\"my_limit_rate_store\", 500, 600, 1, nil, {\n                    locks_shdict_name = \"my_locks\",\n                })\n\n                if not lim_single then\n                    return ngx.exit(500)\n                end\n\n                local t0, err = lim_global:take_available(\"__global__\", 1)\n                if not t0 then\n                    ngx.log(ngx.ERR, \"failed to take global: \", err)\n                    return ngx.exit(500)\n                end\n\n                -- here we use the userid as the limiting key\n                local key = ngx.var.arg_userid or \"__single__\"\n\n                local t1, err = lim_single:take_available(key, 1)\n                if not t1 then\n                    ngx.log(ngx.ERR, \"failed to take single: \", err)\n                    return ngx.exit(500)\n                end\n\n                if t0 == 1 then\n                    return -- global bucket is not hungry\n                else\n                    if t1 == 1 then\n                        return -- single bucket is not hungry\n                    else\n                        return ngx.exit(503)\n                    end\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/limit-rate/#description","title":"Description","text":"<p>This module provides APIs to help the OpenResty/ngx_lua user programmers limit request rate using the \"token bucket\" method.</p> <p>If you want to use multiple different instances of this class at once or use one instance of this class with instances of other classes (like resty.limit.conn), then you must use the resty.limit.traffic module to combine them.</p> <p>The main difference between this module and resty.limit.req:</p> <ul> <li>resty.limit.req limit request rate using the \"leaky bucket\" method, this module using the \"token bucket\" method.</li> </ul> <p>The main difference between this module and resty.limit.count:</p> <ul> <li>resty.limit.count offers a straightforward mental model that limit request rate by a fixed number of requests in given time window, but it can sometimes let through twice the number of allowed requests per minute. For example, if our rate limit were 10 requests per minute and a user made 10 requests at 10:00:59, they could make 10 more requests at 10:01:00 because a new counter begins at the start of each minute. In this case, this module able to control more precisely and smoothly.</li> </ul>"},{"location":"lua/limit-rate/#methods","title":"Methods","text":""},{"location":"lua/limit-rate/#new","title":"new","text":"<p>syntax: <code>obj, err = class.new(shdict_name, interval, capacity, quantum?, max_wait?, opts?)</code></p> <p>Instantiates an object of this class. The <code>class</code> value is returned by the call <code>require \"resty.limit.rate\"</code>.</p> <p>The method returns a new token bucket that fills at the rate of <code>quantum</code> number tokens every <code>interval</code>, up to the given maximum <code>capacity</code>. The bucket is initially full.</p> <p>This method takes the following arguments and an optional options table <code>opts</code>:</p> <ul> <li> <p><code>shdict_name</code> is the name of the lua_shared_dict shm zone.</p> <p>It is best practice to use separate shm zones for different kinds of limiters.</p> </li> <li> <p><code>interval</code> is the time passing between adding tokens, in milliseconds.</p> </li> <li> <p><code>capacity</code> is the maximum number of tokens to hold in the bucket.</p> </li> <li> <p><code>quantum</code> is the number of tokens to add to the bucket in one interval, this argument is optional, default <code>1</code>.</p> </li> <li> <p><code>max_wait</code> is the maximum time that we would wait for enough tokens to be added, in milliseconds, this argument is optional, default <code>nil</code>, it means infinity.</p> </li> </ul> <p>The options table accepts the following options:</p> <ul> <li> <p><code>lock_enable</code> When enabled, update shdict state across multiple nginx worker process is atomic; otherwise will have a (small) race-condition window between the \"read-and-then-write\" behavior, default <code>false</code>. See lua-resty-lock for more details.</p> </li> <li> <p><code>locks_shdict_name</code> Specifies the shared dictionary name (created by lua_shared_dict) for the lock, default <code>locks</code>.</p> </li> </ul> <p>On failure, this method returns <code>nil</code> and a string describing the error (like a bad <code>lua_shared_dict</code> name).</p>"},{"location":"lua/limit-rate/#incoming","title":"incoming","text":"<p>syntax: <code>delay, err = obj:take(key, commit)</code></p> <p>Fires a new request incoming event and calculates the delay needed (if any) for the current request upon the specified key or whether the user should reject it immediately.</p> <p>Similar to the take method, but this method only takes one token from the bucket at a time.</p> <p>This method accepts the following arguments:</p> <ul> <li> <p><code>key</code> is the user specified key to limit the rate.</p> <p>Please note that this module does not prefix nor suffix the user key so it is the user's responsibility to ensure the key is unique in the <code>lua_shared_dict</code> shm zone.</p> </li> <li> <p><code>commit</code> is a boolean value. If set to <code>true</code>, the object will actually record the event in the shm zone backing the current object; otherwise it would just be a \"dry run\" (which is the default).</p> </li> </ul>"},{"location":"lua/limit-rate/#set_max_wait","title":"set_max_wait","text":"<p>syntax: <code>obj:set_max_wait(max_wait?)</code></p> <p>Overwrites the <code>max_wait</code> threshold as specified in the new method.</p>"},{"location":"lua/limit-rate/#take","title":"take","text":"<p>syntax: <code>delay, err = obj:take(key, count, commit)</code></p> <p>The method takes count tokens from the bucket without blocking.</p> <p>This method accepts the following arguments:</p> <ul> <li> <p><code>key</code> is the user specified key to limit the rate.</p> <p>Please note that this module does not prefix nor suffix the user key so it is the user's responsibility to ensure the key is unique in the <code>lua_shared_dict</code> shm zone.</p> </li> <li> <p><code>count</code> is the number of tokens to remove.</p> </li> <li> <p><code>commit</code> is a boolean value. If set to <code>true</code>, the object will actually record the event in the shm zone backing the current object; otherwise it would just be a \"dry run\" (which is the default).</p> </li> </ul> <p>The return values depend on the following cases:</p> <ol> <li> <p>If the <code>max_wait</code> vaule specified in the new or set_max_wait method, the method will only take tokens from the bucket if the wait time for the tokens is no greater than <code>max_wait</code>, and returns the time that the caller should wait until the tokens are actually available, otherwise it returns <code>nil</code> and the error string <code>\"rejected\"</code>.</p> </li> <li> <p>If the <code>max_wait</code> vaule is nil, it returns the time that the caller should wait until the tokens are actually available.</p> </li> </ol> <p>In addition, this method also returns a second return value indicating the number of the current avail tokens at this point.</p> <p>If an error occurred (like failures when accessing the <code>lua_shared_dict</code> shm zone backing the current object), then this method returns nil and a string describing the error.</p> <p>This method never sleeps itself. It simply returns a delay if necessary and requires the caller to later invoke the ngx.sleep method to sleep.</p>"},{"location":"lua/limit-rate/#take_available","title":"take_available","text":"<p>syntax: <code>count, err = obj:take_available(key, count)</code></p> <p>The method takes up to count immediately available tokens from the bucket. It returns the number of tokens removed, or zero if there are no available tokens. It does not block.</p> <p>This method accepts the following arguments:</p> <ul> <li> <p><code>key</code> is the user specified key to limit the rate.</p> <p>Please note that this module does not prefix nor suffix the user key so it is the user's responsibility to ensure the key is unique in the <code>lua_shared_dict</code> shm zone.</p> </li> <li> <p><code>count</code> is the number of tokens to remove.</p> </li> </ul> <p>If an error occurred (like failures when accessing the lua_shared_dict shm zone backing the current object), then this method returns nil and a string describing the error.</p>"},{"location":"lua/limit-rate/#uncommit","title":"uncommit","text":"<p>syntax: <code>ok, err = obj:uncommit(key)</code></p> <p>This tries to undo the commit of the <code>incoming</code> call. This is simply an approximation and should be used with care. This method is mainly for being used in the resty.limit.traffic Lua module when combining multiple limiters at the same time.</p>"},{"location":"lua/limit-rate/#limiting-granularity","title":"Limiting Granularity","text":"<p>The limiting works on the granularity of an individual NGINX server instance (including all its worker processes). Thanks to the shm mechanism; we can share state cheaply across all the workers in a single NGINX server instance.</p>"},{"location":"lua/limit-rate/#see-also","title":"See Also","text":"<ul> <li>module resty.limit.req</li> <li>module resty.limit.conn</li> <li>module resty.limit.count</li> <li>module resty.limit.traffic</li> <li>library lua-resty-limit-traffic</li> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>OpenResty: https://openresty.org/</li> </ul>"},{"location":"lua/limit-rate/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-limit-rate.</p>"},{"location":"lua/limit-traffic/","title":"limit-traffic: Lua library for limiting and controlling traffic in nginx-module-lua","text":""},{"location":"lua/limit-traffic/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/limit-traffic/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-limit-traffic\n</code></pre>"},{"location":"lua/limit-traffic/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-limit-traffic\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-limit-traffic v0.9  released on Aug 08 2023.</p> <p>lua-resty-limit-traffic - Lua library for limiting and controlling traffic in OpenResty/ngx_lua</p>"},{"location":"lua/limit-traffic/#status","title":"Status","text":"<p>This library is already usable though still highly experimental.</p> <p>The Lua API is still in flux and may change in the near future without notice.</p>"},{"location":"lua/limit-traffic/#synopsis","title":"Synopsis","text":"<pre><code>## demonstrate the usage of the resty.limit.req module (alone!)\nhttp {\n    lua_shared_dict my_limit_req_store 100m;\n\n    server {\n        location / {\n            access_by_lua_block {\n                -- well, we could put the require() and new() calls in our own Lua\n                -- modules to save overhead. here we put them below just for\n                -- convenience.\n\n                local limit_req = require \"resty.limit.req\"\n\n                -- limit the requests under 200 req/sec with a burst of 100 req/sec,\n                -- that is, we delay requests under 300 req/sec and above 200\n                -- req/sec, and reject any requests exceeding 300 req/sec.\n                local lim, err = limit_req.new(\"my_limit_req_store\", 200, 100)\n                if not lim then\n                    ngx.log(ngx.ERR,\n                            \"failed to instantiate a resty.limit.req object: \", err)\n                    return ngx.exit(500)\n                end\n\n                -- the following call must be per-request.\n                -- here we use the remote (IP) address as the limiting key\n                local key = ngx.var.binary_remote_addr\n                local delay, err = lim:incoming(key, true)\n                if not delay then\n                    if err == \"rejected\" then\n                        return ngx.exit(503)\n                    end\n                    ngx.log(ngx.ERR, \"failed to limit req: \", err)\n                    return ngx.exit(500)\n                end\n\n                if delay &gt;= 0.001 then\n                    -- the 2nd return value holds the number of excess requests\n                    -- per second for the specified key. for example, number 31\n                    -- means the current request rate is at 231 req/sec for the\n                    -- specified key.\n                    local excess = err\n\n                    -- the request exceeding the 200 req/sec but below 300 req/sec,\n                    -- so we intentionally delay it here a bit to conform to the\n                    -- 200 req/sec rate.\n                    ngx.sleep(delay)\n                end\n            }\n\n            # content handler goes here. if it is content_by_lua, then you can\n            # merge the Lua code above in access_by_lua into your content_by_lua's\n            # Lua handler to save a little bit of CPU time.\n        }\n    }\n}\n</code></pre> <pre><code>## demonstrate the usage of the resty.limit.conn module (alone!)\nhttp {\n    lua_shared_dict my_limit_conn_store 100m;\n\n    server {\n        location / {\n            access_by_lua_block {\n                -- well, we could put the require() and new() calls in our own Lua\n                -- modules to save overhead. here we put them below just for\n                -- convenience.\n\n                local limit_conn = require \"resty.limit.conn\"\n\n                -- limit the requests under 200 concurrent requests (normally just\n                -- incoming connections unless protocols like SPDY is used) with\n                -- a burst of 100 extra concurrent requests, that is, we delay\n                -- requests under 300 concurrent connections and above 200\n                -- connections, and reject any new requests exceeding 300\n                -- connections.\n                -- also, we assume a default request time of 0.5 sec, which can be\n                -- dynamically adjusted by the leaving() call in log_by_lua below.\n                local lim, err = limit_conn.new(\"my_limit_conn_store\", 200, 100, 0.5)\n                if not lim then\n                    ngx.log(ngx.ERR,\n                            \"failed to instantiate a resty.limit.conn object: \", err)\n                    return ngx.exit(500)\n                end\n\n                -- the following call must be per-request.\n                -- here we use the remote (IP) address as the limiting key\n                local key = ngx.var.binary_remote_addr\n                local delay, err = lim:incoming(key, true)\n                if not delay then\n                    if err == \"rejected\" then\n                        return ngx.exit(503)\n                    end\n                    ngx.log(ngx.ERR, \"failed to limit req: \", err)\n                    return ngx.exit(500)\n                end\n\n                if lim:is_committed() then\n                    local ctx = ngx.ctx\n                    ctx.limit_conn = lim\n                    ctx.limit_conn_key = key\n                    ctx.limit_conn_delay = delay\n                end\n\n                -- the 2nd return value holds the current concurrency level\n                -- for the specified key.\n                local conn = err\n\n                if delay &gt;= 0.001 then\n                    -- the request exceeding the 200 connections ratio but below\n                    -- 300 connections, so\n                    -- we intentionally delay it here a bit to conform to the\n                    -- 200 connection limit.\n                    -- ngx.log(ngx.WARN, \"delaying\")\n                    ngx.sleep(delay)\n                end\n            }\n\n            # content handler goes here. if it is content_by_lua, then you can\n            # merge the Lua code above in access_by_lua into your\n            # content_by_lua's Lua handler to save a little bit of CPU time.\n\n            log_by_lua_block {\n                local ctx = ngx.ctx\n                local lim = ctx.limit_conn\n                if lim then\n                    -- if you are using an upstream module in the content phase,\n                    -- then you probably want to use $upstream_response_time\n                    -- instead of ($request_time - ctx.limit_conn_delay) below.\n                    local latency = tonumber(ngx.var.request_time) - ctx.limit_conn_delay\n                    local key = ctx.limit_conn_key\n                    assert(key)\n                    local conn, err = lim:leaving(key, latency)\n                    if not conn then\n                        ngx.log(ngx.ERR,\n                                \"failed to record the connection leaving \",\n                                \"request: \", err)\n                        return\n                    end\n                end\n            }\n        }\n    }\n}\n</code></pre> <pre><code>## demonstrate the usage of the resty.limit.traffic module\nhttp {\n    lua_shared_dict my_req_store 100m;\n    lua_shared_dict my_conn_store 100m;\n\n    server {\n        location / {\n            access_by_lua_block {\n                local limit_conn = require \"resty.limit.conn\"\n                local limit_req = require \"resty.limit.req\"\n                local limit_traffic = require \"resty.limit.traffic\"\n\n                local lim1, err = limit_req.new(\"my_req_store\", 300, 200)\n                assert(lim1, err)\n                local lim2, err = limit_req.new(\"my_req_store\", 200, 100)\n                assert(lim2, err)\n                local lim3, err = limit_conn.new(\"my_conn_store\", 1000, 1000, 0.5)\n                assert(lim3, err)\n\n                local limiters = {lim1, lim2, lim3}\n\n                local host = ngx.var.host\n                local client = ngx.var.binary_remote_addr\n                local keys = {host, client, client}\n\n                local states = {}\n\n                local delay, err = limit_traffic.combine(limiters, keys, states)\n                if not delay then\n                    if err == \"rejected\" then\n                        return ngx.exit(503)\n                    end\n                    ngx.log(ngx.ERR, \"failed to limit traffic: \", err)\n                    return ngx.exit(500)\n                end\n\n                if lim3:is_committed() then\n                    local ctx = ngx.ctx\n                    ctx.limit_conn = lim3\n                    ctx.limit_conn_key = keys[3]\n                end\n\n                print(\"sleeping \", delay, \" sec, states: \",\n                      table.concat(states, \", \"))\n\n                if delay &gt;= 0.001 then\n                    ngx.sleep(delay)\n                end\n            }\n\n            # content handler goes here. if it is content_by_lua, then you can\n            # merge the Lua code above in access_by_lua into your\n            # content_by_lua's Lua handler to save a little bit of CPU time.\n\n            log_by_lua_block {\n                local ctx = ngx.ctx\n                local lim = ctx.limit_conn\n                if lim then\n                    -- if you are using an upstream module in the content phase,\n                    -- then you probably want to use $upstream_response_time\n                    -- instead of $request_time below.\n                    local latency = tonumber(ngx.var.request_time)\n                    local key = ctx.limit_conn_key\n                    assert(key)\n                    local conn, err = lim:leaving(key, latency)\n                    if not conn then\n                        ngx.log(ngx.ERR,\n                                \"failed to record the connection leaving \",\n                                \"request: \", err)\n                        return\n                    end\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/limit-traffic/#description","title":"Description","text":"<p>This library provides several Lua modules to help OpenResty/ngx_lua users to control and limit the traffic, either request rate or request concurrency (or both).</p> <ul> <li>resty.limit.req provides request rate limiting and adjustment based on the \"leaky bucket\" method.</li> <li>resty.limit.count provides rate limiting based on a \"fixed window\" implementation since OpenResty 1.13.6.1+.</li> <li>resty.limit.conn provides request concurrency level limiting and adjustment based on extra delays.</li> <li>resty.limit.traffic provides an aggregator to combine multiple instances of the resty.limit.req, resty.limit.count, or resty.limit.conn classes (or all).</li> </ul> <p>Please check out these Lua modules' own documentation for more details.</p> <p>This library provides more flexible alternatives to NGINX's standard modules ngx_limit_req and ngx_limit_conn. For example, the Lua-based limiters provided by this library can be used in any contexts like right before the downstream SSL handshaking procedure (as with <code>ssl_certificate_by_lua</code>) or right before issuing backend requests.</p>"},{"location":"lua/limit-traffic/#nginxconf","title":"nginx.conf","text":"<p>http {     ... } <pre><code>and then load one of the modules provided by this library in Lua. For example,\n\n```lua\nlocal limit_req = require \"resty.limit.req\"\n</code></pre></p>"},{"location":"lua/limit-traffic/#see-also","title":"See Also","text":"<ul> <li>module resty.limit.req</li> <li>module resty.limit.count</li> <li>module resty.limit.conn</li> <li>module resty.limit.traffic</li> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>OpenResty: https://openresty.org/</li> </ul>"},{"location":"lua/limit-traffic/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-limit-traffic.</p>"},{"location":"lua/lmdb/","title":"lmdb: Safe API for manipulating LMDB databases using nginx-module-lua","text":""},{"location":"lua/lmdb/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/lmdb/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-lmdb\n</code></pre>"},{"location":"lua/lmdb/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-lmdb\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-lmdb v1.6.1  released on Jul 09 2025.</p> <p>This module allows OpenResty applications to use the LMDB (Lightning Memory-Mapped Database) inside the Nginx worker process. It has two parts, a core module built into Nginx that controls the life cycle of the database environment, and a FFI based Lua binding for interacting with the module to access/change data.</p>"},{"location":"lua/lmdb/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-lmdb.</p>"},{"location":"lua/locations/","title":"locations: Lua library implementing nginx style location uri matching","text":""},{"location":"lua/locations/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/locations/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-locations\n</code></pre>"},{"location":"lua/locations/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-locations\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-locations v0.2  released on Aug 31 2017.</p> <p>Lua library implementing nginx style 'location' uri matching.</p> <p>As nginx's location feature.  Supports longest prefix matching, regex matching, case insensitive regex matching and exact matches.</p> <ul> <li>Exact matches are checked first, search returns on hit.</li> <li>Prefix matches then checked and the longest match is remembered.</li> <li>If prefix match has <code>^~</code> modifier search returns</li> <li>Regexes are checked in order</li> <li>If no regex match longest prefix is returned</li> </ul>"},{"location":"lua/locations/#overview","title":"Overview","text":"<pre><code>init_by_lua_block {\n        local locations = require(\"resty.locations\")\n        my_locs = locations:new()\n\n        -- Prefix match\n        local ok, err = my_locs:set(\"/foo\", \"/foo\")\n\n        -- exact match\n        local ok, err = my_locs:set(\"/bar\", \"= /bar\", \"=\")\n\n        -- regex match\n        local ok, err = my_locs:set(\"^/baz\", \"~ ^/baz\", \"~\")\n\n        -- case insensitive regex match\n        local ok, err = my_locs:set(\"^/qux\", \"~* ^/qux\", \"~*\")\n\n        -- prefix match, no regex check\n        local ok, err = my_locs:set(\"/bazfoo\", \"^~ /bazfoo\", \"^~\")\n}\n\nserver {\n    listen 80 default_server;\n\n    server_name locations;\n\n    location / {\n        content_by_lua_block {\n            local val, err = my_locs:lookup(ngx.var.uri)\n            if val then\n                -- do something based on val\n                ngx.say(\"Matched: \", val)\n            else\n                if err then\n                    ngx.log(ngx.ERR, err)\n                end\n                ngx.exit(404)\n            end\n        }\n    }\n}\n</code></pre>"},{"location":"lua/locations/#methods","title":"Methods","text":""},{"location":"lua/locations/#new","title":"new","text":"<p><code>syntax: my_locations, err = locations:new(size?)</code></p> <p>Creates a new instance of resty-locations with an optional initial size</p>"},{"location":"lua/locations/#set","title":"set","text":"<p><code>syntax: ok, err = my_locations:set(key, value, modifier?)</code></p> <p>Adds a new key with associated value and modifier, default is an empty string for prefix match.  Keys must be strings.  Returns false and an error message on failure.</p> <p>Modifiers are as the nginx location feature.  * <code>` (empty string) - Prefix match  *</code>=<code>- Exact match  *</code>~<code>- Regex match  *</code>~*<code>- Case insensitive regex match  *</code>^~` - Prefix match, skip regexes</p>"},{"location":"lua/locations/#lookup","title":"lookup","text":"<p><code>syntax: val, err = my_locations:lookup(uri)</code></p> <p>Retrieves value for provided uri.  Returns nil and an error message on failure</p>"},{"location":"lua/locations/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-locations.</p>"},{"location":"lua/lock/","title":"lock: Simple nonblocking lock API for nginx-module-lua based on shared memory dictionaries","text":""},{"location":"lua/lock/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/lock/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-lock\n</code></pre>"},{"location":"lua/lock/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-lock\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-lock v0.9  released on Jun 17 2022.</p> <p>lua-resty-lock - Simple shm-based nonblocking lock API</p>"},{"location":"lua/lock/#status","title":"Status","text":"<p>This library is still under early development and is production ready.</p>"},{"location":"lua/lock/#synopsis","title":"Synopsis","text":"<pre><code>## nginx.conf\n\nhttp {\n    # you do not need the following line if you are using the\n    # OpenResty bundle:\n    lua_shared_dict my_locks 100k;\n\n    server {\n        ...\n\n        location = /t {\n            content_by_lua '\n                local resty_lock = require \"resty.lock\"\n                for i = 1, 2 do\n                    local lock, err = resty_lock:new(\"my_locks\")\n                    if not lock then\n                        ngx.say(\"failed to create lock: \", err)\n                    end\n\n                    local elapsed, err = lock:lock(\"my_key\")\n                    ngx.say(\"lock: \", elapsed, \", \", err)\n\n                    local ok, err = lock:unlock()\n                    if not ok then\n                        ngx.say(\"failed to unlock: \", err)\n                    end\n                    ngx.say(\"unlock: \", ok)\n                end\n            ';\n        }\n    }\n}\n</code></pre>"},{"location":"lua/lock/#description","title":"Description","text":"<p>This library implements a simple mutex lock in a similar way to ngx_proxy module's proxy_cache_lock directive.</p> <p>Under the hood, this library uses ngx_lua module's shared memory dictionaries. The lock waiting is nonblocking because we use stepwise ngx.sleep to poll the lock periodically.</p>"},{"location":"lua/lock/#methods","title":"Methods","text":"<p>To load this library,</p> <ol> <li>you need to specify this library's path in ngx_lua's lua_package_path directive. For example, <code>lua_package_path \"/path/to/lua-resty-lock/lib/?.lua;;\";</code>.</li> <li>you use <code>require</code> to load the library into a local Lua variable:</li> </ol> <pre><code>    local lock = require \"resty.lock\"\n</code></pre>"},{"location":"lua/lock/#new","title":"new","text":"<p><code>syntax: obj, err = lock:new(dict_name)</code></p> <p><code>syntax: obj, err = lock:new(dict_name, opts)</code></p> <p>Creates a new lock object instance by specifying the shared dictionary name (created by lua_shared_dict) and an optional options table <code>opts</code>.</p> <p>In case of failure, returns <code>nil</code> and a string describing the error.</p> <p>The options table accepts the following options:</p> <ul> <li><code>exptime</code> Specifies expiration time (in seconds) for the lock entry in the shared memory dictionary. You can specify up to <code>0.001</code> seconds. Default to 30 (seconds). Even if the invoker does not call <code>unlock</code> or the object holding the lock is not GC'd, the lock will be released after this time. So deadlock won't happen even when the worker process holding the lock crashes.</li> <li><code>timeout</code> Specifies the maximal waiting time (in seconds) for the lock method calls on the current object instance. You can specify up to <code>0.001</code> seconds. Default to 5 (seconds). This option value cannot be bigger than <code>exptime</code>. This timeout is to prevent a lock method call from waiting forever. You can specify <code>0</code> to make the lock method return immediately without waiting if it cannot acquire the lock right away.</li> <li><code>step</code> Specifies the initial step (in seconds) of sleeping when waiting for the lock. Default to <code>0.001</code> (seconds). When the lock method is waiting on a busy lock, it sleeps by steps. The step size is increased by a ratio (specified by the <code>ratio</code> option) until reaching the step size limit (specified by the <code>max_step</code> option).</li> <li><code>ratio</code> Specifies the step increasing ratio. Default to 2, that is, the step size doubles at each waiting iteration.</li> <li><code>max_step</code> Specifies the maximal step size (i.e., sleep interval, in seconds) allowed. See also the <code>step</code> and <code>ratio</code> options). Default to 0.5 (seconds).</li> </ul>"},{"location":"lua/lock/#lock","title":"lock","text":"<p><code>syntax: elapsed, err = obj:lock(key)</code></p> <p>Tries to lock a key across all the Nginx worker processes in the current Nginx server instance. Different keys are different locks.</p> <p>The length of the key string must not be larger than 65535 bytes.</p> <p>Returns the waiting time (in seconds) if the lock is successfully acquired. Otherwise returns <code>nil</code> and a string describing the error.</p> <p>The waiting time is not from the wallclock, but rather is from simply adding up all the waiting \"steps\". A nonzero <code>elapsed</code> return value indicates that someone else has just hold this lock. But a zero return value cannot gurantee that no one else has just acquired and released the lock.</p> <p>When this method is waiting on fetching the lock, no operating system threads will be blocked and the current Lua \"light thread\" will be automatically yielded behind the scene.</p> <p>It is strongly recommended to always call the unlock() method to actively release the lock as soon as possible.</p> <p>If the unlock() method is never called after this method call, the lock will get released when</p> <ol> <li>the current <code>resty.lock</code> object instance is collected automatically by the Lua GC.</li> <li>the <code>exptime</code> for the lock entry is reached.</li> </ol> <p>Common errors for this method call is * \"timeout\" : The timeout threshold specified by the <code>timeout</code> option of the new method is exceeded. * \"locked\" : The current <code>resty.lock</code> object instance is already holding a lock (not necessarily of the same key).</p> <p>Other possible errors are from ngx_lua's shared dictionary API.</p> <p>It is required to create different <code>resty.lock</code> instances for multiple simultaneous locks (i.e., those around different keys).</p>"},{"location":"lua/lock/#unlock","title":"unlock","text":"<p><code>syntax: ok, err = obj:unlock()</code></p> <p>Releases the lock held by the current <code>resty.lock</code> object instance.</p> <p>Returns <code>1</code> on success. Returns <code>nil</code> and a string describing the error otherwise.</p> <p>If you call <code>unlock</code> when no lock is currently held, the error \"unlocked\" will be returned.</p>"},{"location":"lua/lock/#expire","title":"expire","text":"<p><code>syntax: ok, err = obj:expire(timeout)</code></p> <p>Sets the TTL of the lock held by the current <code>resty.lock</code> object instance. This will reset the timeout of the lock to <code>timeout</code> seconds if it is given, otherwise the <code>timeout</code> provided while calling new will be used.</p> <p>Note that the <code>timeout</code> supplied inside this function is independent from the <code>timeout</code> provided while calling new. Calling <code>expire()</code> will not change the <code>timeout</code> value specified inside new and subsequent <code>expire(nil)</code> call will still use the <code>timeout</code> number from new.</p> <p>Returns <code>true</code> on success. Returns <code>nil</code> and a string describing the error otherwise.</p> <p>If you call <code>expire</code> when no lock is currently held, the error \"unlocked\" will be returned.</p>"},{"location":"lua/lock/#for-multiple-lua-light-threads","title":"For Multiple Lua Light Threads","text":"<p>It is always a bad idea to share a single <code>resty.lock</code> object instance across multiple ngx_lua \"light threads\" because the object itself is stateful and is vulnerable to race conditions. It is highly recommended to always allocate a separate <code>resty.lock</code> object instance for each \"light thread\" that needs one.</p>"},{"location":"lua/lock/#for-cache-locks","title":"For Cache Locks","text":"<p>One common use case for this library is avoid the so-called \"dog-pile effect\", that is, to limit concurrent backend queries for the same key when a cache miss happens. This usage is similar to the standard ngx_proxy module's proxy_cache_lock directive.</p> <p>The basic workflow for a cache lock is as follows:</p> <ol> <li>Check the cache for a hit with the key. If a cache miss happens, proceed to step 2.</li> <li>Instantiate a <code>resty.lock</code> object, call the lock method on the key, and check the 1st return value, i.e., the lock waiting time. If it is <code>nil</code>, handle the error; otherwise proceed to step 3.</li> <li>Check the cache again for a hit. If it is still a miss, proceed to step 4; otherwise release the lock by calling unlock and then return the cached value.</li> <li>Query the backend (the data source) for the value, put the result into the cache, and then release the lock currently held by calling unlock.</li> </ol> <p>Below is a kinda complete code example that demonstrates the idea.</p> <pre><code>    local resty_lock = require \"resty.lock\"\n    local cache = ngx.shared.my_cache\n\n    -- step 1:\n    local val, err = cache:get(key)\n    if val then\n        ngx.say(\"result: \", val)\n        return\n    end\n\n    if err then\n        return fail(\"failed to get key from shm: \", err)\n    end\n\n    -- cache miss!\n    -- step 2:\n    local lock, err = resty_lock:new(\"my_locks\")\n    if not lock then\n        return fail(\"failed to create lock: \", err)\n    end\n\n    local elapsed, err = lock:lock(key)\n    if not elapsed then\n        return fail(\"failed to acquire the lock: \", err)\n    end\n\n    -- lock successfully acquired!\n\n    -- step 3:\n    -- someone might have already put the value into the cache\n    -- so we check it here again:\n    val, err = cache:get(key)\n    if val then\n        local ok, err = lock:unlock()\n        if not ok then\n            return fail(\"failed to unlock: \", err)\n        end\n\n        ngx.say(\"result: \", val)\n        return\n    end\n\n    --- step 4:\n    local val = fetch_redis(key)\n    if not val then\n        local ok, err = lock:unlock()\n        if not ok then\n            return fail(\"failed to unlock: \", err)\n        end\n\n        -- FIXME: we should handle the backend miss more carefully\n        -- here, like inserting a stub value into the cache.\n\n        ngx.say(\"no value found\")\n        return\n    end\n\n    -- update the shm cache with the newly fetched value\n    local ok, err = cache:set(key, val, 1)\n    if not ok then\n        local ok, err = lock:unlock()\n        if not ok then\n            return fail(\"failed to unlock: \", err)\n        end\n\n        return fail(\"failed to update shm cache: \", err)\n    end\n\n    local ok, err = lock:unlock()\n    if not ok then\n        return fail(\"failed to unlock: \", err)\n    end\n\n    ngx.say(\"result: \", val)\n</code></pre> <p>Here we assume that we use the ngx_lua shared memory dictionary to cache the Redis query results and we have the following configurations in <code>nginx.conf</code>:</p> <pre><code>    # you may want to change the dictionary size for your cases.\n    lua_shared_dict my_cache 10m;\n    lua_shared_dict my_locks 1m;\n</code></pre> <p>The <code>my_cache</code> dictionary is for the data cache while the <code>my_locks</code> dictionary is for <code>resty.lock</code> itself.</p> <p>Several important things to note in the example above:</p> <ol> <li>You need to release the lock as soon as possible, even when some other unrelated errors happen.</li> <li>You need to update the cache with the result got from the backend before releasing the lock so other threads already waiting on the lock can get cached value when they get the lock afterwards.</li> <li>When the backend returns no value at all, we should handle the case carefully by inserting some stub value into the cache.</li> </ol>"},{"location":"lua/lock/#limitations","title":"Limitations","text":"<p>Some of this library's API functions may yield. So do not call those functions in <code>ngx_lua</code> module contexts where yielding is not supported (yet), like <code>init_by_lua*</code>, <code>init_worker_by_lua*</code>, <code>header_filter_by_lua*</code>, <code>body_filter_by_lua*</code>, <code>balancer_by_lua*</code>, and <code>log_by_lua*</code>.</p>"},{"location":"lua/lock/#prerequisites","title":"Prerequisites","text":"<ul> <li>LuaJIT 2.0+</li> <li>ngx_lua 0.8.10+</li> </ul>"},{"location":"lua/lock/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>OpenResty: http://openresty.org</li> </ul>"},{"location":"lua/lock/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-lock.</p>"},{"location":"lua/logger-socket/","title":"logger-socket: Raw-socket-based Logger Library for NGINX (based on nginx-module-lua)","text":""},{"location":"lua/logger-socket/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/logger-socket/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-logger-socket\n</code></pre>"},{"location":"lua/logger-socket/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-logger-socket\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-logger-socket v0.1  released on Feb 18 2015.</p> <p>lua-resty-logger-socket - nonblocking remote access logging for Nginx</p>"},{"location":"lua/logger-socket/#status","title":"Status","text":"<p>This library is still experimental and under early development.</p>"},{"location":"lua/logger-socket/#description","title":"Description","text":"<p>This lua library is a remote logging module for ngx_lua:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>This is aimed to replace Nginx's standard ngx_http_log_module to push access logs to a remote server via an nonblocking socket. A common remote log server supporting sockets is syslog-ng.</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p>"},{"location":"lua/logger-socket/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location / {\n            log_by_lua '\n                local logger = require \"resty.logger.socket\"\n                if not logger.initted() then\n                    local ok, err = logger.init{\n                        host = 'xxx',\n                        port = 1234,\n                        flush_limit = 1234,\n                        drop_limit = 5678,\n                    }\n                    if not ok then\n                        ngx.log(ngx.ERR, \"failed to initialize the logger: \",\n                                err)\n                        return\n                    end\n                end\n\n                -- construct the custom access log message in\n                -- the Lua variable \"msg\"\n\n                local bytes, err = logger.log(msg)\n                if err then\n                    ngx.log(ngx.ERR, \"failed to log message: \", err)\n                    return\n                end\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/logger-socket/#methods","title":"Methods","text":"<p>This logger module is designed to be shared inside an Nginx worker process by all the requests. So currently only one remote log server is supported. We may support multiple log server sharding in the future.</p>"},{"location":"lua/logger-socket/#init","title":"init","text":"<p><code>syntax: ok, err = logger.init(user_config)</code></p> <p>Initialize logger with user configurations. This logger must be initted before use. If you do not initialize the logger, you will get an error.</p> <p>Available user configurations are listed as follows:</p> <ul> <li> <p><code>flush_limit</code></p> <p>If the buffered messages' size plus the current message size reaches (<code>&gt;=</code>) this limit (in bytes), the buffered log messages will be written to log server. Default to 4096 (4KB).</p> </li> <li> <p><code>drop_limit</code></p> <p>If the buffered messages' size plus the current message size is larger than this limit (in bytes), the current log message will be dropped because of limited buffer size. Default drop_limit is 1048576 (1MB).</p> </li> <li> <p><code>timeout</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the connect method. Default value is 1000 (1 sec).</p> </li> <li> <p><code>host</code></p> <p>log server host.</p> </li> <li> <p><code>port</code></p> <p>log server port number.</p> </li> <li> <p><code>path</code></p> <p>If the log server uses a stream-typed unix domain socket, <code>path</code> is the socket file path. Note that host/port and path cannot both be empty. At least one must be supplied.</p> </li> <li> <p><code>max_retry_times</code></p> <p>Max number of retry times after a connect to a log server failed or send log messages to a log server failed.</p> </li> <li> <p><code>retry_interval</code></p> <p>The time delay (in ms) before retry to connect to a log server or retry to send log messages to a log server, default to 100 (0.1s).</p> </li> <li> <p><code>pool_size</code></p> <p>Keepalive pool size used by sock:keepalive. Default to 10.</p> </li> <li> <p><code>max_buffer_reuse</code></p> <p>Max number of reuse times of internal logging buffer before creating a new one (to prevent memory leak).</p> </li> <li> <p><code>periodic_flush</code></p> <p>Periodic flush interval (in seconds). Set to <code>nil</code> to turn off this feature.</p> </li> <li> <p><code>ssl</code></p> <p>Boolean, enable or disable connecting via SSL. Default to false.</p> </li> <li> <p><code>ssl_verify</code></p> <p>Boolean, enable or disable verifying host and certificate match. Default to true.</p> </li> <li> <p><code>sni_host</code></p> <p>Set the hostname to send in SNI and to use when verifying certificate match.</p> </li> </ul>"},{"location":"lua/logger-socket/#initted","title":"initted","text":"<p><code>syntax: initted = logger.initted()</code></p> <p>Get a boolean value indicating whether this module has been initted (by calling the init method).</p>"},{"location":"lua/logger-socket/#log","title":"log","text":"<p><code>syntax: bytes, err = logger.log(msg)</code></p> <p>Log a message. By default, the log message will be buffered in the logger module until <code>flush_limit</code> is reached in which case the logger will flush all the buffered messages to remote log server via a socket. <code>bytes</code> is the number of bytes that successfully buffered in the logger. If <code>bytes</code> is nil, <code>err</code> is a string describing what kind of error happens this time. If bytes is not nil, then <code>err</code> is a previous error message. <code>err</code> can be nil when <code>bytes</code> is not nil.</p>"},{"location":"lua/logger-socket/#flush","title":"flush","text":"<p><code>syntax: bytes, err = logger.flush()</code></p> <p>Flushes any buffered messages out to remote immediately. Usually you do not need to call this manually because flushing happens automatically when the buffer is full.</p>"},{"location":"lua/logger-socket/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-logger-socket.</p>"},{"location":"lua/lrucache/","title":"lrucache: Lua-land LRU Cache based on LuaJIT FFI","text":""},{"location":"lua/lrucache/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/lrucache/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-lrucache\n</code></pre>"},{"location":"lua/lrucache/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-lrucache\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-lrucache v0.15  released on Oct 10 2024.</p> <p>lua-resty-lrucache - Lua-land LRU cache based on the LuaJIT FFI.</p>"},{"location":"lua/lrucache/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/lrucache/#synopsis","title":"Synopsis","text":"<pre><code>-- file myapp.lua: example \"myapp\" module\n\nlocal _M = {}\n\n-- alternatively: local lrucache = require \"resty.lrucache.pureffi\"\nlocal lrucache = require \"resty.lrucache\"\n\n-- we need to initialize the cache on the lua module level so that\n-- it can be shared by all the requests served by each nginx worker process:\nlocal c, err = lrucache.new(200)  -- allow up to 200 items in the cache\nif not c then\n    error(\"failed to create the cache: \" .. (err or \"unknown\"))\nend\n\nfunction _M.go()\n    c:set(\"dog\", 32)\n    c:set(\"cat\", 56)\n    ngx.say(\"dog: \", c:get(\"dog\"))\n    ngx.say(\"cat: \", c:get(\"cat\"))\n\n    c:set(\"dog\", { age = 10 }, 0.1)  -- expire in 0.1 sec\n    c:delete(\"dog\")\n\n    c:flush_all()  -- flush all the cached data\nend\n\nreturn _M\n</code></pre> <pre><code>## nginx.conf\n\nhttp {\n    # only if not using an official OpenResty release\n    server {\n        listen 8080;\n\n        location = /t {\n            content_by_lua_block {\n                require(\"myapp\").go()\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/lrucache/#description","title":"Description","text":"<p>This library implements a simple LRU cache for OpenResty and the ngx_lua module.</p> <p>This cache also supports expiration time.</p> <p>The LRU cache resides completely in the Lua VM and is subject to Lua GC. As such, do not expect it to get shared across the OS process boundary. The upside is that you can cache arbitrary complex Lua values (such as deep nested Lua tables) without the overhead of serialization (as with <code>ngx_lua</code>'s shared dictionary API). The downside is that your cache is always limited to the current OS process (i.e. the current Nginx worker process). It does not really make much sense to use this library in the context of init_by_lua because the cache will not get shared by any of the worker processes (unless you just want to \"warm up\" the cache with predefined items which will get inherited by the workers via <code>fork()</code>).</p> <p>This library offers two different implementations in the form of two classes: <code>resty.lrucache</code> and <code>resty.lrucache.pureffi</code>. Both implement the same API. The only difference is that the latter is a pure FFI implementation that also implements an FFI-based hash table for the cache lookup, while the former uses native Lua tables.</p> <p>If the cache hit rate is relatively high, you should use the <code>resty.lrucache</code> class which is faster than <code>resty.lrucache.pureffi</code>.</p> <p>However, if the cache hit rate is relatively low and there can be a lot of variations of keys inserted into and removed from the cache, then you should use the <code>resty.lrucache.pureffi</code> instead, because Lua tables are not good at removing keys frequently. You would likely see the <code>resizetab</code> function call in the LuaJIT runtime being very hot in on-CPU flame graphs if you use the <code>resty.lrucache</code> class instead of <code>resty.lrucache.pureffi</code> in such a use case.</p>"},{"location":"lua/lrucache/#methods","title":"Methods","text":"<p>To load this library,</p> <ol> <li>use an official OpenResty release or follow the    Installation instructions.</li> <li>use <code>require</code> to load the library into a local Lua variable:</li> </ol> <pre><code>local lrucache = require \"resty.lrucache\"\n</code></pre> <p>or</p> <pre><code>local lrucache = require \"resty.lrucache.pureffi\"\n</code></pre>"},{"location":"lua/lrucache/#new","title":"new","text":"<p><code>syntax: cache, err = lrucache.new(max_items [, load_factor])</code></p> <p>Creates a new cache instance. Upon failure, returns <code>nil</code> and a string describing the error.</p> <p>The <code>max_items</code> argument specifies the maximal number of items this cache can hold.</p> <p>The <code>load-factor</code> argument designates the \"load factor\" of the FFI-based hash-table used internally by <code>resty.lrucache.pureffi</code>; the default value is 0.5 (i.e. 50%); if the load factor is specified, it will be clamped to the range of <code>[0.1, 1]</code> (i.e. if load factor is greater than 1, it will be saturated to 1; likewise, if load-factor is smaller than <code>0.1</code>, it will be clamped to <code>0.1</code>). This argument is only meaningful for <code>resty.lrucache.pureffi</code>.</p>"},{"location":"lua/lrucache/#set","title":"set","text":"<p><code>syntax: cache:set(key, value, ttl?, flags?)</code></p> <p>Sets a key with a value and an expiration time.</p> <p>When the cache is full, the cache will automatically evict the least recently used item.</p> <p>The optional <code>ttl</code> argument specifies the expiration time. The time value is in seconds, but you can also specify the fraction number part (e.g. <code>0.25</code>). A nil <code>ttl</code> argument means the value would never expire (which is the default).</p> <p>The optional <code>flags</code> argument specifies a user flags value associated with the item to be stored. It can be retrieved later with the item. The user flags are stored as an unsigned 32-bit integer internally, and thus must be specified as a Lua number. If not specified, flags will have a default value of <code>0</code>. This argument was added in the <code>v0.10</code> release.</p>"},{"location":"lua/lrucache/#get","title":"get","text":"<p><code>syntax: data, stale_data, flags = cache:get(key)</code></p> <p>Fetches a value with the key. If the key does not exist in the cache or has already expired, <code>nil</code> will be returned.</p> <p>Starting from <code>v0.03</code>, the stale data is also returned as the second return value if available.</p> <p>Starting from <code>v0.10</code>, the user flags value associated with the stored item is also returned as the third return value. If no user flags were given to an item, its default flags will be <code>0</code>.</p>"},{"location":"lua/lrucache/#delete","title":"delete","text":"<p><code>syntax: cache:delete(key)</code></p> <p>Removes an item specified by the key from the cache.</p>"},{"location":"lua/lrucache/#count","title":"count","text":"<p><code>syntax: count = cache:count()</code></p> <p>Returns the number of items currently stored in the cache including expired items if any.</p> <p>The returned <code>count</code> value will always be greater or equal to 0 and smaller than or equal to the <code>size</code> argument given to <code>cache:new</code>.</p> <p>This method was added in the <code>v0.10</code> release.</p>"},{"location":"lua/lrucache/#capacity","title":"capacity","text":"<p><code>syntax: size = cache:capacity()</code></p> <p>Returns the maximum number of items the cache can hold. The return value is the same as the <code>size</code> argument given to <code>cache:new</code> when the cache was created.</p> <p>This method was added in the <code>v0.10</code> release.</p>"},{"location":"lua/lrucache/#get_keys","title":"get_keys","text":"<p><code>syntax: keys = cache:get_keys(max_count?, res?)</code></p> <p>Fetch the list of keys currently inside the cache up to <code>max_count</code>. The keys will be ordered in MRU fashion (Most-Recently-Used keys first).</p> <p>This function returns a Lua (array) table (with integer keys) containing the keys.</p> <p>When <code>max_count</code> is <code>nil</code> or <code>0</code>, all keys (if any) will be returned.</p> <p>When provided with a <code>res</code> table argument, this function will not allocate a table and will instead insert the keys in <code>res</code>, along with a trailing <code>nil</code> value.</p> <p>This method was added in the <code>v0.10</code> release.</p>"},{"location":"lua/lrucache/#flush_all","title":"flush_all","text":"<p><code>syntax: cache:flush_all()</code></p> <p>Flushes all the existing data (if any) in the current cache instance. This is an <code>O(1)</code> operation and should be much faster than creating a brand new cache instance.</p> <p>Note however that the <code>flush_all()</code> method of <code>resty.lrucache.pureffi</code> is an <code>O(n)</code> operation.</p>"},{"location":"lua/lrucache/#prerequisites","title":"Prerequisites","text":"<ul> <li>LuaJIT 2.0+</li> <li>ngx_lua 0.8.10+</li> </ul>"},{"location":"lua/lrucache/#nginxconf","title":"nginx.conf","text":"<pre><code>http {\n    ...\n}\n</code></pre> <p><code>and then load the library in Lua:</code>lua local lrucache = require \"resty.lrucache\" ```</p>"},{"location":"lua/lrucache/#see-also","title":"See Also","text":"<ul> <li>OpenResty: https://openresty.org</li> <li>the ngx_http_lua module: https://github.com/openresty/lua-nginx-module</li> <li>the ngx_stream_lua module: https://github.com/openresty/stream-lua-nginx-module</li> <li>the lua-resty-core library: https://github.com/openresty/lua-resty-core</li> </ul>"},{"location":"lua/lrucache/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-lrucache.</p>"},{"location":"lua/macaroons/","title":"macaroons: LuaJIT FFI Bindings to libmacaroons \u2013 Macaroons are flexible authorization credentials that support decentralized delegation, attenuation, and verification","text":""},{"location":"lua/macaroons/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/macaroons/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-macaroons\n</code></pre>"},{"location":"lua/macaroons/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-macaroons\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-macaroons v1.0  released on Jul 06 2016.</p> <p>LuaJIT FFI Bindings to libmacaroons \u2013 Macaroons are flexible authorization credentials that support decentralized delegation, attenuation, and verification.</p>"},{"location":"lua/macaroons/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-macaroons.</p>"},{"location":"lua/mail/","title":"mail: A high-level, easy to use, and non-blocking email and SMTP library for nginx-module-lua","text":""},{"location":"lua/mail/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/mail/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-mail\n</code></pre>"},{"location":"lua/mail/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-mail\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-mail v1.1.0  released on Sep 23 2023.</p> <p></p> <p>A high-level, easy to use, and non-blocking email and SMTP library for OpenResty.</p>"},{"location":"lua/mail/#features","title":"Features","text":"<ul> <li>SMTP authentication, STARTTLS, and SSL support.</li> <li>Multipart plain text and HTML message bodies.</li> <li>From, To, Cc, Bcc, Reply-To, and Subject fields (custom headers also supported).</li> <li>Email addresses in \"test@example.com\" and \"Name &lt;test@example.com&gt;\" formats.</li> <li>File attachments.</li> </ul>"},{"location":"lua/mail/#usage","title":"Usage","text":"<pre><code>local mail = require \"resty.mail\"\n\nlocal mailer, err = mail.new({\n  host = \"smtp.gmail.com\",\n  port = 587,\n  starttls = true,\n  username = \"example@gmail.com\",\n  password = \"password\",\n})\nif err then\n  ngx.log(ngx.ERR, \"mail.new error: \", err)\n  return ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\nend\n\nlocal ok, err = mailer:send({\n  from = \"Master Splinter &lt;splinter@example.com&gt;\",\n  to = { \"michelangelo@example.com\" },\n  cc = { \"leo@example.com\", \"Raphael &lt;raph@example.com&gt;\", \"donatello@example.com\" },\n  subject = \"Pizza is here!\",\n  text = \"There's pizza in the sewer.\",\n  html = \"&lt;h1&gt;There's pizza in the sewer.&lt;/h1&gt;\",\n  attachments = {\n    {\n      filename = \"toppings.txt\",\n      content_type = \"text/plain\",\n      content = \"1. Cheese\\n2. Pepperoni\",\n    },\n  },\n})\nif err then\n  ngx.log(ngx.ERR, \"mailer:send error: \", err)\n  return ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\nend\n</code></pre>"},{"location":"lua/mail/#api","title":"API","text":""},{"location":"lua/mail/#new","title":"new","text":"<p>syntax: <code>mailer, err = mail.new(options)</code></p> <p>Create and return a new mail object. In case of errors, returns <code>nil</code> and a string describing the error.</p> <p>The <code>options</code> table accepts the following fields:</p> <ul> <li><code>host</code>: The host of the SMTP server to connect to. (default: <code>localhost</code>)</li> <li><code>port</code>: The port number on the SMTP server to connect to. (default: <code>25</code>)</li> <li><code>starttls</code>: Set to <code>true</code> to ensure STARTTLS is always used to encrypt communication with the SMTP server. If not set, STARTTLS will automatically be enabled if the server supports it (but explicitly setting this to true if your server supports it is preferable to prevent STRIPTLS attacks). This is usually used in conjunction with port 587. (default: <code>nil</code>)</li> <li><code>ssl</code>: Set to <code>true</code> to use SMTPS to encrypt communication with the SMTP server (not needed if STARTTLS is being used instead). This is usually used in conjunction with port 465. (default: <code>nil</code>)</li> <li><code>username</code>: Username to use for SMTP authentication. (default: <code>nil</code>)</li> <li><code>password</code>: Password to use for SMTP authentication. (default: <code>nil</code>)</li> <li><code>auth_type</code>: The type of SMTP authentication to perform. Can either be <code>plain</code> or <code>login</code>. (default: <code>plain</code> if username and password are present)</li> <li><code>domain</code>: The domain name presented to the SMTP server during the <code>EHLO</code> connection and used as part of the Message-ID header. (default: <code>localhost.localdomain</code>)</li> <li><code>ssl_verify</code>: Whether or not to perform verification of the server's certificate when either <code>ssl</code> or <code>starttls</code> is enabled. If this is enabled then configuring the <code>lua_ssl_trusted_certificate</code> setting will be required. (default: <code>false</code>)</li> <li><code>ssl_host</code>: If the hostname of the server's certificate is different than the <code>host</code> option, this setting can be used to specify a different host used for SNI and TLS verification when either <code>ssl</code> or <code>starttls</code> is enabled. (default: the <code>host</code> option's value)</li> <li><code>timeout_connect</code>: The timeout (in milliseconds) for connecting to the SMTP server. (default: OpenResty's global <code>lua_socket_connect_timeout</code> timeout, which defaults to 60s)</li> <li><code>timeout_send</code>: The timeout (in milliseconds) for sending data to the SMTP server. (default: OpenResty's global <code>lua_socket_send_timeout</code> timeout, which defaults to 60s)</li> <li><code>timeout_read</code>: The timeout (in milliseconds) for reading data from the SMTP server. (default: OpenResty's global <code>lua_socket_read_timeout</code> timeout, which defaults to 60s)</li> </ul>"},{"location":"lua/mail/#mailersend","title":"mailer:send","text":"<p>syntax: <code>ok, err = mailer:send(data)</code></p> <p>Send an email via the SMTP server. This function returns <code>true</code> on success. In case of errors, returns <code>nil</code> and a string describing the error.</p> <p>The <code>data</code> table accepts the following fields:</p> <ul> <li><code>from</code>: Email address for the <code>From</code> header.</li> <li><code>reply_to</code>: Email address for the <code>Reply-To</code> header.</li> <li><code>to</code>: A table (list-like) of email addresses for the <code>To</code> recipients.</li> <li><code>cc</code>: A table (list-like) of email addresses for the <code>Cc</code> recipients.</li> <li><code>bcc</code>: A table (list-like) of email addresses for the <code>Bcc</code> recipients.</li> <li><code>subject</code>: Message subject.</li> <li><code>text</code>: Body of the message (plain text version).</li> <li><code>html</code>: Body of the message (HTML verion).</li> <li><code>headers</code>: A table of additional headers to set on the message.</li> <li><code>attachments</code>: A table (list-like) of file attachments for the message. Each attachment must be an table (map-like) with the following fields:</li> <li><code>filename</code>: The filename of the attachment.</li> <li><code>content_type</code>: The <code>Content-Type</code> of the file attachment.</li> <li><code>content</code>: The contents of the file attachment as a string.</li> <li><code>disposition</code>: The <code>Content-Disposition</code> of the file attachment. Can either be <code>attachment</code> or <code>inline</code>. (default: <code>attachment</code>)</li> <li><code>content_id</code>: The <code>Content-ID</code> of the file attachment. (default: randomly generated ID)</li> </ul>"},{"location":"lua/mail/#development","title":"Development","text":"<p>After checking out the repo, Docker can be used to run the test suite:</p> <pre><code>docker-compose run --rm app make test\n</code></pre>"},{"location":"lua/mail/#release-process","title":"Release Process","text":"<p>To release a new version to LuaRocks and OPM:</p> <ul> <li>Ensure <code>CHANGELOG.md</code> is up to date.</li> <li>Update the <code>_VERSION</code> in <code>lib/resty/mail.lua</code>.</li> <li>Update the <code>version</code> in <code>dist.ini</code>.</li> <li>Move the rockspec file to the new version number (<code>git mv lua-resty-mail-X.X.X-1.rockspec lua-resty-mail-X.X.X-1.rockspec</code>), and update the <code>version</code> and <code>tag</code> variables in the rockspec file.</li> <li>Commit and tag the release (<code>git tag -a vX.X.X -m \"Tagging vX.X.X\" &amp;&amp; git push origin vX.X.X</code>).</li> <li>Run <code>make release VERSION=X.X.X</code>.</li> </ul>"},{"location":"lua/mail/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-mail.</p>"},{"location":"lua/maxminddb/","title":"maxminddb: A Lua library for reading MaxMind's Geolocation database","text":""},{"location":"lua/maxminddb/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/maxminddb/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-maxminddb\n</code></pre>"},{"location":"lua/maxminddb/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-maxminddb\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-maxminddb v1.3.7  released on Dec 08 2025.</p> <p>lua-resty-maxminddb - A Lua library for reading MaxMind's Geolocation database format  (aka mmdb or geoip2).</p> <p>Original multi database support</p>"},{"location":"lua/maxminddb/#prerequisites","title":"Prerequisites","text":"<p>Note - [maxmind/libmaxminddb][]</p> <ul> <li> <p>[openresty][]</p> </li> <li> <p>[GeoLite2 Free Downloadable Databases][linkGeolite2FreeDownloadableDatabases]</p> </li> <li> <p>[maxmind/geoipupdate][]</p> </li> </ul> <p>New Features</p> <ul> <li>Multiple Database Support: Initialize and use multiple MaxMind databases simultaneously</li> <li>Profile Selection: Choose which database to query using profile names</li> <li>Automatic Fallback: Uses first available database if no profile specified</li> </ul> <p>Bug fixed</p> <ul> <li> <p>Error at lookup IP</p> </li> <li> <p>bad argument #1 to 'concat' (table expected, got nil)</p> </li> <li> <p>Memory leak</p> </li> <li> <p>Multiple subdivisions</p> </li> </ul> <p>API Reference</p> <p>Functions: - <code>geo.init(profiles)</code>: Initialize databases with profile names and file paths - <code>geo.lookup(ip, lookup_path, profile)</code>: Lookup IP address, optionally specify profile - <code>geo.initted()</code>: Check if databases are initialized - <code>geo.get_profiles()</code>: Get list of available profile names - <code>geo.has_profile(profile)</code>: Check if a specific profile exists</p> <p>Apology for infringement - https://github.com/anjia0532/lua-resty-maxminddb/issues/25</p>"},{"location":"lua/maxminddb/#opm-manual-install-libmaxminddb-and-download-geolite2-citymmdb","title":"opm (manual install libmaxminddb and download GeoLite2-City.mmdb)","text":""},{"location":"lua/maxminddb/#openrestyopenrestyalpine-and-apacheapisix2130-alpine-docker-image-need-to-install-perl-libmaxminddb","title":"openresty/openresty:alpine and apache/apisix:2.13.0-alpine docker image need to install perl libmaxminddb","text":""},{"location":"lua/maxminddb/#eg-apk-no-cache-add-perl-libmaxminddb-ln-s-usrliblibmaxminddbso0-usrliblibmaxminddbso","title":"e.g. apk --no-cache add perl libmaxminddb &amp;&amp; ln -s /usr/lib/libmaxminddb.so.0  /usr/lib/libmaxminddb.so","text":"<p>opm get anjia0532/lua-resty-maxminddb</p>"},{"location":"lua/maxminddb/#openrestyopenrestyalpine-fat-docker-image","title":"openresty/openresty:alpine-fat docker image","text":"<p>luarocks install lua-resty-maxminddb</p>"},{"location":"lua/maxminddb/#openrestyopenrestyalpine-docker-image-need-to-install-luarocks-ref-httpsgithubcomopenrestydocker-openrestyblobmasteralpinedockerfilefat","title":"openresty/openresty:alpine docker image need to install luarocks (ref https://github.com/openresty/docker-openresty/blob/master/alpine/Dockerfile.fat)","text":""},{"location":"lua/maxminddb/#special-apacheapisix2xx0-alpine-luarocks-install-lua-resty-maxminddb-unzipusrbinunzip","title":"special apache/apisix:2.xx.0-alpine luarocks install lua-resty-maxminddb UNZIP=/usr/bin/unzip","text":""},{"location":"lua/maxminddb/#eg-apk-no-cache-add-perl-alpine-sdk-luarocks-install-lua-resty-maxminddb-unzipusrbinunzip","title":"e.g. apk --no-cache add perl alpine-sdk &amp;&amp; luarocks install lua-resty-maxminddb UNZIP=/usr/bin/unzip","text":"<pre><code>## Synopsis\n\n**Basic Usage (Single Database)**\n```lua\nlocal geo = require 'resty.maxminddb'\nif not geo.initted() then\n    geo.init(\"/path/to/GeoLite2-City.mmdb\")\nend\nlocal res, err = geo.lookup(\"8.8.8.8\")\n</code></pre> <p>Multiple Database Support <pre><code>local geo = require 'resty.maxminddb'\nif not geo.initted() then\n    geo.init({\n        city = \"/path/to/GeoLite2-City.mmdb\",\n        country = \"/path/to/GeoLite2-Country.mmdb\",\n        asn = \"/path/to/GeoLite2-ASN.mmdb\"\n    })\nend\n\n-- Lookup using default profile (first one)\nlocal res, err = geo.lookup(\"8.8.8.8\")\n\n-- Or specify a specific profile\nlocal city_data, err = geo.lookup(\"8.8.8.8\", nil, \"city\")\nlocal country_data, err = geo.lookup(\"8.8.8.8\", nil, \"country\")\nlocal asn_data, err = geo.lookup(\"8.8.8.8\", nil, \"asn\")\n</code></pre></p> <p>Complete Nginx Example <pre><code>server {\n    listen 80;\n    server_name localhost;\n    location / {\n        content_by_lua_block{\n            local cjson = require 'cjson'\n            local geo = require 'resty.maxminddb'\n            if not geo.initted() then\n                geo.init({\n                    city = \"/path/to/GeoLite2-City.mmdb\",\n                    country = \"/path/to/GeoLite2-Country.mmdb\"\n                })\n            end\n\n            -- Lookup using default profile (first one)\n            local res,err = geo.lookup(ngx.var.arg_ip or ngx.var.remote_addr)\n\n            -- Multi database support\n            -- local res,err = geo.lookup(ngx.var.arg_ip or ngx.var.remote_addr, nil, ngx.var.arg_type or 'city')\n\n            if not res then\n                ngx.log(ngx.ERR,'failed to lookup by ip ,reason:',err)\n            end\n            ngx.say(\"full :\",cjson.encode(res))\n            if ngx.var.arg_node then\n               ngx.say(\"node name:\",ngx.var.arg_node,\" ,value:\", cjson.encode(res[ngx.var.arg_node] or {}))\n            end\n        }\n    }\n}\n</code></pre></p> <pre><code>  #ipv4\n  $ curl \"http://localhost/?ip=114.114.114.114&amp;node=city&amp;type=city\"\n\n  #ipv6\n  #$ curl \"http://localhost/?ip=2001:4860:0:1001::3004:ef68&amp;node=country\"\n\n  full :{\"city\":{\"geoname_id\":1799962,\"names\":{\"en\":\"Nanjing\",\"ru\":\"\u041d\u0430\u043d\u043a\u0438\u043d\",\"fr\":\"Nankin\",\"pt-BR\":\"Nanquim\",\"zh-CN\":\"\u5357\u4eac\",\"es\":\"Nank\u00edn\",\"de\":\"Nanjing\",\"ja\":\"\u5357\u4eac\u5e02\"}},\"subdivisions\":[{\"geoname_id\":1806260,\"names\":{\"en\":\"Jiangsu\",\"fr\":\"Province de Jiangsu\",\"zh-CN\":\"\u6c5f\u82cf\u7701\"},\"iso_code\":\"32\"}],\"country\":{\"geoname_id\":1814991,\"names\":{\"en\":\"China\",\"ru\":\"\u041a\u0438\u0442\u0430\u0439\",\"fr\":\"Chine\",\"pt-BR\":\"China\",\"zh-CN\":\"\u4e2d\u56fd\",\"es\":\"China\",\"de\":\"China\",\"ja\":\"\u4e2d\u56fd\"},\"iso_code\":\"CN\"},\"registered_country\":{\"geoname_id\":1814991,\"names\":{\"en\":\"China\",\"ru\":\"\u041a\u0438\u0442\u0430\u0439\",\"fr\":\"Chine\",\"pt-BR\":\"China\",\"zh-CN\":\"\u4e2d\u56fd\",\"es\":\"China\",\"de\":\"China\",\"ja\":\"\u4e2d\u56fd\"},\"iso_code\":\"CN\"},\"location\":{\"time_zone\":\"Asia\\/Shanghai\",\"longitude\":118.7778,\"accuracy_radius\":50,\"latitude\":32.0617},\"continent\":{\"geoname_id\":6255147,\"names\":{\"en\":\"Asia\",\"ru\":\"\u0410\u0437\u0438\u044f\",\"fr\":\"Asie\",\"pt-BR\":\"\u00c1sia\",\"zh-CN\":\"\u4e9a\u6d32\",\"es\":\"Asia\",\"de\":\"Asien\",\"ja\":\"\u30a2\u30b8\u30a2\"},\"code\":\"AS\"}}\n  node name:city ,value:{\"geoname_id\":1799962,\"names\":{\"en\":\"Nanjing\",\"ru\":\"\u041d\u0430\u043d\u043a\u0438\u043d\",\"fr\":\"Nankin\",\"pt-BR\":\"Nanquim\",\"zh-CN\":\"\u5357\u4eac\",\"es\":\"Nank\u00edn\",\"de\":\"Nanjing\",\"ja\":\"\u5357\u4eac\u5e02\"}}\n</code></pre> <p>prettify <pre><code>full: {\n    \"city\": {\n        \"geoname_id\": 1799962,\n        \"names\": {\n            \"en\": \"Nanjing\",\n            \"ru\": \"\u041d\u0430\u043d\u043a\u0438\u043d\",\n            \"fr\": \"Nankin\",\n            \"pt-BR\": \"Nanquim\",\n            \"zh-CN\": \"\u5357\u4eac\",\n            \"es\": \"Nank\u00edn\",\n            \"de\": \"Nanjing\",\n            \"ja\": \"\u5357\u4eac\u5e02\"\n        }\n    },\n    \"subdivisions\": [{\n            \"geoname_id\": 1806260,\n            \"names\": {\n                \"en\": \"Jiangsu\",\n                \"fr\": \"Province de Jiangsu\",\n                \"zh-CN\": \"\u6c5f\u82cf\u7701\"\n            },\n            \"iso_code\": \"32\"\n        }\n    ],\n    \"country\": {\n        \"geoname_id\": 1814991,\n        \"names\": {\n            \"en\": \"China\",\n            \"ru\": \"\u041a\u0438\u0442\u0430\u0439\",\n            \"fr\": \"Chine\",\n            \"pt-BR\": \"China\",\n            \"zh-CN\": \"\u4e2d\u56fd\",\n            \"es\": \"China\",\n            \"de\": \"China\",\n            \"ja\": \"\u4e2d\u56fd\"\n        },\n        \"iso_code\": \"CN\"\n    },\n    \"registered_country\": {\n        \"geoname_id\": 1814991,\n        \"names\": {\n            \"en\": \"China\",\n            \"ru\": \"\u041a\u0438\u0442\u0430\u0439\",\n            \"fr\": \"Chine\",\n            \"pt-BR\": \"China\",\n            \"zh-CN\": \"\u4e2d\u56fd\",\n            \"es\": \"China\",\n            \"de\": \"China\",\n            \"ja\": \"\u4e2d\u56fd\"\n        },\n        \"iso_code\": \"CN\"\n    },\n    \"location\": {\n        \"time_zone\": \"Asia\\/Shanghai\",\n        \"longitude\": 118.7778,\n        \"accuracy_radius\": 50,\n        \"latitude\": 32.0617\n    },\n    \"continent\": {\n        \"geoname_id\": 6255147,\n        \"names\": {\n            \"en\": \"Asia\",\n            \"ru\": \"\u0410\u0437\u0438\u044f\",\n            \"fr\": \"Asie\",\n            \"pt-BR\": \"\u00c1sia\",\n            \"zh-CN\": \"\u4e9a\u6d32\",\n            \"es\": \"Asia\",\n            \"de\": \"Asien\",\n            \"ja\": \"\u30a2\u30b8\u30a2\"\n        },\n        \"code\": \"AS\"\n    }\n}\nnode name: city, value: {\n    \"geoname_id\": 1799962,\n    \"names\": {\n        \"en\": \"Nanjing\",\n        \"ru\": \"\u041d\u0430\u043d\u043a\u0438\u043d\",\n        \"fr\": \"Nankin\",\n        \"pt-BR\": \"Nanquim\",\n        \"zh-CN\": \"\u5357\u4eac\",\n        \"es\": \"Nank\u00edn\",\n        \"de\": \"Nanjing\",\n        \"ja\": \"\u5357\u4eac\u5e02\"\n    }\n}\n</code></pre></p>"},{"location":"lua/maxminddb/#references","title":"References","text":"<ul> <li>[GeoIP2 City and Country CSV Databases][linkGeoip2CityAndCountryCsvDatabases]</li> <li>[lilien1010/lua-resty-maxminddb][]</li> <li>[maxmind/libmaxminddb#source#lookup_and_print][]</li> <li>[maxmind/libmaxminddb#source#dump_entry_data_list][]</li> </ul>"},{"location":"lua/maxminddb/#bug-reports","title":"Bug Reports","text":"<p>Please report bugs by filing an issue with our GitHub issue tracker at https://github.com/anjia0532/lua-resty-maxminddb/issues</p> <p>If the bug is casued by libmaxminddb  tracker at https://github.com/maxmind/libmaxminddb/issues</p>"},{"location":"lua/maxminddb/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-maxminddb.</p>"},{"location":"lua/memcached/","title":"memcached: Lua memcached client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/memcached/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/memcached/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-memcached\n</code></pre>"},{"location":"lua/memcached/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-memcached\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-memcached v0.17  released on Jan 19 2023.</p> <p>lua-resty-memcached - Lua memcached client driver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/memcached/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/memcached/#description","title":"Description","text":"<p>This Lua library is a memcached client driver for the ngx_lua nginx module:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.5.0rc29 or OpenResty 1.0.15.7 is required.</p>"},{"location":"lua/memcached/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua '\n                local memcached = require \"resty.memcached\"\n                local memc, err = memcached:new()\n                if not memc then\n                    ngx.say(\"failed to instantiate memc: \", err)\n                    return\n                end\n\n                memc:set_timeout(1000) -- 1 sec\n\n                -- or connect to a unix domain socket file listened\n                -- by a memcached server:\n                --     local ok, err = memc:connect(\"unix:/path/to/memc.sock\")\n\n                local ok, err = memc:connect(\"127.0.0.1\", 11211)\n                if not ok then\n                    ngx.say(\"failed to connect: \", err)\n                    return\n                end\n\n                local ok, err = memc:flush_all()\n                if not ok then\n                    ngx.say(\"failed to flush all: \", err)\n                    return\n                end\n\n                local ok, err = memc:set(\"dog\", 32)\n                if not ok then\n                    ngx.say(\"failed to set dog: \", err)\n                    return\n                end\n\n                local res, flags, err = memc:get(\"dog\")\n                if err then\n                    ngx.say(\"failed to get dog: \", err)\n                    return\n                end\n\n                if not res then\n                    ngx.say(\"dog not found\")\n                    return\n                end\n\n                ngx.say(\"dog: \", res)\n\n                -- put it into the connection pool of size 100,\n                -- with 10 seconds max idle timeout\n                local ok, err = memc:set_keepalive(10000, 100)\n                if not ok then\n                    ngx.say(\"cannot set keepalive: \", err)\n                    return\n                end\n\n                -- or just close the connection right away:\n                -- local ok, err = memc:close()\n                -- if not ok then\n                --     ngx.say(\"failed to close: \", err)\n                --     return\n                -- end\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/memcached/#methods","title":"Methods","text":"<p>The <code>key</code> argument provided in the following methods will be automatically escaped according to the URI escaping rules before sending to the memcached server.</p>"},{"location":"lua/memcached/#new","title":"new","text":"<p><code>syntax: memc, err = memcached:new(opts?)</code></p> <p>Creates a memcached object. In case of failures, returns <code>nil</code> and a string describing the error.</p> <p>It accepts an optional <code>opts</code> table argument. The following options are supported:</p> <ul> <li> <p><code>key_transform</code></p> <p>an array table containing two functions for escaping and unescaping the memcached keys, respectively. By default, the memcached keys will be escaped and unescaped as URI components, that is</p> </li> </ul> <pre><code>    memached:new{\n        key_transform = { ngx.escape_uri, ngx.unescape_uri }\n    }\n</code></pre>"},{"location":"lua/memcached/#connect","title":"connect","text":"<p><code>syntax: ok, err = memc:connect(host, port)</code></p> <p><code>syntax: ok, err = memc:connect(\"unix:/path/to/unix.sock\")</code></p> <p>Attempts to connect to the remote host and port that the memcached server is listening to or a local unix domain socket file listened by the memcached server.</p> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p>"},{"location":"lua/memcached/#sslhandshake","title":"sslhandshake","text":"<p>syntax: session, err = memc:sslhandshake(reused_session?, server_name?, ssl_verify?, send_status_req?)</p> <p>Does SSL/TLS handshake on the currently established connection. See the tcpsock.sslhandshake API from OpenResty for more details.</p>"},{"location":"lua/memcached/#set","title":"set","text":"<p><code>syntax: ok, err = memc:set(key, value, exptime, flags)</code></p> <p>Inserts an entry into memcached unconditionally. If the key already exists, overrides it.</p> <p>The <code>value</code> argument could also be a Lua table holding multiple Lua strings that are supposed to be concatenated as a whole (without any delimiters). For example,</p> <pre><code>    memc:set(\"dog\", {\"a \", {\"kind of\"}, \" animal\"})\n</code></pre> <p>is functionally equivalent to</p> <pre><code>    memc:set(\"dog\", \"a kind of animal\")\n</code></pre> <p>The <code>exptime</code> parameter is optional and defaults to <code>0</code> (meaning never expires). The expiration time is in seconds.</p> <p>The <code>flags</code> parameter is optional and defaults to <code>0</code>.</p>"},{"location":"lua/memcached/#set_timeout","title":"set_timeout","text":"<p><code>syntax: ok, err = memc:set_timeout(timeout)</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the <code>connect</code> method.</p> <p>Returns 1 when successful and nil plus a string describing the error otherwise.</p>"},{"location":"lua/memcached/#set_timeouts","title":"set_timeouts","text":"<p><code>syntax: ok, err = memc:set_timeouts(connect_timeout, send_timeout, read_timeout)</code></p> <p>Sets the timeouts (in ms) for connect, send and read operations respectively.</p> <p>Returns 1 when successful and nil plus a string describing the error otherwise.</p>"},{"location":"lua/memcached/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = memc:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Puts the current memcached connection immediately into the ngx_lua cosocket connection pool.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p> <p>Only call this method in the place you would have called the <code>close</code> method instead. Calling this method will immediately turn the current memcached object into the <code>closed</code> state. Any subsequent operations other than <code>connect()</code> on the current object will return the <code>closed</code> error.</p>"},{"location":"lua/memcached/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: times, err = memc:get_reused_times()</code></p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p>"},{"location":"lua/memcached/#close","title":"close","text":"<p><code>syntax: ok, err = memc:close()</code></p> <p>Closes the current memcached connection and returns the status.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#add","title":"add","text":"<p><code>syntax: ok, err = memc:add(key, value, exptime, flags)</code></p> <p>Inserts an entry into memcached if and only if the key does not exist.</p> <p>The <code>value</code> argument could also be a Lua table holding multiple Lua strings that are supposed to be concatenated as a whole (without any delimiters). For example,</p> <pre><code>    memc:add(\"dog\", {\"a \", {\"kind of\"}, \" animal\"})\n</code></pre> <p>is functionally equivalent to</p> <pre><code>    memc:add(\"dog\", \"a kind of animal\")\n</code></pre> <p>The <code>exptime</code> parameter is optional and defaults to <code>0</code> (meaning never expires). The expiration time is in seconds.</p> <p>The <code>flags</code> parameter is optional, defaults to <code>0</code>.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#replace","title":"replace","text":"<p><code>syntax: ok, err = memc:replace(key, value, exptime, flags)</code></p> <p>Inserts an entry into memcached if and only if the key does exist.</p> <p>The <code>value</code> argument could also be a Lua table holding multiple Lua strings that are supposed to be concatenated as a whole (without any delimiters). For example,</p> <pre><code>    memc:replace(\"dog\", {\"a \", {\"kind of\"}, \" animal\"})\n</code></pre> <p>is functionally equivalent to</p> <pre><code>    memc:replace(\"dog\", \"a kind of animal\")\n</code></pre> <p>The <code>exptime</code> parameter is optional and defaults to <code>0</code> (meaning never expires). The expiration time is in seconds.</p> <p>The <code>flags</code> parameter is optional, defaults to <code>0</code>.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#append","title":"append","text":"<p><code>syntax: ok, err = memc:append(key, value, exptime, flags)</code></p> <p>Appends the value to an entry with the same key that already exists in memcached.</p> <p>The <code>value</code> argument could also be a Lua table holding multiple Lua strings that are supposed to be concatenated as a whole (without any delimiters). For example,</p> <pre><code>    memc:append(\"dog\", {\"a \", {\"kind of\"}, \" animal\"})\n</code></pre> <p>is functionally equivalent to</p> <pre><code>    memc:append(\"dog\", \"a kind of animal\")\n</code></pre> <p>The <code>exptime</code> parameter is optional and defaults to <code>0</code> (meaning never expires). The expiration time is in seconds.</p> <p>The <code>flags</code> parameter is optional, defaults to <code>0</code>.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#prepend","title":"prepend","text":"<p><code>syntax: ok, err = memc:prepend(key, value, exptime, flags)</code></p> <p>Prepends the value to an entry with the same key that already exists in memcached.</p> <p>The <code>value</code> argument could also be a Lua table holding multiple Lua strings that are supposed to be concatenated as a whole (without any delimiters). For example,</p> <pre><code>    memc:prepend(\"dog\", {\"a \", {\"kind of\"}, \" animal\"})\n</code></pre> <p>is functionally equivalent to</p> <pre><code>    memc:prepend(\"dog\", \"a kind of animal\")\n</code></pre> <p>The <code>exptime</code> parameter is optional and defaults to <code>0</code> (meaning never expires). The expiration time is in seconds.</p> <p>The <code>flags</code> parameter is optional and defaults to <code>0</code>.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#get","title":"get","text":"<p><code>syntax: value, flags, err = memc:get(key)</code> <code>syntax: results, err = memc:get(keys)</code></p> <p>Get a single entry or multiple entries in the memcached server via a single key or a table of keys.</p> <p>Let us first discuss the case When the key is a single string.</p> <p>The key's value and associated flags value will be returned if the entry is found and no error happens.</p> <p>In case of errors, <code>nil</code> values will be turned for <code>value</code> and <code>flags</code> and a 3rd (string) value will also be returned for describing the error.</p> <p>If the entry is not found, then three <code>nil</code> values will be returned.</p> <p>Then let us discuss the case when the a Lua table of multiple keys are provided.</p> <p>In this case, a Lua table holding the key-result pairs will be always returned in case of success. Each value corresponding each key in the table is also a table holding two values, the key's value and the key's flags. If a key does not exist, then there is no responding entries in the <code>results</code> table.</p> <p>In case of errors, <code>nil</code> will be returned, and the second return value will be a string describing the error.</p>"},{"location":"lua/memcached/#gets","title":"gets","text":"<p><code>syntax: value, flags, cas_unique, err = memc:gets(key)</code></p> <p><code>syntax: results, err = memc:gets(keys)</code></p> <p>Just like the <code>get</code> method, but will also return the CAS unique value associated with the entry in addition to the key's value and flags.</p> <p>This method is usually used together with the <code>cas</code> method.</p>"},{"location":"lua/memcached/#cas","title":"cas","text":"<p><code>syntax: ok, err = memc:cas(key, value, cas_unique, exptime?, flags?)</code></p> <p>Just like the <code>set</code> method but does a check and set operation, which means \"store this data but   only if no one else has updated since I last fetched it.\"</p> <p>The <code>cas_unique</code> argument can be obtained from the <code>gets</code> method.</p>"},{"location":"lua/memcached/#touch","title":"touch","text":"<p><code>syntax: ok, err = memc:touch(key, exptime)</code></p> <p>Update the expiration time of an existing key.</p> <p>Returns <code>1</code> for success or <code>nil</code> with a string describing the error otherwise.</p> <p>This method was first introduced in the <code>v0.11</code> release.</p>"},{"location":"lua/memcached/#flush_all","title":"flush_all","text":"<p><code>syntax: ok, err = memc:flush_all(time?)</code></p> <p>Flushes (or invalidates) all the existing entries in the memcached server immediately (by default) or after the expiration specified by the <code>time</code> argument (in seconds).</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#delete","title":"delete","text":"<p><code>syntax: ok, err = memc:delete(key)</code></p> <p>Deletes the key from memcached immediately.</p> <p>The key to be deleted must already exist in memcached.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/memcached/#incr","title":"incr","text":"<p><code>syntax: new_value, err = memc:incr(key, delta)</code></p> <p>Increments the value of the specified key by the integer value specified in the <code>delta</code> argument.</p> <p>Returns the new value after incrementation in success, and <code>nil</code> with a string describing the error in case of failures.</p>"},{"location":"lua/memcached/#decr","title":"decr","text":"<p><code>syntax: new_value, err = memc:decr(key, value)</code></p> <p>Decrements the value of the specified key by the integer value specified in the <code>delta</code> argument.</p> <p>Returns the new value after decrementation in success, and <code>nil</code> with a string describing the error in case of failures.</p>"},{"location":"lua/memcached/#stats","title":"stats","text":"<p><code>syntax: lines, err = memc:stats(args?)</code></p> <p>Returns memcached server statistics information with an optional <code>args</code> argument.</p> <p>In case of success, this method returns a lua table holding all of the lines of the output; in case of failures, it returns <code>nil</code> with a string describing the error.</p> <p>If the <code>args</code> argument is omitted, general server statistics is returned. Possible <code>args</code> argument values are <code>items</code>, <code>sizes</code>, <code>slabs</code>, among others.</p>"},{"location":"lua/memcached/#quit","title":"quit","text":"<p><code>syntax: ok, err = memc:quit()</code></p> <p>Tells the server to close the current memcached connection.</p> <p>Returns <code>1</code> in case of success and <code>nil</code> other wise. In case of failures, another string value will also be returned to describe the error.</p> <p>Generally you can just directly call the <code>close</code> method to achieve the same effect.</p>"},{"location":"lua/memcached/#verbosity","title":"verbosity","text":"<p><code>syntax: ok, err = memc:verbosity(level)</code></p> <p>Sets the verbosity level used by the memcached server. The <code>level</code> argument should be given integers only.</p> <p>Returns <code>1</code> in case of success and <code>nil</code> other wise. In case of failures, another string value will also be returned to describe the error.</p>"},{"location":"lua/memcached/#init_pipeline","title":"init_pipeline","text":"<p><code>syntax: err = memc:init_pipeline(n?)</code></p> <p>Enable the Memcache pipelining mode. All subsequent calls to Memcache command methods will automatically get buffer and will send to the server in one run when the commit_pipeline method is called or get cancelled by calling the cancel_pipeline method.</p> <p>The optional params <code>n</code> is buffer tables size. default value 4</p>"},{"location":"lua/memcached/#commit_pipeline","title":"commit_pipeline","text":"<p><code>syntax: results, err = memc:commit_pipeline()</code></p> <p>Quits the pipelining mode by committing all the cached Memcache queries to the remote server in a single run. All the replies for these queries will be collected automatically and are returned as if a big multi-bulk reply at the highest level.</p> <p>This method success return a lua table. failed return a lua string describing the error upon failures.</p>"},{"location":"lua/memcached/#cancel_pipeline","title":"cancel_pipeline","text":"<p><code>syntax: memc:cancel_pipeline()</code></p> <p>Quits the pipelining mode by discarding all existing buffer Memcache commands since the last call to the init_pipeline method.</p> <p>the method no return. always succeeds.</p>"},{"location":"lua/memcached/#automatic-error-logging","title":"Automatic Error Logging","text":"<p>By default the underlying ngx_lua module does error logging when socket errors happen. If you are already doing proper error handling in your own Lua code, then you are recommended to disable this automatic error logging by turning off ngx_lua's lua_socket_log_errors directive, that is,</p> <pre><code>    lua_socket_log_errors off;\n</code></pre>"},{"location":"lua/memcached/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like <code>set_by_lua*</code>, <code>log_by_lua*</code>, and <code>header_filter_by_lua*</code> where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.memcached</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see http://wiki.nginx.org/HttpLuaModule#Data_Sharing_within_an_Nginx_Worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.memcached</code> instance. You should always initiate <code>resty.memcached</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/memcached/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> <li>the memcached wired protocol specification: http://code.sixapart.com/svn/memcached/trunk/server/doc/protocol.txt</li> <li>the lua-resty-redis library.</li> <li>the lua-resty-mysql library.</li> </ul>"},{"location":"lua/memcached/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-memcached.</p>"},{"location":"lua/mlcache/","title":"mlcache: Layered caching library for nginx-module-lua","text":""},{"location":"lua/mlcache/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/mlcache/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-mlcache\n</code></pre>"},{"location":"lua/mlcache/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-mlcache\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-mlcache v2.7.0  released on Feb 14 2024.</p> <p></p> <p>Fast and automated layered caching for OpenResty.</p> <p>This library can be manipulated as a key/value store caching scalar Lua types and tables, combining the power of the [lua_shared_dict] API and [lua-resty-lrucache], which results in an extremely performant and flexible caching solution.</p> <p>Features:</p> <ul> <li>Caching and negative caching with TTLs.</li> <li>Built-in mutex via [lua-resty-lock] to prevent dog-pile effects to your   database/backend on cache misses.</li> <li>Built-in inter-worker communication to propagate cache invalidations   and allow workers to update their L1 (lua-resty-lrucache) caches upon changes   (<code>set()</code>, <code>delete()</code>).</li> <li>Support for split hits and misses caching queues.</li> <li>Multiple isolated instances can be created to hold various types of data   while relying on the same <code>lua_shared_dict</code> L2 cache.</li> </ul> <p>Illustration of the various caching levels built into this library:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Nginx                                           \u2502\n\u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502       \u2502worker     \u2502 \u2502worker     \u2502 \u2502worker     \u2502 \u2502\n\u2502 L1    \u2502           \u2502 \u2502           \u2502 \u2502           \u2502 \u2502\n\u2502       \u2502 Lua cache \u2502 \u2502 Lua cache \u2502 \u2502 Lua cache \u2502 \u2502\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502             \u2502             \u2502             \u2502       \u2502\n\u2502             \u25bc             \u25bc             \u25bc       \u2502\n\u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502       \u2502                                       \u2502 \u2502\n\u2502 L2    \u2502           lua_shared_dict             \u2502 \u2502\n\u2502       \u2502                                       \u2502 \u2502\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                           \u2502 mutex               \u2502\n\u2502                           \u25bc                     \u2502\n\u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502                  \u2502     callback     \u2502           \u2502\n\u2502                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n  L3                        \u2502   I/O fetch\n                            \u25bc\n\n                   Database, API, DNS, Disk, any I/O...\n</code></pre> <p>The cache level hierarchy is: - L1: Least-Recently-Used Lua VM cache using [lua-resty-lrucache].    Provides the fastest lookup if populated, and avoids exhausting the workers'    Lua VM memory. - L2: <code>lua_shared_dict</code> memory zone shared by all workers. This level    is only accessed if L1 was a miss, and prevents workers from requesting the    L3 cache. - L3: a custom function that will only be run by a single worker    to avoid the dog-pile effect on your database/backend    (via [lua-resty-lock]). Values fetched via L3 will be set to the L2 cache    for other workers to retrieve.</p> <p>This library has been presented at OpenResty Con 2018.  See the Resources section for a recording of the talk.</p>"},{"location":"lua/mlcache/#synopsis","title":"Synopsis","text":"<pre><code>## nginx.conf\n\nhttp {\n    # you do not need to configure the following line when you\n    # use LuaRocks or opm.\n    # 'on' already is the default for this directive. If 'off', the L1 cache\n    # will be inefective since the Lua VM will be re-created for every\n    # request. This is fine during development, but ensure production is 'on'.\n    lua_code_cache on;\n\n    lua_shared_dict cache_dict 1m;\n\n    init_by_lua_block {\n        local mlcache = require \"resty.mlcache\"\n\n        local cache, err = mlcache.new(\"my_cache\", \"cache_dict\", {\n            lru_size = 500,    -- size of the L1 (Lua VM) cache\n            ttl      = 3600,   -- 1h ttl for hits\n            neg_ttl  = 30,     -- 30s ttl for misses\n        })\n        if err then\n\n        end\n\n        -- we put our instance in the global table for brevity in\n        -- this example, but prefer an upvalue to one of your modules\n        -- as recommended by ngx_lua\n        _G.cache = cache\n    }\n\n    server {\n        listen 8080;\n\n        location / {\n            content_by_lua_block {\n                local function callback(username)\n                    -- this only runs *once* until the key expires, so\n                    -- do expensive operations like connecting to a remote\n                    -- backend here. i.e: call a MySQL server in this callback\n                    return db:get_user(username) -- { name = \"John Doe\", email = \"john@example.com\" }\n                end\n\n                -- this call will try L1 and L2 before running the callback (L3)\n                -- the returned value will then be stored in L2 and L1\n                -- for the next request.\n                local user, err = cache:get(\"my_key\", nil, callback, \"jdoe\")\n\n                ngx.say(user.name) -- \"John Doe\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/mlcache/#methods","title":"Methods","text":""},{"location":"lua/mlcache/#new","title":"new","text":"<p>syntax: <code>cache, err = mlcache.new(name, shm, opts?)</code></p> <p>Create a new mlcache instance. If failed, returns <code>nil</code> and a string describing the error.</p> <p>The first argument <code>name</code> is an arbitrary name of your choosing for this cache, and must be a string. Each mlcache instance namespaces the values it holds according to its name, so several instances with the same name will share the same data.</p> <p>The second argument <code>shm</code> is the name of the <code>lua_shared_dict</code> shared memory zone. Several instances of mlcache can use the same shm (values will be namespaced).</p> <p>The third argument <code>opts</code> is optional. If provided, it must be a table holding the desired options for this instance. The possible options are:</p> <ul> <li><code>lru_size</code>: a number defining the size of the underlying L1 cache   (lua-resty-lrucache instance). This size is the maximal number of items   that the L1 cache can hold.   Default: <code>100</code>.</li> <li><code>ttl</code>: a number specifying the expiration time period of the cached   values. The unit is seconds, but accepts fractional number parts, like   <code>0.3</code>. A <code>ttl</code> of <code>0</code> means the cached values will never expire.   Default: <code>30</code>.</li> <li><code>neg_ttl</code>: a number specifying the expiration time period of the cached   misses (when the L3 callback returns <code>nil</code>). The unit is seconds, but   accepts fractional number parts, like <code>0.3</code>. A <code>neg_ttl</code> of <code>0</code> means the   cached misses will never expire.   Default: <code>5</code>.</li> <li><code>resurrect_ttl</code>: optional number. When specified, the mlcache instance will   attempt to resurrect stale values when the L3 callback returns <code>nil, err</code>   (soft errors). More details are available for this option in the   get() section. The unit is seconds, but accepts fractional number   parts, like <code>0.3</code>.</li> <li><code>lru</code>: optional. A lua-resty-lrucache instance of your choosing. If   specified, mlcache will not instantiate an LRU. One can use this value to use   the <code>resty.lrucache.pureffi</code> implementation of lua-resty-lrucache if desired.</li> <li><code>shm_set_tries</code>: the number of tries for the lua_shared_dict <code>set()</code>   operation. When the <code>lua_shared_dict</code> is full, it attempts to free up to 30   items from its queue. When the value being set is much larger than the freed   space, this option allows mlcache to retry the operation (and free more slots)   until the maximum number of tries is reached or enough memory was freed for   the value to fit.   Default: <code>3</code>.</li> <li><code>shm_miss</code>: optional string. The name of a <code>lua_shared_dict</code>. When   specified, misses (callbacks returning <code>nil</code>) will be cached in this separate   <code>lua_shared_dict</code>. This is useful to ensure that a large number of cache   misses (e.g. triggered by malicious clients) does not evict too many cached   items (hits) from the <code>lua_shared_dict</code> specified in <code>shm</code>.</li> <li><code>shm_locks</code>: optional string. The name of a <code>lua_shared_dict</code>. When   specified, lua-resty-lock will use this shared dict to store its locks. This   option can help reducing cache churning: when the L2 cache (shm) is full,   every insertion (such as locks created by concurrent accesses triggering L3   callbacks) purges the oldest 30 accessed items. These purged items are most   likely to be previously (and valuable) cached values. By isolating locks in a   separate shared dict, workloads experiencing cache churning can mitigate this   effect.</li> <li><code>resty_lock_opts</code>: optional table. Options for [lua-resty-lock] instances.   When mlcache runs the L3 callback, it uses lua-resty-lock to ensure that a   single worker runs the provided callback.</li> <li><code>ipc_shm</code>: optional string. If you wish to use set(),   delete(), or purge(), you must provide an IPC   (Inter-Process Communication) mechanism for workers to synchronize and   invalidate their L1 caches. This module bundles an \"off-the-shelf\" IPC   library, and you can enable it by specifying a dedicated <code>lua_shared_dict</code> in   this option. Several mlcache instances can use the same shared dict (events   will be namespaced), but no other actor than mlcache should tamper with it.</li> <li><code>ipc</code>: optional table. Like the above <code>ipc_shm</code> option, but lets you use   the IPC library of your choice to propagate inter-worker events.</li> <li><code>l1_serializer</code>: optional function. Its signature and accepted values are   documented under the get() method, along with an example. If   specified, this function will be called each time a value is promoted from the   L2 cache into the L1 (worker Lua VM). This function can perform arbitrary   serialization of the cached item to transform it into any Lua object before   storing it into the L1 cache. It can thus avoid your application from   having to repeat such transformations on every request, such as creating   tables, cdata objects, loading new Lua code, etc...</li> </ul> <p>Example:</p> <pre><code>local mlcache = require \"resty.mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache\", \"cache_shared_dict\", {\n    lru_size = 1000, -- hold up to 1000 items in the L1 cache (Lua VM)\n    ttl      = 3600, -- caches scalar types and tables for 1h\n    neg_ttl  = 60    -- caches nil values for 60s\n})\nif not cache then\n    error(\"could not create mlcache: \" .. err)\nend\n</code></pre> <p>You can create several mlcache instances relying on the same underlying <code>lua_shared_dict</code> shared memory zone:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache_1 = mlcache.new(\"cache_1\", \"cache_shared_dict\", { lru_size = 100 })\nlocal cache_2 = mlcache.new(\"cache_2\", \"cache_shared_dict\", { lru_size = 1e5 })\n</code></pre> <p>In the above example, <code>cache_1</code> is ideal for holding a few, very large values. <code>cache_2</code> can be used to hold a large number of small values. Both instances will rely on the same shm: <code>lua_shared_dict cache_shared_dict 2048m;</code>. Even if you use identical keys in both caches, they will not conflict with each other since they each have a different namespace.</p> <p>This other example instantiates an mlcache using the bundled IPC module for inter-worker invalidation events (so we can use set(), delete(), and purge()):</p> <pre><code>local mlcache = require \"resty.mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache_with_ipc\", \"cache_shared_dict\", {\n    lru_size = 1000,\n    ipc_shm = \"ipc_shared_dict\"\n})\n</code></pre> <p>Note: for the L1 cache to be effective, ensure that lua_code_cache is enabled (which is the default). If you turn off this directive during development, mlcache will work, but L1 caching will be ineffective since a new Lua VM will be created for every request.</p>"},{"location":"lua/mlcache/#get","title":"get","text":"<p>syntax: <code>value, err, hit_level = cache:get(key, opts?, callback?, ...)</code></p> <p>Perform a cache lookup. This is the primary and most efficient method of this module. A typical pattern is to not call set(), and let get() perform all the work.</p> <p>When this method succeeds, it returns <code>value</code> and <code>err</code> is set to <code>nil</code>. Because <code>nil</code> values from the L3 callback can be cached (i.e. \"negative caching\"), <code>value</code> can be <code>nil</code> albeit already cached. Hence, one must note to check the second return value <code>err</code> to determine if this method succeeded or not.</p> <p>The third return value is a number which is set if no error was encountered. It indicates the level at which the value was fetched: <code>1</code> for L1, <code>2</code> for L2, and <code>3</code> for L3.</p> <p>If, however, an error is encountered, then this method returns <code>nil</code> in <code>value</code> and a string describing the error in <code>err</code>.</p> <p>The first argument <code>key</code> is a string. Each value must be stored under a unique key.</p> <p>The second argument <code>opts</code> is optional. If provided, it must be a table holding the desired options for this key. These options will supersede the instance's options:</p> <ul> <li><code>ttl</code>: a number specifying the expiration time period of the cached   values. The unit is seconds, but accepts fractional number parts, like   <code>0.3</code>. A <code>ttl</code> of <code>0</code> means the cached values will never expire.   Default: inherited from the instance.</li> <li><code>neg_ttl</code>: a number specifying the expiration time period of the cached   misses (when the L3 callback returns <code>nil</code>). The unit is seconds, but   accepts fractional number parts, like <code>0.3</code>. A <code>neg_ttl</code> of <code>0</code> means the   cached misses will never expire.   Default: inherited from the instance.</li> <li><code>resurrect_ttl</code>: optional number. When specified, <code>get()</code> will attempt to   resurrect stale values when errors are encountered. Errors returned by the L3   callback (<code>nil, err</code>) are considered to be failures to fetch/refresh a value.   When such return values from the callback are seen by <code>get()</code>, and if the   stale value is still in memory, then <code>get()</code> will resurrect the stale value   for <code>resurrect_ttl</code> seconds. The error returned by <code>get()</code> will be logged at   the WARN level, but not returned to the caller. Finally, the <code>hit_level</code>   return value will be <code>4</code> to signify that the served item is stale. When   <code>resurrect_ttl</code> is reached, <code>get()</code> will once again attempt to run the   callback. If by then, the callback returns an error again, the value is   resurrected once again, and so on. If the callback succeeds, the value is   refreshed and not marked as stale anymore. Due to current limitations within   the LRU cache module, <code>hit_level</code> will be <code>1</code> when stale values are promoted   to the L1 cache and retrieved from there. Lua errors thrown by the   callback do not trigger a resurrect, and are returned by <code>get()</code> as usual   (<code>nil, err</code>). When several workers time out while waiting for the worker   running the callback (e.g. because the datastore is timing out), then users   of this option will see a slight difference compared to the traditional   behavior of <code>get()</code>. Instead of returning <code>nil, err</code> (indicating a lock   timeout), <code>get()</code> will return the stale value (if available), no error, and   <code>hit_level</code> will be <code>4</code>. However, the value will not be resurrected (since   another worker is still running the callback). The unit for this option is   seconds, but it accepts fractional number parts, like <code>0.3</code>. This option   must be greater than <code>0</code>, to prevent stale values from being cached   indefinitely.   Default: inherited from the instance.</li> <li><code>shm_set_tries</code>: the number of tries for the lua_shared_dict <code>set()</code>   operation. When the <code>lua_shared_dict</code> is full, it attempts to free up to 30   items from its queue. When the value being set is much larger than the freed   space, this option allows mlcache to retry the operation (and free more slots)   until the maximum number of tries is reached or enough memory was freed for   the value to fit.   Default: inherited from the instance.</li> <li><code>l1_serializer</code>: optional function. Its signature and accepted values are   documented under the get() method, along with an example. If   specified, this function will be called each time a value is promoted from the   L2 cache into the L1 (worker Lua VM). This function can perform arbitrary   serialization of the cached item to transform it into any Lua object before   storing it into the L1 cache. It can thus avoid your application from   having to repeat such transformations on every request, such as creating   tables, cdata objects, loading new Lua code, etc...   Default: inherited from the instance.</li> <li><code>resty_lock_opts</code>: optional table. If specified, override the instance   <code>resty_lock_opts</code> for the current <code>get()</code> lookup.   Default: inherited from the instance.</li> </ul> <p>The third argument <code>callback</code> is optional. If provided, it must be a function whose signature and return values are documented in the following example:</p> <pre><code>-- arg1, arg2, and arg3 are arguments forwarded to the callback from the\n-- `get()` variadic arguments, like so:\n-- cache:get(key, opts, callback, arg1, arg2, arg3)\n\nlocal function callback(arg1, arg2, arg3)\n    -- I/O lookup logic\n    -- ...\n\n    -- value: the value to cache (Lua scalar or table)\n    -- err: if not `nil`, will abort get(), which will return `value` and `err`\n    -- ttl: override ttl for this value\n    --      If returned as `ttl &gt;= 0`, it will override the instance\n    --      (or option) `ttl` or `neg_ttl`.\n    --      If returned as `ttl &lt; 0`, `value` will be returned by get(),\n    --      but not cached. This return value will be ignored if not a number.\n    return value, err, ttl\nend\n</code></pre> <p>The provided <code>callback</code> function is allowed to throw Lua errors as it runs in protected mode. Such errors thrown from the callback will be returned as strings in the second return value <code>err</code>.</p> <p>If <code>callback</code> is not provided, <code>get()</code> will still lookup the requested key in the L1 and L2 caches and return it if found. In the case when no value is found in the cache and no callback is provided, <code>get()</code> will return <code>nil, nil, -1</code>, where -1 signifies a cache miss (no value). This is not to be confused with return values such as <code>nil, nil, 1</code>, where 1 signifies a negative cached item found in L1 (cached <code>nil</code>).</p> <p>Not providing a <code>callback</code> function allows implementing cache lookup patterns that are guaranteed to be on-cpu for a more constant, smoother latency tail end (e.g. with values refreshed in background timers via <code>set()</code>).</p> <pre><code>local value, err, hit_lvl = cache:get(\"key\")\nif value == nil then\n    if err ~= nil then\n        -- error\n    elseif hit_lvl == -1 then\n        -- miss (no value)\n    else\n        -- negative hit (cached `nil` value)\n    end\nend\n</code></pre> <p>When provided a callback, <code>get()</code> follows the below logic:</p> <ol> <li>query the L1 cache (lua-resty-lrucache instance). This cache lives in the    Lua VM, and as such, it is the most efficient one to query.<ol> <li>if the L1 cache has the value, return it.</li> <li>if the L1 cache does not have the value (L1 miss), continue.</li> </ol> </li> <li>query the L2 cache (<code>lua_shared_dict</code> memory zone). This cache is    shared by all workers, and is almost as efficient as the L1 cache. It    however requires serialization of stored Lua tables.<ol> <li>if the L2 cache has the value, return it.<ol> <li>if <code>l1_serializer</code> is set, run it, and promote the resulting value    in the L1 cache.</li> <li>if not, directly promote the value as-is in the L1 cache.</li> </ol> </li> <li>if the L2 cache does not have the value (L2 miss), continue.</li> </ol> </li> <li>create a [lua-resty-lock], and ensures that a single worker will run the    callback (other workers trying to access the same value will wait).</li> <li>a single worker runs the L3 callback (e.g. performs a database query)</li> <li>the callback succeeds and returns a value: the value is set in the       L2 cache, and then in the L1 cache (as-is by default, or as returned by       <code>l1_serializer</code> if specified).</li> <li>the callback failed and returned <code>nil, err</code>:       a. if <code>resurrect_ttl</code> is specified, and if the stale value is still          available, resurrect it in the L2 cache and promote it to the L1.       b. otherwise, <code>get()</code> returns <code>nil, err</code>.</li> <li>other workers that were trying to access the same value but were waiting    are unlocked and read the value from the L2 cache (they do not run the L3    callback) and return it.</li> </ol> <p>When not provided a callback, <code>get()</code> will only execute steps 1. and 2.</p> <p>Here is a complete example usage:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache\", \"cache_shared_dict\", {\n    lru_size = 1000,\n    ttl      = 3600,\n    neg_ttl  = 60\n})\n\nlocal function fetch_user(user_id)\n    local user, err = db:query_user(user_id)\n    if err then\n        -- in this case, get() will return `nil` + `err`\n        return nil, err\n    end\n\n    return user -- table or nil\nend\n\nlocal user_id = 3\n\nlocal user, err = cache:get(\"users:\" .. user_id, nil, fetch_user, user_id)\nif err then\n    ngx.log(ngx.ERR, \"could not retrieve user: \", err)\n    return\nend\n\n-- `user` could be a table, but could also be `nil` (does not exist)\n-- regardless, it will be cached and subsequent calls to get() will\n-- return the cached value, for up to `ttl` or `neg_ttl`.\nif user then\n    ngx.say(\"user exists: \", user.name)\nelse\n    ngx.say(\"user does not exists\")\nend\n</code></pre> <p>This second example is similar to the one above, but here we apply some transformation to the retrieved <code>user</code> record before caching it via the <code>l1_serializer</code> callback:</p> <pre><code>-- Our l1_serializer, called when a value is promoted from L2 to L1\n--\n-- Its signature receives a single argument: the item as returned from\n-- an L2 hit. Therefore, this argument can never be `nil`. The result will be\n-- kept in the L1 cache, but it cannot be `nil`.\n--\n-- This function can return `nil` and a string describing an error, which\n-- will bubble up to the caller of `get()`. It also runs in protected mode\n-- and will report any Lua error.\nlocal function load_code(user_row)\n    if user_row.custom_code ~= nil then\n        local f, err = loadstring(user_row.raw_lua_code)\n        if not f then\n            -- in this case, nothing will be stored in the cache (as if the L3\n            -- callback failed)\n            return nil, \"failed to compile custom code: \" .. err\n        end\n\n        user_row.f = f\n    end\n\n    return user_row\nend\n\nlocal user, err = cache:get(\"users:\" .. user_id,\n                            { l1_serializer = load_code },\n                            fetch_user, user_id)\nif err then\n     ngx.log(ngx.ERR, \"could not retrieve user: \", err)\n     return\nend\n\n-- now we can call a function that was already loaded once, upon entering\n-- the L1 cache (Lua VM)\nuser.f()\n</code></pre>"},{"location":"lua/mlcache/#get_bulk","title":"get_bulk","text":"<p>syntax: <code>res, err = cache:get_bulk(bulk, opts?)</code></p> <p>Performs several get() lookups at once (in bulk). Any of these lookups requiring an L3 callback call will be executed concurrently, in a pool of ngx.thread.</p> <p>The first argument <code>bulk</code> is a table containing <code>n</code> operations.</p> <p>The second argument <code>opts</code> is optional. If provided, it must be a table holding the options for this bulk lookup. The possible options are:</p> <ul> <li><code>concurrency</code>: a number greater than <code>0</code>. Specifies the number of threads   that will concurrently execute the L3 callbacks for this bulk lookup. A   concurrency of <code>3</code> with 6 callbacks to run means than each thread will   execute 2 callbacks. A concurrency of <code>1</code> with 6 callbacks means than a   single thread will execute all 6 callbacks. With a concurrency of <code>6</code> and 1   callback, a single thread will run the callback.   Default: <code>3</code>.</li> </ul> <p>Upon success, this method returns <code>res</code>, a table containing the results of each lookup, and no error.</p> <p>Upon failure, this method returns <code>nil</code> plus a string describing the error.</p> <p>All lookup operations performed by this method will fully integrate into other operations being concurrently performed by other methods and Nginx workers (e.g. L1/L2 hits/misses storage, L3 callback mutex, etc...).</p> <p>The <code>bulk</code> argument is a table that must have a particular layout (documented in the below example). It can be built manually, or via the new_bulk() helper method.</p> <p>Similarly, the <code>res</code> table also has a particular layout of its own. It can be iterated upon manually, or via the each_bulk_res iterator helper.</p> <p>Example:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache\", \"cache_shared_dict\")\n\ncache:get(\"key_c\", nil, function() return nil end)\n\nlocal res, err = cache:get_bulk({\n  -- bulk layout:\n  -- key     opts          L3 callback                    callback argument\n\n    \"key_a\", { ttl = 60 }, function() return \"hello\" end, nil,\n    \"key_b\", nil,          function() return \"world\" end, nil,\n    \"key_c\", nil,          function() return \"bye\" end,   nil,\n    n = 3 -- specify the number of operations\n}, { concurrency = 3 })\nif err then\n     ngx.log(ngx.ERR, \"could not execute bulk lookup: \", err)\n     return\nend\n\n-- res layout:\n-- data, \"err\", hit_lvl }\n\nfor i = 1, res.n, 3 do\n    local data = res[i]\n    local err = res[i + 1]\n    local hit_lvl = res[i + 2]\n\n    if not err then\n        ngx.say(\"data: \", data, \", hit_lvl: \", hit_lvl)\n    end\nend\n</code></pre> <p>The above example would produce the following output:</p> <pre><code>data: hello, hit_lvl: 3\ndata: world, hit_lvl: 3\ndata: nil, hit_lvl: 1\n</code></pre> <p>Note that since <code>key_c</code> was already in the cache, the callback returning <code>\"bye\"</code> was never run, since <code>get_bulk()</code> retrieved the value from L1, as indicated by the <code>hit_lvl</code> value.</p> <p>Note: unlike get(), this method only allows specifying a single argument to each lookup's callback.</p>"},{"location":"lua/mlcache/#new_bulk","title":"new_bulk","text":"<p>syntax: <code>bulk = mlcache.new_bulk(n_lookups?)</code></p> <p>Creates a table holding lookup operations for the get_bulk() function. It is not required to use this function to construct a bulk lookup table, but it provides a nice abstraction.</p> <p>The first and only argument <code>n_lookups</code> is optional, and if specified, is a number hinting the amount of lookups this bulk will eventually contain so that the underlying table is pre-allocated for optimization purposes.</p> <p>This function returns a table <code>bulk</code>, which contains no lookup operations yet. Lookups are added to a <code>bulk</code> table by invoking <code>bulk:add(key, opts?, cb, arg?)</code>:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache\", \"cache_shared_dict\")\n\nlocal bulk = mlcache.new_bulk(3)\n\nbulk:add(\"key_a\", { ttl = 60 }, function(n) return n * n, 42)\nbulk:add(\"key_b\", nil, function(str) return str end, \"hello\")\nbulk:add(\"key_c\", nil, function() return nil end)\n\nlocal res, err = cache:get_bulk(bulk)\n</code></pre>"},{"location":"lua/mlcache/#each_bulk_res","title":"each_bulk_res","text":"<p>syntax: <code>iter, res, i = mlcache.each_bulk_res(res)</code></p> <p>Provides an abstraction to iterate over a get_bulk() <code>res</code> return table. It is not required to use this method to iterate over a <code>res</code> table, but it provides a nice abstraction.</p> <p>This method can be invoked as a Lua iterator:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache, err = mlcache.new(\"my_cache\", \"cache_shared_dict\")\n\nlocal res, err = cache:get_bulk(bulk)\n\nfor i, data, err, hit_lvl in mlcache.each_bulk_res(res) do\n    if not err then\n        ngx.say(\"lookup \", i, \": \", data)\n    end\nend\n</code></pre>"},{"location":"lua/mlcache/#peek","title":"peek","text":"<p>syntax: <code>ttl, err, value = cache:peek(key, stale?)</code></p> <p>Peek into the L2 (<code>lua_shared_dict</code>) cache.</p> <p>The first argument <code>key</code> is a string which is the key to lookup in the cache.</p> <p>The second argument <code>stale</code> is optional. If <code>true</code>, then <code>peek()</code> will consider stale values as cached values. If not provided, <code>peek()</code> will consider stale values, as if they were not in the cache</p> <p>This method returns <code>nil</code> and a string describing the error upon failure.</p> <p>If there is no value for the queried <code>key</code>, it returns <code>nil</code> and no error.</p> <p>If there is a value for the queried <code>key</code>, it returns a number indicating the remaining TTL of the cached value (in seconds) and no error. If the value for <code>key</code> has expired but is still in the L2 cache, returned TTL value will be negative. The remaining TTL return value will only be <code>0</code> if the queried <code>key</code> has an indefinite ttl (<code>ttl=0</code>). Otherwise, this return value may be positive (<code>key</code> still valid), or negative (<code>key</code> is stale).</p> <p>The third returned value will be the cached value as stored in the L2 cache, if still available.</p> <p>This method is useful when you want to determine if a value is cached. A value stored in the L2 cache is considered cached regardless of whether or not it is also set in the L1 cache of the worker. That is because the L1 cache is considered volatile (as its size unit is a number of slots), and the L2 cache is still several orders of magnitude faster than the L3 callback anyway.</p> <p>As its only intent is to take a \"peek\" into the cache to determine its warmth for a given value, <code>peek()</code> does not count as a query like get(), and does not promote the value to the L1 cache.</p> <p>Example:</p> <pre><code>local mlcache = require \"mlcache\"\n\nlocal cache = mlcache.new(\"my_cache\", \"cache_shared_dict\")\n\nlocal ttl, err, value = cache:peek(\"key\")\nif err then\n    ngx.log(ngx.ERR, \"could not peek cache: \", err)\n    return\nend\n\nngx.say(ttl)   -- nil because `key` has no value yet\nngx.say(value) -- nil\n\n-- cache the value\n\ncache:get(\"key\", { ttl = 5 }, function() return \"some value\" end)\n\n-- wait 2 seconds\n\nngx.sleep(2)\n\nlocal ttl, err, value = cache:peek(\"key\")\nif err then\n    ngx.log(ngx.ERR, \"could not peek cache: \", err)\n    return\nend\n\nngx.say(ttl)   -- 3\nngx.say(value) -- \"some value\"\n</code></pre> <p>Note: since mlcache <code>2.5.0</code>, it is also possible to call get() without a callback function in order to \"query\" the cache. Unlike <code>peek()</code>, a <code>get()</code> call with no callback will promote the value to the L1 cache, and will not return its TTL.</p>"},{"location":"lua/mlcache/#set","title":"set","text":"<p>syntax: <code>ok, err = cache:set(key, opts?, value)</code></p> <p>Unconditionally set a value in the L2 cache and broadcasts an event to other workers so they can refresh the value from their L1 cache.</p> <p>The first argument <code>key</code> is a string, and is the key under which to store the value.</p> <p>The second argument <code>opts</code> is optional, and if provided, is identical to the one of get().</p> <p>The third argument <code>value</code> is the value to cache, similar to the return value of the L3 callback. Just like the callback's return value, it must be a Lua scalar, a table, or <code>nil</code>. If a <code>l1_serializer</code> is provided either from the constructor or in the <code>opts</code> argument, it will be called with <code>value</code> if <code>value</code> is not <code>nil</code>.</p> <p>On success, the first return value will be <code>true</code>.</p> <p>On failure, this method returns <code>nil</code> and a string describing the error.</p> <p>Note: by its nature, <code>set()</code> requires that other instances of mlcache (from other workers) refresh their L1 cache. If <code>set()</code> is called from a single worker, other workers' mlcache instances bearing the same <code>name</code> must call update() before their cache be requested during the next request, to make sure they refreshed their L1 cache.</p> <p>Note bis: It is generally considered inefficient to call <code>set()</code> on a hot code path (such as in a request being served by OpenResty). Instead, one should rely on get() and its built-in mutex in the L3 callback. <code>set()</code> is better suited when called occasionally from a single worker, for example upon a particular event that triggers a cached value to be updated. Once <code>set()</code> updates the L2 cache with the fresh value, other workers will rely on update() to poll the invalidation event and invalidate their L1 cache, which will make them fetch the (fresh) value in L2.</p> <p>See: update()</p>"},{"location":"lua/mlcache/#delete","title":"delete","text":"<p>syntax: <code>ok, err = cache:delete(key)</code></p> <p>Delete a value in the L2 cache and publish an event to other workers so they can evict the value from their L1 cache.</p> <p>The first and only argument <code>key</code> is the string at which the value is stored.</p> <p>On success, the first return value will be <code>true</code>.</p> <p>On failure, this method returns <code>nil</code> and a string describing the error.</p> <p>Note: by its nature, <code>delete()</code> requires that other instances of mlcache (from other workers) refresh their L1 cache. If <code>delete()</code> is called from a single worker, other workers' mlcache instances bearing the same <code>name</code> must call update() before their cache be requested during the next request, to make sure they refreshed their L1 cache.</p> <p>See: update()</p>"},{"location":"lua/mlcache/#purge","title":"purge","text":"<p>syntax: <code>ok, err = cache:purge(flush_expired?)</code></p> <p>Purge the content of the cache, in both the L1 and L2 levels. Then publishes an event to other workers so they can purge their L1 cache as well.</p> <p>This method recycles the lua-resty-lrucache instance, and calls ngx.shared.DICT:flush_all , so it can be rather expensive.</p> <p>The first and only argument <code>flush_expired</code> is optional, but if given <code>true</code>, this method will also call ngx.shared.DICT:flush_expired (with no arguments). This is useful to release memory claimed by the L2 (shm) cache if needed.</p> <p>On success, the first return value will be <code>true</code>.</p> <p>On failure, this method returns <code>nil</code> and a string describing the error.</p> <p>Note: it is not possible to call <code>purge()</code> when using a custom LRU cache in OpenResty 1.13.6.1 and below. This limitation does not apply for OpenResty 1.13.6.2 and above.</p> <p>Note: by its nature, <code>purge()</code> requires that other instances of mlcache (from other workers) refresh their L1 cache. If <code>purge()</code> is called from a single worker, other workers' mlcache instances bearing the same <code>name</code> must call update() before their cache be requested during the next request, to make sure they refreshed their L1 cache.</p> <p>See: update()</p>"},{"location":"lua/mlcache/#update","title":"update","text":"<p>syntax: <code>ok, err = cache:update(timeout?)</code></p> <p>Poll and execute pending cache invalidation events published by other workers.</p> <p>The set(), delete(), and purge() methods require that other instances of mlcache (from other workers) refresh their L1 cache. Since OpenResty currently has no built-in mechanism for inter-worker communication, this module bundles an \"off-the-shelf\" IPC library to propagate inter-worker events. If the bundled IPC library is used, the <code>lua_shared_dict</code> specified in the <code>ipc_shm</code> option must not be used by other actors than mlcache itself.</p> <p>This method allows a worker to update its L1 cache (by purging values considered stale due to an other worker calling <code>set()</code>, <code>delete()</code>, or <code>purge()</code>) before processing a request.</p> <p>This method accepts a <code>timeout</code> argument whose unit is seconds and which defaults to <code>0.3</code> (300ms). The update operation will timeout if it isn't done when this threshold in reached. This avoids <code>update()</code> from staying on the CPU too long in case there are too many events to process. In an eventually consistent system, additional events can wait for the next call to be processed.</p> <p>A typical design pattern is to call <code>update()</code> only once before each request processing. This allows your hot code paths to perform a single shm access in the best case scenario: no invalidation events were received, all <code>get()</code> calls will hit in the L1 cache. Only on a worst case scenario (<code>n</code> values were evicted by another worker) will <code>get()</code> access the L2 or L3 cache <code>n</code> times. Subsequent requests will then hit the best case scenario again, because <code>get()</code> populated the L1 cache.</p> <p>For example, if your workers make use of set(), delete(), or purge() anywhere in your application, call <code>update()</code> at the entrance of your hot code path, before using <code>get()</code>:</p> <pre><code>http {\n    listen 9000;\n\n    location / {\n        content_by_lua_block {\n            local cache = ... -- retrieve mlcache instance\n\n            -- make sure L1 cache is evicted of stale values\n            -- before calling get()\n            local ok, err = cache:update()\n            if not ok then\n                ngx.log(ngx.ERR, \"failed to poll eviction events: \", err)\n                -- /!\\ we might get stale data from get()\n            end\n\n            -- L1/L2/L3 lookup (best case: L1)\n            local value, err = cache:get(\"key_1\", nil, cb1)\n\n            -- L1/L2/L3 lookup (best case: L1)\n            local other_value, err = cache:get(key_2\", nil, cb2)\n\n            -- value and other_value are up-to-date because:\n            -- either they were not stale and directly came from L1 (best case scenario)\n            -- either they were stale and evicted from L1, and came from L2\n            -- either they were not in L1 nor L2, and came from L3 (worst case scenario)\n        }\n    }\n\n    location /delete {\n        content_by_lua_block {\n            local cache = ... -- retrieve mlcache instance\n\n            -- delete some value\n            local ok, err = cache:delete(\"key_1\")\n            if not ok then\n                ngx.log(ngx.ERR, \"failed to delete value from cache: \", err)\n                return ngx.exit(500)\n            end\n\n            ngx.exit(204)\n        }\n    }\n\n    location /set {\n        content_by_lua_block {\n            local cache = ... -- retrieve mlcache instance\n\n            -- update some value\n            local ok, err = cache:set(\"key_1\", nil, 123)\n            if not ok then\n                ngx.log(ngx.ERR, \"failed to set value in cache: \", err)\n                return ngx.exit(500)\n            end\n\n            ngx.exit(200)\n        }\n    }\n}\n</code></pre> <p>Note: you do not need to call <code>update()</code> to refresh your workers if they never call <code>set()</code>,  <code>delete()</code>, or <code>purge()</code>. When workers only rely on <code>get()</code>, values expire naturally from the L1/L2 caches according to their TTL.</p> <p>Note bis: this library was built with the intent to use a better solution for inter-worker communication as soon as one emerges. In future versions of this library, if an IPC library can avoid the polling approach, so will this library. <code>update()</code> is only a necessary evil due to today's Nginx/OpenResty \"limitations\". You can however use your own IPC library by use of the <code>opts.ipc</code> option when creating your mlcache instance.</p>"},{"location":"lua/mlcache/#resources","title":"Resources","text":"<p>In November 2018, this library was presented at OpenResty Con in Hangzhou, China.</p> <p>The slides and a recording of the talk (about 40 min long) can be viewed [here][talk].</p>"},{"location":"lua/mlcache/#changelog","title":"Changelog","text":"<p>See CHANGELOG.md.</p>"},{"location":"lua/mlcache/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-mlcache.</p>"},{"location":"lua/multiplexer/","title":"multiplexer: Transparent port service multiplexer for stream subsystem","text":""},{"location":"lua/multiplexer/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/multiplexer/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-multiplexer\n</code></pre>"},{"location":"lua/multiplexer/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-multiplexer\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-multiplexer v0.2  released on Aug 31 2020.</p> <p>lua-resty-multiplexer - Transparent port service multiplexer for stream subsystem </p>"},{"location":"lua/multiplexer/#description","title":"Description","text":"<p>This library implemented a transparent port service multiplexer, which can be used to run multiple TCP services on the same port.</p> <p>Note that nginx stream module and stream-lua-nginx-module is required.</p> <p>Tested on Openresty &gt;= 1.13.6.1.</p> <p>With OpenResty 1.13.6.1, a customed patch from @fcicq is needed. The origin discussion can be found here. And native proxying is not supported as <code>reqsock:peek</code> is missing.</p> <p>Starting OpenResty 1.15.8.1, only native proxying is supported and no patch is needed. Lua land proxying will be possible when stream-lua-nginx-module implemented <code>tcpsock:receiveany</code>.</p>"},{"location":"lua/multiplexer/#status","title":"Status","text":"<p>Experimental.</p>"},{"location":"lua/multiplexer/#synopsis","title":"Synopsis","text":"<pre><code>stream {\n    init_by_lua_block {\n        local mul = require(\"resty.multiplexer\")\n        mul.load_protocols(\n            \"http\", \"ssh\", \"dns\", \"tls\", \"xmpp\"\n        )\n        mul.set_rules(\n            {{\"client-host\", \"10.0.0.1\"}, \"internal-host\", 80},\n            {{\"protocol\", \"http\"}, {\"client-host\", \"10.0.0.2\"}, \"internal-host\", 8001},\n            {{\"protocol\", \"http\"}, \"example.com\", 80},\n            {{\"protocol\", \"ssh\"}, \"github.com\", 22},\n            {{\"protocol\", \"dns\"}, \"1.1.1.1\", 53},\n            {{\"protocol\", \"tls\"}, {\"time\", nil}, \"twitter.com\", 443},\n            {{\"protocol\", \"tls\"}, \"www.google.com\", 443},\n            {{\"default\", nil}, \"127.0.0.1\", 80}\n        )\n        mul.matcher_config.time = {\n            minute_match = {0, 30},\n            minute_not_match = {{31, 59}},\n        }\n    }\n\n    resolver 8.8.8.8;\n\n    # for OpenResty &gt;= 1.13.6.1, native Nginx proxying\n    lua_add_variable $multiplexer_upstream;\n    server {\n            error_log /var/log/nginx/multiplexer-error.log error;\n            listen 443;\n\n            resolver 8.8.8.8;\n\n            preread_by_lua_block {\n                local mul = require(\"resty.multiplexer\")\n                local mp = mul:new()\n                mp:preread_by()\n            }\n            proxy_pass $multiplexer_upstream;\n    }\n\n    # for OpenResty &lt; 1.13.6.1, Lua land proxying\n    server {\n            error_log /var/log/nginx/multiplexer-error.log error;\n            listen 443;\n\n            resolver 8.8.8.8;\n\n            server {\n                listen 80;\n                content_by_lua_block {\n                    local mul = require(\"resty.multiplexer\")\n                    local mp = mul:new()\n                    mp:content_by()\n                }\n            }\n    }\n}\n</code></pre> <p>This module consists of two parts: protocol identifiers and matchers.</p> <p>Protocol identifies need to loaded through <code>load_protocols</code> in <code>init_by_lua_block</code> directive. See protocol section for currently supported protocols and guide to add a new protocol.</p> <p>Rules are defined through <code>set_rules</code> to route traffic to different upstreams. For every matcher that is defined in the rule, the corresponding matcher is loaded automatically. See matcher section for currently implmented matchers and guide to add a new matcher.</p> <p>See API section for syntax of <code>load_protocols</code> and <code>set_rules</code>.</p> <p>The rules defined is prioritized. In the example above, we defined a rule such that:</p> <ul> <li>If client address is <code>10.0.0.1</code>, proxy to internal-host.com:80</li> <li>If protocol is <code>HTTP</code> and client address is <code>10.0.0.2</code>, proxy to internal-host:8001</li> <li>If protocol is <code>SSH</code>, proxy to github.com:22</li> <li>If protocol is <code>DNS</code>, proxy to 1.1.1.1:53</li> <li>If protocol is <code>SSL/TLS</code> and current minute is between 0 and 30,  proxy to twitter:443</li> <li>If protocol is <code>SSL/TLS</code> and current minute is between 31 and 59, proxy to www.google.com:443</li> <li>Otherwise, proxy to 127.0.0.1:80</li> </ul>"},{"location":"lua/multiplexer/#protocol","title":"Protocol","text":"<p>The protocol part analyzes the first request that is sent from client and try to match it using known protocol signatures.</p> <p>Currently supported: <code>dns</code>, <code>http</code>, <code>ssh</code>, <code>tls</code>, <code>xmpp</code>. Based on the bytes of signature, each protocol may have different possibilities to be falsely identified.</p> Protocol Length of signature False rate dns 9 1/4 5.29e-23 http 4 2.33e-10 ssh 4 2.33e-10 tls 6 3.55e-15 xmpp 6 in 8 1/4 ?"},{"location":"lua/multiplexer/#add-new-protocol","title":"Add new protocol","text":"<p>Create a new <code>protocol_name.lua</code> file under <code>resty/multiplexer/protocol</code> in the format of:</p> <pre><code>return {\n    required_bytes = ?,\n    check = function(buf)\n    -- check with the buf and return true if the protocol is identified\n    end\n}\n</code></pre> <p><code>required_bytes</code> is the length of bytes we need to read before identifying the protocol. </p>"},{"location":"lua/multiplexer/#matcher","title":"Matcher","text":""},{"location":"lua/multiplexer/#client-host","title":"client-host","text":"<p>Match if <code>$remote_addr</code> equals to expected value.</p>"},{"location":"lua/multiplexer/#protocol_1","title":"protocol","text":"<p>Match if protocol equals to expected value.</p>"},{"location":"lua/multiplexer/#time","title":"time","text":"<p>Match if current time is in configured range in <code>mul.matcher_config.time</code>. If no range is defined, the matcher will always return false.</p> <p>For example, to match year <code>2018</code>, <code>January</code> and <code>March</code> and hour <code>6</code> to <code>24</code> except for hour <code>12</code>:</p> <pre><code> init_by_lua_block {\n    local mul = require(\"resty.multiplexer\")\n    mul.load_protocols(\n        \"http\", \"ssh\", \"dns\", \"tls\", \"xmpp\"\n    )\n    mul.set_rules(\n        {{\"time\", \"\"}, \"twitter.com\", 443}\n    )\n    mul.matcher_config.time = {\n        year_match = {2018},\n        year_not_match = {},\n        month_match = {{1}, {3}},\n        month_not_match = {},\n        day_match = {}, -- day of month\n        day_not_match = {},\n        hour_match = {{6, 24}},\n        hour_not_match = {{12}},\n        minute_match = {},\n        minute_not_match = {},\n        second_match = {},\n        second_not_match = {},\n    }\n }\n</code></pre>"},{"location":"lua/multiplexer/#default","title":"default","text":"<p>Always matches.</p>"},{"location":"lua/multiplexer/#add-new-matcher","title":"Add new matcher","text":"<p>Create a new <code>matcher_name.lua</code> file under <code>resty/multiplexer/matchers</code> in the format of:</p> <pre><code>local _M = {}\n\nfunction _M.match(protocol, expected)\n    -- return true if it's a match\nend\n\nreturn _M\n</code></pre> <p>Where <code>protocol</code> is the identified protocol in lowercase string, and <code>expected</code> is the expected value for this matcher defined in <code>set_rules</code>.</p>"},{"location":"lua/multiplexer/#api","title":"API","text":""},{"location":"lua/multiplexer/#multiplexernew","title":"multiplexer.new","text":"<p>syntax: multiplexer:new(connect_timeout, send_timeout, read_timeout)</p> <p>Initialize the multiplexer instance. And sets the connect timeout thresold, send timeout threshold, and read timeout threshold, as in tcpsock:settimeouts.</p>"},{"location":"lua/multiplexer/#multiplexerload_protocols","title":"multiplexer.load_protocols","text":"<p>syntax: multiplexer:load_protocols(\"protocol-1\", \"protocol-2\", ...)</p> <p>Load the protocol modules into memory.</p> <p>Supported protocols can be found in protocol.</p>"},{"location":"lua/multiplexer/#multiplexerset_rules","title":"multiplexer.set_rules","text":"<p>syntax: multiplexer:set_rules(rule1, rule2, ...)</p> <p>Load rules in order. Each rule is an array table that is in the format of:</p> <pre><code>{{\"matcher-1\", \"expected-value-1\"}, {\"matcher-2\", \"expected-value-2\"}, ..., \"upstream_host\", upstream_port}\n</code></pre> <p>Supported matchers can be found in matcher.</p>"},{"location":"lua/multiplexer/#see-also","title":"See Also","text":"<ul> <li>Original patch to add the read partial mode</li> <li>stream-lua-nginx-module</li> <li>yrutschle/sslh</li> </ul>"},{"location":"lua/multiplexer/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-multiplexer.</p>"},{"location":"lua/murmurhash2/","title":"murmurhash2: LuaJIT MurmurHash 2 bindings to NGINX / nginx-module-lua murmurhash2 implementation","text":""},{"location":"lua/murmurhash2/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/murmurhash2/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-murmurhash2\n</code></pre>"},{"location":"lua/murmurhash2/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-murmurhash2\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-murmurhash2 v1.0  released on Sep 29 2014.</p> <p>lua-resty-murmurhash2 is MurmurHash 2 library (LuaJIT bindings) for OpenResty's / Nginx's murmurhash2 implementation.</p>"},{"location":"lua/murmurhash2/#lua-api","title":"Lua API","text":""},{"location":"lua/murmurhash2/#number-require-restymurmurhash2-string","title":"number require \"resty.murmurhash2\" string","text":"<p>This module has only one function that you can get just by requiring this module:</p> <pre><code>local mmh2 = require \"resty.murmurhash2\"\nlocal hash = mmh2 \"test\" -- hash contains number 403862830\n</code></pre>"},{"location":"lua/murmurhash2/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-murmurhash2.</p>"},{"location":"lua/mysql/","title":"mysql: Nonblocking Lua MySQL driver library for nginx-module-lua","text":""},{"location":"lua/mysql/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/mysql/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-mysql\n</code></pre>"},{"location":"lua/mysql/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-mysql\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-mysql v0.28  released on May 08 2025.</p> <p>lua-resty-mysql - Lua MySQL client driver for ngx_lua based on the cosocket API</p>"},{"location":"lua/mysql/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/mysql/#description","title":"Description","text":"<p>This Lua library is a MySQL client driver for the ngx_lua nginx module:</p> <p>https://github.com/openresty/lua-nginx-module</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.9.11 or ngx_openresty 1.7.4.1 is required.</p> <p>Also, the bit library is also required. If you're using LuaJIT 2 with ngx_lua, then the <code>bit</code> library is already available by default.</p>"},{"location":"lua/mysql/#synopsis","title":"Synopsis","text":"<pre><code>    # you do not need the following line if you are using\n    # the ngx_openresty bundle:\n    server {\n        location /test {\n            content_by_lua '\n                local mysql = require \"resty.mysql\"\n                local db, err = mysql:new()\n                if not db then\n                    ngx.say(\"failed to instantiate mysql: \", err)\n                    return\n                end\n\n                db:set_timeout(1000) -- 1 sec\n\n                -- or connect to a unix domain socket file listened\n                -- by a mysql server:\n                --     local ok, err, errcode, sqlstate =\n                --           db:connect{\n                --              path = \"/path/to/mysql.sock\",\n                --              database = \"ngx_test\",\n                --              user = \"ngx_test\",\n                --              password = \"ngx_test\" }\n\n                local ok, err, errcode, sqlstate = db:connect{\n                    host = \"127.0.0.1\",\n                    port = 3306,\n                    database = \"ngx_test\",\n                    user = \"ngx_test\",\n                    password = \"ngx_test\",\n                    charset = \"utf8\",\n                    max_packet_size = 1024 * 1024,\n                }\n\n                if not ok then\n                    ngx.say(\"failed to connect: \", err, \": \", errcode, \" \", sqlstate)\n                    db:close()\n                    return\n                end\n\n                ngx.say(\"connected to mysql.\")\n\n                local res, err, errcode, sqlstate =\n                    db:query(\"drop table if exists cats\")\n                if not res then\n                    ngx.say(\"bad result: \", err, \": \", errcode, \": \", sqlstate, \".\")\n                    db:close()\n                    return\n                end\n\n                res, err, errcode, sqlstate =\n                    db:query(\"create table cats \"\n                             .. \"(id serial primary key, \"\n                             .. \"name varchar(5))\")\n                if not res then\n                    ngx.say(\"bad result: \", err, \": \", errcode, \": \", sqlstate, \".\")\n                    db:close()\n                    return\n                end\n\n                ngx.say(\"table cats created.\")\n\n                res, err, errcode, sqlstate =\n                    db:query(\"insert into cats (name) \"\n                             .. \"values (\\'Bob\\'),(\\'\\'),(null)\")\n                if not res then\n                    ngx.say(\"bad result: \", err, \": \", errcode, \": \", sqlstate, \".\")\n                    db:close()\n                    return\n                end\n\n                ngx.say(res.affected_rows, \" rows inserted into table cats \",\n                        \"(last insert id: \", res.insert_id, \")\")\n\n                -- run a select query, expected about 10 rows in\n                -- the result set:\n                res, err, errcode, sqlstate =\n                    db:query(\"select * from cats order by id asc\", 10)\n                if not res then\n                    ngx.say(\"bad result: \", err, \": \", errcode, \": \", sqlstate, \".\")\n                    db:close()\n                    return\n                end\n\n                local cjson = require \"cjson\"\n                ngx.say(\"result: \", cjson.encode(res))\n\n                -- put it into the connection pool of size 100,\n                -- with 10 seconds max idle timeout\n                local ok, err = db:set_keepalive(10000, 100)\n                if not ok then\n                    ngx.say(\"failed to set keepalive: \", err)\n                    db:close()\n                    return\n                end\n\n                -- or just close the connection right away:\n                -- local ok, err = db:close()\n                -- if not ok then\n                --     ngx.say(\"failed to close: \", err)\n                --     return\n                -- end\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/mysql/#methods","title":"Methods","text":""},{"location":"lua/mysql/#new","title":"new","text":"<p><code>syntax: db, err = mysql:new()</code></p> <p>Creates a MySQL connection object. In case of failures, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/mysql/#connect","title":"connect","text":"<p><code>syntax: ok, err, errcode, sqlstate = db:connect(options)</code></p> <p>Attempts to connect to the remote MySQL server.</p> <p>The <code>options</code> argument is a Lua table holding the following keys:</p> <ul> <li> <p><code>host</code></p> <p>the host name for the MySQL server. * <code>port</code></p> <p>the port that the MySQL server is listening on. Default to 3306. * <code>path</code></p> <p>the path of the unix socket file listened by the MySQL server. * <code>database</code></p> <p>the MySQL database name. * <code>user</code></p> <p>MySQL account name for login. * <code>password</code></p> <p>MySQL account password for login (in clear text). * <code>charset</code></p> <p>the character set used on the MySQL connection, which can be different from the default charset setting. The following values are accepted: <code>big5</code>, <code>dec8</code>, <code>cp850</code>, <code>hp8</code>, <code>koi8r</code>, <code>latin1</code>, <code>latin2</code>, <code>swe7</code>, <code>ascii</code>, <code>ujis</code>, <code>sjis</code>, <code>hebrew</code>, <code>tis620</code>, <code>euckr</code>, <code>koi8u</code>, <code>gb2312</code>, <code>greek</code>, <code>cp1250</code>, <code>gbk</code>, <code>latin5</code>, <code>armscii8</code>, <code>utf8</code>, <code>ucs2</code>, <code>cp866</code>, <code>keybcs2</code>, <code>macce</code>, <code>macroman</code>, <code>cp852</code>, <code>latin7</code>, <code>utf8mb4</code>, <code>cp1251</code>, <code>utf16</code>, <code>utf16le</code>, <code>cp1256</code>, <code>cp1257</code>, <code>utf32</code>, <code>binary</code>, <code>geostd8</code>, <code>cp932</code>, <code>eucjpms</code>, <code>gb18030</code>. * <code>max_packet_size</code></p> <p>the upper limit for the reply packets sent from the MySQL server (default to 1MB). * <code>ssl</code></p> <p>If set to <code>true</code>, then uses SSL to connect to MySQL (default to <code>false</code>). If the MySQL server does not have SSL support (or just disabled), the error string \"ssl disabled on server\" will be returned. * <code>ssl_verify</code></p> <p>If set to <code>true</code>, then verifies the validity of the server SSL certificate (default to <code>false</code>). Note that you need to configure the lua_ssl_trusted_certificate to specify the CA (or server) certificate used by your MySQL server. You may also need to configure lua_ssl_verify_depth accordingly. * <code>pool</code></p> <p>the name for the MySQL connection pool. if omitted, an ambiguous pool name will be generated automatically with the string template <code>user:database:host:port</code> or <code>user:database:path</code>. (this option was first introduced in <code>v0.08</code>.)</p> </li> <li> <p><code>pool_size</code></p> <p>Specifies the size of the connection pool. If omitted and no <code>backlog</code> option was provided, no pool will be created. If omitted but <code>backlog</code> was provided, the pool will be created with a default size equal to the value of the lua_socket_pool_size directive. The connection pool holds up to <code>pool_size</code> alive connections ready to be reused by subsequent calls to connect, but note that there is no upper limit to the total number of opened connections outside of the pool. If you need to restrict the total number of opened connections, specify the <code>backlog</code> option. When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so the size limit specified here also applies to every single Nginx worker process. Also note that the size of the connection pool cannot be changed once it has been created. Note that at least ngx_lua 0.10.14 is required to use this options.</p> </li> <li> <p><code>backlog</code></p> <p>If specified, this module will limit the total number of opened connections for this pool. No more connections than <code>pool_size</code> can be opened for this pool at any time. If the connection pool is full, subsequent connect operations will be queued into a queue equal to this option's value (the \"backlog\" queue). If the number of queued connect operations is equal to <code>backlog</code>, subsequent connect operations will fail and return nil plus the error string <code>\"too many waiting connect operations\"</code>. The queued connect operations will be resumed once the number of connections in the pool is less than <code>pool_size</code>. The queued connect operation will abort once they have been queued for more than <code>connect_timeout</code>, controlled by set_timeout, and will return nil plus the error string \"timeout\". Note that at least ngx_lua 0.10.14 is required to use this options.</p> </li> <li> <p><code>compact_arrays</code></p> <p>when this option is set to true, then the query and read_result methods will return the array-of-arrays structure for the resultset, rather than the default array-of-hashes structure.</p> </li> </ul> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p>"},{"location":"lua/mysql/#set_timeout","title":"set_timeout","text":"<p><code>syntax: db:set_timeout(time)</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the <code>connect</code> method.</p>"},{"location":"lua/mysql/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = db:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Puts the current MySQL connection immediately into the ngx_lua cosocket connection pool.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p> <p>Only call this method in the place you would have called the <code>close</code> method instead. Calling this method will immediately turn the current <code>resty.mysql</code> object into the <code>closed</code> state. Any subsequent operations other than <code>connect()</code> on the current objet will return the <code>closed</code> error.</p>"},{"location":"lua/mysql/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: times, err = db:get_reused_times()</code></p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p>"},{"location":"lua/mysql/#close","title":"close","text":"<p><code>syntax: ok, err = db:close()</code></p> <p>Closes the current mysql connection and returns the status.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/mysql/#send_query","title":"send_query","text":"<p><code>syntax: bytes, err = db:send_query(query)</code></p> <p>Sends the query to the remote MySQL server without waiting for its replies.</p> <p>Returns the bytes successfully sent out in success and otherwise returns <code>nil</code> and a string describing the error.</p> <p>You should use the read_result method to read the MySQL replies afterwards.</p>"},{"location":"lua/mysql/#read_result","title":"read_result","text":"<p><code>syntax: res, err, errcode, sqlstate = db:read_result()</code></p> <p><code>syntax: res, err, errcode, sqlstate = db:read_result(nrows)</code></p> <p>Reads in one result returned from the MySQL server.</p> <p>It returns a Lua table (<code>res</code>) describing the MySQL <code>OK packet</code> or <code>result set packet</code> for the query result.</p> <p>For queries corresponding to a result set, it returns an array holding all the rows. Each row holds key-value pairs for each data fields. For instance,</p> <pre><code>    {\n        { name = \"Bob\", age = 32, phone = ngx.null },\n        { name = \"Marry\", age = 18, phone = \"10666372\"}\n    }\n</code></pre> <p>For queries that do not correspond to a result set, it returns a Lua table like this:</p> <pre><code>    {\n        insert_id = 0,\n        server_status = 2,\n        warning_count = 1,\n        affected_rows = 32,\n        message = nil\n    }\n</code></pre> <p>If more results are following the current result, a second <code>err</code> return value will be given the string <code>again</code>. One should always check this (second) return value and if it is <code>again</code>, then she should call this method again to retrieve more results. This usually happens when the original query contains multiple statements (separated by semicolon in the same query string) or calling a MySQL procedure. See also Multi-Resultset Support.</p> <p>In case of errors, this method returns at most 4 values: <code>nil</code>, <code>err</code>, <code>errcode</code>, and <code>sqlstate</code>. The <code>err</code> return value contains a string describing the error, the <code>errcode</code> return value holds the MySQL error code (a numerical value), and finally, the <code>sqlstate</code> return value contains the standard SQL error code that consists of 5 characters. Note that, the <code>errcode</code> and <code>sqlstate</code> might be <code>nil</code> if MySQL does not return them.</p> <p>The optional argument <code>nrows</code> can be used to specify an approximate number of rows for the result set. This value can be used to pre-allocate space in the resulting Lua table for the result set. By default, it takes the value 4.</p>"},{"location":"lua/mysql/#query","title":"query","text":"<p><code>syntax: res, err, errcode, sqlstate = db:query(query)</code></p> <p><code>syntax: res, err, errcode, sqlstate = db:query(query, nrows)</code></p> <p>This is a shortcut for combining the send_query call and the first read_result call.</p> <p>You should always check if the <code>err</code> return value  is <code>again</code> in case of success because this method will only call read_result only once for you. See also Multi-Resultset Support.</p>"},{"location":"lua/mysql/#server_ver","title":"server_ver","text":"<p><code>syntax: str = db:server_ver()</code></p> <p>Returns the MySQL server version string, like <code>\"5.1.64\"</code>.</p> <p>You should only call this method after successfully connecting to a MySQL server, otherwise <code>nil</code> will be returned.</p>"},{"location":"lua/mysql/#set_compact_arrays","title":"set_compact_arrays","text":"<p><code>syntax: db:set_compact_arrays(boolean)</code></p> <p>Sets whether to use the \"compact-arrays\" structure for the resultsets returned by subsequent queries. See the <code>compact_arrays</code> option for the <code>connect</code> method for more details.</p> <p>This method was first introduced in the <code>v0.09</code> release.</p>"},{"location":"lua/mysql/#sql-literal-quoting","title":"SQL Literal Quoting","text":"<p>It is always important to quote SQL literals properly to prevent SQL injection attacks. You can use the ngx.quote_sql_str function provided by ngx_lua to quote values. Here is an example:</p> <pre><code>    local name = ngx.unescape_uri(ngx.var.arg_name)\n    local quoted_name = ngx.quote_sql_str(name)\n    local sql = \"select * from users where name = \" .. quoted_name\n</code></pre>"},{"location":"lua/mysql/#multi-resultset-support","title":"Multi-Resultset Support","text":"<p>For a SQL query that produces multiple result-sets, it is always your duty to check the \"again\" error message returned by the query or read_result method calls, and keep pulling more result sets by calling the read_result method until no \"again\" error message returned (or some other errors happen).</p> <p>Below is a trivial example for this:</p> <pre><code>    local cjson = require \"cjson\"\n    local mysql = require \"resty.mysql\"\n\n    local db = mysql:new()\n    local ok, err, errcode, sqlstate = db:connect({\n        host = \"127.0.0.1\",\n        port = 3306,\n        database = \"world\",\n        user = \"monty\",\n        password = \"pass\"})\n\n    if not ok then\n        ngx.log(ngx.ERR, \"failed to connect: \", err, \": \", errcode, \" \", sqlstate)\n        return ngx.exit(500)\n    end\n\n    res, err, errcode, sqlstate = db:query(\"select 1; select 2; select 3;\")\n    if not res then\n        ngx.log(ngx.ERR, \"bad result #1: \", err, \": \", errcode, \": \", sqlstate, \".\")\n        db:close()\n        return ngx.exit(500)\n    end\n\n    ngx.say(\"result #1: \", cjson.encode(res))\n\n    local i = 2\n    while err == \"again\" do\n        res, err, errcode, sqlstate = db:read_result()\n        if not res then\n            ngx.log(ngx.ERR, \"bad result #\", i, \": \", err, \": \", errcode, \": \", sqlstate, \".\")\n            db:close()\n            return ngx.exit(500)\n        end\n\n        ngx.say(\"result #\", i, \": \", cjson.encode(res))\n        i = i + 1\n    end\n\n    local ok, err = db:set_keepalive(10000, 50)\n    if not ok then\n        ngx.log(ngx.ERR, \"failed to set keepalive: \", err)\n        db:close()\n        ngx.exit(500)\n    end\n</code></pre> <p>This code snippet will produce the following response body data:</p> <pre><code>result #1: [{\"1\":\"1\"}]\nresult #2: [{\"2\":\"2\"}]\nresult #3: [{\"3\":\"3\"}]\n</code></pre>"},{"location":"lua/mysql/#debugging","title":"Debugging","text":"<p>It is usually convenient to use the lua-cjson library to encode the return values of the MySQL query methods to JSON. For example,</p> <pre><code>    local cjson = require \"cjson\"\n    ...\n    local res, err, errcode, sqlstate = db:query(\"select * from cats\")\n    if res then\n        print(\"res: \", cjson.encode(res))\n    end\n</code></pre>"},{"location":"lua/mysql/#automatic-error-logging","title":"Automatic Error Logging","text":"<p>By default the underlying ngx_lua module does error logging when socket errors happen. If you are already doing proper error handling in your own Lua code, then you are recommended to disable this automatic error logging by turning off ngx_lua's lua_socket_log_errors directive, that is,</p> <pre><code>    lua_socket_log_errors off;\n</code></pre>"},{"location":"lua/mysql/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like init_by_lua, set_by_lua, log_by_lua, and header_filter_by_lua where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.mysql</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see https://github.com/openresty/lua-nginx-module#data-sharing-within-an-nginx-worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.mysql</code> instance. You should always initiate <code>resty.mysql</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/mysql/#more-authentication-method-support","title":"More Authentication Method Support","text":"<p>By default, Of all authentication method, only Old Password Authentication(mysql_old_password) and Secure Password Authentication(mysql_native_password) are suppored. If the server requires sha256_password or cache_sha2_password, an error like <code>auth plugin caching_sha2_password or sha256_password are not supported because resty.rsa is not installed</code> may be returned.</p> <p>Need lua-resty-rsa when using the <code>sha256_password</code> and <code>cache_sha2_password</code>.</p>"},{"location":"lua/mysql/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>the MySQL wired protocol specification: http://forge.mysql.com/wiki/MySQL_Internals_ClientServer_Protocol</li> <li>the lua-resty-memcached library</li> <li>the lua-resty-redis library</li> <li>the ngx_drizzle module: https://github.com/openresty/drizzle-nginx-module</li> </ul>"},{"location":"lua/mysql/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-mysql.</p>"},{"location":"lua/nettle/","title":"nettle: LuaJIT FFI bindings for Nettle (a low-level cryptographic library)","text":""},{"location":"lua/nettle/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/nettle/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-nettle\n</code></pre>"},{"location":"lua/nettle/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-nettle\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-nettle v2.1  released on Apr 07 2021.</p> <p>LuaJIT FFI bindings for Nettle (a low-level cryptographic library)</p>"},{"location":"lua/nettle/#synopsis","title":"Synopsis","text":"<pre><code>local require = require\nlocal print = print\nlocal gsub = string.gsub\nlocal byte = string.byte\nlocal format = string.format\nlocal ipairs = ipairs\nlocal concat = table.concat\n\nlocal function hex(str,spacer)\n  return (gsub(str,\"(.)\", function (c)\n    return format(\"%02X%s\", byte(c), spacer or \"\")\n  end))\nend\n\ndo\n  local md2 = require \"resty.nettle.md2\"\n  print(\"md2      \", #md2(\"\"), hex(md2(\"\")))\n  local hash = md2.new()\n  hash:update(\"\")\n  print(\"md2     \", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local md4 = require \"resty.nettle.md4\"\n  print(\"md4      \", #md4(\"\"), hex(md4(\"\")))\n  local hash = md4.new()\n  hash:update(\"\")\n  print(\"md4      \", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local md5 = require \"resty.nettle.md5\"\n  print(\"md5      \", #md5(\"\"), hex(md5(\"\")))\n  local hash = md5.new()\n  hash:update(\"\")\n  print(\"md5      \", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local ripemd160 = require \"resty.nettle.ripemd160\"\n  local hash = ripemd160.new()\n  hash:update(\"\")\n  print(\"ripemd160\", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local gosthash94 = require \"resty.nettle.gosthash94\"\n  local hash = gosthash94.new()\n  hash:update(\"\")\n  print(\"gosthash94\", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local sha1 = require \"resty.nettle.sha1\"\n  print(\"sha1      \", #sha1(\"\"), hex(sha1(\"\")))\n  local hash = sha1.new()\n  hash:update(\"\")\n  print(\"sha1     \", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local sha2 = require \"resty.nettle.sha2\"\n\n  local hash = sha2.sha224.new()\n  hash:update(\"\")\n  print(\"sha224      \", #hash:digest(), hex(hash:digest()))\n  print(\"sha224      \", #sha2.sha224(\"\"), hex(sha2.sha224(\"\")))\n\n  local hash = sha2.sha256.new()\n  hash:update(\"\")\n  print(\"sha256      \", #hash:digest(), hex(hash:digest()))\n  print(\"sha256      \", #sha2.sha256(\"\"), hex(sha2.sha256(\"\")))\n\n  local hash = sha2.sha384.new()\n  hash:update(\"\")\n  print(\"sha384      \", #hash:digest(), hex(hash:digest()))\n  print(\"sha384      \", #sha2.sha384(\"\"), hex(sha2.sha384(\"\")))\n\n  local hash = sha2.sha512.new()\n  hash:update(\"\")\n  print(\"sha512      \", #hash:digest(), hex(hash:digest()))\n  print(\"sha512      \", #sha2.sha512(\"\"), hex(sha2.sha512(\"\")))\n\n  local hash = sha2.sha512_224.new()\n  hash:update(\"\")\n  print(\"sha512_224\", #hash:digest(), hex(hash:digest()))\n  print(\"sha512_224\", #sha2.sha512_224(\"\"), hex(sha2.sha512_224(\"\")))\n\n  local hash = sha2.sha512_256.new()\n  hash:update(\"\")\n  print(\"sha512_256\", #hash:digest(), hex(hash:digest()))\n  print(\"sha512_256\", #sha2.sha512_256(\"\"), hex(sha2.sha512_256(\"\")))\nend\n\ndo\n  local sha3 = require \"resty.nettle.sha3\"\n\n  local hash = sha3.sha224.new()\n  hash:update(\"\")\n  print(\"sha3 224\", #hash:digest(), hex(hash:digest()))\n\n  local hash = sha3.sha256.new()\n  hash:update(\"\")\n  print(\"sha3 256\", #hash:digest(), hex(hash:digest()))\n\n  local hash = sha3.sha384.new()\n  hash:update(\"\")\n  print(\"sha3 384\", #hash:digest(), hex(hash:digest()))\n\n  local hash = sha3.sha512.new()\n  hash:update(\"\")\n  print(\"sha3 512\", #hash:digest(), hex(hash:digest()))\nend\n\ndo\n  local hmac = require \"resty.nettle.hmac\"\n  print(\"hmac md5\", #hmac(\"md5\", \"a\", \"a\"), hex(hmac(\"md5\", \"a\", \"a\")))\n  print(\"hmac md5\", #hmac.md5(\"a\", \"a\"), hex(hmac.md5(\"a\", \"a\")))\n  local hash = hmac.md5.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac md5\", #dgst, hex(dgst))\n\n  local hash = hmac.ripemd160.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac ripemd160\", #dgst, hex(dgst))\n\n  local hash = hmac.sha1.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac sha1\", #dgst, hex(dgst))\n\n  local hash = hmac.sha224.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac sha224\", #dgst, hex(dgst))\n\n  local hash = hmac.sha256.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac sha256\", #dgst, hex(dgst))\n\n  local hash = hmac.sha384.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac sha384\", #dgst, hex(dgst))\n\n  local hash = hmac.sha512.new(\"a\")\n  hash:update(\"a\")\n  local dgst = hash:digest()\n  print(\"hmac sha512\", #dgst, hex(dgst))\nend\n\ndo\n  local umac = require \"resty.nettle.umac\"\n  local hash = umac.umac32.new(\"umac32\")\n  hash:update(\"\")\n  local dgst = hash:digest()\n  print(\"umac32     \", #dgst, hex(dgst))\n\n  local hash = umac.umac64.new(\"umac64\")\n  hash:update(\"\")\n  local dgst = hash:digest()\n  print(\"umac64     \", #dgst, hex(dgst))\n\n  local hash = umac.umac96.new(\"umac96\")\n  hash:update(\"\")\n  local dgst = hash:digest()\n  print(\"umac96     \", #dgst, hex(dgst))\n\n  local hash = umac.umac128.new(\"umac128\")\n  hash:update(\"\")\n  local dgst = hash:digest()\n  print(\"umac128     \", #dgst, hex(dgst))\nend\n\ndo\n  local poly = require \"resty.nettle.poly1305\"\n  local hash = poly.new(\"poly\")\n  hash:update(\"\")\n  local dgst = hash:digest()\n  print(\"poly1305    \", #dgst, hex(dgst))\nend\n\ndo\n  local pbkdf2 = require \"resty.nettle.pbkdf2\"\n  local hmac = pbkdf2.hmac_sha1(\"password\", 1, \"salt\", 20)\n  print(\"pbkdf2 sha1\", #hmac, hex(hmac))\n  local hmac = pbkdf2.hmac_sha256(\"pass\\0word\", 4096, \"sa\\0lt\", 32)\n  print(\"pbkdf2 sha256\", #hmac, hex(hmac))\nend\n\nprint()\n\ndo\n  local aes = require \"resty.nettle.aes\"\n  local aes128 = aes.new(\"testtesttesttest\")\n  local ciphertext = aes128:encrypt(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n  print(\"aes128 encrypt\", #ciphertext, hex(ciphertext))\n  local aes128 = aes.new(\"testtesttesttest\")\n  local plaintext = aes128:decrypt(ciphertext)\n  print(\"aes128 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local aes128 = aes.new(\"testtesttesttest\", \"cbc\", \"testtesttesttest\")\n  local ciphertext = aes128:encrypt(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n  print(\"aes128 cbc enc\", #ciphertext, hex(ciphertext))\n  local aes128 = aes.new(\"testtesttesttest\", \"cbc\", \"testtesttesttest\")\n  local plaintext = aes128:decrypt(ciphertext)\n  print(\"aes128 cbc dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes128 = aes.new(\"testtesttesttest\", \"ctr\", \"testtesttesttest\")\n  local ciphertext = aes128:encrypt(\"a\")\n  print(\"aes128 ctr enc\", #ciphertext, hex(ciphertext))\n  local aes128 = aes.new(\"testtesttesttest\", \"ctr\", \"testtesttesttest\")\n  local plaintext = aes128:decrypt(ciphertext)\n  print(\"aes128 ctr dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes128 = aes.new(\"testtesttesttest\", \"eax\", \"testtesttest\")\n  local ciphertext, digest = aes128:encrypt(\"a\")\n  print(\"aes128 eax enc\", #ciphertext, hex(ciphertext))\n  print(\"aes128 eax dgst\", #digest, hex(digest))\n  local aes128 = aes.new(\"testtesttesttest\", \"eax\", \"testtesttest\")\n  local plaintext, digest = aes128:decrypt(ciphertext)\n  print(\"aes128 eax dec\", #plaintext, plaintext)\n  print(\"aes128 eax dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes128 = aes.new(\"testtesttesttest\", \"gcm\", \"testtesttest\")\n  local ciphertext, digest = aes128:encrypt(\"a\")\n  print(\"aes128 gcm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes128 gcm dgst\", #digest, hex(digest))\n  local aes128 = aes.new(\"testtesttesttest\", \"gcm\", \"testtesttest\")\n  local plaintext, digest = aes128:decrypt(ciphertext)\n  print(\"aes128 gcm dec\", #plaintext, plaintext)\n  print(\"aes128 gcm dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes128 = aes.new(\"testtesttesttest\", \"ccm\", \"testtesttest\")\n  local ciphertext, digest = aes128:encrypt(\"a\")\n  print(\"aes128 ccm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes128 ccm dgst\", #digest, hex(digest))\n  local aes128 = aes.new(\"testtesttesttest\", \"ccm\", \"testtesttest\")\n  local plaintext, digest = aes128:decrypt(ciphertext)\n  print(\"aes128 ccm dec\", #plaintext, plaintext)\n  print(\"aes128 ccm dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes192 = aes.new(\"testtesttesttesttesttest\")\n  local ciphertext = aes192:encrypt(\"a\")\n  print(\"aes192 encrypt\", #ciphertext, hex(ciphertext))\n  local aes192 = aes.new(\"testtesttesttesttesttest\")\n  local plaintext = aes192:decrypt(ciphertext)\n  print(\"aes192 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"cbc\", \"testtesttesttest\")\n  local ciphertext = aes192:encrypt(\"a\")\n  print(\"aes192 cbc enc\", #ciphertext, hex(ciphertext))\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"cbc\", \"testtesttesttest\")\n  local plaintext = aes192:decrypt(ciphertext)\n  print(\"aes192 cbc dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"ctr\", \"testtesttesttest\")\n  local ciphertext = aes192:encrypt(\"a\")\n  print(\"aes192 ctr enc\", #ciphertext, hex(ciphertext))\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"ctr\", \"testtesttesttest\")\n  local plaintext = aes192:decrypt(ciphertext)\n  print(\"aes192 ctr dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"gcm\", \"testtesttest\")\n  local ciphertext, digest = aes192:encrypt(\"a\")\n  print(\"aes192 gcm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes192 gcm dgst\", #digest, hex(digest))\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"gcm\", \"testtesttest\")\n  local plaintext, digest = aes192:decrypt(ciphertext)\n  print(\"aes192 gcm dec\", #plaintext, plaintext)\n  print(\"aes192 gcm dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"ccm\", \"testtesttest\")\n  local ciphertext, digest = aes192:encrypt(\"a\")\n  print(\"aes192 ccm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes192 ccm dgst\", #digest, hex(digest))\n  local aes192 = aes.new(\"testtesttesttesttesttest\", \"ccm\", \"testtesttest\")\n  local plaintext, digest = aes192:decrypt(ciphertext)\n  print(\"aes192 ccm dec\", #plaintext, plaintext)\n  print(\"aes192 ccm dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\")\n  local ciphertext = aes256:encrypt(\"a\")\n  print(\"aes256 encrypt\", #ciphertext, hex(ciphertext))\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\")\n  local plaintext = aes256:decrypt(ciphertext)\n  print(\"aes256 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"cbc\", \"testtesttesttest\")\n  local ciphertext = aes256:encrypt(\"a\")\n  print(\"aes256 cbc enc\", #ciphertext, hex(ciphertext))\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"cbc\", \"testtesttesttest\")\n  local plaintext = aes256:decrypt(ciphertext)\n  print(\"aes256 cbc dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"ctr\", \"testtesttesttest\")\n  local ciphertext = aes256:encrypt(\"a\")\n  print(\"aes256 ctr enc\", #ciphertext, hex(ciphertext))\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"ctr\", \"testtesttesttest\")\n  local plaintext = aes256:decrypt(ciphertext)\n  print(\"aes256 ctr dec\", #plaintext, plaintext)\n\n  print()\n\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"gcm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local ciphertext, digest = aes256:encrypt(\"a\")\n  print(\"aes256 gcm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes256 gcm dgst\", #digest, hex(digest))\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"gcm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local plaintext, digest = aes256:decrypt(ciphertext)\n  print(\"aes256 gcm dec\", #plaintext, plaintext)\n  print(\"aes256 gcm dgst\", #digest, hex(digest))\n\n  print()\n\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"ccm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local ciphertext, digest = aes256:encrypt(\"a\")\n  print(\"aes256 ccm enc\", #ciphertext, hex(ciphertext))\n  print(\"aes256 ccm dgst\", #digest, hex(digest))\n  local aes256 = aes.new(\"testtesttesttesttesttesttesttest\", \"ccm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local plaintext, digest = aes256:decrypt(ciphertext)\n  print(\"aes256 ccm dec\", #plaintext, plaintext)\n  print(\"aes256 ccm dgst\", #digest, hex(digest))\nend\n\nprint()\n\ndo\n  local camellia = require \"resty.nettle.camellia\"\n  local camellia128 = camellia.new(\"testtesttesttest\")\n  local ciphertext = camellia128:encrypt(\"a\")\n  print(\"cam128 encrypt\", #ciphertext, hex(ciphertext))\n  local camellia128 = camellia.new(\"testtesttesttest\")\n  local plaintext = camellia128:decrypt(ciphertext)\n  print(\"cam128 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local camellia128 = camellia.new(\"testtesttesttest\", \"gcm\", \"testtesttest\")\n  local ciphertext, digest = camellia128:encrypt(\"a\")\n  print(\"cam128 gcm enc\", #ciphertext, hex(ciphertext))\n  print(\"cam128 gcm dgst\", #digest, hex(digest))\n  local camellia128 = camellia.new(\"testtesttesttest\", \"gcm\", \"testtesttest\")\n  local plaintext, digest = camellia128:decrypt(ciphertext)\n  print(\"cam128 gcm dec\", #plaintext, plaintext)\n  print(\"cam128 gcm dgst\", #digest, hex(digest))\n\n  print()\n\n  local camellia192 = camellia.new(\"testtesttesttesttesttest\")\n  local ciphertext = camellia192:encrypt(\"a\")\n  print(\"cam192 encrypt\", #ciphertext, hex(ciphertext))\n  local camellia192 = camellia.new(\"testtesttesttesttesttest\")\n  local plaintext = camellia192:decrypt(ciphertext)\n  print(\"cam192 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local camellia256 = camellia.new(\"testtesttesttesttesttesttesttest\")\n  local ciphertext = camellia256:encrypt(\"a\")\n  print(\"cam256 encrypt\", #ciphertext, hex(ciphertext))\n  local camellia256 = camellia.new(\"testtesttesttesttesttesttesttest\")\n  local plaintext = camellia256:decrypt(ciphertext)\n  print(\"cam256 decrypt\", #plaintext, plaintext)\n\n  print()\n\n  local camellia256 = camellia.new(\"testtesttesttesttesttesttesttest\", \"gcm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local ciphertext, digest = camellia256:encrypt(\"a\")\n  print(\"cam256 gcm enc\", #ciphertext, hex(ciphertext))\n  print(\"cam256 gcm dgst\", #digest, hex(digest))\n  local camellia256 = camellia.new(\"testtesttesttesttesttesttesttest\", \"gcm\", \"testtesttest\", \"testtesttesttest1asdasdasdasdasdasdasdasdasdasdasdasdasdasdasd\")\n  local plaintext, digest = camellia256:decrypt(ciphertext)\n  print(\"cam256 gcm dec\", #plaintext, plaintext)\n  print(\"cam256 gcm dgst\", #digest, hex(digest))\nend\n\nprint()\n\ndo\n  local arcfour = require \"resty.nettle.arcfour\"\n  local af = arcfour.new(\"testtesttesttest\")\n  local ciphertext = af:encrypt(\"a\")\n  print(\"ARCFOUR encrypt\", #ciphertext, hex(ciphertext))\n  local af = arcfour.new(\"testtesttesttest\")\n  local plaintext = af:decrypt(ciphertext)\n  print(\"ARCFOUR decrypt\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local blowfish = require \"resty.nettle.blowfish\"\n  local bf = blowfish.new(\"testtesttesttest\")\n  local ciphertext = bf:encrypt(\"a\")\n  print(\"BLOWFISH enc\", #ciphertext, hex(ciphertext))\n  local bf = blowfish.new(\"testtesttesttest\")\n  local plaintext = bf:decrypt(ciphertext)\n  print(\"BLOWFISH dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local twofish = require \"resty.nettle.twofish\"\n  local tf = twofish.new(\"testtesttesttest\")\n  local ciphertext = tf:encrypt(\"a\")\n  print(\"TWOFISH enc\", #ciphertext, hex(ciphertext))\n  local tf = twofish.new(\"testtesttesttest\")\n  local plaintext = tf:decrypt(ciphertext)\n  print(\"TWOFISH dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local serpent = require \"resty.nettle.serpent\"\n  local sp = serpent.new(\"testtesttesttest\")\n  local ciphertext = sp:encrypt(\"a\")\n  print(\"SERPENT enc\", #ciphertext, hex(ciphertext))\n  local sp = serpent.new(\"testtesttesttest\")\n  local plaintext = sp:decrypt(ciphertext)\n  print(\"SERPENT dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local cast128 = require \"resty.nettle.cast128\"\n  local ct = cast128.new(\"testtesttesttest\")\n  local ciphertext = ct:encrypt(\"a\")\n  print(\"CAST128 enc\", #ciphertext, hex(ciphertext))\n  local ct = cast128.new(\"testtesttesttest\")\n  local plaintext = ct:decrypt(ciphertext)\n  print(\"CAST128 dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local chacha = require \"resty.nettle.chacha\"\n  local cc = chacha.new(\"testtesttesttesttesttesttesttest\", \"testtest\")\n  local ciphertext = cc:encrypt(\"a\")\n  print(\"ChaCha enc\", #ciphertext, hex(ciphertext))\n  local cc = chacha.new(\"testtesttesttesttesttesttesttest\", \"testtest\")\n  local plaintext = cc:decrypt(ciphertext)\n  print(\"ChaCha dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local salsa20 = require \"resty.nettle.salsa20\"\n  local ss = salsa20.new(\"testtesttesttest\", \"testtest\")\n  local ciphertext = ss:encrypt(\"a\")\n  print(\"Salsa20 128 enc\", #ciphertext, hex(ciphertext))\n  local ss = salsa20.new(\"testtesttesttest\", \"testtest\")\n  local plaintext = ss:decrypt(ciphertext)\n  print(\"Salsa20 128 dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local salsa20 = require \"resty.nettle.salsa20\"\n  local ss = salsa20.new(\"testtesttesttesttesttesttesttest\", \"testtest\")\n  local ciphertext = ss:encrypt(\"a\")\n  print(\"Salsa20 256 enc\", #ciphertext, hex(ciphertext))\n  local ss = salsa20.new(\"testtesttesttesttesttesttesttest\", \"testtest\")\n  local plaintext = ss:decrypt(ciphertext)\n  print(\"Salsa20 256 dec\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local salsa20 = require \"resty.nettle.salsa20\"\n  local ss = salsa20.new(\"testtesttesttest\", \"testtest\", 12)\n  local ciphertext = ss:encrypt(\"a\")\n  print(\"Sal20r12 128 e\", #ciphertext, hex(ciphertext))\n  local ss = salsa20.new(\"testtesttesttest\", \"testtest\", 12)\n  local plaintext = ss:decrypt(ciphertext)\n  print(\"Sal20r12 128 d\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local salsa20 = require \"resty.nettle.salsa20\"\n  local ss = salsa20.new(\"testtesttesttesttesttesttesttest\", \"testtest\", 12)\n  local ciphertext = ss:encrypt(\"a\")\n  print(\"Sal20r12 256 e\", #ciphertext, hex(ciphertext))\n  local ss = salsa20.new(\"testtesttesttesttesttesttesttest\", \"testtest\", 12)\n  local plaintext = ss:decrypt(ciphertext)\n  print(\"Sal20r12 256 d\", #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local chacha_poly1305 = require \"resty.nettle.chacha-poly1305\"\n  local cp = chacha_poly1305.new(\"testtesttesttesttesttesttesttest\", \"testtesttesttest\", \"testtest\")\n  local ciphertext, digest = cp:encrypt(\"a\")\n  print(\"cc-p1305 enc\", #ciphertext, hex(ciphertext))\n  print(\"cc-p1305 dgst\", #digest, hex(digest))\n  local cp = chacha_poly1305.new(\"testtesttesttesttesttesttesttest\", \"testtesttesttest\", \"testtest\")\n  local plaintext, digest = cp:decrypt(ciphertext)\n  print(\"cc-p1305 dec\", #plaintext, plaintext)\n  print(\"cc-p1305 dgst\", #digest, hex(digest))\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  print(\"DES check   \", \"testtest\", des.check_parity(\"testtest\"))\n  print(\"DES fix     \", \"testtest\", des.fix_parity(\"testtest\"))\n  print(\"DES check   \", des.fix_parity(\"testtest\"), des.check_parity(des.fix_parity(\"testtest\")))\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtest\")\n  local ciphertext = ds:encrypt(\"a\")\n  print(\"DES enc     \", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtest\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES dec     \", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtest\", \"cbc\", \"kalakala\")\n  local ciphertext = ds:encrypt(\"testtestkalakala\")\n  print(\"DES cbc enc \", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtest\", \"cbc\", \"kalakala\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES cbc dec \", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtest\", \"ctr\", \"kalakala\")\n  local ciphertext = ds:encrypt(\"testtestkalakala\")\n  print(\"DES ctr enc \", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtest\", \"ctr\", \"kalakala\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES ctr dec \", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  print(\"DES3 check   \", \"testtestkalakalatesttest\", des.check_parity(\"testtestkalakalatesttest\"))\n  print(\"DES3 fix     \", \"testtestkalakalatesttest\", des.fix_parity(\"testtestkalakalatesttest\"))\n  print(\"DES3 check   \", des.fix_parity(\"testtestkalakalatesttest\"), des.check_parity(des.fix_parity(\"testtestkalakalatesttest\")))\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtestkalakalatesttest\")\n  local ciphertext = ds:encrypt(\"a\")\n  print(\"DES3 enc     \", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtestkalakalatesttest\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES3 dec     \", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtestkalakalatesttest\", \"cbc\", \"kalakala\")\n  local ciphertext = ds:encrypt(\"testtestkalakala\")\n  print(\"DES3 cbc enc\", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtestkalakalatesttest\", \"cbc\", \"kalakala\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES3 cbc dec\", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local des = require \"resty.nettle.des\"\n  local ds, wk = des.new(\"testtestkalakalatesttest\", \"ctr\", \"kalakala\")\n  local ciphertext = ds:encrypt(\"testtestkalakala\")\n  print(\"DES3 ctr enc\", wk, #ciphertext, hex(ciphertext))\n  local ds, wk = des.new(\"testtestkalakalatesttest\", \"ctr\", \"kalakala\")\n  local plaintext = ds:decrypt(ciphertext)\n  print(\"DES3 ctr dec\", wk, #plaintext, plaintext)\nend\n\nprint()\n\ndo\n  local base64 = require \"resty.nettle.base64\"\n  local encoded = base64.encode(\"testtesttesttest\")\n  print(\"BASE64 enc\", #encoded, encoded)\n  local decoded = base64.decode(encoded)\n  print(\"BASE64 dec\", #decoded, decoded)\n\n  print()\n\n  local encoded = base64.encode(\"testtesttesttest+&amp;\", true)\n  print(\"BASE64 enc-url\", #encoded, encoded)\n  local decoded = base64.decode(encoded, true)\n  print(\"BASE64 dec-url\", #decoded, decoded)\n\n  print()\n\n\n  local base64enc = base64.encoder.new()\n  print(base64enc:single(\"t\"))\n  print(base64enc:single(\"e\"))\n  print(base64enc:single(\"s\"))\n  print(base64enc:single(\"t\"))\n  print(base64enc:update(\"test\"))\n  print(base64enc:single(\"t\"))\n  print(base64enc:single(\"e\"))\n  print(base64enc:single(\"s\"))\n  print(base64enc:single(\"t\"))\n  print(base64enc:update(\"test\"))\n  print(base64enc:final())\n\n  print()\n\n  local base64dec = base64.decoder.new()\n  print(base64dec:single(\"d\"))\n  print(base64dec:single(\"G\"))\n  print(base64dec:single(\"V\"))\n  print(base64dec:single(\"z\"))\n  print(base64dec:single(\"d\"))\n  print(base64dec:update(\"HRlc3\"))\n  print(base64dec:single(\"R\"))\n  print(base64dec:single(\"0\"))\n  print(base64dec:single(\"Z\"))\n  print(base64dec:single(\"X\"))\n  print(base64dec:single(\"N\"))\n  print(base64dec:single(\"0\"))\n  print(base64dec:update(\"dGVzdA==\"))\n  print(base64dec:final())\nend\n\nprint()\n\ndo\n  local base16 = require \"resty.nettle.base16\"\n  local encoded = base16.encode(\"testtesttesttest\")\n  print(\"BASE16 enc\", #encoded, encoded)\n  local decoded = base16.decode(encoded)\n  print(\"BASE16 dec\", #decoded, decoded)\n\n  print()\n\n  local base16enc = base16.encoder.new()\n  print(base16enc:single(\"t\"))\n  print(base16enc:single(\"e\"))\n  print(base16enc:single(\"s\"))\n  print(base16enc:single(\"t\"))\n  print(base16enc:update(\"test\"))\n  print(base16enc:single(\"t\"))\n  print(base16enc:single(\"e\"))\n  print(base16enc:single(\"s\"))\n  print(base16enc:single(\"t\"))\n  print(base16enc:update(\"test\"))\n\n  print()\n\n  local base16dec = base16.decoder.new()\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"4\"))\n  print(base16dec:single(\"6\"))\n  print(base16dec:single(\"5\"))\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"3\"))\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"4\"))\n  print(base16dec:update(\"74657374\"))\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"4\"))\n  print(base16dec:single(\"6\"))\n  print(base16dec:single(\"5\"))\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"3\"))\n  print(base16dec:single(\"7\"))\n  print(base16dec:single(\"4\"))\n  print(base16dec:update(\"74657374\"))\n  print(base16dec:final())\nend\n\nprint()\n\ndo\n  local yarrow = require \"resty.nettle.yarrow\"\n  local y = yarrow.new()\n  print(y.sources)\n  print(y.seeded)\n  y:seed(\"testtesttesttesttesttesttesttest\")\n  print(y.seeded)\n\n  print(hex(y:random(30)))\n  print(hex(y:random(30)))\n\n  y:fast_reseed()\n\n  print(hex(y:random(30)))\n\n  y:slow_reseed()\n  print(hex(y:random(30)))\nend\n\nprint()\n\ndo\n  local knuth = require \"resty.nettle.knuth-lfib\"\n  local k = knuth.new()\n  print(k:number())\n  print(k:number())\n  print(hex(k:random(10)))\n  local t = k:array(10)\n  print(concat(t, '|'))\nend\n\nprint()\n\ndo\n  local rsa = require \"resty.nettle.rsa\"\n  local r = rsa.new()\n  local gibb = r:encrypt(\"fish\")\n  print(hex(gibb))\n  local clear = r:decrypt(gibb)\n  print(clear)\nend\n\nprint()\n\ndo\n  local ed = require \"resty.nettle.ed25519-sha512\"\n  local pri = \"testtesttesttesttesttesttesttest\"\n  print(\"EdDSA25519 SHA-512 private key\", #pri, pri)\n  local pub = ed.public_key(pri)\n  print(\"EdDSA25519 SHA-512 public key\", #pub, hex(pub))\n  local msg = \"hello\"\n  print(\"EdDSA25519 SHA-512 message\", #msg, msg)\n  local sig = ed.sign(pub, pri, msg)\n  print(\"EdDSA25519 SHA-512 signature\", #sig, hex(sig))\n  local chk = ed.verify(pub, msg, sig)\n  print(\"EdDSA25519 SHA-512 verify (true)\", chk)\n  local err = \"error\"\n  local chk = ed.verify(pub, err, sig)\n  print(\"EdDSA25519 SHA-512 verify (false)\", chk)\nend\n</code></pre> <p>The above should output this (randoms are different of course):</p> <pre><code>md2         16  8350E5A3E24C153DF2275C9F80692773\nmd2         16  8350E5A3E24C153DF2275C9F80692773\nmd4         16  31D6CFE0D16AE931B73C59D7E0C089C0\nmd4         16  31D6CFE0D16AE931B73C59D7E0C089C0\nmd5         16  D41D8CD98F00B204E9800998ECF8427E\nmd5         16  D41D8CD98F00B204E9800998ECF8427E\nripemd160   20  9C1185A5C5E9FC54612808977EE8F548B2258D31\ngosthash94  32  CE85B99CC46752FFFEE35CAB9A7B0278ABB4C2D2055CFF685AF4912C49490F8D\nsha1        20  DA39A3EE5E6B4B0D3255BFEF95601890AFD80709\nsha1        20  DA39A3EE5E6B4B0D3255BFEF95601890AFD80709\nsha224          28  D14A028C2A3A2BC9476102BB288234C415A2B01F828EA62AC5B3E42F\nsha224          28  D14A028C2A3A2BC9476102BB288234C415A2B01F828EA62AC5B3E42F\nsha256          32  E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855\nsha256          32  E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855\nsha384          48  38B060A751AC96384CD9327EB1B1E36A21FDB71114BE07434C0CC7BF63F6E1DA274EDEBFE76F65FBD51AD2F14898B95B\nsha384          48  38B060A751AC96384CD9327EB1B1E36A21FDB71114BE07434C0CC7BF63F6E1DA274EDEBFE76F65FBD51AD2F14898B95B\nsha512          64  CF83E1357EEFB8BDF1542850D66D8007D620E4050B5715DC83F4A921D36CE9CE47D0D13C5D85F2B0FF8318D2877EEC2F63B931BD47417A81A538327AF927DA3E\nsha512          64  CF83E1357EEFB8BDF1542850D66D8007D620E4050B5715DC83F4A921D36CE9CE47D0D13C5D85F2B0FF8318D2877EEC2F63B931BD47417A81A538327AF927DA3E\nsha512_224  28  6ED0DD02806FA89E25DE060C19D3AC86CABB87D6A0DDD05C333B84F4\nsha512_224  28  6ED0DD02806FA89E25DE060C19D3AC86CABB87D6A0DDD05C333B84F4\nsha512_256  32  C672B8D1EF56ED28AB87C3622C5114069BDD3AD7B8F9737498D0C01ECEF0967A\nsha512_256  32  C672B8D1EF56ED28AB87C3622C5114069BDD3AD7B8F9737498D0C01ECEF0967A\nsha3 224    28  6B4E03423667DBB73B6E15454F0EB1ABD4597F9A1B078E3F5B5A6BC7\nsha3 256    32  A7FFC6F8BF1ED76651C14756A061D662F580FF4DE43B49FA82D80A4B80F8434A\nsha3 384    48  0C63A75B845E4F7D01107D852E4C2485C51A50AAAA94FC61995E71BBEE983A2AC3713831264ADB47FB6BD1E058D5F004\nsha3 512    64  A69F73CCA23A9AC5C8B567DC185A756E97C982164FE25859E0D1DCC1475C80A615B2123AF1F5F94C11E3E9402C3AC558F500199D95B6D3E301758586281DCD26\nhmac md5    16  06F30DC9049F859EA0CCB39FDC8FD5C2\nhmac md5    16  06F30DC9049F859EA0CCB39FDC8FD5C2\nhmac md5    16  06F30DC9049F859EA0CCB39FDC8FD5C2\nhmac ripemd160  20  ECB2E5CA0EEFFD84F5566B5DE1D037EF1F9689EF\nhmac sha1   20  3902ED847FF28930B5F141ABFA8B471681253673\nhmac sha224 28  7A5027C4F3A358A76D943D6D83A8242675FE96E2D30A526FE9E19629\nhmac sha256 32  3ECF5388E220DA9E0F919485DEB676D8BEE3AEC046A779353B463418511EE622\nhmac sha384 48  724C212553F366248BC76017E812C8ACC85B94FEC2F396C2A925BCC2571F7AB29FEDEE6B3B3013BBF9DE7B89549D5A69\nhmac sha512 64  FC8C80E6B943CD07ECCECF01BC6038BAE68EBB6FA2E1E62B44753D7C177AF7A46B089DF349A19F7622A22312C76906CA9C984E1446D3AB86A98FDFA1425341C5\numac32      4   D262065C\numac64      8   DA7E5EB7E37A27E6\numac96      12  6B8FBA819AB2FEFA8A18F5AA\numac128         16  D55988EE39924D7642FFB401A79BCE29\npoly1305        16  879E865A98C8CDE7C899D9A3A243EDB9\npbkdf2 sha1 20  0C60C80F961F0E71F3A9B524AF6012062FE037A6\npbkdf2 sha256   32  89B69D0516F829893C696226650A86878C029AC13EE276509D5AE58B6466A724\n\naes128 encrypt  32  2EBEA9810D3056A2159BBE45A72429692EBEA9810D3056A2159BBE45A7242969\naes128 decrypt  32  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n\naes128 cbc enc  32  D3D069910C09DFC1675562A0EC9D8B204DD27DB3413D24D994F7300DD331135A\naes128 cbc dec  32  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n\naes128 ctr enc  1   64\naes128 ctr dec  1   a\n\naes128 eax enc  1   73\naes128 eax dgst 16  B4D34C46BFCA2E729FECC7638F9A6199\naes128 eax dec  1   a\naes128 eax dgst 16  B4D34C46BFCA2E729FECC7638F9A6199\n\naes128 gcm enc  1   BB\naes128 gcm dgst 16  18D5F5CCECB218322F21005BCBFF16E0\naes128 gcm dec  1   a\naes128 gcm dgst 16  18D5F5CCECB218322F21005BCBFF16E0\n\naes128 ccm enc  1   6E\naes128 ccm dgst 16  415B65935A4B546B9E81C988B9C68E53\naes128 ccm dec  1   a\naes128 ccm dgst 16  415B65935A4B546B9E81C988B9C68E53\n\naes192 encrypt  16  E21AE894602E835C9A21A6CBC5BDC030\naes192 decrypt  16  a\n\naes192 cbc enc  16  896A1B518F24B9FC5C5765BF102DB40A\naes192 cbc dec  16  a\n\naes192 ctr enc  1   98\naes192 ctr dec  1   a\n\naes192 gcm enc  1   1B\naes192 gcm dgst 16  8F616E7FF9A858FBDC2C1C4C302C4747\naes192 gcm dec  1   a\naes192 gcm dgst 16  8F616E7FF9A858FBDC2C1C4C302C4747\n\naes192 ccm enc  1   CD\naes192 ccm dgst 16  0D19B5B3D3B637D240B48BDE79395B94\naes192 ccm dec  1   a\naes192 ccm dgst 16  0D19B5B3D3B637D240B48BDE79395B94\n\naes256 encrypt  16  A18335BBBFFBA0996D6B7E36FBC8C0D4\naes256 decrypt  16  a\n\naes256 cbc enc  16  55A88E8F506DA90A694059A3A2F22E77\naes256 cbc dec  16  a\n\naes256 ctr enc  1   70\naes256 ctr dec  1   a\n\naes256 gcm enc  1   3B\naes256 gcm dgst 16  EFB12AF268F64A602779EAE2F8C2FA03\naes256 gcm dec  1   a\naes256 gcm dgst 16  EFB12AF268F64A602779EAE2F8C2FA03\n\naes256 ccm enc  1   A1\naes256 ccm dgst 16  B743659EF6F2FB95C77870FE3F9BD297\naes256 ccm dec  1   a\naes256 ccm dgst 16  B743659EF6F2FB95C77870FE3F9BD297\n\ncam128 encrypt  16  FE50E0F47DF41615C2C5DC042F75B1AC\ncam128 decrypt  16  a\n\ncam128 gcm enc  1   E0\ncam128 gcm dgst 16  AF2E1CC47D3D31CCC3EA63F417DF35DD\ncam128 gcm dec  1   a\ncam128 gcm dgst 16  AF2E1CC47D3D31CCC3EA63F417DF35DD\n\ncam192 encrypt  16  3870F36C308368F14B4EDFFF1C577811\ncam192 decrypt  16  a\n\ncam256 encrypt  16  B2572D8BFEF8199B241C0B1008D8506B\ncam256 decrypt  16  a\n\ncam256 gcm enc  1   A0\ncam256 gcm dgst 16  6B1891EE8E1F20FA49788E75A8F9447F\ncam256 gcm dec  1   a\ncam256 gcm dgst 16  6B1891EE8E1F20FA49788E75A8F9447F\n\nARCFOUR encrypt 1   CF\nARCFOUR decrypt 1   a\n\nBLOWFISH enc    8   821C2FA4533A2FD2\nBLOWFISH dec    8   a\n\nTWOFISH enc 16  6375B41B0C29E7446D217F79A909BB4B\nTWOFISH dec 16  a\n\nSERPENT enc 16  0F65C1891EA2BCCA60A1AA228A84B233\nSERPENT dec 16  a\n\nCAST128 enc 8   FA80BC104398019E\nCAST128 dec 8   a\n\nChaCha enc  1   E2\nChaCha dec  1   a\n\nSalsa20 128 enc 1   27\nSalsa20 128 dec 1   a\n\nSalsa20 256 enc 1   2B\nSalsa20 256 dec 1   a\n\nSal20r12 128 e  1   C1\nSal20r12 128 d  1   a\n\nSal20r12 256 e  1   E8\nSal20r12 256 d  1   a\n\ncc-p1305 enc    1   35\ncc-p1305 dgst   16  94BECC3FD052F18D657B4F18521C0409\ncc-p1305 dec    1   a\ncc-p1305 dgst   16  94BECC3FD052F18D657B4F18521C0409\n\nDES check       testtest    false\nDES fix         testtest    udsuudsu\nDES check       udsuudsu    true\n\nDES enc         false   8   236BF47A8D784246\nDES dec         false   8   a\n\nDES cbc enc     false   16  3840F08DBAD6CD6DE2AF46AF2656BE48\nDES cbc dec     false   16  testtestkalakala\n\nDES ctr enc     false   16  AEC72E5671C9D82D343F9F721F668701\nDES ctr dec     false   16  testtestkalakala\n\nDES3 check      testtestkalakalatesttest    false\nDES3 fix        testtestkalakalatesttest    udsuudsukamakamaudsuudsu\nDES3 check      udsuudsukamakamaudsuudsu    true\n\nDES3 enc        false   8   95D3D64AEA12A4B5\nDES3 dec        false   8   a\n\nDES3 cbc enc    false   16  C668BD2F4C1154F638A5995EC10EF184\nDES3 cbc dec    false   16  testtestkalakala\n\nDES3 ctr enc    false   16  BDD1394B141DE724ADB714DEC4D8E30F\nDES3 ctr dec    false   16  testtestkalakala\n\nBASE64 enc  24  dGVzdHRlc3R0ZXN0dGVzdA==\nBASE64 dec  16  testtesttesttest\n\nBASE64 enc-url  24  dGVzdHRlc3R0ZXN0dGVzdCsm\nBASE64 dec-url  18  testtesttesttest+&amp;\n\nd   1\nG   1\nVz  2\nd   1\nHRlc3   5\nR0  2\nZ   1\nX   1\nN0  2\ndGVzd   5\nA== 3\n\n    0\nt   1\ne   1\ns   1\n    0\nttes    4\nt   1\nt   1\n    0\ne   1\ns   1\nt   1\ntest    4\ntrue\n\nBASE16 enc  32  74657374746573747465737474657374\nBASE16 dec  16  testtesttesttest\n\n74\n65\n73\n74\n74657374\n74\n65\n73\n74\n74657374\n\n    0\nt   1\n    0\ne   1\n    0\ns   1\n    0\nt   1\ntest    4\n    0\nt   1\n    0\ne   1\n    0\ns   1\n    0\nt   1\ntest    4\ntrue\n\n2\nfalse\ntrue\n5DBE3C56BEDDA2608DD6D0924902271A7CE0A9C81EF955E396594329306A\n0D3CE56865CF002F7A53914C58D6C8037904C82E3D72ED1E5F09D0178A93\n5114614E5779289597D9DC54EF2716531A6543718ED8F26CE850632E4B46\n7D0D2C1F5D5C4D59F4C07115A5B0E0AED2BA6FF406AE9A85412EB62091E6\n\n1028764519\n765133839\nDC1424283A03BA0C01E9\n584484306|437203720|985724606|714176836|864733948|650443754|198142580|632065637|974210952|193718333\n\n411CFFB5C68DC3BA80CE5A72E127A5E06B1AEB7820BCEE14C738708DC048F8889CD3A86E16379F6E56DACF941C0841CA2C7B948D336CD5E529587383B2C03438C60B4BBE3BB2D3CF7CCB25BC9260FEA7C6117CC9E0D289DA0D85614CFBAEB33590AD43CF8C65802B794F160E04AFB98B883887E7A290AB3E2EFEF46D5D6D760E78904CAF3BBCE8ADC3C3B400012D06AB40032B2BB4689DF84A1AB0AB8CF72B89BDC8F1A572270B8A8A4C5C61DA01FADC1F5D9DCF70BD6E1C3A79990467295D32DF4182C8EC81A4C2050DFAB419102393886920D40FD5DE5AA6CC4E435F70A9341B849266B092E3C3C33623C34262C907A9FB92A1A480B87E6E375E9DE96D104CFF6A97800BD8B9F2C454FC99D9FF400865EFC8CE882F50BA9488DB47A071311EB0B1CC3F6D477A39098F2714F92229B4497AE78DC6477BBF1705071C58B459F907C3D7D82727A7FA87C3ECEA1EACE01B92341FC93499AC00C1473721E4EED81B39C7635BC810C516BDD0F184B19AE8C92BE4E025419E01DA5A2CA712375EA0BA9C3D9E35BC57AB24FA695B8685E5BE570BC8148CAF5BF0C3AFA74F588080E60DFDE821B1271FE7F111831DE64E39F12FF309298E57819D1B284A29349707DB5D7BD9604FA433FBF0B718CC9B15B02AB9AA34C53ECBBE759018AC9D3251EEEA8CE6CCAC56AA1402FB078A7A3E802554BEDACF8F7976CFC68EAC8DA06FD6FA4CE1\nfish\n\nEdDSA25519 SHA-512 private key  32  testtesttesttesttesttesttesttest\nEdDSA25519 SHA-512 public key   32  06B77FC89D2B9785433DD37A9B98A3C8FA37F03DB2B2CC0E79BE76F87B223D21\nEdDSA25519 SHA-512 message  5   hello\nEdDSA25519 SHA-512 signature    64  0E202379D19190BC1A933D3DD1753FF0B833393BEED1DC12469309F2A07094348E340C302069CDB7C7C54C21CCDA8891F21FA4588D63803C9538F2A513DA6E04\nEdDSA25519 SHA-512 verify (true)    true\nEdDSA25519 SHA-512 verify (false)   nil\n</code></pre>"},{"location":"lua/nettle/#hash-functions","title":"Hash Functions","text":""},{"location":"lua/nettle/#sha-224","title":"SHA-224","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha224\", \"test\")\n-- or\nlocal dgst = hash.sha224 \"test\"\n-- or\nlocal sha2 = hash.sha224..new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-256","title":"SHA-256","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha256\", \"test\")\n-- or\nlocal dgst = hash.sha256 \"test\"\n-- or\nlocal sha2 = hash.sha256.new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-384","title":"SHA-384","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha384\", \"test\")\n-- or\nlocal dgst = hash.sha384 \"test\"\n-- or\nlocal sha2 = hash.sha384.new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-512","title":"SHA-512","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha512\", \"test\")\n-- or\nlocal dgst = hash.sha512 \"test\"\n-- or\nlocal sha2 = hash.sha512.new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-512224","title":"SHA-512/224","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha512_224\", \"test\")\n-- or\nlocal dgst = hash.sha512_224 \"test\"\n-- or\nlocal sha2 = hash.sha512_224.new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-512256","title":"SHA-512/256","text":"<pre><code>local hash = require \"resty.nettle.sha2\"\nlocal dgst = hash(\"sha512_256\", \"test\")\n-- or\nlocal dgst = hash.sha512_256 \"test\"\n-- or\nlocal sha2 = hash.sha512_256.new()\nsha2:update \"te\"\nsha2:update \"st\"\nlocal dgst = sha2:digest()\n</code></pre>"},{"location":"lua/nettle/#sha3-224","title":"SHA3-224","text":"<pre><code>local hash = require \"resty.nettle.sha3\"\nlocal dgst = hash(224, \"test\")\n-- or\nlocal dgst = hash.sha224 \"test\"\n-- or\nlocal sha3 = hash.sha224.new()\nsha3:update \"te\"\nsha3:update \"st\"\nlocal dgst = sha3:digest()\n</code></pre>"},{"location":"lua/nettle/#sha3-256","title":"SHA3-256","text":"<pre><code>local hash = require \"resty.nettle.sha3\"\nlocal dgst = hash(256, \"test\")\n-- or\nlocal dgst = hash.sha256 \"test\"\n-- or\nlocal sha3 = hash.sha256.new()\nsha3:update \"te\"\nsha3:update \"st\"\nlocal dgst = sha3:digest()\n</code></pre>"},{"location":"lua/nettle/#sha3-384","title":"SHA3-384","text":"<pre><code>local hash = require \"resty.nettle.sha3\"\nlocal dgst = hash(384, \"test\")\n-- or\nlocal dgst = hash.sha384 \"test\"\n-- or\nlocal sha3 = hash.sha384.new()\nsha3:update \"te\"\nsha3:update \"st\"\nlocal dgst = sha3:digest()\n</code></pre>"},{"location":"lua/nettle/#sha3-512","title":"SHA3-512","text":"<pre><code>local hash = require \"resty.nettle.sha3\"\nlocal dgst = hash(512, \"test\")\n-- or\nlocal dgst = hash.sha512 \"test\"\n-- or\nlocal sha3 = hash.sha512.new()\nsha3:update \"te\"\nsha3:update \"st\"\nlocal dgst = sha3:digest()\n</code></pre>"},{"location":"lua/nettle/#md2","title":"MD2","text":"<pre><code>local hash = require \"resty.nettle.md2\"\nlocal dgst = hash \"test\"\n-- or\nlocal md2 = hash.new()\nmd2:update \"te\"\nmd2:update \"st\"\nlocal dgst = md2:digest()\n</code></pre>"},{"location":"lua/nettle/#md4","title":"MD4","text":"<pre><code>local hash = require \"resty.nettle.md4\"\nlocal dgst = hash \"test\"\n-- or\nlocal md4 = hash.new()\nmd4:update \"te\"\nmd4:update \"st\"\nlocal dgst = md4:digest()\n</code></pre>"},{"location":"lua/nettle/#md5","title":"MD5","text":"<pre><code>local hash = require \"resty.nettle.md5\"\nlocal dgst = hash \"test\"\n-- or\nlocal md5 = hash.new()\nmd5:update \"te\"\nmd5:update \"st\"\nlocal dgst = md5:digest()\n</code></pre>"},{"location":"lua/nettle/#ripemd160","title":"RIPEMD160","text":"<pre><code>local hash = require \"resty.nettle.ripemd160\"\nlocal dgst = hash \"test\"\n-- or\nlocal ripe = hash.new()\nripe:update \"te\"\nripe:update \"st\"\nlocal dgst = ripe:digest()\n</code></pre>"},{"location":"lua/nettle/#sha-1","title":"SHA-1","text":"<pre><code>local hash = require \"resty.nettle.sha1\"\nlocal dgst = hash \"test\"\n-- or\nlocal sha1 = hash.new()\nsha1:update \"te\"\nsha1:update \"st\"\nlocal dgst = sha1:digest()\n</code></pre>"},{"location":"lua/nettle/#gosthash94","title":"GOSTHASH94","text":"<pre><code>local hash = require \"resty.nettle.gosthash94\"\nlocal dgst = hash \"test\"\n-- or\nlocal gh94 = hash.new()\ngh94:update \"te\"\ngh94:update \"st\"\nlocal dgst = gh94:digest()\n</code></pre>"},{"location":"lua/nettle/#keyed-hash-functions","title":"Keyed Hash Functions","text":""},{"location":"lua/nettle/#hmac-md5","title":"HMAC-MD5","text":""},{"location":"lua/nettle/#hmac-ripemd160","title":"HMAC-RIPEMD160","text":""},{"location":"lua/nettle/#hmac-sha1","title":"HMAC-SHA1","text":""},{"location":"lua/nettle/#hmac-sha256","title":"HMAC-SHA256","text":""},{"location":"lua/nettle/#hmac-sha512","title":"HMAC-SHA512","text":""},{"location":"lua/nettle/#umac","title":"UMAC","text":""},{"location":"lua/nettle/#cmac","title":"CMAC","text":""},{"location":"lua/nettle/#poly1305","title":"Poly1305","text":""},{"location":"lua/nettle/#key-derivation-functions","title":"Key Derivation Functions","text":""},{"location":"lua/nettle/#hkdf","title":"HKDF","text":""},{"location":"lua/nettle/#pbkdf2-hmac-sha1","title":"PBKDF2-HMAC-SHA1","text":""},{"location":"lua/nettle/#pbkdf2-hmac-sha256","title":"PBKDF2-HMAC-SHA256","text":""},{"location":"lua/nettle/#cipher-functions","title":"Cipher Functions","text":""},{"location":"lua/nettle/#aes","title":"AES","text":""},{"location":"lua/nettle/#arcfour","title":"ARCFOUR","text":""},{"location":"lua/nettle/#arctwo","title":"ARCTWO","text":""},{"location":"lua/nettle/#blowfish","title":"BLOWFISH","text":""},{"location":"lua/nettle/#camellia","title":"Camellia","text":""},{"location":"lua/nettle/#cast128","title":"CAST128","text":""},{"location":"lua/nettle/#chacha","title":"ChaCha","text":""},{"location":"lua/nettle/#des","title":"DES","text":""},{"location":"lua/nettle/#des3","title":"DES3","text":""},{"location":"lua/nettle/#salsa20","title":"Salsa20","text":""},{"location":"lua/nettle/#serpent","title":"SERPENT","text":""},{"location":"lua/nettle/#twofish","title":"TWOFISH","text":""},{"location":"lua/nettle/#cipher-modes","title":"Cipher Modes","text":""},{"location":"lua/nettle/#cipher-block-chaining-cbc","title":"Cipher Block Chaining (CBC)","text":""},{"location":"lua/nettle/#counter-mode-ctr","title":"Counter Mode (CTR)","text":""},{"location":"lua/nettle/#cipher-feedback-mode-cfb","title":"Cipher Feedback Mode (CFB)","text":""},{"location":"lua/nettle/#xex-based-tweaked-codebook-mode-with-ciphertext-stealing-xts","title":"XEX-based tweaked-codebook Mode with Ciphertext Stealing (XTS)","text":""},{"location":"lua/nettle/#authenticated-encryption-with-associated-data","title":"Authenticated Encryption with Associated Data","text":""},{"location":"lua/nettle/#eax","title":"EAX","text":""},{"location":"lua/nettle/#galois-counter-mode-gcm","title":"Galois Counter Mode (GCM)","text":""},{"location":"lua/nettle/#counter-with-cbc-mac-mode-ccm","title":"Counter with CBC-MAC Mode (CCM)","text":""},{"location":"lua/nettle/#chacha-poly1305","title":"ChaCha-Poly1305","text":""},{"location":"lua/nettle/#asymmentric-encryption-aka-public-key-encryption","title":"Asymmentric Encryption (aka Public Key Encryption)","text":""},{"location":"lua/nettle/#rsa","title":"RSA","text":""},{"location":"lua/nettle/#rsa-pss","title":"RSA PSS","text":""},{"location":"lua/nettle/#dsa","title":"DSA","text":""},{"location":"lua/nettle/#ecdsa","title":"ECDSA","text":""},{"location":"lua/nettle/#eddsa","title":"EdDSA","text":""},{"location":"lua/nettle/#randomness","title":"Randomness","text":""},{"location":"lua/nettle/#yarrow","title":"Yarrow","text":""},{"location":"lua/nettle/#knuth-lfib-a-lagged-fibonacci-pseudorandomness-generator","title":"Knuth LFIB (a \"lagged fibonacci\" pseudorandomness generator)","text":""},{"location":"lua/nettle/#ascii-encoding","title":"ASCII Encoding","text":""},{"location":"lua/nettle/#base64","title":"Base64","text":""},{"location":"lua/nettle/#base16","title":"Base16","text":""},{"location":"lua/nettle/#changes","title":"Changes","text":"<p>The changes of every release of this module is recorded in Changes.md file.</p>"},{"location":"lua/nettle/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-nettle.</p>"},{"location":"lua/newrelic/","title":"newrelic: This Lua library is a luajit ffi-based wrapper around newrelic agent SDK for nginx-module-lua nginx module","text":""},{"location":"lua/newrelic/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following steps.</p>"},{"location":"lua/newrelic/#centosrhel-6-7-8-or-amazon-linux-2","title":"CentOS/RHEL 6, 7, 8 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install lua-resty-newrelic\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-newrelic v0.1.post6  released on Dec 06 2016.</p>"},{"location":"lua/newrelic/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-newrelic.</p>"},{"location":"lua/nsq/","title":"nsq: Lua nsq client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/nsq/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/nsq/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-nsq\n</code></pre>"},{"location":"lua/nsq/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-nsq\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-nsq v0.1  released on Aug 07 2018.</p> <p>lua-resty-nsq - Lua nsq client driver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/nsq/#status","title":"Status","text":"<p>This library is developing.</p>"},{"location":"lua/nsq/#description","title":"Description","text":"<p>This Lua library is a NSQ client driver for the ngx_lua nginx module:</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p>"},{"location":"lua/nsq/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua_block {\n                local config = {\n                    read_timeout = 3,\n                    heartbeat = 1,\n                }\n                local producer = require \"resty.nsq.producer\"\n                local consumer = require \"resty.nsq.consumer\"\n\n                local cons = consumer:new()\n                local prod = producer:new()\n\n                local ok, err = cons:connect(\"127.0.0.1\", 4150, config)\n                if not ok then\n                    ngx.say(\"failed to connect: \", err)\n                    return\n                end\n\n                local ok, err = prod:connect(\"127.0.0.1\", 4150)\n                if not ok then\n                    ngx.say(\"failed to connect: \", err)\n                    return\n                end\n\n                ok, err = prod:pub(\"new_topic\", \"hellow world!\")\n                if not ok then\n                    ngx.say(\"failed to pub: \", err)\n                    return\n                end\n\n                ok, err = prod:close()\n                if not ok then\n                    ngx.say(\"failed to close: \", err)\n                    return\n                end\n\n                ok, err = cons:sub(\"new_topic\", \"new_channel\")\n                if not ok then\n                    ngx.say(\"failed to sub: \", err)\n                    return\n                end\n\n                local function read(c)\n                    c:rdy(10)\n                    local ret = cons:message()\n                    ngx.say(\"sub success: \", require(\"cjson\").encode(ret))\n                end\n\n                local co = ngx.thread.spawn(read, cons) -- read message in new thread\n                ngx.thread.wait(co)\n\n                ok, err = cons:close()\n                if not ok then\n                    ngx.say(\"failed to close: \", err)\n                    return\n                end\n            }\n        }\n    }\n</code></pre>"},{"location":"lua/nsq/#modules","title":"Modules","text":""},{"location":"lua/nsq/#restynsqproducer","title":"resty.nsq.producer","text":""},{"location":"lua/nsq/#methods","title":"Methods","text":""},{"location":"lua/nsq/#new","title":"new","text":""},{"location":"lua/nsq/#pub","title":"pub","text":""},{"location":"lua/nsq/#restynsqconsumer","title":"resty.nsq.consumer","text":""},{"location":"lua/nsq/#methods_1","title":"Methods","text":""},{"location":"lua/nsq/#new_1","title":"new","text":""},{"location":"lua/nsq/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module/#readme</li> <li>the nsq wired protocol specification: https://nsq.io/clients/tcp_protocol_spec.html</li> <li>the semaphore in openresty: ngx.sema</li> <li>the thread in openresty: ngx.thread</li> </ul>"},{"location":"lua/nsq/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-nsq.</p>"},{"location":"lua/ntlm/","title":"ntlm: Nginx ntlm module implemented by lua","text":""},{"location":"lua/ntlm/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/ntlm/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-ntlm\n</code></pre>"},{"location":"lua/ntlm/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-ntlm\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-ntlm v0.2  released on Feb 07 2018.</p> <p><code>Windows authentication</code> is always used inside company. <code>IIS</code> can enable <code>Windows authentication</code> easily. For Nginx users, some solutions aren't friendly: <code>Nginx Pro</code> provides ntlm module but it isn't free; <code>reverse proxy</code> must setup other server firstly.</p> <p>The project is inspired by express-ntlm and PyAuthenNTLM2. IIS will trigger windows authentication scenario for each connection. Unlike IIS, the project only trigger ntlm for first requestion. After authentication done, http header <code>Authorization:Bearer</code> will be sent to browser, and browser should put it in each request package to avoid ntlm again. At the same time, http header: <code>X-Ntlm-Username</code> and <code>X-Ntlm-Domain</code> will be sent to upstream.</p> <p>NOTICE: don't <code>set-cookie</code> during ntlm authentication. (#1175)</p>"},{"location":"lua/ntlm/#usage","title":"Usage","text":"<ul> <li>install OpenResty which integrates Nginx and LuaJIT</li> <li>intall LuaRocks because <code>ntlm.lua</code> depends on <code>struct</code>, <code>iconv</code> module</li> <li>install <code>struct</code> module: <code>sudo /usr/local/openresty/luajit/bin/luarocks install struct</code></li> <li>install <code>iconv</code> module: <code>sudo /usr/local/openresty/luajit/bin/luarocks install lua-iconv</code></li> <li>save <code>ntlm.lua</code> into <code>/usr/local/openresty/site/lualib</code></li> <li>add the following code to <code>/usr/local/openresty/nginx/conf/nginx.conf</code>:      <pre><code>    lua_shared_dict ntlm_cache 10m;\n    keepalive_timeout  35;\n    ... ...\n    access_by_lua_block {\n        local cache = ngx.shared.ntlm_cache\n        require('ntlm').negotiate(\"ldap://domain.net:389\", cache, 10)\n        -- cache is shared DICT\n        -- timeout is less than keepalive\n    }\n</code></pre></li> <li>restart nginx service: <code>sudo service openresty restart</code></li> </ul>"},{"location":"lua/ntlm/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-ntlm.</p>"},{"location":"lua/openidc/","title":"openidc: OpenID Connect Relying Party and OAuth 2.0 Resource Server implementation in Lua for NGINX / nginx-module-lua","text":""},{"location":"lua/openidc/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/openidc/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-openidc\n</code></pre>"},{"location":"lua/openidc/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-openidc\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-openidc v1.8.0  released on Sep 13 2024.</p> <p> </p>"},{"location":"lua/openidc/#lua-resty-openidc","title":"lua-resty-openidc","text":"<p>lua-resty-openidc is a library for NGINX implementing the OpenID Connect Relying Party (RP) and/or the OAuth 2.0 Resource Server (RS) functionality.</p> <p>When used as an OpenID Connect Relying Party it authenticates users against an OpenID Connect Provider using OpenID Connect Discovery and the Basic Client Profile (i.e. the Authorization Code flow). When used as an OAuth 2.0 Resource Server it can validate OAuth 2.0 Bearer Access Tokens against an Authorization Server or, in case a JSON Web Token is used for an Access Token, verification can happen against a pre-configured secret/key .</p> <p>It maintains sessions for authenticated users by leveraging <code>lua-resty-session</code> thus offering a configurable choice between storing the session state in a client-side browser cookie or use in of the server-side storage mechanisms <code>shared-memory|memcache|redis</code>.</p> <p>It supports server-wide caching of resolved Discovery documents and validated Access Tokens.</p> <p>It can be used as a reverse proxy terminating OAuth/OpenID Connect in front of an origin server so that the origin server/services can be protected with the relevant standards without implementing those on the server itself.</p>"},{"location":"lua/openidc/#sample-configuration-for-google-signin","title":"Sample Configuration for Google+ Signin","text":"<p>Sample <code>nginx.conf</code> configuration for authenticating users against Google+ Signin, protecting a reverse-proxied path.</p> <pre><code>events {\n  worker_connections 128;\n}\n\nhttp {\n\n  resolver 8.8.8.8;\n\n  lua_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;\n  lua_ssl_verify_depth 5;\n\n  # cache for discovery metadata documents\n  lua_shared_dict discovery 1m;\n  # cache for JWKs\n  lua_shared_dict jwks 1m;\n\n  # NB: if you have \"lua_code_cache off;\", use:\n  # set $session_secret xxxxxxxxxxxxxxxxxxx;\n  # see: https://github.com/bungle/lua-resty-session#notes-about-turning-lua-code-cache-off\n\n  server {\n    listen 8080;\n\n    location / {\n\n      access_by_lua_block {\n\n          local opts = {\n             -- the full redirect URI must be protected by this script\n             -- if the URI starts with a / the full redirect URI becomes\n             -- ngx.var.scheme..\"://\"..ngx.var.http_host..opts.redirect_uri\n             -- unless the scheme was overridden using opts.redirect_uri_scheme or an X-Forwarded-Proto header in the incoming request\n             redirect_uri = \"https://MY_HOST_NAME/redirect_uri\",\n             -- up until version 1.6.1 you'd specify\n             -- redirect_uri_path = \"/redirect_uri\",\n             -- and could not set the hostname\n\n             -- The discovery endpoint of the OP. Enable to get the URI of all endpoints (Token, introspection, logout...)\n             discovery = \"https://accounts.google.com/.well-known/openid-configuration\",\n\n             -- Access to OP Token endpoint requires an authentication. Several authentication modes are supported:\n             --token_endpoint_auth_method = [\"client_secret_basic\"|\"client_secret_post\"|\"private_key_jwt\"|\"client_secret_jwt\"],\n             -- o If token_endpoint_auth_method is set to \"client_secret_basic\", \"client_secret_post\", or \"client_secret_jwt\", authentication to Token endpoint is using client_id and client_secret\n             --   For non compliant OPs to OAuth 2.0 RFC 6749 for client Authentication (cf. https://tools.ietf.org/html/rfc6749#section-2.3.1)\n             --   client_id and client_secret MUST be invariant when url encoded\n             client_id = \"&lt;client_id&gt;\",\n             client_secret = \"&lt;client_secret&gt;\",\n             -- o If token_endpoint_auth_method is set to \"private_key_jwt\" authentication to Token endpoint is using client_id, client_rsa_private_key and client_rsa_private_key_id to compute a signed JWT\n             --   client_rsa_private_key is the RSA private key to be used to sign the JWT generated by lua-resty-openidc for authentication to the OP\n             --   client_rsa_private_key_id (optional) is the key id to be set in the JWT header to identify which public key the OP shall use to verify the JWT signature\n             --client_id = \"&lt;client_id&gt;\",\n             --client_rsa_private_key=[[-----BEGIN RSA PRIVATE KEY-----\nMIIEogIBAAKCAQEAiThmpvXBYdur716D2q7fYKirKxzZIU5QrkBGDvUOwg5izcTv\n[...]\nh2JHukolz9xf6qN61QMLSd83+kwoBr2drp6xg3eGDLIkQCQLrkY=\n-----END RSA PRIVATE KEY-----]],\n             --client_rsa_private_key_id=\"key id#1\",\n             --   Life duration expressed in seconds of the signed JWT generated by lua-resty-openidc for authentication to the OP.\n             --   (used when token_endpoint_auth_method is set to \"private_key_jwt\" or \"client_secret_jwt\" authentication). Default is 60 seconds.\n             --client_jwt_assertion_expires_in = 60,\n             -- When using https to any OP endpoints, enforcement of SSL certificate check can be mandated (\"yes\") or not (\"no\").\n             --ssl_verify = \"no\",\n             -- Connection keepalive with the OP can be enabled (\"yes\") or disabled (\"no\").\n             --keepalive = \"no\",\n\n             --response_mode=form_post can be used to make lua-resty-openidc use the [OAuth 2.0 Form Post Response Mode](https://openid.net/specs/oauth-v2-form-post-response-mode-1_0.html). *Note* for modern browsers you will need to set [`$session_cookie_samesite`](https://github.com/bungle/lua-resty-session#string-sessioncookiesamesite) to `None` with form_post unless your OpenID Connect Provider and Relying Party share the same domain.\n             --authorization_params = { hd=\"zmartzone.eu\" },\n             --scope = \"openid email profile\",\n             -- Refresh the users id_token after 900 seconds without requiring re-authentication\n             --refresh_session_interval = 900,\n             --iat_slack = 600,\n             --redirect_uri_scheme = \"https\",\n             --logout_path = \"/logout\",\n             --redirect_after_logout_uri = \"/\",\n             -- Where should the user be redirected after logout from the RP. This option overides any end_session_endpoint that the OP may have provided in the discovery response.\n             --redirect_after_logout_with_id_token_hint = true,\n             -- Whether the redirection after logout should include the id token as an hint (if available). This option is used only if redirect_after_logout_uri is set.\n             --post_logout_redirect_uri = \"https://www.zmartzone.eu/logoutSuccessful\",\n             -- Where does the RP requests that the OP redirects the user after logout. If this option is set to a relative URI, it will be relative to the OP's logout endpoint, not the RP's.\n\n             --accept_none_alg = false\n             -- if your OpenID Connect Provider doesn't sign its id tokens\n             -- (uses the \"none\" signature algorithm) then set this to true.\n\n             --accept_unsupported_alg = true\n             -- if you want to reject tokens signed using an algorithm\n             -- not supported by lua-resty-jwt set this to false. If\n             -- you leave it unset or set it to true, the token signature will not be\n             -- verified when an unsupported algorithm is used.\n\n             --renew_access_token_on_expiry = true\n             -- whether this plugin shall try to silently renew the access token once it is expired if a refresh token is available.\n             -- if it fails to renew the token, the user will be redirected to the authorization endpoint.\n             --access_token_expires_in = 3600\n             -- Default lifetime in seconds of the access_token if no expires_in attribute is present in the token endpoint response.\n\n             --access_token_expires_leeway = 0\n             --  Expiration leeway for access_token renewal. If this is set, renewal will happen access_token_expires_leeway seconds before the token expiration. This avoids errors in case the access_token just expires when arriving to the OAuth Resource Server.\n\n             --force_reauthorize = false\n             -- When force_reauthorize is set to true the authorization flow will be executed even if a token has been cached already\n             --session_contents = {id_token=true}\n             -- Whitelist of session content to enable. This can be used to reduce the session size.\n             -- When not set everything will be included in the session.\n             -- Available are:\n             -- id_token, enc_id_token, user, access_token (includes refresh token)\n\n             -- You can specify timeouts for connect/send/read as a single number (setting all timeouts) or as a table. Values are in milliseconds\n             -- timeout = 1000\n             -- timeout = { connect = 500, send = 1000, read = 1000 }\n\n             --use_nonce = false\n             -- By default the authorization request includes the\n             -- nonce paramter. You can use this option to disable it\n             -- which may be necessary when talking to a broken OpenID\n             -- Connect provider that ignores the paramter as the\n             -- id_token will be rejected otherwise.\n\n             --revoke_tokens_on_logout = false\n             -- When revoke_tokens_on_logout is set to true a logout notifies the authorization server that previously obtained refresh and access tokens are no longer needed. This requires that revocation_endpoint is discoverable.\n             -- If there is no revocation endpoint supplied or if there are errors on revocation the user will not be notified and the logout process continues normally.\n\n             -- Optional : use outgoing proxy to the OpenID Connect provider endpoints with the proxy_opts table :\n             -- this requires lua-resty-http &gt;= 0.12\n             -- proxy_opts = {\n             --    http_proxy  = \"http://&lt;proxy_host&gt;:&lt;proxy_port&gt;/\",\n             --    https_proxy = \"http://&lt;proxy_host&gt;:&lt;proxy_port&gt;/\"\n             -- }\n\n             -- Lifecycle Hooks\n             --\n             -- lifecycle = {\n             --    on_created = handle_created,\n             --    on_authenticated = handle_authenticated,\n             --    on_regenerated = handle_regenerated\n             --    on_logout = handle_logout\n             -- }\n             --\n             -- where `handle_created`, `handle_authenticated`, `handle_regenerated` and `handle_logout` are callables\n             -- accepting argument `session`. `handle_created` accepts also second argument `params` which is a table\n             -- containing the query parameters of the authorization request used to redirect the user to the OpenID\n             -- Connect provider endpoint.\n             --\n             --  -- `on_created` hook is invoked *after* a session has been created in\n             --     `openidc_authorize` immediately prior to saving the session\n             --  -- `on_authenticated` hook is invoked *after* receiving authorization response in\n             --     `openidc_authorization_response` immediately prior to saving the session\n             --     Starting with lua-resty-openidc 1.7.5 this receives the decoded id_token as second and the response of the token endpoint as third argument      \n             --  -- `on_regenerated` is invoked immediately after the\n                     a new access token has been obtained via token\n                     refresh and is called with the regenerated session table\n             --  -- `on_logout` hook is invoked *before* a session is destroyed in\n             --     `openidc_logout`\n             --\n             --  Any, all or none of the hooks may be used. Empty `lifecycle` does nothing.\n             --  A hook that returns a truthy value causes the lifecycle action they are taking part of to fail.\n\n             -- Optional : add decorator for HTTP request that is\n             -- applied when lua-resty-openidc talks to the OpenID Connect\n             -- provider directly. Can be used to provide extra HTTP headers\n             -- or add other similar behavior.\n             -- http_request_decorator = function(req)\n             --   local h = req.headers or {}\n             --   h[EXTRA_HEADER] = 'my extra header'\n             --   req.headers = h\n             --   return req\n             -- end,\n\n             -- use_pkce = false,\n             -- when set to true the \"Proof Key for Code Exchange\" as\n             -- defined in RFC 7636 will be used. The code challenge\n             -- method will alwas be S256\n\n          }\n\n          -- call authenticate for OpenID Connect user authentication\n          local res, err = require(\"resty.openidc\").authenticate(opts)\n\n          if err then\n            ngx.status = 500\n            ngx.say(err)\n            ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\n          end\n\n          -- at this point res is a Lua table with 3 keys:\n          --   id_token    : a Lua table with the claims from the id_token (required)\n          --   access_token: the access token (optional)\n          --   user        : a Lua table with the claims returned from the user info endpoint (optional)\n\n          --if res.id_token.hd ~= \"zmartzone.eu\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n\n          --if res.user.email ~= \"hans.zandbelt@zmartzone.eu\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n\n          -- set headers with user info: this will overwrite any existing headers\n          -- but also scrub(!) them in case no value is provided in the token\n          ngx.req.set_header(\"X-USER\", res.id_token.sub)\n      }\n\n      proxy_pass http://localhost:80;\n    }\n  }\n}\n</code></pre>"},{"location":"lua/openidc/#about-redirect_uri","title":"About <code>redirect_uri</code>","text":"<p>The so called <code>redirect_uri</code> is an URI that is part of the OpenID Connect protocoll. The redirect URI is registered with your OpenID Connect provider and is the URI your provider will redirect the users to after successful login. This URI then is handelled by lua-resty-openidc where it obtains tokens and performs some checks and only after that the browser is redirected to where your user wanted to go initially.</p> <p>The <code>redirect_uri</code> is not expected to be handelled by your appication code at all. It must be an URI wthat lua-resty-openidc is responsible for so it must be in a <code>location</code> protected by lua-resty-openidc.</p> <p>You configure the <code>redirect_uri</code> on the lua-resty-openidc side via the <code>opts.redirect_uri</code> parameter (which defaults to <code>/redirect_uri</code>). If it starts with a <code>/</code> then lua-resty-openidc will prepend the protocoll and current hostname to it when sending the URI to the OpenID Connect provider (taking <code>Forwarded</code> and <code>X-Forwarded-*</code> HTTP headers into account). But you can also specify an absolute URI containing host and protocoll yourself.</p> <p>Before version 1.6.1 <code>opts.redirect_uri_path</code> has been the way to configure the <code>redirect_uri</code> without any option to take control over the protocoll and host parts.</p> <p>Whenever lua-resty-openidc \"sees\" a local path navigated that matches the path of <code>opts.redirect_uri</code> (or <code>opts.redirect_uri_path</code>) it will intercept the request and handle it itself.</p> <p>This works for most cases but sometimes the externally visible <code>redirect_uri</code> has a different path than the one locally visible to the server. This may happen if a reverse proxy in front of your server rewrites URIs before forwarding the requests. Therefore version 1.7.6 introduced a new option <code>opts.local_redirect_uri_path</code>. If it is set lua-resty-opendic will intercepts requests to this path rather than the path of <code>opts.redirect_uri</code>.</p>"},{"location":"lua/openidc/#check-authentication-only","title":"Check authentication only","text":"<pre><code>-- check session, but do not redirect to auth if not already logged in\nlocal res, err = require(\"resty.openidc\").authenticate(opts, nil, \"pass\")\n</code></pre>"},{"location":"lua/openidc/#check-authentication-only-and-deny-unauthenticated-access","title":"Check authentication only and deny unauthenticated access","text":"<pre><code>-- check session, do not redirect to auth if not already logged in but return an error instead\nlocal res, err = require(\"resty.openidc\").authenticate(opts, nil, \"deny\")\n</code></pre>"},{"location":"lua/openidc/#sessions-and-locking","title":"Sessions and Locking","text":"<p>The <code>authenticate</code> function returns the current session object as its forth return argument. If you have configured lua-resty-session to use a server side storage backend that uses locking, the session may still be locked when it is returned. In this case you may want to close it explicitly</p> <pre><code>local res, err, target, session = require(\"resty.openidc\").authenticate(opts)\nsession:close()\n</code></pre>"},{"location":"lua/openidc/#caching","title":"Caching","text":"<p>lua-resty-openidc can use shared memory caches for several things. If you want it to use the caches, you must use <code>lua_shared_dict</code> in your <code>nginx.conf</code> file.</p> <p>Currently up to four caches are used</p> <ul> <li>the cache named <code>discovery</code> stores the OpenID Connect Disovery   metadata of your OpenID Connect Provider. Cache items expire after   24 hours unless overriden by <code>opts.discovery_expires_in</code> (a value   given in seconds) . This cache will store one item per issuer URI   and you can look up the discovery document yourself to get an   estimate for the size required - usually a few kB per OpenID Connect   Provider.</li> <li>the cache named <code>jwks</code> stores the key material of your OpenID   Connect Provider if it is provided via the JWKS endpoint. Cache   items expire after 24 hours unless overriden by   <code>opts.jwks_expires_in</code>. This cache will store one item per JWKS URI   and you can look up the jwks yourself to get an estimate for the   size required - usually a few kB per OpenID Connect Provider.</li> <li>the cache named <code>introspection</code> stores the result of OAuth2 token   introspection. Cache items expire when the corresponding token   expires. Tokens with unknown expiry are not cached at all. This   cache will contain one entry per introspected access token - usually   this will be a few kB per token.</li> <li>the cache named <code>jwt_verification</code> stores the result of JWT   verification.  Cache items expire when the corresponding token   expires. Tokens with unknown expiry are not cached for two   minutes. This cache will contain one entry per verified JWT -   usually this will be a few kB per token.</li> </ul>"},{"location":"lua/openidc/#caching-of-introspection-and-jwt-verification-results","title":"Caching of Introspection and JWT Verification Results","text":"<p>Note the <code>jwt_verification</code> and <code>introspection</code> caches are shared between all configured locations. If you are using locations with different <code>opts</code> configuration the shared cache may allow a token that is valid for only one location to be accepted by another if it is read from the cache. In order to avoid cache confusion it is recommended to set <code>opts.cache_segment</code> to unique strings for each set of related locations.</p>"},{"location":"lua/openidc/#revoke-tokens","title":"Revoke tokens","text":"<p>The <code>revoke_tokens(opts, session)</code> function revokes the current refresh and access token. In contrast to a full logout, the session cookie will not be destroyed and the endsession endpoint will not be called. The function returns <code>true</code> if both tokens were revoked successfully. This function might be helpful in scenarios where you want to destroy/remove a session from the server side.</p> <p>With <code>revoke_token(opts, token_type_hint, token)</code> it is also possible to revoke a specific token. <code>token_type_hint</code> can usually be <code>refresh_token</code> or <code>access_token</code>.</p>"},{"location":"lua/openidc/#sample-configuration-for-oauth-20-jwt-token-validation","title":"Sample Configuration for OAuth 2.0 JWT Token Validation","text":"<p>Sample <code>nginx.conf</code> configuration for verifying Bearer JWT Access Tokens against a pre-configured secret/key. Once successfully verified, the NGINX server may function as a reverse proxy to an internal origin server.</p> <pre><code>events {\n  worker_connections 128;\n}\n\nhttp {\n\n  resolver 8.8.8.8;\n\n  # cache for JWT verification results\n  lua_shared_dict jwt_verification 10m;\n\n  server {\n    listen 8080;\n\n    location /api {\n\n      access_by_lua '\n\n          local opts = {\n\n            -- 1. example of a shared secret for HS??? signature verification\n            --symmetric_key = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\",\n            -- in versions up to 1.6.1 this option's key would have been secret\n            -- rather than symmetric_key\n\n            -- 2. another example of a public cert for RS??? signature verification\n            public_key = [[-----BEGIN CERTIFICATE-----\nMIIC0DCCAbigAwIBAgIGAVSbMZs1MA0GCSqGSIb3DQEBCwUAMCkxCzAJBgNVBAYTAlVTMQwwCgYD\nVQQKEwNibGExDDAKBgNVBAMTA2JsYTAeFw0xNjA1MTAxNTAzMjBaFw0yNjA1MDgxNTAzMjBaMCkx\nCzAJBgNVBAYTAlVTMQwwCgYDVQQKEwNibGExDDAKBgNVBAMTA2JsYTCCASIwDQYJKoZIhvcNAQEB\nBQADggEPADCCAQoCggEBAIcLtHjX2GFxYv1033dvfohyCU6nsuR1qoDXfHTG3Mf/Yj4BfLHtMjJr\nnR3sgHItH3B6qZPnfErfsN0LP4uZ10/74CrWVqT5dy6ecXMqYtz/KNJ8rG0vY8vltc417AU4fie8\ngyeWv/Z6wHWUCf3NHRV8GfFgfuvywgUpHo8ujpUPFr+zrPr8butrzJPq1h3+r0f5P45tfWOdpjCT\ngsTzK6urUG0k3WkwdDYapL3wRCAw597nYfgKzzXuh9N0ZL3Uj+eJ6BgCzUZDLXABpMBZfk6hmmzp\ncAFV4nTf1AaAs/EOwVE0YgZBJiBrueMcteAIxKrKjEHgThU2Zs9gN9cSFicCAwEAATANBgkqhkiG\n9w0BAQsFAAOCAQEAQLU1A58TrSwrEccCIy0wxiGdCwQbaNMohzirc41zRMCXleJXbtsn1vv85J6A\nRmejeH5f/JbDqRRRArGMdLooGbqjWG/lwZT456Q6DXqF2plkBvh37kp/GjthGyR8ODJn5ekZwxuB\nOcTuruRhqYOIJjiYZSgK/P0zUw1cjLwUJ9ig/O6ozYmof83974fygA/wK3SgFNEoFlTkTpOvZhVW\n9kLfCVA/CRBfJNKnz5PWBBxd/3XSEuP/fcWqKGTy7zZso4MTB0NKgWO4duGTgMyZbM4onJPyA0CY\nlAc5Csj0o5Q+oEhPUAVBIF07m4rd0OvAVPOCQ2NJhQSL1oWASbf+fg==\n-----END CERTIFICATE-----]],\n            -- in versions up to 1.6.1 this option's key would have been secret\n            -- rather than public_key\n\n            -- 3. alternatively one can point to a so-called Discovery document that\n            -- contains \"jwks_uri\" entry; the jwks endpoint must provide either an \"x5c\" entry\n            -- or both the \"n\" modulus and \"e\" exponent entries for RSA signature verification\n            -- discovery = \"https://accounts.google.com/.well-known/openid-configuration\",\n\n             -- the signature algorithm that you expect has been used;\n             -- can be a single string or a table.\n             -- You should set this for security reasons in order to\n             -- avoid accepting a token claiming to be signed by HMAC\n             -- using a public RSA key.\n             --token_signing_alg_values_expected = { \"RS256\" }\n\n             -- if you want to accept unsigned tokens (using the\n             -- \"none\" signature algorithm) then set this to true.\n             --accept_none_alg = false\n\n             -- if you want to reject tokens signed using an algorithm\n             -- not supported by lua-resty-jwt set this to false. If\n             -- you leave it unset, the token signature will not be\n             -- verified at all.\n             --accept_unsupported_alg = true\n\n             -- the expiration time in seconds for jwk cache, default is 1 day.\n             --jwk_expires_in = 24 * 60 * 60\n\n             -- It may be necessary to force verification for a bearer token and ignore the existing cached\n             -- verification results. If so you need to set set the jwt_verification_cache_ignore option to true.\n             -- jwt_verification_cache_ignore = true\n\n             -- optional name of a cache-segment if you need separate\n             -- caches for differently configured locations\n             -- cache_segment = 'api'\n          }\n\n          -- call bearer_jwt_verify for OAuth 2.0 JWT validation\n          local res, err = require(\"resty.openidc\").bearer_jwt_verify(opts)\n\n           if err or not res then\n            ngx.status = 403\n            ngx.say(err and err or \"no access_token provided\")\n            ngx.exit(ngx.HTTP_FORBIDDEN)\n          end\n\n          -- at this point res is a Lua table that represents the (validated) JSON\n          -- payload in the JWT token; now we typically do not want to allow just any\n          -- token that was issued by the Authorization Server but we want to apply\n          -- some access restrictions via client IDs or scopes\n\n          --if res.scope ~= \"edit\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n\n          --if res.client_id ~= \"ro_client\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n      ';\n\n       proxy_pass http://localhost:80;\n    }\n  }\n}\n</code></pre>"},{"location":"lua/openidc/#sample-configuration-for-pingfederate-oauth-20","title":"Sample Configuration for PingFederate OAuth 2.0","text":"<p>Sample <code>nginx.conf</code> configuration for validating Bearer Access Tokens against a PingFederate OAuth 2.0 Authorization Server.</p> <pre><code>events {\n  worker_connections 128;\n}\n\nhttp {\n\n  resolver 8.8.8.8;\n\n  lua_ssl_trusted_certificate /opt/local/etc/openssl/cert.pem;\n  lua_ssl_verify_depth 5;\n\n  # cache for validation results\n  lua_shared_dict introspection 10m;\n\n  server {\n    listen 8080;\n\n    location /api {\n\n      access_by_lua '\n\n          local opts = {\n             introspection_endpoint=\"https://localhost:9031/as/introspect.oauth2\",\n             client_id=\"rs_client\",\n             client_secret=\"2Federate\",\n             ssl_verify = \"no\",\n\n             -- Defaults to \"exp\" - Controls the TTL of the introspection cache\n             -- https://tools.ietf.org/html/rfc7662#section-2.2\n             -- introspection_expiry_claim = \"exp\"\n\n             -- optional name of a cache-segment if you need separate\n             -- caches for differently configured locations\n             -- cache_segment = 'api'\n          }\n\n          -- call introspect for OAuth 2.0 Bearer Access Token validation\n          local res, err = require(\"resty.openidc\").introspect(opts)\n\n          if err then\n            ngx.status = 403\n            ngx.say(err)\n            ngx.exit(ngx.HTTP_FORBIDDEN)\n          end\n\n          -- at this point res is a Lua table that represents the JSON\n          -- object returned from the introspection/validation endpoint\n\n          --if res.scope ~= \"edit\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n\n          --if res.client_id ~= \"ro_client\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n      ';\n    }\n  }\n}\n</code></pre>"},{"location":"lua/openidc/#sample-configuration-for-passing-bearer-oauth-20-access-tokens-as-cookie","title":"Sample Configuration for passing bearer OAuth 2.0 access tokens as cookie","text":"<p>Sample <code>nginx.conf</code> configuration for validating Bearer Access Tokens passed as cookie against a ORY/Hydra Authorization Server.</p> <pre><code>events {\n  worker_connections 128;\n}\n\nhttp {\n\n  resolver 8.8.8.8;\n\n  lua_ssl_trusted_certificate /opt/local/etc/openssl/cert.pem;\n  lua_ssl_verify_depth 5;\n\n  # cache for validation results\n  lua_shared_dict introspection 10m;\n\n  server {\n    listen 8080;\n\n    location /api {\n\n      access_by_lua '\n\n          local opts = {\n             -- sets the URI of the introspection endpoint\n             introspection_endpoint=\"https://localhost:9031/oauth2/introspect\",\n\n             -- alternatively if your OAuth2 Provider provides a discovery document that contains the\n             -- introspection_endpoint claim you can leave the introspection_endpoint option\n             -- unset and instead use\n             -- discovery = \"https://my-oauth2-provider/.well-known/oauth-authorization-server\",\n\n             client_id=\"admin\",\n             client_secret=\"demo-password\",\n             ssl_verify = \"no\",\n\n             -- Defines the interval in seconds after which a cached and introspected access token needs\n             -- to be refreshed by introspecting (and validating) it again against the Authorization Server.\n             -- When not defined the value is 0, which means it only expires after the `exp` (or alternative,\n             -- see introspection_expiry_claim) hint as returned by the Authorization Server\n             -- introspection_interval = 60,\n\n             -- Defines the way in which bearer OAuth 2.0 access tokens can be passed to this Resource Server.\n             -- \"cookie\" as a cookie header called \"PA.global\" or using the name specified after \":\"\n             -- \"header\" \"Authorization: bearer\" header\n             -- When not defined the default \"Authorization: bearer\" header is used\n             -- auth_accept_token_as = \"cookie:PA\",\n\n             -- If header is used header field is Authorization\n             -- auth_accept_token_as_header_name = \"cf-Access-Jwt-Assertion\"\n\n             -- Authentication method for the OAuth 2.0 Authorization Server introspection endpoint,\n             -- Used to authenticate the client to the introspection endpoint with a client_id/client_secret\n             -- Defaults to \"client_secret_post\"\n             -- introspection_endpoint_auth_method = \"client_secret_basic\",\n\n             -- Specify the names of cookies separated by whitespace to pickup from the browser and send along on backchannel\n             -- calls to the OP and AS endpoints.\n             -- When not defined, no such cookies are sent.\n             -- pass_cookies = \"JSESSION\"\n\n             -- Defaults to \"exp\" - Controls the TTL of the introspection cache\n             -- https://tools.ietf.org/html/rfc7662#section-2.2\n             -- introspection_expiry_claim = \"exp\"\n\n             -- It may be necessary to force an introspection call for an access_token and ignore the existing cached\n             -- introspection results. If so you need to set set the introspection_cache_ignore option to true.\n             -- introspection_cache_ignore = true\n\n             -- optional name of a cache-segment if you need separate\n             -- caches for differently configured locations\n             -- cache_segment = 'api'\n          }\n\n          -- call introspect for OAuth 2.0 Bearer Access Token validation\n          local res, err = require(\"resty.openidc\").introspect(opts)\n\n          if err then\n            ngx.status = 403\n            ngx.say(err)\n            ngx.exit(ngx.HTTP_FORBIDDEN)\n          end\n\n          -- at this point res is a Lua table that represents the JSON\n          -- object returned from the introspection/validation endpoint\n\n          --if res.scope ~= \"edit\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n\n          --if res.client_id ~= \"ro_client\" then\n          --  ngx.exit(ngx.HTTP_FORBIDDEN)\n          --end\n      ';\n    }\n  }\n}\n</code></pre>"},{"location":"lua/openidc/#logging","title":"Logging","text":"<p>Logging can be customized, including using custom logger and remapping OpenIDC's default log levels, e.g:</p> <pre><code>local openidc = require(\"resty.openidc\")\nopenidc.set_logging(nil, { DEBUG = ngx.INFO })\n</code></pre>"},{"location":"lua/openidc/#running-tests","title":"Running Tests","text":"<p>We've created a dockerized setup for the test in order to simplify the installation of dependencies.</p> <p>In order to run the tests perform</p> <pre><code>$ docker build -f tests/Dockerfile . -t lua-resty-openidc/test\n$ docker run -it --rm lua-resty-openidc/test:latest\n</code></pre> <p>if you want to create luacov coverage while testing use</p> <pre><code>$ docker run -it --rm -e coverage=t lua-resty-openidc/test:latest\n</code></pre> <p>as the second command</p>"},{"location":"lua/openidc/#support","title":"Support","text":"<p>For generic questions, see the Wiki pages with Frequently Asked Questions at: https://github.com/zmartzone/lua-resty-openidc/wiki Any questions/issues should go to the Github Discussons or Issues tracker.</p>"},{"location":"lua/openidc/#disclaimer","title":"Disclaimer","text":"<p>This software is open sourced by ZmartZone IAM but not supported commercially as such. Any questions/issues should go to the Github Discussions or Issues tracker. See also the DISCLAIMER file in this directory.</p>"},{"location":"lua/openidc/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-openidc.</p>"},{"location":"lua/openssl/","title":"openssl: FFI-based OpenSSL binding for nginx-module-lua","text":""},{"location":"lua/openssl/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/openssl/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-openssl\n</code></pre>"},{"location":"lua/openssl/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-openssl\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-openssl v1.7.0  released on Oct 30 2025.</p> <p>FFI-based OpenSSL binding for LuaJIT, supporting OpenSSL 3.x, 1.1 series.</p> <p>OpenSSL 1.1.0, 1.0.2 and BoringSSL support has been dropped, but are still available at the 0.x branch.</p> <p> </p>"},{"location":"lua/openssl/#description","title":"Description","text":"<p><code>lua-resty-openssl</code> is a FFI-based OpenSSL binding library, currently supports OpenSSL <code>3.x</code> and <code>1.1.1</code> series.</p>"},{"location":"lua/openssl/#status","title":"Status","text":"<p>Production.</p>"},{"location":"lua/openssl/#synopsis","title":"Synopsis","text":"<p>This library is greatly inspired by luaossl, while uses the naming conversion closer to original OpenSSL API. For example, a function called <code>X509_set_pubkey</code> in OpenSSL C API will expect to exist as <code>resty.openssl.x509:set_pubkey</code>. CamelCases are replaced to underscore_cases, for exmaple <code>X509_set_serialNumber</code> becomes <code>resty.openssl.x509:set_serial_number</code>. Another difference than <code>luaossl</code> is that errors are never thrown using <code>error()</code> but instead return as last parameter.</p> <p>Each Lua table returned by <code>new()</code> contains a cdata object <code>ctx</code>. User are not supposed to manully setting <code>ffi.gc</code> or calling corresponding destructor of the <code>ctx</code> struct (like <code>*_free</code> functions).</p>"},{"location":"lua/openssl/#restyopenssl","title":"resty.openssl","text":"<p>This meta module provides a version sanity check against linked OpenSSL library.</p>"},{"location":"lua/openssl/#opensslload_library","title":"openssl.load_library","text":"<p>syntax: name, err = openssl.load_library()</p> <p>Try to load OpenSSL shared libraries. This function tries couple of known patterns the library could be named and return the name of <code>crypto</code> library if it's being successfully loaded and error if any.</p> <p>When running inside <code>resty</code> CLI or OpenResty with SSL enabled, calling this function is not necessary.</p>"},{"location":"lua/openssl/#opensslload_modules","title":"openssl.load_modules","text":"<p>syntax: openssl.load_modules()</p> <p>Load all available sub modules into current module:</p> <pre><code>  bn = require(\"resty.openssl.bn\"),\n  cipher = require(\"resty.openssl.cipher\"),\n  digest = require(\"resty.openssl.digest\"),\n  hmac = require(\"resty.openssl.hmac\"),\n  kdf = require(\"resty.openssl.kdf\"),\n  pkey = require(\"resty.openssl.pkey\"),\n  objects = require(\"resty.openssl.objects\"),\n  rand = require(\"resty.openssl.rand\"),\n  version = require(\"resty.openssl.version\"),\n  x509 = require(\"resty.openssl.x509\"),\n  altname = require(\"resty.openssl.x509.altname\"),\n  chain = require(\"resty.openssl.x509.chain\"),\n  csr = require(\"resty.openssl.x509.csr\"),\n  crl = require(\"resty.openssl.x509.crl\"),\n  extension = require(\"resty.openssl.x509.extension\"),\n  extensions = require(\"resty.openssl.x509.extensions\"),\n  name = require(\"resty.openssl.x509.name\"),\n  store = require(\"resty.openssl.x509.store\"),\n  ssl = require(\"resty.openssl.ssl\"),\n  ssl_ctx = require(\"resty.openssl.ssl_ctx\"),\n</code></pre> <p>Starting OpenSSL 3.0, <code>provider</code> and <code>mac</code> <code>ctx</code> is also available.</p>"},{"location":"lua/openssl/#opensslluaossl_compat","title":"openssl.luaossl_compat","text":"<p>syntax: openssl.luaossl_compat()</p> <p>Provides <code>luaossl</code> flavored API which uses camelCase naming; user can expect drop in replacement.</p> <p>For example, <code>pkey:get_parameters</code> is mapped to <code>pkey:getParameters</code>.</p> <p>Note that not all <code>luaossl</code> API has been implemented, please check readme for source of truth.</p>"},{"location":"lua/openssl/#opensslget_fips_mode","title":"openssl.get_fips_mode","text":"<p>syntax: enabled = openssl.get_fips_mode()</p> <p>Returns a boolean indicating if FIPS mode is enabled.</p>"},{"location":"lua/openssl/#opensslset_fips_mode","title":"openssl.set_fips_mode","text":"<p>syntax: ok, err = openssl.set_fips_mode(enabled)</p> <p>Toggle FIPS mode on or off.</p> <p>lua-resty-openssl supports following modes:</p> <p>OpenSSL 1.0.2 series with fips 2.0 module</p> <p>Compile the module per security policy,</p> <p>OpenSSL 3.0.0 fips provider</p> <p>Refer to https://wiki.openssl.org/index.php/OpenSSL_3.0 Section 7 Compile the provider per guide, install the fipsmodule.cnf that matches hash of FIPS provider fips.so.</p> <p>On OpenSSL 3.0 or later, this function also turns on and off default properties for EVP functions. When turned on, all applications using EVP_* API will be redirected to FIPS-compliant implementations and have no access to non-FIPS-compliant algorithms.</p> <p>Calling this function is equivalent of loading <code>fips</code> provider and call openssl.set_default_properties(\"fips=yes\").</p> <p>If fips provider is loaded but default properties are not set, use following to explictly fetch FIPS implementation. <pre><code>local provider = require \"resty.openssl.provider\"\nassert(provider.load(\"fips\"))\nlocal cipher = require \"resty.openssl.cipher\"\nlocal c = assert(cipher.new(\"aes256\"))\nprint(c:get_provider_name()) -- prints \"default\"\nlocal c = assert(cipher.new(\"aes256\", \"fips=yes\"))\nprint(c:get_provider_name()) -- prints \"fips\"\n</code></pre></p>"},{"location":"lua/openssl/#opensslget_fips_version_text","title":"openssl.get_fips_version_text","text":"<p>syntax: text, err = openssl.get_fips_version_text()</p> <p>Returns the version text of the FIPS module, only available on OpenSSL 3.x.</p>"},{"location":"lua/openssl/#opensslset_default_properties","title":"openssl.set_default_properties","text":"<p>syntax: ok, err = openssl.set_default_properties(props)</p> <p>Sets the default properties for all future EVP algorithm fetches, implicit as well as explicit. See \"ALGORITHM FETCHING\" in crypto(7) for information about implicit and explicit fetching.</p>"},{"location":"lua/openssl/#openssllist_cipher_algorithms","title":"openssl.list_cipher_algorithms","text":"<p>syntax: ret = openssl.list_cipher_algorithms(hide_provider?)</p> <p>Return available cipher algorithms in an array. Set <code>hide_provider</code> to <code>true</code> to hide provider name from the result.</p>"},{"location":"lua/openssl/#openssllist_digest_algorithms","title":"openssl.list_digest_algorithms","text":"<p>syntax: ret = openssl.list_digest_algorithms(hide_provider?)</p> <p>Return available digest algorithms in an array. Set <code>hide_provider</code> to <code>true</code> to hide provider name from the result.</p>"},{"location":"lua/openssl/#openssllist_mac_algorithms","title":"openssl.list_mac_algorithms","text":"<p>syntax: ret = openssl.list_mac_algorithms(hide_provider?)</p> <p>Return available MAC algorithms in an array. Set <code>hide_provider</code> to <code>true</code> to hide provider name from the result.</p>"},{"location":"lua/openssl/#openssllist_kdf_algorithms","title":"openssl.list_kdf_algorithms","text":"<p>syntax: ret = openssl.list_kdf_algorithms(hide_provider?)</p> <p>Return available KDF algorithms in an array. Set <code>hide_provider</code> to <code>true</code> to hide provider name from the result.</p>"},{"location":"lua/openssl/#openssllist_ssl_ciphers","title":"openssl.list_ssl_ciphers","text":"<p>syntax: cipher_string, err = openssl.list_ssl_ciphers(cipher_list?, ciphersuites?, protocol?)</p> <p>Return default SSL ciphers as a string. <code>cipher_list</code> (prior TLSv1.3) and <code>ciphersuites</code> (TLSv1.3) can be used to expand the cipher settings matches <code>protocol</code>.</p> <pre><code>openssl.list_ssl_ciphers()\nopenssl.list_ssl_ciphers(\"ECDHE-ECDSA-AES128-SHA\")\nopenssl.list_ssl_ciphers(\"ECDHE-ECDSA-AES128-SHA\", nil, \"TLSv1.2\")\nopenssl.list_ssl_ciphers(\"ECDHE-ECDSA-AES128-SHA\", \"TLS_CHACHA20_POLY1305_SHA256\", \"TLSv1.3\")\n</code></pre>"},{"location":"lua/openssl/#restyopensslctx","title":"resty.openssl.ctx","text":"<p>A module to provide OSSL_LIB_CTX context switches.</p> <p>OSSL_LIB_CTX is an internal OpenSSL library context type. Applications may allocate their own, but may also use NULL to use a default context with functions that take an OSSL_LIB_CTX argument.</p> <p>See OSSL_LIB_CTX.3 for deeper reading.</p> <p>The context is currently effective following modules:</p> <ul> <li>cipher</li> <li>digest</li> <li>kdf</li> <li>mac</li> <li>pkcs12.encode</li> <li>pkey</li> <li>provider</li> <li>rand</li> <li>x509, x509.csr, x509.crl and some x509.store functions</li> </ul> <p>This module is only available on OpenSSL 3.0 or later.</p>"},{"location":"lua/openssl/#ctxnew","title":"ctx.new","text":"<p>syntax: ok, err = ctx.new(request_context_only?, conf_file?)</p> <p>Create a new context and use as default context for this module. When <code>request_context_only</code> is set to true, the context is only used inside current request's context. <code>conf_file</code> can optionally specify an OpenSSL conf file to create the context.</p> <p>The created context is automatically freed with its given lifecycle.</p> <pre><code>-- initialize a AES cipher instance from given provider implementation only\n-- for current request, without interfering other part of code\n-- or future requests from using the same algorithm.\nassert(require(\"resty.openssl.ctx\").new(true))\nlocal p = assert(require(\"resty.openssl.provider\").load(\"myprovider\"))\nlocal c = require(\"resty.openssl.cipher\").new(\"aes256\")\nprint(c:encrypt(string.rep(\"0\", 32), string.rep(\"0\", 16), \"\ud83e\udda2\"))\n-- don't need to release provider and ctx, they are GC'ed automatically\n</code></pre>"},{"location":"lua/openssl/#ctxfree","title":"ctx.free","text":"<p>syntax: ctx.free(request_context_only?)</p> <p>Free the context that was previously created by ctx.new.</p>"},{"location":"lua/openssl/#restyopensslerr","title":"resty.openssl.err","text":"<p>A module to provide error messages.</p>"},{"location":"lua/openssl/#errformat_error","title":"err.format_error","text":"<p>syntax: msg = err.format_error(ctx_msg?, return_code?, all_errors?)</p> <p>syntax: msg = err.format_all_errors(ctx_msg?, return_code?)</p> <p>Return the latest error message from the last error code. Errors are formatted as:</p> <pre><code>[ctx_msg]: code: [return_code]: error:[error code]:[library name]:[func name]:[reason string]:[file name]:[line number]:\n</code></pre> <p>On OpenSSL prior to 3.x, errors are formatted as:</p> <pre><code>[ctx_msg]: code: [return_code]: [file name]:[line number]:error:[error code]:[library name]:[func name]:[reason string]:\n</code></pre> <p>If <code>all_errors</code> is set to <code>true</code>, all errors no just the latest one will be returned in a single string. All errors thrown by this library internally only thrown the latest error.</p> <p>For example:</p> <pre><code>local f = io.open(\"t/fixtures/ec_key_encrypted.pem\"):read(\"*a\")\nlocal privkey, err = require(\"resty.openssl.pkey\").new(f, {\n    format = \"PEM\",\n    type = \"pr\",\n    passphrase = \"wrongpasswrod\",\n})\nngx.say(err)\n-- pkey.new:load_key: error:4800065:PEM routines:PEM_do_header:bad decrypt:crypto/pem/pem_lib.c:467:\n</code></pre>"},{"location":"lua/openssl/#errget_last_error_code","title":"err.get_last_error_code","text":"<p>syntax: code = err.get_last_error_code()</p> <p>Return the last error code.</p>"},{"location":"lua/openssl/#errget_lib_error_string","title":"err.get_lib_error_string","text":"<p>syntax: lib_error_message = err.get_lib_error_string(code?)</p> <p>Return the library name of the last error code as string. If <code>code</code> is set, return the library name corresponding to provided error code instead.</p>"},{"location":"lua/openssl/#errget_reason_error_string","title":"err.get_reason_error_string","text":"<p>syntax: reason_error_message = err.get_reason_error_string(code?)</p> <p>Return the reason of the last error code as string. If <code>code</code> is set, return the reason corresponding to provided error code instead.</p>"},{"location":"lua/openssl/#restyopensslversion","title":"resty.openssl.version","text":"<p>A module to provide version info.</p>"},{"location":"lua/openssl/#restyopensslprovider","title":"resty.openssl.provider","text":"<p>Module to interact with providers. This module only work on OpenSSL &gt;= 3.0.0.</p>"},{"location":"lua/openssl/#providerload","title":"provider.load","text":"<p>syntax: pro, err = provider.load(name, try?)</p> <p>Load provider with <code>name</code>. If <code>try</code> is set to true, OpenSSL will not disable the fall-back providers if the provider cannot be loaded and initialized. If the provider loads successfully, however, the fall-back providers are disabled.</p> <p>By default this functions loads provider into the default context, meaning it will affect other applications in the same process using the default context as well. If such behaviour is not desired, consider using ctx to load provider only to limited scope.</p>"},{"location":"lua/openssl/#provideristype","title":"provider.istype","text":"<p>syntax: ok = pkey.provider(table)</p> <p>Returns <code>true</code> if table is an instance of <code>provider</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#provideris_available","title":"provider.is_available","text":"<p>syntax: ok, err = provider.is_available(name)</p> <p>Checks if a named provider is available for use.</p>"},{"location":"lua/openssl/#providerset_default_search_path","title":"provider.set_default_search_path","text":"<p>syntax: ok, err = provider.set_default_search_path(name)</p> <p>Specifies the default search path that is to be used for looking for providers.</p>"},{"location":"lua/openssl/#providerunload","title":"provider:unload","text":"<p>syntax: ok, err = pro:unload(name)</p> <p>Unload a provider that is previously loaded by <code>provider.load</code>.</p>"},{"location":"lua/openssl/#providerself_test","title":"provider:self_test","text":"<p>syntax: ok, err = pro:self_test(name)</p> <p>Runs a provider's self tests on demand. If the self tests fail then the provider will fail to provide any further services and algorithms.</p>"},{"location":"lua/openssl/#providerget_params","title":"provider:get_params","text":"<p>syntax: ok, err = pro:get_params(key1, key2?...)</p> <p>Returns one or more provider parameter values.</p> <pre><code>local pro = require \"resty.openssl.provider\"\n\nlocal p = pro.load(\"default\")\n\nlocal name = assert(p:get_params(\"name\"))\nprint(name)\n-- outputs \"OpenSSL Default Provider\"\n\nlocal result = assert(p:get_params(\"name\", \"version\", \"buildinfo\", \"status\"))\nprint(require(\"cjson\").encode(result))\n-- outputs '{\"buildinfo\":\"3.0.0-alpha7\",\"name\":\"OpenSSL Default Provider\",\"status\":1,\"version\":\"3.0.0\"}'\n</code></pre>"},{"location":"lua/openssl/#restyopensslpkey","title":"resty.openssl.pkey","text":"<p>Module to interact with private keys and public keys (EVP_PKEY).</p> <p>Each key type may only support part of operations:</p> Key Type Load existing key Key generation Encrypt/Decrypt Sign/Verify Key Exchange RSA Y Y Y Y DH Y Y Y EC Y Y Y (ECDSA) Y (ECDH) Ed25519 Y Y Y (PureEdDSA) X25519 Y Y Y (ECDH) Ed448 Y Y Y (PureEdDSA) X448 Y Y Y (ECDH) <p>Direct support of encryption and decryption for EC and ECX does not exist, but processes like ECIES is possible with pkey:derive, kdf and cipher</p>"},{"location":"lua/openssl/#pkeynew","title":"pkey.new","text":""},{"location":"lua/openssl/#load-existing-key","title":"Load existing key","text":"<p>syntax: pk, err = pkey.new(string, opts?)</p> <p>Supports loading a private or public key in PEM, DER or JWK format passed as first argument <code>string</code>.</p> <p>The second parameter <code>opts</code> accepts an optional table to constraint the behaviour of key loading.</p> <ul> <li><code>opts.format</code>: set explictly to <code>\"PEM\"</code>, <code>\"DER\"</code>, <code>\"JWK\"</code> to load specific format or set to <code>\"*\"</code> for auto detect</li> <li><code>opts.type</code>: set explictly to <code>\"pr\"</code> for privatekey, <code>\"pu\"</code> for public key; set to <code>\"*\"</code> for auto detect</li> </ul> <p>When loading a PEM encoded RSA key, it can either be a PKCS#8 encoded <code>SubjectPublicKeyInfo</code>/<code>PrivateKeyInfo</code> or a PKCS#1 encoded <code>RSAPublicKey</code>/<code>RSAPrivateKey</code>.</p> <p>When loading a encrypted PEM encoded key, the <code>passphrase</code> to decrypt it can either be set in <code>opts.passphrase</code> or <code>opts.passphrase_cb</code>:</p> <pre><code>pkey.new(pem_or_der_text, {\n  format = \"*\", -- choice of \"PEM\", \"DER\", \"JWK\" or \"*\" for auto detect\n  type = \"*\", -- choice of \"pr\" for privatekey, \"pu\" for public key and \"*\" for auto detect\n  passphrase = \"secret password\", -- the PEM encryption passphrase\n  passphrase_cb = function()\n    return \"secret password\"\n  end, -- the PEM encryption passphrase callback function\n}\n</code></pre> <p>When loading JWK, there are couple of caveats: - Make sure the encoded JSON text is passed in, it must have been base64 decoded. - When using OpenSSL 1.1.1 or lua-resty-openssl earlier than 1.6.0, constraint <code>type</code> on JWK key is only supported on OpenSSL 3.x and lua-resty-openssl 1.6.0. Otherwise the parameters in provided JSON will decide if a private or public key is loaded,  specifying <code>type</code> will result in an error; also public key part for <code>OKP</code> keys (the <code>x</code> parameter) is not honored and derived from private key part (the <code>d</code> parameter) if it's specified. - Only key type of <code>RSA</code>, <code>P-256</code>, <code>P-384</code> and <code>P-512</code> <code>EC</code>, <code>Ed25519</code>, <code>X25519</code>, <code>Ed448</code> and <code>X448</code> <code>OKP</code> keys are supported. - Signatures and verification must use <code>ecdsa_use_raw</code> option to work with JWS standards for EC keys. See pkey:sign and pkey.verify for detail. - When running outside of OpenResty, needs to install a JSON library (<code>cjson</code> or <code>dkjson</code>) and <code>basexx</code>.</p>"},{"location":"lua/openssl/#key-generation","title":"Key generation","text":"<p>syntax: pk, err = pkey.new(config?)</p> <p>Generate a new public key or private key.</p> <p>To generate RSA key, <code>config</code> table can have <code>bits</code> and <code>exp</code> field to control key generation. When <code>config</code> is emitted, this function generates a 2048 bit RSA key with <code>exponent</code> of 65537, which is equivalent to:</p> <pre><code>local key, err = pkey.new({\n  type = 'RSA',\n  bits = 2048,\n  exp = 65537\n})\n</code></pre> <p>To generate EC or DH key, please refer to pkey.paramgen for possible values of <code>config</code> table. For example:</p> <pre><code>local key, err = pkey.new({\n  type = 'EC',\n  curve = 'prime256v1',\n})\n</code></pre> <p>It's also possible to pass a PEM-encoded EC or DH parameters to <code>config.param</code> for key generation:</p> <pre><code>local dhparam = pkey.paramgen({\n  type = 'DH',\n  group = 'dh_1024_160'\n})\n-- OR\n-- local dhparam = io.read(\"dhparams.pem\"):read(\"*a\")\n\nlocal key, err = pkey.new({\n  type = 'DH',\n  param = dhparam,\n}) \n</code></pre> <p>It's also possible to pass raw pkeyopt control strings in <code>config</code> table as used in the <code>genpkey</code> CLI program. See openssl-genpkey(1) for a list of options.</p> <p>For example:</p> <pre><code>pkey.new({\n  type = 'RSA',\n  bits = 2048,\n  exp = 65537,\n})\n-- is same as\npkey.new({\n  type = 'RSA',\n  exp = 65537,\n  \"rsa_keygen_bits:4096\",\n})\n</code></pre>"},{"location":"lua/openssl/#key-composition","title":"Key composition","text":"<p>syntax: pk, err = pkey.new(config?)</p> <p>Compose a public or private key using existing parameters. To see list of parameters for each key, refer to pkey:set_parameters.</p> <p>Only <code>type</code> and <code>params</code> should exist in <code>config</code> table, all other keys will be ignored.</p> <pre><code>local private_bn = require \"resty.openssl.bn\".new(\"7F48282CCA4C1A65D589C06DBE9C42AE50FBFFDF3A18CBB48498E1DE47F11BE1A3486CD8FA950D68F111970F922279D8\", 16)\nlocal p_384, err = assert(require(\"resty.openssl.pkey\").new({\n    type = \"EC\",\n    params = {\n        private = private_bn,\n        group = \"secp384r1\",\n    }\n}))\n</code></pre>"},{"location":"lua/openssl/#pkeyistype","title":"pkey.istype","text":"<p>syntax: ok = pkey.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>pkey</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#pkeyparamgen","title":"pkey.paramgen","text":"<p>syntax: pem_txt, err = pk.paramgen(config)</p> <p>Generate parameters for EC or DH key and output as PEM-encoded text.</p> <p>For EC key:</p> Parameter Description type <code>\"EC\"</code> curve EC curves. If omitted, default to <code>\"prime192v1\"</code>. To see list of supported EC curves, use <code>openssl ecparam -list_curves</code>. <p>For DH key:</p> Parameter Description type <code>\"DH\"</code> bits Generate a new DH parameter with <code>bits</code> long prime. If omitted, default to <code>2048</code>. Starting OpenSSL 3.0, only bits equal to 2048 is allowed. group Use predefined groups instead of generating new one. <code>bit</code> will be ignored if <code>group</code> is set. <p>Possible values for <code>group</code> are: - RFC7919 <code>\"ffdhe2048\"</code>, <code>\"ffdhe3072\"</code>, <code>\"ffdhe4096\"</code>, <code>\"ffdhe6144\"</code>, <code>\"ffdhe8192\"</code> - RFC5114 <code>\"dh_1024_160\"</code>, <code>\"dh_2048_224\"</code>, <code>\"dh_2048_256\"</code> - RFC3526 <code>\"modp_1536\"</code>, <code>\"modp_2048\"</code>, <code>\"modp_3072\"</code>, <code>\"modp_4096\"</code>, <code>\"modp_6144\"</code>, <code>\"modp_8192\"</code></p> <pre><code>local pem, err = pkey.paramgen({\n  type = 'EC',\n  curve = 'prime192v1',\n})\n\nlocal pem, err = pkey.paramgen({\n  type = 'DH',\n  group = 'ffdhe4096',\n})\n</code></pre> <p>It's also possible to pass raw pkeyopt control strings in <code>config</code> table as used in the <code>genpkey</code> CLI program. See openssl-genpkey(1) for a list of options.</p>"},{"location":"lua/openssl/#pkeyget_provider_name","title":"pkey:get_provider_name","text":"<p>syntax: name = pkey:get_provider_name()</p> <p>Returns the provider name of <code>pkey</code>.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#pkeygettable_params-pkeysettable_params-pkeyget_param-pkeyset_params","title":"pkey:gettable_params, pkey:settable_params, pkey:get_param, pkey:set_params","text":"<p>Query settable or gettable params and set or get params. See Generic EVP parameter getter/setter.</p>"},{"location":"lua/openssl/#pkeyget_parameters","title":"pkey:get_parameters","text":"<p>syntax: parameters, err = pk:get_parameters()</p> <p>Returns a table containing the <code>parameters</code> of pkey instance.</p>"},{"location":"lua/openssl/#pkeyset_parameters","title":"pkey:set_parameters","text":"<p>syntax: ok, err = pk:set_parameters(params)</p> <p>Set the parameters of the pkey from a table <code>params</code>. If the parameter is not set in the <code>params</code> table, it remains untouched in the pkey instance.</p> <pre><code>local pk, err = require(\"resty.openssl.pkey\").new()\nlocal parameters, err = pk:get_parameters()\nlocal e = parameters.e\nngx.say(e:to_number())\n-- outputs 65537\n\nlocal ok, err = pk:set_parameters({\n  e = require(\"resty.openssl.bn\").from_hex(\"100001\")\n})\n\nlocal ok, err = pk:set_parameters(parameters)\n</code></pre> <p>Parameters for RSA key:</p> Parameter Description Type n modulus common to both public and private key bn e public exponent bn d private exponent bn p first factor of n bn q second factor of n bn dmp1 <code>d mod (p - 1)</code>, exponent1 bn dmq1 <code>d mod (q - 1)</code>, exponent2 bn iqmp <code>(InverseQ)(q) = 1 mod p</code>, coefficient bn <p>Parameters for EC key:</p> Parameter Description Type private private key bn public public key bn x x coordinate of the public key bn y y coordinate of the public key bn group the named curve group NID as a number, when passed in as <code>set_parameters()</code>, it's also possible to use the text representation. This is different from <code>luaossl</code> where a <code>EC_GROUP</code> instance is returned. <p>It's not possible to set <code>x</code>, <code>y</code> with <code>public</code> at same time as <code>x</code> and <code>y</code> is basically another representation of <code>public</code>. Also currently it's only possible to set <code>x</code> and <code>y</code> at same time.</p> <p>Parameters for DH key:</p> Parameter Description Type private private key bn public public key bn p prime modulus bn q reference position bn g base generator bn <p>Parameters for Curve25519 and Curve448 keys:</p> Parameter Description Type private raw private key represented as bytes string public raw public key represented as bytes string"},{"location":"lua/openssl/#pkeyis_private","title":"pkey:is_private","text":"<p>syntax: ok = pk:is_private()</p> <p>Checks whether <code>pk</code> is a private key. Returns true if it's a private key, returns false if it's a public key.</p>"},{"location":"lua/openssl/#pkeyget_key_type","title":"pkey:get_key_type","text":"<p>syntax: obj, err = pk:get_key_type(nid_only?)</p> <p>Returns a ASN1_OBJECT of key type of the private key as a table.</p> <p>Starting from lua-resty-openssl 1.6.0, an optional argument <code>nid_only</code> can be set to <code>true</code> to only return the numeric NID of the key.</p> <pre><code>local pkey, err = require(\"resty.openssl.pkey\").new({type=\"X448\"})\n\nngx.say(require(\"cjson\").encode(pkey:get_key_type()))\n-- outputs '{\"ln\":\"X448\",\"nid\":1035,\"sn\":\"X448\",\"id\":\"1.3.101.111\"}'\nngx.say(pkey:get_key_type(true))\n-- outputs 1035\n</code></pre>"},{"location":"lua/openssl/#pkeyget_size","title":"pkey:get_size","text":"<p>syntax: size, err = pk:get_size()</p> <p>Returns the maximum suitable size for the output buffers for almost all operations that can be done with pkey.</p> <p>For RSA key, this is the size of the modulus. For EC, Ed25519 and Ed448 keys, this is the size of the private key. For DH key, this is the size of the prime modulus.</p>"},{"location":"lua/openssl/#pkeyget_default_digest_type","title":"pkey:get_default_digest_type","text":"<p>syntax: obj, err = pk:get_default_digest_type()</p> <p>Returns a ASN1_OBJECT of key type of the private key as a table. An additional field <code>mandatory</code> is also returned in the table, if <code>mandatory</code> is true then other digests can not be used.</p> <pre><code>local pkey, err = require(\"resty.openssl.pkey\").new()\n\nngx.say(require(\"cjson\").encode(pkey:get_default_digest_type()))\n-- outputs '{\"ln\":\"sha256\",\"nid\":672,\"id\":\"2.16.840.1.101.3.4.2.1\",\"mandatory\":false,\"sn\":\"SHA256\"}'\n</code></pre>"},{"location":"lua/openssl/#pkeysign","title":"pkey:sign","text":"<p>syntax: signature, err = pk:sign(digest)</p> <p>syntax: signature, err = pk:sign(message, md_alg?, padding?, opts?)</p> <p>Perform a digest signing using the private key defined in <code>pkey</code> instance. The first parameter must be a resty.openssl.digest instance or a string. Returns the signed text and error if any.</p> <p>When passing a digest instance as first parameter, it should not have been called final(), user should only use update(). This mode only supports RSA and EC keys.</p> <p>When passing a string as first parameter, <code>md_alg</code> parameter will specify the name to use when signing. When <code>md_alg</code> is undefined, for RSA and EC keys, this function does SHA256 by default. For Ed25519 or Ed448 keys, this function does a PureEdDSA signing, no message digest should be specified and will not be used.</p> <p>For RSA key, it's also possible to specify <code>padding</code> scheme with following choices:</p> <pre><code>  pkey.PADDINGS = {\n    RSA_PKCS1_PADDING       = 1,\n    RSA_SSLV23_PADDING      = 2,\n    RSA_NO_PADDING          = 3,\n    RSA_PKCS1_OAEP_PADDING  = 4,\n    RSA_X931_PADDING        = 5, -- sign only\n    RSA_PKCS1_PSS_PADDING   = 6, -- sign and verify only\n  }\n</code></pre> <p>When <code>padding</code> is <code>RSA_PKCS1_PSS_PADDING</code>, it's possible to specify PSS salt length by setting <code>opts.pss_saltlen</code>.</p> <p>For EC key, this function does a ECDSA signing. Note that OpenSSL does not support EC digital signature (ECDSA) with the obsolete MD5 hash algorithm and will return error on this combination. See EVP_DigestSign(3) for a list of algorithms and associated public key algorithms. Normally, the ECDSA signature is encoded in ASN.1 DER format. If the <code>opts</code> table contains a <code>ecdsa_use_raw</code> field with a true value, a binary with just the concatenation of binary representation <code>pr</code> and <code>ps</code> is returned. This is useful for example to send the signature as JWS.</p> <p><code>opts</code> is a table that accepts additional parameters with following choices:</p> <pre><code>{\n  pss_saltlen, -- For PSS mode only this option specifies the salt length.\n  mgf1_md, -- For PSS and OAEP padding sets the MGF1 digest. If the MGF1 digest is not explicitly set in PSS mode then the signing digest is used.\n  oaep_md, -- The digest used for the OAEP hash function. If not explicitly set then SHA1 is used.\n}\n</code></pre> <p>It's also possible to pass raw pkeyopt control strings as used in the <code>pkeyutl</code> CLI program. This lets user pass in options that are not explictly supported as parameters above. See openssl-pkeyutl(1) for a list of options.</p> <pre><code>pk:sign(message, nil, pk.PADDINGS.RSA_PKCS1_OAEP_PADDING, {\n  oaep_md = \"sha256\",\n})\n-- is same as\npk:sign(message, nil, nil, {\n  \"rsa_padding_mode:oaep\",\n  \"rsa_oaep_md:sha256\",\n})\n-- in pkeyutl CLI the above is equivalent to: `openssl pkeyutl -sign -pkeyopt rsa_padding_mode:oaep -pkeyopt rsa_oaep_md:sha256\n</code></pre> <p>To sign a message without doing message digest, please check pkey:sign_raw.</p>"},{"location":"lua/openssl/#pkeyverify","title":"pkey:verify","text":"<p>syntax: ok, err = pk:verify(signature, digest)</p> <p>syntax: ok, err = pk:verify(signature, message, md_alg?, padding?, opts?)</p> <p>Verify a signture (which can be the string returned by pkey:sign). The second argument must be a resty.openssl.digest instance that uses the same digest algorithm as used in <code>sign</code> or a string. <code>ok</code> returns <code>true</code> if verficiation is successful and <code>false</code> otherwise. Note when verfication failed <code>err</code> will not be set when used with OpenSSL 1.1.1 or lower.</p> <p>When passing digest instances as second parameter, it should not have been called final(), user should only use update(). This mode only supports RSA and EC keys.</p> <p>When passing a string as second parameter, <code>md_alg</code> parameter will specify the name to use when verifying. When <code>md_alg</code> is undefined, for RSA and EC keys, this function does SHA256 by default. For Ed25519 or Ed448 keys, this function does a PureEdDSA verification, no message digest should be specified and will not be used.</p> <p>When key is a RSA key, the function accepts an optional argument <code>padding</code> which choices of values are same as those in pkey:sign. When <code>padding</code> is <code>RSA_PKCS1_PSS_PADDING</code>, it's possible to specify PSS salt length by setting <code>opts.pss_saltlen</code>.</p> <p>For EC key, this function does a ECDSA verification. Normally, the ECDSA signature should be encoded in ASN.1 DER format. If the <code>opts</code> table contains a <code>ecdsa_use_raw</code> field with a true value, this library treat <code>signature</code> as concatenation of binary representation <code>pr</code> and <code>ps</code>. This is useful for example to verify the signature as JWS.</p> <p><code>opts</code> is a table that accepts additional parameters which choices of values are same as those in pkey:sign.</p> <pre><code>-- RSA and EC keys\nlocal pk, err = require(\"resty.openssl.pkey\").new()\nlocal digest, err = require(\"resty.openssl.digest\").new(\"SHA256\")\ndigest:update(\"dog\")\n-- WRONG:\n-- digest:final(\"dog\")\nlocal signature, err = pk:sign(digest)\n-- uses SHA256 by default\nlocal signature, err = pk:sign(\"dog\")\nngx.say(ngx.encode_base64(signature))\n-- uses SHA256 and PSS padding\nlocal signature_pss, err = pk:sign(\"dog\", \"sha256\", pk.PADDINGS.RSA_PKCS1_PSS_PADDING)\n\ndigest, err = require(\"resty.openssl.digest\").new(\"SHA256\")\ndigest:update(\"dog\")\nlocal ok, err = pk:verify(signature, digest)\n-- uses SHA256 by default\nlocal ok, err = pk:verify(signature, \"dog\")\n-- uses SHA256 and PSS padding\nlocal ok, err = pk:verify(signature_pss, \"dog\", \"sha256\", pk.PADDINGS.RSA_PKCS1_PSS_PADDING)\n\n-- Ed25519 and Ed448 keys\nlocal pk, err = require(\"resty.openssl.pkey\").new({\n  type = \"Ed25519\",\n})\nlocal signature, err = pk:sign(\"23333\")\nngx.say(ngx.encode_base64(signature))\n</code></pre> <p>To verify a message without doing message digest, please check pkey:verify_raw and pkey:verify_recover.</p>"},{"location":"lua/openssl/#pkeyencrypt","title":"pkey:encrypt","text":"<p>syntax: cipher_txt, err = pk:encrypt(txt, padding?, opts?)</p> <p>Encrypts plain text <code>txt</code> with <code>pkey</code> instance, which must loaded a public key.</p> <p>The optional second argument <code>padding</code> has same meaning as in pkey:sign. If omitted, <code>padding</code> is default to <code>pkey.PADDINGS.RSA_PKCS1_PADDING</code>.</p> <p>The third optional argument <code>opts</code> has same meaning as in pkey:sign.</p>"},{"location":"lua/openssl/#pkeydecrypt","title":"pkey:decrypt","text":"<p>syntax: txt, err = pk:decrypt(cipher_txt, padding?, opts?)</p> <p>Decrypts cipher text <code>cipher_txt</code> with pkey instance, which must loaded a private key.</p> <p>The optional second argument <code>padding</code> has same meaning as in pkey:sign. If omitted, <code>padding</code> is default to <code>pkey.PADDINGS.RSA_PKCS1_PADDING</code>.</p> <p>The third optional argument <code>opts</code> has same meaning as in pkey:sign.</p> <pre><code>local pkey = require(\"resty.openssl.pkey\")\nlocal privkey, err = pkey.new()\nlocal pub_pem = privkey:to_PEM(\"public\")\nlocal pubkey, err = pkey.new(pub_pem)\nlocal s, err = pubkey:encrypt(\"\ud83e\udda2\", pkey.PADDINGS.RSA_PKCS1_PADDING)\nngx.say(#s)\n-- outputs 256\nlocal decrypted, err = privkey:decrypt(s)\nngx.say(decrypted)\n-- outputs \"\ud83e\udda2\"\n</code></pre>"},{"location":"lua/openssl/#pkeysign_raw","title":"pkey:sign_raw","text":"<p>syntax: signature, err = pk:sign_raw(txt, padding?, opts?)</p> <p>Signs the cipher text <code>cipher_txt</code> with pkey instance, which must loaded a private key.</p> <p>The optional second argument <code>padding</code> has same meaning as in pkey:sign. If omitted, <code>padding</code> is default to <code>pkey.PADDINGS.RSA_PKCS1_PADDING</code>.</p> <p>The third optional argument <code>opts</code> has same meaning as in pkey:sign.</p> <p>This function may also be called \"private encrypt\" in some implementations like NodeJS or PHP. Do note as the function names suggested, this function is not secure to be regarded as an encryption. When developing new applications, user should use pkey:sign for signing with digest, or  pkey:encrypt for encryption.</p> <p>See examples/raw-sign-and-recover.lua for an example.</p>"},{"location":"lua/openssl/#pkeyverify_raw","title":"pkey:verify_raw","text":"<p>syntax: ok, err = pk:verify_raw(signature, data, md_alg, padding?, opts?)</p> <p>Verify the cipher text <code>signature</code> with the message <code>data</code> with pkey instance, which must loaded a public key. Set the message digest to <code>md_alg</code> but doesn't do message digest automatically, in other words, this function assumes <code>data</code> has already been hashed with <code>md_alg</code>.</p> <p>When <code>md_alg</code> is undefined, for RSA and EC keys, this function does SHA256 by default. For Ed25519 or Ed448 keys, no default value is set.</p> <p>The optinal fourth argument <code>padding</code> has same meaning as in pkey:sign. If omitted, <code>padding</code> is default to <code>pkey.PADDINGS.RSA_PKCS1_PADDING</code>.</p> <p>The fifth optional argument <code>opts</code> has same meaning as in pkey:sign.</p> <p>See examples/raw-sign-and-recover.lua for an example.</p>"},{"location":"lua/openssl/#pkeyverify_recover","title":"pkey:verify_recover","text":"<p>syntax: txt, err = pk:verify_recover(signature, padding?, opts?)</p> <p>Verify the cipher text <code>signature</code> with pkey instance, which must loaded a public key, and also returns the original text being signed. This operation is only supported by RSA key.</p> <p>The optional second argument <code>padding</code> has same meaning as in pkey:sign. If omitted, <code>padding</code> is default to <code>pkey.PADDINGS.RSA_PKCS1_PADDING</code>.</p> <p>The third optional argument <code>opts</code> has same meaning as in pkey:sign.</p> <p>This function may also be called \"public decrypt\" in some implementations like NodeJS or PHP.</p> <p>See examples/raw-sign-and-recover.lua for an example.</p>"},{"location":"lua/openssl/#pkeyderive","title":"pkey:derive","text":"<p>syntax: txt, err = pk:derive(peer_key)</p> <p>Derive public key algorithm shared secret <code>peer_key</code>, which must be a pkey instance.</p> <p>See examples/x25519-dh.lua for an example on how key exchange works for X25519 keys with DH algorithm.</p>"},{"location":"lua/openssl/#pkeytostring","title":"pkey:tostring","text":"<p>syntax: txt, err = pk:tostring(private_or_public?, fmt?, is_pkcs1?)</p> <p>Outputs private key or public key of pkey instance in PEM-formatted text. The first argument must be a choice of <code>public</code>, <code>PublicKey</code>, <code>private</code>, <code>PrivateKey</code> or nil.</p> <p>The second argument <code>fmt</code> can be <code>PEM</code>, <code>DER</code>, <code>JWK</code> or nil. If both arguments are omitted, this functions returns the <code>PEM</code> representation of public key.</p> <p>If <code>is_pkcs1</code> is set to true, the output is encoded using a PKCS#1 RSAPublicKey structure; <code>PKCS#1</code> encoding is currently supported for RSA key in PEM format. Writing out a PKCS#1 encoded RSA key is currently not supported when using with OpenSSL 3.0.</p>"},{"location":"lua/openssl/#pkeyto_pem","title":"pkey:to_PEM","text":"<p>syntax: pem, err = pk:to_PEM(private_or_public?, is_pkcs1?)</p> <p>Equivalent to <code>pkey:tostring(private_or_public, \"PEM\", is_pkcs1)</code>.</p>"},{"location":"lua/openssl/#restyopensslbn","title":"resty.openssl.bn","text":"<p>Module to expose BIGNUM structure. Note bignum is a big integer, no float operations (like square root) are supported.</p>"},{"location":"lua/openssl/#bnnew","title":"bn.new","text":"<p>syntax: b, err = bn.new(number?)</p> <p>syntax: b, err = bn.new(string?, base?)</p> <p>Creates a <code>bn</code> instance. The first argument can be:</p> <ul> <li><code>nil</code> to creates an empty bn instance.</li> <li>A Lua number to initialize the bn instance.</li> <li>A string to initialize the bn instance. The second argument <code>base</code> specifies the base of the string, and can take value from (compatible with Ruby OpenSSL.BN API):</li> <li><code>10</code> or omitted, for decimal string (<code>\"23333\"</code>)</li> <li><code>16</code>, for hex encoded string (<code>\"5b25\"</code>)</li> <li><code>2</code>, for binary string (<code>\"\\x5b\\x25\"</code>)</li> <li><code>0</code>, for MPI formated string (<code>\"\\x00\\x00\\x00\\x02\\x5b\\x25\"</code>)</li> </ul> <p>MPI is a format that consists of the number's length in bytes represented as a 4-byte big-endian number, and the number itself in big-endian format, where the most significant bit signals a negative number (the representation of numbers with the MSB set is prefixed with null byte).</p>"},{"location":"lua/openssl/#bndup","title":"bn.dup","text":"<p>syntax: b, err = bn.dup(bn_ptr_cdata)</p> <p>Duplicates a <code>BIGNUM*</code> to create a new <code>bn</code> instance.</p>"},{"location":"lua/openssl/#bnistype","title":"bn.istype","text":"<p>syntax: ok = bn.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>bn</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#bnset","title":"bn.set","text":"<p>syntax: b, err = bn:set(number)</p> <p>syntax: b, err = bn:set(string, base?)</p> <p>Reuse the existing bn instance and reset its value with given number or string. Refer to bn.new for the type of arguments supported.</p>"},{"location":"lua/openssl/#bnfrom_binary-bnto_binary","title":"bn.from_binary, bn:to_binary","text":"<p>syntax: bn, err = bn.from_binary(bin)</p> <p>syntax: bin, err = bn:to_binary(padto?)</p> <p>Creates a <code>bn</code> instance from binary string.</p> <p>Exports the BIGNUM value in binary string.</p> <p><code>bn:to_binary</code> accepts an optional number argument <code>padto</code> that can be used to pad leading zeros to the output to a specific length.</p> <pre><code>local to_hex = require \"resty.string\".to_hex\nlocal b, err = require(\"resty.openssl.bn\").from_binary(\"\\x5b\\x25\")\nlocal bin, err = b:to_binary()\nngx.say(to_hex(bin))\n-- outputs \"5b25\n</code></pre>"},{"location":"lua/openssl/#bnfrom_mpi-bnto_mpi","title":"bn.from_mpi, bn:to_mpi","text":"<p>syntax: bn, err = bn.from_mpi(bin)</p> <p>syntax: bin, err = bn:to_mpi()</p> <p>Creates a <code>bn</code> instance from MPI formatted binary string.</p> <p>Exports the BIGNUM value in MPI formatted binary string.</p> <pre><code>local to_hex = require \"resty.string\".to_hex\nlocal b, err = require(\"resty.openssl.bn\").from_mpi(\"\\x00\\x00\\x00\\x02\\x5b\\x25\")\nlocal bin, err = b:to_mpi()\nngx.say(to_hex(bin))\n-- outputs \"000000025b25\n</code></pre>"},{"location":"lua/openssl/#bnfrom_hex-bnto_hex","title":"bn.from_hex, bn:to_hex","text":"<p>syntax: bn, err = bn.from_hex(hex)</p> <p>syntax: hex, err = bn:to_hex()</p> <p>Creates a <code>bn</code> instance from hex encoded string. Note that the leading <code>0x</code> should not be included. A leading <code>-</code> indicating the sign may be included.</p> <p>Exports the <code>bn</code> instance to hex encoded string.</p> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal b = bn.from_hex(\"5B25\")\nlocal hex, err = b:to_hex()\nngx.say(hex)\n-- outputs \"5B25\"\n</code></pre>"},{"location":"lua/openssl/#bnfrom_dec-bnto_dec","title":"bn.from_dec, bn:to_dec","text":"<p>syntax: bn, err = bn.from_dec(dec)</p> <p>syntax: dec, err = bn:to_dec()</p> <p>Creates a <code>bn</code> instance from decimal string. A leading <code>-</code> indicating the sign may be included.</p> <p>Exports the <code>bn</code> instance to decimal string.</p> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal b = bn.from_dec(\"23333\")\nlocal dec, err = b:to_dec()\nngx.say(dec)\n-- outputs \"23333\"\n</code></pre>"},{"location":"lua/openssl/#bnto_number","title":"bn:to_number","text":"<p>syntax: n, err = bn:to_number()</p> <p>syntax: n, err = bn:tonumber()</p> <p>Export the lowest 32 bits or 64 bits part (based on the ABI) of <code>bn</code> instance to a number. This is useful when user wants to perform bitwise operations.</p> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal b = bn.from_dec(\"23333\")\nlocal n, err = b:to_number()\nngx.say(n)\n-- outputs 23333\nngx.say(type(n))\n-- outputs \"number\"\n</code></pre>"},{"location":"lua/openssl/#bngenerate_prime","title":"bn.generate_prime","text":"<p>syntax: bn, err = bn.generate_prime(bits, safe)</p> <p>Generates a pseudo-random prime number of bit length <code>bits</code>.</p> <p>If <code>safe</code> is true, it will be a safe prime (i.e. a prime p so that (p-1)/2 is also prime).</p> <p>The PRNG must be seeded prior to calling BN_generate_prime_ex(). The prime number generation has a negligible error probability.</p>"},{"location":"lua/openssl/#bn__metamethods","title":"bn:__metamethods","text":"<p>Various mathematical operations can be performed as if it's a number.</p> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal a = bn.new(123456)\nlocal b = bn.new(222)\n -- the following returns a bn\nlocal r\nr = -a\nr = a + b\nr = a - b\nr = a * b\nr = a / b -- equal to bn:idiv, returns floor division\nr = a % b\n-- all operations can be performed between number and bignum\nr = a + 222\nr = 222 + a\n-- the following returns a bool\nlocal bool\nbool = a &lt; b\nbool = a &gt;= b\n-- compare between number will not work\n-- WRONG: bool = a &lt; 222\n</code></pre>"},{"location":"lua/openssl/#bnadd-bnsub-bnmul-bndiv-bnexp-bnmod-bngcd","title":"bn:add, bn:sub, bn:mul, bn:div, bn:exp, bn:mod, bn:gcd","text":"<p>syntax: r = a:op(b)</p> <p>syntax: r = bn.op(a, b)</p> <p>Perform mathematical operations <code>op</code>.</p> <ul> <li><code>add</code>: add</li> <li><code>sub</code>: subtract</li> <li><code>mul</code>: multiply</li> <li><code>div</code>, <code>idiv</code>: floor division (division with rounding down to nearest integer)</li> <li><code>exp</code>, <code>pow</code>: the <code>b</code>-th power of <code>a</code>, this function is faster than repeated <code>a * a * ...</code>.</li> <li><code>mod</code>: modulo</li> <li><code>gcd</code>: the greatest common divider of <code>a</code> and <code>b</code>.</li> </ul> <p>Note that <code>add</code>, <code>sub</code>, <code>mul</code>, <code>div</code>, <code>mod</code> is also available with <code>+, -, *, /, %</code> operaters. See above section for examples.</p> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal a = bn.new(123456)\nlocal b = bn.new(9876)\nlocal r\n-- the followings are equal\nr = a:add(b)\nr = bn.add(a, b)\nr = a:add(9876)\nr = bn.add(a, 9876)\nr = bn.add(123456, b)\nr = bn.add(123456, 9876)\n</code></pre>"},{"location":"lua/openssl/#bnsqr","title":"bn:sqr","text":"<p>syntax: r = a:sqr()</p> <p>syntax: r = bn.sqr(a)</p> <p>Computes the 2-th power of <code>a</code>. This function is faster than <code>r = a * a</code>.</p>"},{"location":"lua/openssl/#bnmod_add-bnmod_sub-bnmod_mul-bnmod_exp","title":"bn:mod_add, bn:mod_sub, bn:mod_mul, bn:mod_exp","text":"<p>syntax: r = a:op(b, m)</p> <p>syntax: r = bn.op(a, b, m)</p> <p>Perform modulo mathematical operations <code>op</code>.</p> <ul> <li><code>mod_add</code>: adds <code>a</code> to <code>b</code> modulo <code>m</code></li> <li><code>mod_sub</code>: substracts <code>b</code> from <code>a</code> modulo <code>m</code></li> <li><code>mod_mul</code>: multiplies <code>a</code> by <code>b</code> and finds the non-negative remainder respective to modulus <code>m</code></li> <li><code>mod_exp</code>, <code>mod_pow</code>: computes <code>a</code> to the <code>b</code>-th power modulo <code>m</code> (r=a^b % m). This function uses less time and space than <code>exp</code>. Do not call this function when <code>m</code> is even and any of the parameters have the <code>BN_FLG_CONSTTIME</code> flag set.</li> </ul> <pre><code>local bn = require(\"resty.openssl.bn\")\nlocal a = bn.new(123456)\nlocal b = bn.new(9876)\nlocal r\n-- the followings are equal\nr = a:mod_add(b, 3)\nr = bn.mod_add(a, b, 3)\nr = a:mod_add(9876, 3)\nr = bn.mod_add(a, 9876, 3)\nr = bn.mod_add(123456, b, 3)\nr = bn.mod_add(123456, 9876, 3)\n</code></pre>"},{"location":"lua/openssl/#bnmod_sqr","title":"bn:mod_sqr","text":"<p>syntax: r = a:mod_sqr(m)</p> <p>syntax: r = bn.mod_sqr(a, m)</p> <p>Takes the square of <code>a</code> modulo <code>m</code>.</p>"},{"location":"lua/openssl/#bnlshift-bnrshift","title":"bn:lshift, bn:rshift","text":"<p>syntax: r = bn:lshift(bit)</p> <p>syntax: r = bn.lshift(a, bit)</p> <p>syntax: r = bn:rshift(bit)</p> <p>syntax: r = bn.rshift(a, bit)</p> <p>Bit shift <code>a</code> to <code>bit</code> bits.</p>"},{"location":"lua/openssl/#bnis_zero-bnis_one-bnis_odd-bnis_word","title":"bn:is_zero, bn:is_one, bn:is_odd, bn:is_word","text":"<p>syntax: ok = bn:is_zero()</p> <p>syntax: ok = bn:is_one()</p> <p>syntax: ok = bn:is_odd()</p> <p>syntax: ok, err = bn:is_word(n)</p> <p>Checks if <code>bn</code> is <code>0</code>, <code>1</code>, and odd number or a number <code>n</code> respectively.</p>"},{"location":"lua/openssl/#bnis_prime","title":"bn:is_prime","text":"<p>syntax: ok, err = bn:is_prime(nchecks?)</p> <p>Checks if <code>bn</code> is a prime number. Returns <code>true</code> if it is prime with an error probability of less than 0.25^<code>nchecks</code> and error if any. If omitted, <code>nchecks</code> is set to 0 which means to select number of iterations basedon the size of the number</p> <p>This function perform a Miller-Rabin probabilistic primality test with nchecks iterations. If nchecks == BN_prime_checks (0), a number of iterations is used that yields a false positive rate of at most 2^-64 for random input. The error rate depends on the size of the prime and goes down for bigger primes. The rate is 2^-80 starting at 308 bits, 2^-112 at 852 bits, 2^-128 at 1080 bits, 2^-192 at 3747 bits and 2^-256 at 6394 bits.</p> <p>When the source of the prime is not random or not trusted, the number of checks needs to be much higher to reach the same level of assurance: It should equal half of the targeted security level in bits (rounded up to the next integer if necessary). For instance, to reach the 128 bit security level, nchecks should be set to 64.</p> <p>See also BN_is_prime(3).</p>"},{"location":"lua/openssl/#restyopensslcipher","title":"resty.openssl.cipher","text":"<p>Module to interact with symmetric cryptography (EVP_CIPHER).</p>"},{"location":"lua/openssl/#ciphernew","title":"cipher.new","text":"<p>syntax: d, err = cipher.new(cipher_name, properties?)</p> <p>Creates a cipher instance. <code>cipher_name</code> is a case-insensitive string of cipher algorithm name. To view a list of cipher algorithms implemented, use openssl.list_cipher_algorithms or <code>openssl list -cipher-algorithms</code></p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#cipheristype","title":"cipher.istype","text":"<p>syntax: ok = cipher.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>cipher</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#cipherset_buffer_size","title":"cipher.set_buffer_size","text":"<p>syntax: ok = cipher.set_buffer_size(sz)</p> <p>Resize the internal buffer size used by all cipher instance. The default buffer size is 1024 bytes.</p> <p>If you are expecting to pass input text larger than 1024 bytes at one time to <code>update()</code>, <code>encrypt()</code> or <code>decrypt()</code>, setting the buffer to larger than the expected input size will improve performance by let more code to be JIT-able.</p> <p>Avoid call this function at hotpath, as this re-allocate the buffer every time it's called.</p>"},{"location":"lua/openssl/#cipherget_provider_name","title":"cipher:get_provider_name","text":"<p>syntax: name = cipher:get_provider_name()</p> <p>Returns the provider name of <code>cipher</code>.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#ciphergettable_params-ciphersettable_params-cipherget_param-cipherset_params","title":"cipher:gettable_params, cipher:settable_params, cipher:get_param, cipher:set_params","text":"<p>Query settable or gettable params and set or get params. See Generic EVP parameter getter/setter.</p>"},{"location":"lua/openssl/#cipherencrypt","title":"cipher:encrypt","text":"<p>syntax: s, err = cipher:encrypt(key, iv?, s, no_padding?, aead_aad?)</p> <p>Encrypt the text <code>s</code> with key <code>key</code> and IV <code>iv</code>. Returns the encrypted text in raw binary string and error if any. Optionally accepts a boolean <code>no_padding</code> which tells the cipher to enable or disable padding and default to <code>false</code> (enable padding). If <code>no_padding</code> is <code>true</code>, the length of <code>s</code> must then be a multiple of the block size or an error will occur.</p> <p>When using GCM or CCM mode or <code>chacha20-poly1305</code> cipher, it's also possible to pass the Additional Authenticated Data (AAD) as the fifth argument.</p> <p>This function is a shorthand of <code>cipher:init</code>, <code>cipher:set_aead_aad</code> (if appliable) then <code>cipher:final</code>.</p>"},{"location":"lua/openssl/#cipherdecrypt","title":"cipher:decrypt","text":"<p>syntax: s, err = cipher:decrypt(key, iv?, s, no_padding?, aead_aad?, aead_tag?)</p> <p>Decrypt the text <code>s</code> with key <code>key</code> and IV <code>iv</code>. Returns the decrypted text in raw binary string and error if any. Optionally accepts a boolean <code>no_padding</code> which tells the cipher to enable or disable padding and default to <code>false</code> (enable padding). If <code>no_padding</code> is <code>true</code>, the length of <code>s</code> must then be a multiple of the block size or an error will occur; also, padding in the decrypted text will not be removed.</p> <p>When using GCM or CCM mode or <code>chacha20-poly1305</code> cipher, it's also possible to pas the Additional Authenticated Data (AAD) as the fifth argument and authentication tag as the sixth argument.</p> <p>This function is a shorthand of <code>cipher:init</code>, <code>cipher:set_aead_aad</code> (if appliable), <code>cipher:set_aead_tag</code> (if appliable) then <code>cipher:final</code>.</p>"},{"location":"lua/openssl/#cipherinit","title":"cipher:init","text":"<p>syntax: ok, err = cipher:init(key, iv?, opts?)</p> <p>Initialize the cipher with key <code>key</code> and IV <code>iv</code>. The optional third argument is a table consists of:</p> <pre><code>{\n    is_encrypt = false,\n    no_padding = false,\n}\n</code></pre> <p>Calling function is needed before cipher:update and cipher:final if the cipher is not being initialized already. But not cipher:encrypt and cipher:decrypt.</p> <p>If you wish to reuse <code>cipher</code> instance multiple times, calling this function is necessary to clear the internal state of the cipher. The shorthand functions cipher:encrypt and cipher:decrypt already take care of initialization and reset.</p>"},{"location":"lua/openssl/#cipherupdate","title":"cipher:update","text":"<p>syntax: s, err = cipher:update(partial, ...)</p> <p>Updates the cipher with one or more strings. If the cipher has larger than block size of data to flush, the function will return a non-empty string as first argument. This function can be used in a streaming fashion to encrypt or decrypt continous data stream.</p>"},{"location":"lua/openssl/#cipherupdate_aead_aad","title":"cipher:update_aead_aad","text":"<p>syntax: ok, err = cipher:update_aead_aad(aad)</p> <p>Provides AAD data to the cipher, this function can be called more than one times.</p>"},{"location":"lua/openssl/#cipherget_aead_tag","title":"cipher:get_aead_tag","text":"<p>syntax: tag, err = cipher:get_aead_tag(size?)</p> <p>Gets the authentication tag from cipher with length specified as <code>size</code>. If omitted, a tag with length of half of the block size will be returned. The size cannot exceed block size.</p> <p>This function can only be called after encryption is finished.</p>"},{"location":"lua/openssl/#cipherset_aead_tag","title":"cipher:set_aead_tag","text":"<p>syntax: ok, err = cipher:set_aead_tag(tag)</p> <p>Set the authentication tag of cipher with <code>tag</code>.</p> <p>This function can only be called before decryption starts.</p>"},{"location":"lua/openssl/#cipherfinal","title":"cipher:final","text":"<p>syntax: s, err = cipher:final(partial?)</p> <p>Returns the encrypted or decrypted text in raw binary string, optionally accept one string to encrypt or decrypt.</p> <pre><code>-- encryption\nlocal c, err = require(\"resty.openssl.cipher\").new(\"aes256\")\nc:init(string.rep(\"0\", 32), string.rep(\"0\", 16), {\n    is_encrypt = true,\n})\nc:update(\"\ud83e\udda2\")\nlocal cipher, err = c:final()\nngx.say(ngx.encode_base64(cipher))\n-- outputs \"vGJRHufPYrbbnYYC0+BnwQ==\"\n-- OR:\nlocal c, err = require(\"resty.openssl.cipher\").new(\"aes256\")\nlocal cipher, err = c:encrypt(string.rep(\"0\", 32), string.rep(\"0\", 16), \"\ud83e\udda2\")\nngx.say(ngx.encode_base64(cipher))\n-- outputs \"vGJRHufPYrbbnYYC0+BnwQ==\"\n\n-- decryption\nlocal encrypted = ngx.decode_base64(\"vGJRHufPYrbbnYYC0+BnwQ==\")\nlocal c, err = require(\"resty.openssl.cipher\").new(\"aes256\")\nc:init(string.rep(\"0\", 32), string.rep(\"0\", 16), {\n    is_encrypt = false,\n})\nc:update(encrypted)\nlocal cipher, err = c:final()\nngx.say(cipher)\n-- outputs \"\ud83e\udda2\"\n-- OR:\nlocal c, err = require(\"resty.openssl.cipher\").new(\"aes256\")\nlocal cipher, err = c:decrypt(string.rep(\"0\", 32), string.rep(\"0\", 16), encrypted)\nngx.say(cipher)\n-- outputs \"\ud83e\udda2\"\n</code></pre> <p>Note: in some implementations like <code>libsodium</code> or Java, AEAD ciphers append the <code>tag</code> (or <code>MAC</code>) at the end of encrypted ciphertext. In such case, user will need to manually cut off the <code>tag</code> with correct size(usually 16 bytes) and pass in the ciphertext and <code>tag</code> seperately.</p> <p>See examples/aes-gcm-aead.lua for an example to use AEAD modes with authentication.</p>"},{"location":"lua/openssl/#cipherderive","title":"cipher:derive","text":"<p>syntax: key, iv, err = cipher:derive(key, salt?, count?, md?)</p> <p>Derive a key and IV (if appliable) from given material that can be used in current cipher. This function is useful mainly to work with keys that were already derived from same algorithm. Newer applications should use a more modern algorithm such as PBKDF2 provided by kdf.derive.</p> <p><code>count</code> is the iteration count to perform. If it's omitted, it's set to <code>1</code>. Note the recent version of <code>openssl enc</code> cli tool automatically use PBKDF2 if <code>-iter</code> is set to larger than 1, while this function will not. To use PBKDF2 to derive a key, please refer to kdf.derive.</p> <p><code>md</code> is the message digest name to use, it can take one of the values <code>md2</code>, <code>md5</code>, <code>sha</code> or <code>sha1</code>. If it's omitted, it's default to <code>sha1</code>.</p> <pre><code>local cipher = require(\"resty.openssl.cipher\").new(\"aes-128-cfb\")\nlocal key, iv, err = cipher:derive(\"x\")\n-- equivalent to `openssl enc -aes-128-cfb -pass pass:x -nosalt -P -md sha1`\n</code></pre>"},{"location":"lua/openssl/#restyopenssldigest","title":"resty.openssl.digest","text":"<p>Module to interact with message digest (EVP_MD_CTX).</p>"},{"location":"lua/openssl/#digestnew","title":"digest.new","text":"<p>syntax: d, err = digest.new(digest_name?, properties?)</p> <p>Creates a digest instance. <code>digest_name</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use  openssl.list_digest_algorithms or <code>openssl list -digest-algorithms</code>.</p> <p>If <code>digest_name</code> is omitted, it's default to <code>sha1</code>. Specially, the digest_name <code>\"null\"</code> represents a \"null\" message digest that does nothing: i.e. the hash it returns is of zero length.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#digestistype","title":"digest.istype","text":"<p>syntax: ok = digest.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>digest</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#digestget_provider_name","title":"digest:get_provider_name","text":"<p>syntax: name = digest:get_provider_name()</p> <p>Returns the provider name of <code>digest</code>.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#digestgettable_params-digestsettable_params-digestget_param-digestset_params","title":"digest:gettable_params, digest:settable_params, digest:get_param, digest:set_params","text":"<p>Query settable or gettable params and set or get params. See Generic EVP parameter getter/setter.</p>"},{"location":"lua/openssl/#digestupdate","title":"digest:update","text":"<p>syntax: ok, err = digest:update(partial, ...)</p> <p>Updates the digest with one or more strings.</p>"},{"location":"lua/openssl/#digestfinal","title":"digest:final","text":"<p>syntax: str, err = digest:final(partial?)</p> <p>Returns the digest in raw binary string, optionally accept one string to digest.</p> <pre><code>local d, err = require(\"resty.openssl.digest\").new(\"sha256\")\nd:update(\"\ud83e\udda2\")\nlocal digest, err = d:final()\nngx.say(ngx.encode_base64(digest))\n-- outputs \"tWW/2P/uOa/yIV1gRJySJLsHq1xwg0E1RWCvEUDlla0=\"\n-- OR:\nlocal d, err = require(\"resty.openssl.digest\").new(\"sha256\")\nlocal digest, err = d:final(\"\ud83e\udda2\")\nngx.say(ngx.encode_base64(digest))\n-- outputs \"tWW/2P/uOa/yIV1gRJySJLsHq1xwg0E1RWCvEUDlla0=\"\n</code></pre>"},{"location":"lua/openssl/#digestreset","title":"digest:reset","text":"<p>syntax: ok, err = digest:reset()</p> <p>Reset the internal state of <code>digest</code> instance as it's just created by digest.new. It calls EVP_DigestInit_ex under the hood.</p> <p>User must call this before reusing the same <code>digest</code> instance.</p>"},{"location":"lua/openssl/#restyopensslhmac","title":"resty.openssl.hmac","text":"<p>Module to interact with hash-based message authentication code (HMAC_CTX).</p> <p>Use of this module is deprecated since OpenSSL 3.0, please use resty.openssl.mac instead.</p>"},{"location":"lua/openssl/#hmacnew","title":"hmac.new","text":"<p>syntax: h, err = hmac.new(key, digest_name?)</p> <p>Creates a hmac instance. <code>digest_name</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use openssl.list_digest_algorithms or <code>openssl list -digest-algorithms</code>.</p> <p>If <code>digest_name</code> is omitted, it's default to <code>sha1</code>.</p>"},{"location":"lua/openssl/#hmacistype","title":"hmac.istype","text":"<p>syntax: ok = hmac.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>hmac</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#hmacupdate","title":"hmac:update","text":"<p>syntax: ok, err = hmac:update(partial, ...)</p> <p>Updates the HMAC with one or more strings.</p>"},{"location":"lua/openssl/#hmacfinal","title":"hmac:final","text":"<p>syntax: str, err = hmac:final(partial?)</p> <p>Returns the HMAC in raw binary string, optionally accept one string to digest.</p> <pre><code>local d, err = require(\"resty.openssl.hmac\").new(\"goose\", \"sha256\")\nd:update(\"\ud83e\udda2\")\nlocal hmac, err = d:final()\nngx.say(ngx.encode_base64(hmac))\n-- outputs \"k2UcrRp25tj1Spff89mJF3fAVQ0lodq/tJT53EYXp0c=\"\n-- OR:\nlocal d, err = require(\"resty.openssl.hmac\").new(\"goose\", \"sha256\")\nlocal hmac, err = d:final(\"\ud83e\udda2\")\nngx.say(ngx.encode_base64(hmac))\n-- outputs \"k2UcrRp25tj1Spff89mJF3fAVQ0lodq/tJT53EYXp0c=\"\n</code></pre>"},{"location":"lua/openssl/#hmacreset","title":"hmac:reset","text":"<p>syntax: ok, err = hmac:reset()</p> <p>Reset the internal state of <code>hmac</code> instance as it's just created by hmac.new. It calls HMAC_Init_ex under the hood.</p> <p>User must call this before reusing the same <code>hmac</code> instance.</p>"},{"location":"lua/openssl/#restyopensslmac","title":"resty.openssl.mac","text":"<p>Module to interact with message authentication code (EVP_MAC).</p>"},{"location":"lua/openssl/#macnew","title":"mac.new","text":"<p>syntax: h, err = mac.new(key, mac, cipher?, digest?, properties?)</p> <p>Creates a mac instance. <code>mac</code> is a case-insensitive string of MAC algorithm name. To view a list of digest algorithms implemented, use openssl.list_mac_algorithms or <code>openssl list -mac-algorithms</code>.</p> <p>At least one of <code>cipher</code> or <code>digest</code> must be specified.</p> <p><code>cipher</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use openssl.list_cipher_algorithms or <code>openssl list -cipher-algorithms</code>. <code>digest</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use openssl.list_digest_algorithms or <code>openssl list -digest-algorithms</code>. <code>properties</code> parameter can be used to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#macistype","title":"mac.istype","text":"<p>syntax: ok = mac.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>mac</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#macget_provider_name","title":"mac:get_provider_name","text":"<p>syntax: name = mac:get_provider_name()</p> <p>Returns the provider name of <code>mac</code>.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#macgettable_params-macsettable_params-macget_param-macset_params","title":"mac:gettable_params, mac:settable_params, mac:get_param, mac:set_params","text":"<p>Query settable or gettable params and set or get params. See Generic EVP parameter getter/setter.</p>"},{"location":"lua/openssl/#macupdate","title":"mac:update","text":"<p>syntax: ok, err = mac:update(partial, ...)</p> <p>Updates the MAC with one or more strings.</p>"},{"location":"lua/openssl/#macfinal","title":"mac:final","text":"<p>syntax: str, err = mac:final(partial?)</p> <p>Returns the MAC in raw binary string, optionally accept one string to digest.</p> <pre><code>local d, err = require(\"resty.openssl.mac\").new(\"goose\", \"HMAC\", nil, \"sha256\")\nd:update(\"\ud83e\udda2\")\nlocal mac, err = d:final()\nngx.say(ngx.encode_base64(mac))\n-- outputs \"k2UcrRp25tj1Spff89mJF3fAVQ0lodq/tJT53EYXp0c=\"\n-- OR:\nlocal d, err = require(\"resty.openssl.mac\").new(\"goose\", \"HMAC\", nil, \"sha256\")\nlocal hmac, err = d:final(\"\ud83e\udda2\")\nngx.say(ngx.encode_base64(mac))\n-- outputs \"k2UcrRp25tj1Spff89mJF3fAVQ0lodq/tJT53EYXp0c=\"\n</code></pre>"},{"location":"lua/openssl/#macreset","title":"mac:reset","text":"<p>syntax: ok, err = mac:reset()</p> <p>Reset the internal state of <code>mac</code> instance as it's just created by mac.new. It calls EVP_MAC_Init under the hood.</p> <p>User must call this before reusing the same <code>mac</code> instance.</p>"},{"location":"lua/openssl/#restyopensslkdf","title":"resty.openssl.kdf","text":"<p>Module to interact with KDF (key derivation function).</p>"},{"location":"lua/openssl/#kdfderive-legacy","title":"kdf.derive (legacy)","text":"<p>syntax: key, err = kdf.derive(options)</p> <p>Use of this module is deprecated since OpenSSL 3.0, please use kdf.new instead.</p> <p>Derive a key from given material. Various KDFs are supported based on OpenSSL version:</p> <p><code>PBKDF2</code>(RFC 2898, NIST SP 800-132), <code>HKDF</code>(RFC 5869), <code>TLS1-PRF</code>(RFC 2246, RFC 5246 and NIST SP 800-135 r1) and <code>scrypt</code>(RFC 7914) is available.</p> <p><code>options</code> is a table that contains:</p> Key Type Description Required or default type number Type of KDF function to use, one of <code>kdf.PBKDF2</code>, <code>kdf.SCRYPT</code>, <code>kdf.TLS1_PRF</code> or <code>kdf.HKDF</code> required outlen number Desired key length to derive required pass string Initial key material to derive from (empty string) salt string Add some salt (empty string) md string Message digest method name to use, not effective for <code>scrypt</code> type <code>\"sha1\"</code> properties string Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms. pbkdf2_iter number PBKDF2 iteration count. RFC 2898 suggests an iteration count of at least 1000. Any value less than 1 is treated as a single iteration. <code>1</code> hkdf_key string HKDF key required hkdf_mode number HKDF mode to use, one of <code>kdf.HKDEF_MODE_EXTRACT_AND_EXPAND</code>, <code>kdf.HKDEF_MODE_EXTRACT_ONLY</code> or <code>kdf.HKDEF_MODE_EXPAND_ONLY</code>. To learn about mode, please refer to EVP_PKEY_CTX_set1_hkdf_key(3). Note with <code>kdf.HKDEF_MODE_EXTRACT_ONLY</code>, <code>outlen</code> is ignored and the output will be fixed size of <code>HMAC-&lt;md&gt;</code>. <code>kdf.HKDEF_MODE_EXTRACT_AND_EXPAND</code> hkdf_info string HKDF info value (empty string) tls1_prf_secret string TLS1-PRF secret required tls1_prf_seed string TLS1-PRF seed required scrypt_maxmem number Scrypt maximum memory usage in bytes <code>32 * 1024 * 1024</code> scrypt_N number Scrypt CPU/memory cost parameter, must be a power of 2 required scrypt_r number Scrypt blocksize parameter (8 is commonly used) required scrypt_p number Scrypt parallelization parameter required <pre><code>local kdf = require(\"resty.openssl.kdf\")\nlocal key, err = kdf.derive({\n    type = kdf.PBKDF2,\n    outlen = 16,\n    pass = \"1234567\",\n    md = \"md5\",\n    pbkdf2_iter = 1000,\n})\nngx.say(ngx.encode_base64(key))\n-- outputs \"cDRFLQ7NWt+AP4i0TdBzog==\"\n\nkey, err = kdf.derive({\n    type = kdf.SCRYPT,\n    outlen = 16,\n    pass = \"1234567\",\n    scrypt_N = 1024,\n    scrypt_r = 8,\n    scrypt_p = 16,\n})\nngx.say(ngx.encode_base64(key))\n-- outputs \"9giFtxace5sESmRb8qxuOw==\"\n</code></pre>"},{"location":"lua/openssl/#kdfnew","title":"kdf.new","text":"<p>syntax: k, err = kdf.new(kdf_name?, properties?)</p> <p>Creates a kdf instance. <code>kdf_name</code> is a case-insensitive string of kdf algorithm name. To view a list of kdf algorithms implemented, use openssl.list_kdf_algorithms or <code>openssl list -kdf-algorithms</code>.</p> <p>This function is available since OpenSSL 3.0.</p> <p>This function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#kdfistype","title":"kdf.istype","text":"<p>syntax: ok = kdf.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>kdf</code>. Returns <code>false</code> otherwise.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#kdfget_provider_name","title":"kdf:get_provider_name","text":"<p>syntax: name = kdf:get_provider_name()</p> <p>Returns the provider name of <code>kdf</code>.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#kdfgettable_params-kdfsettable_params-kdfget_param-kdfset_params","title":"kdf:gettable_params, kdf:settable_params, kdf:get_param, kdf:set_params","text":"<p>Query settable or gettable params and set or get params. See Generic EVP parameter getter/setter.</p> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#kdfderive","title":"kdf:derive","text":"<p>syntax: ok, err = kdf:derive(outlen, options?, options_count?)</p> <p>Derive a key with length of <code>outlen</code> with <code>options</code>. Certain algorithms output fixed length of key where <code>outlen</code> should be unset.</p> <p><code>options</code> is a table map holding parameters passing to <code>kdf</code>. To view the list of parameters acceptable by selecter algorithm and provider, use <code>kdf:settable_params</code>.</p> <p>Optionally, if length of <code>options</code> is known, user can provide its length through <code>options_count</code> to gain better performance where <code>options</code> table is relatively large.</p> <pre><code>local k = assert(kdf.new(\"PBKDF2\"))\nkey = assert(k:derive(16, {\n    pass = \"1234567\",\n    iter = 1000,\n    digest = \"md5\",\n    salt = \"\",\n}))\nngx.say(ngx.encode_base64(key))\n-- outputs \"cDRFLQ7NWt+AP4i0TdBzog==\"\nassert(k:reset())\n-- kdf instance is reusable, user can set common parameters\n-- through set_params and don't need to repeat in derive()\nassert(k:set_params({\n    iter = 1000,\n    digest = \"md5\",\n    salt = \"\",\n}))\nkey = assert(k:derive(16, {\n    pass = \"1234567\",\n}))\nngx.say(ngx.encode_base64(key))\n-- outputs \"cDRFLQ7NWt+AP4i0TdBzog==\"\n\nlocal k = assert(kdf.new(\"HKDF\"))\nkey = assert(k:derive(16, {\n    digest = \"md5\",\n    key = \"secret\",\n    salt = \"salt\",\n    info = \"some info\",\n    mode = kdf.HKDEF_MODE_EXPAND_ONLY,\n    -- as HKDF also accepts mode as string, use the literal below also works\n    -- mode = \"EXPAND_ONLY\"\n}))\n</code></pre> <p>This function is available since OpenSSL 3.0.</p>"},{"location":"lua/openssl/#kdfreset","title":"kdf:reset","text":"<p>syntax: ok, err = kdf:reset()</p> <p>Reset the internal state of <code>kdf</code> instance as it's just created by kdf.new.</p> <p>User must call this before reusing the same <code>kdf</code> instance.</p>"},{"location":"lua/openssl/#restyopensslobjects","title":"resty.openssl.objects","text":"<p>Helpfer module on ASN1_OBJECT.</p>"},{"location":"lua/openssl/#objectsobj2table","title":"objects.obj2table","text":"<p>syntax: tbl = objects.bytes(asn1_obj)</p> <p>Convert a ASN1_OBJECT pointer to a Lua table where</p> <pre><code>{\n  id: OID of the object,\n  nid: NID of the object,\n  sn: short name of the object,\n  ln: long name of the object,\n}\n</code></pre>"},{"location":"lua/openssl/#objectsnid2table","title":"objects.nid2table","text":"<p>syntax: tbl, err = objects.nid2table(nid)</p> <p>Convert a NID to a Lua table, returns the same format as objects.obj2table</p>"},{"location":"lua/openssl/#objectstxt2nid","title":"objects.txt2nid","text":"<p>syntax: nid, err = objects.txt2nid(txt)</p> <p>Convert a text representation to NID. </p>"},{"location":"lua/openssl/#restyopensslpkcs12","title":"resty.openssl.pkcs12","text":"<p>Module to interact with PKCS#12 format.</p>"},{"location":"lua/openssl/#pkcs12encode","title":"pkcs12.encode","text":"<p>syntax: der, err = pkcs12.encode(data, passphrase?, properties?)</p> <p>Encode data in <code>data</code> to a PKCS#12 text.</p> <p><code>data</code> is a table that contains:</p> Key Type Description Required or default key pkey Private key required cert x509 Certificate required cacerts A list of x509 as Lua table Additional certificates <code>[]</code> friendly_name string The name used for the supplied certificate and key <code>\"\"</code> nid_key number or string The NID or text to specify algorithm to encrypt key <code>\"PBE-SHA1-RC2-4\"</code> if compiled with RC2, otherwise <code>\"PBE-SHA1-3DES\"</code>; on OpenSSL 3.0 and later <code>PBES2 with PBKDF2 and AES-256-CBC</code>. nid_cert number or string The NID or text to specify algorithm to encrypt cert <code>\"PBE-SHA1-3DES\"</code>; on OpenSSL 3.0 and later <code>PBES2 with PBKDF2 and AES-256-CBC</code> iter number Key iterration count <code>PKCS12_DEFAULT_ITER</code> (2048) mac_iter number MAC iterration count 1 <p><code>passphrase</code> is the string for encryption. If omitted, an empty string will be used.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p> <p>Note in OpenSSL 3.0 <code>RC2</code> has been moved to legacy provider. In order to encode p12 data with RC2 encryption, you need to load the legacy provider first.</p> <pre><code>local pro = require \"resty.openssl.provider\"\nlocal legacy_provider = assert(pro.load(\"legacy\"))\nlocal p12, err = pkcs12.encode({ key = key, cert = cert})\nassert(legacy_provider:unload())\n</code></pre>"},{"location":"lua/openssl/#pkcs12decode","title":"pkcs12.decode","text":"<p>syntax: data, err = pkcs12.decode(p12, passphrase?)</p> <p>Decode a PKCS#12 text to Lua table <code>data</code>. Similar to the <code>data</code> table passed to pkcs12.encode, but onle <code>cert</code>, <code>key</code>, <code>cacerts</code> and <code>friendly_name</code> are returned.</p> <p><code>passphrase</code> is the string for encryption. If omitted, an empty string will be used.</p> <p>Note in OpenSSL 3.0 <code>RC2</code> has been moved to legacy provider. In order to decode p12 data with RC2 encryption, you need to load the legacy provider first.</p>"},{"location":"lua/openssl/#restyopensslrand","title":"resty.openssl.rand","text":"<p>Module to interact with random number generator.</p>"},{"location":"lua/openssl/#randbytes","title":"rand.bytes","text":"<p>syntax: str, err = rand.bytes(length, private?, strength?)</p> <p>Generate random bytes with length of <code>length</code>. If <code>private</code> is set to true, a private PRNG instance is used so that a compromise of the \"public\" PRNG instance will not affect the secrecy of these private values.</p> <p>The bytes generated will have a security strength of at least <code>strength</code> bits.</p>"},{"location":"lua/openssl/#restyopensslx509","title":"resty.openssl.x509","text":"<p>Module to interact with X.509 certificates.</p>"},{"location":"lua/openssl/#x509new","title":"x509.new","text":"<p>syntax: crt, err = x509.new(txt?, fmt?, properties?)</p> <p>Creates a <code>x509</code> instance. <code>txt</code> can be PEM or DER formatted text; <code>fmt</code> is a choice of <code>PEM</code>, <code>DER</code> to load specific format, or <code>*</code> for auto detect.</p> <p>When <code>txt</code> is omitted, <code>new()</code> creates an empty <code>x509</code> instance.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#x509dup","title":"x509.dup","text":"<p>syntax: x509, err = x509.dup(x509_ptr_cdata)</p> <p>Duplicates a <code>X509*</code> to create a new <code>x509</code> instance.</p>"},{"location":"lua/openssl/#x509istype","title":"x509.istype","text":"<p>syntax: ok = x509.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>x509</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#x509digest","title":"x509:digest","text":"<p>syntax: d, err = x509:digest(digest_name?, properties?)</p> <p>Returns a digest of the DER representation of the X509 certificate object in raw binary text.</p> <p><code>digest_name</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use openssl.list_digest_algorithms or <code>openssl list -digest-algorithms</code>.</p> <p>If <code>digest_name</code> is omitted, it's default to <code>sha1</code>.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#x509pubkey_digest","title":"x509:pubkey_digest","text":"<p>syntax: d, err = x509:pubkey_digest(digest_name?, properties?)</p> <p>Returns a digest of the DER representation of the pubkey in the X509 object in raw binary text.</p> <p><code>digest_name</code> is a case-insensitive string of digest algorithm name. To view a list of digest algorithms implemented, use openssl.list_digest_algorithms or <code>openssl list -digest-algorithms</code>.</p> <p>If <code>digest_name</code> is omitted, it's default to <code>sha1</code>.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#x509check_private_key","title":"x509:check_private_key","text":"<p>syntax: match, err = x509:check_private_key(pkey)</p> <p>Checks the consistency of private key <code>pkey</code> with the public key in current X509 object.</p> <p>Returns a boolean indicating if it's a match and err describing the reason.</p> <p>Note this function also checks if k itself is indeed a private key or not.</p>"},{"location":"lua/openssl/#x509get_-x509set_","title":"x509:get_*, x509:set_*","text":"<p>syntax: ok, err = x509:set_attribute(instance)</p> <p>syntax: instance, err = x509:get_attribute()</p> <p>Setters and getters for x509 attributes share the same syntax.</p> Attribute name Type Description issuer_name x509.name Issuer of the certificate not_before number Unix timestamp when certificate is not valid before not_after number Unix timestamp when certificate is not valid after pubkey pkey Public key of the certificate serial_number bn Serial number of the certficate subject_name x509.name Subject of the certificate version number Version of the certificate, value is one less than version. For example, <code>2</code> represents <code>version 3</code> <p>Additionally, getters and setters for extensions are also available:</p> Extension name Type Description subject_alt_name x509.altname Subject Alternative Name of the certificate, SANs are usually used to define \"additional Common Names\" issuer_alt_name x509.altname Issuer Alternative Name of the certificate basic_constraints table, Basic Constriants of the certificate info_access x509.extension.info_access Authority Information Access of the certificate, contains information like OCSP reponder URL. crl_distribution_points x509.extension.dist_points CRL Distribution Points of the certificate, contains information like Certificate Revocation List(CRL) URLs. <p>For all extensions, <code>get_{extension}_critical</code> and <code>set_{extension}_critical</code> is also supported to access the <code>critical</code> flag of the extension.</p> <p>If the attribute is not found, getter will return <code>nil, nil</code>.</p> <pre><code>local x509, err = require(\"resty.openssl.x509\").new()\nerr = x509:set_not_before(ngx.time())\nlocal not_before, err = x509:get_not_before()\nngx.say(not_before)\n-- outputs 1571875065\n\nerr = x509:set_basic_constraints_critical(true)\n</code></pre> <p>If type is a table, setter requires a table with case-insensitive keys to set; getter returns the value of the given case-insensitive key or a table of all keys if no key provided.</p> <pre><code>local x509, err = require(\"resty.openssl.x509\").new()\nerr = x509:set_basic_constraints({\n  cA = false,\n  pathlen = 0,\n})\n\nngx.say(x509:get_basic_constraints(\"pathlen\"))\n-- outputs 0\n\nngx.say(x509:get_basic_constraints())\n-- outputs '{\"ca\":false,\"pathlen\":0}'\n</code></pre> <p>Note that user may also access the certain extension by x509:get_extension and x509:set_extension, while the later two function returns or requires extension instead. User may use getter and setters listed here if modification of current extensions is needed; use x509:get_extension or x509:set_extension if user are adding or replacing the whole extension or getters/setters are not implemented. If the getter returned a type of <code>x509.*</code> instance, it can be converted to a extension instance by extension:from_data, and thus used by x509:get_extension and x509:set_extension </p>"},{"location":"lua/openssl/#x509get_lifetime","title":"x509:get_lifetime","text":"<p>syntax: not_before, not_after, err = x509:get_lifetime()</p> <p>A shortcut of <code>x509:get_not_before</code> plus <code>x509:get_not_after</code></p>"},{"location":"lua/openssl/#x509set_lifetime","title":"x509:set_lifetime","text":"<p>syntax: ok, err = x509:set_lifetime(not_before, not_after)</p> <p>A shortcut of <code>x509:set_not_before</code> plus <code>x509:set_not_after</code>.</p>"},{"location":"lua/openssl/#x509get_signature_name-x509get_signature_nid-x509get_signature_digest_name","title":"x509:get_signature_name, x509:get_signature_nid, x509:get_signature_digest_name","text":"<p>syntax: sn, err = x509:get_signature_name()</p> <p>syntax: nid, err = x509:get_signature_nid()</p> <p>syntax: sn, err = x509:get_signature_digest_name()</p> <p>Return the NID or the short name (SN) of the signature of the certificate.</p> <p><code>x509:get_signature_digest_name</code> returns the short name of the digest algorithm used to sign the certificate.</p>"},{"location":"lua/openssl/#x509get_extension","title":"x509:get_extension","text":"<p>syntax: extension, pos, err = x509:get_extension(nid_or_txt, last_pos?)</p> <p>Get X.509 <code>extension</code> matching the given NID to certificate, returns a resty.openssl.x509.extension instance and the found position.</p> <p>If <code>last_pos</code> is defined, the function searchs from that position; otherwise it finds from beginning. Index is 1-based.</p> <pre><code>local ext, pos, err = x509:get_extension(\"keyUsage\")\nngx.say(ext:text())\n-- outputs \"Digital Signature, Key Encipherment\"\n\nlocal ext, pos, err = x509:get_extension(\"subjectKeyIdentifier\")\nngx.say(ext:text())\n-- outputs \"3D:42:13:57:8F:79:BE:30:7D:86:A9:AC:67:50:E5:56:3E:0E:AF:4F\"\n</code></pre>"},{"location":"lua/openssl/#x509add_extension","title":"x509:add_extension","text":"<p>syntax: ok, err = x509:add_extension(extension)</p> <p>Adds an X.509 <code>extension</code> to certificate, the first argument must be a resty.openssl.x509.extension instance.</p> <pre><code>local extension, err = require(\"resty.openssl.x509.extension\").new(\n  \"keyUsage\", \"critical,keyCertSign,cRLSign\"\n)\nlocal x509, err = require(\"resty.openssl.x509\").new()\nlocal ok, err = x509:add_extension(extension)\n</code></pre>"},{"location":"lua/openssl/#x509set_extension","title":"x509:set_extension","text":"<p>syntax: ok, err = x509:set_extension(extension, last_pos?)</p> <p>Adds an X.509 <code>extension</code> to certificate, the first argument must be a resty.openssl.x509.extension instance. The difference from x509:add_extension is that in this function if a <code>extension</code> with same type already exists, the old extension will be replaced.</p> <p>If <code>last_pos</code> is defined, the function replaces the same extension from that position; otherwise it finds from beginning. Index is 1-based. Returns <code>nil, nil</code> if not found.</p> <p>Note this function is not thread-safe.</p>"},{"location":"lua/openssl/#x509get_extension_critical","title":"x509:get_extension_critical","text":"<p>syntax: ok, err = x509:get_extension_critical(nid_or_txt)</p> <p>Get critical flag of the X.509 <code>extension</code> matching the given NID from certificate.</p>"},{"location":"lua/openssl/#x509set_extension_critical","title":"x509:set_extension_critical","text":"<p>syntax: ok, err = x509:set_extension_critical(nid_or_txt, crit?)</p> <p>Set critical flag of the X.509 <code>extension</code> matching the given NID to certificate.</p>"},{"location":"lua/openssl/#x509get_ocsp_url","title":"x509:get_ocsp_url","text":"<p>syntax: url_or_urls, err = x509:get_ocsp_url(return_all?)</p> <p>Get OCSP URL(s) of the X.509 object. If <code>return_all</code> is set to true, returns a table containing all OCSP URLs; otherwise returns a string with first OCSP URL found. Returns <code>nil</code> if the extension is not found.</p>"},{"location":"lua/openssl/#x509get_crl_url","title":"x509:get_crl_url","text":"<p>syntax: url_or_urls, err = x509:get_crl_url(return_all?)</p> <p>Get CRL URL(s) of the X.509 object. If <code>return_all</code> is set to true, returns a table containing all CRL URLs; otherwise returns a string with first CRL URL found. Returns <code>nil</code> if the extension is not found.</p>"},{"location":"lua/openssl/#x509sign","title":"x509:sign","text":"<p>syntax: ok, err = x509:sign(pkey, digest?)</p> <p>Sign the certificate using the private key specified by <code>pkey</code>, which must be a  resty.openssl.pkey that stores private key. Optionally accept <code>digest</code> parameter to set digest method, whichmust be a resty.openssl.digest instance. Returns a boolean indicating if signing is successful and error if any.</p>"},{"location":"lua/openssl/#x509verify","title":"x509:verify","text":"<p>syntax: ok, err = x509:verify(pkey)</p> <p>Verify the certificate signature using the public key specified by <code>pkey</code>, which must be a resty.openssl.pkey. Returns a boolean indicating if verification is successful and error if any.</p>"},{"location":"lua/openssl/#x509tostring","title":"x509:tostring","text":"<p>syntax: str, err = x509:tostring(fmt?)</p> <p>Outputs certificate in PEM-formatted text or DER-formatted binary. The first argument can be a choice of <code>PEM</code> or <code>DER</code>; when omitted, this function outputs PEM by default.</p>"},{"location":"lua/openssl/#x509to_pem","title":"x509:to_PEM","text":"<p>syntax: pem, err = x509:to_PEM()</p> <p>Outputs the certificate in PEM-formatted text.</p>"},{"location":"lua/openssl/#restyopensslx509csr","title":"resty.openssl.x509.csr","text":"<p>Module to interact with certificate signing request (X509_REQ).</p> <p>See examples/csr.lua for an example to generate CSR.</p>"},{"location":"lua/openssl/#csrnew","title":"csr.new","text":"<p>syntax: csr, err = csr.new(txt?, fmt?, properties?)</p> <p>Create an empty <code>csr</code> instance. <code>txt</code> can be PEM or DER formatted text; <code>fmt</code> is a choice of <code>PEM</code>, <code>DER</code> to load specific format, or <code>*</code> for auto detect.</p> <p>When <code>txt</code> is omitted, <code>new()</code> creates an empty <code>csr</code> instance.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#csristype","title":"csr.istype","text":"<p>syntax: ok = csr.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>csr</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#csrcheck_private_key","title":"csr:check_private_key","text":"<p>syntax: match, err = csr:check_private_key(pkey)</p> <p>Checks the consistency of private key <code>pkey</code> with the public key in current CSR object.</p> <p>Returns a boolean indicating if it's a match and err describing the reason.</p> <p>Note this function also checks if k itself is indeed a private key or not.</p>"},{"location":"lua/openssl/#csrget_-csrset_","title":"csr:get_*, csr:set_*","text":"<p>syntax: ok, err = csr:set_attribute(instance)</p> <p>syntax: instance, err = csr:get_attribute()</p> <p>Setters and getters for x509 attributes share the same syntax.</p> Attribute name Type Description pubkey pkey Public key of the certificate request subject_name x509.name Subject of the certificate request version number Version of the certificate request, value is one less than version. For example, <code>2</code> represents <code>version 3</code> <p>Additionally, getters and setters for extensions are also available:</p> Extension name Type Description subject_alt_name x509.altname Subject Alternative Name of the certificate request, SANs are usually used to define \"additional Common Names\" <p>For all extensions, <code>get_{extension}_critical</code> and <code>set_{extension}_critical</code> is also supported to access the <code>critical</code> flag of the extension.</p> <p>If the attribute is not found, getter will return <code>nil, nil</code>.</p> <pre><code>local csr, err = require(\"resty.openssl.csr\").new()\nerr = csr:set_version(3)\nlocal version, err = csr:get_version()\nngx.say(version)\n-- outputs 3\n</code></pre> <p>Note that user may also access the certain extension by csr:get_extension and csr:set_extension, while the later two function returns or requires extension instead. User may use getter and setters listed here if modification of current extensions is needed; use csr:get_extension or csr:set_extension if user are adding or replacing the whole extension or getters/setters are not implemented. If the getter returned a type of <code>x509.*</code> instance, it can be converted to a extension instance by extension:from_data, and thus used by csr:get_extension and csr:set_extension </p>"},{"location":"lua/openssl/#csrset_subject_alt","title":"csr:set_subject_alt","text":"<p>Same as csr:set_subject_alt_name, this function is deprecated to align with naming convension with other functions.</p>"},{"location":"lua/openssl/#csrget_signature_name-csrget_signature_nid-csrget_signature_digest_name","title":"csr:get_signature_name, csr:get_signature_nid, csr:get_signature_digest_name","text":"<p>syntax: sn, err = csr:get_signature_name()</p> <p>syntax: nid, err = csr:get_signature_nid()</p> <p>syntax: sn, err = csr:get_signature_digest_name()</p> <p>Return the NID or the short name (SN) of the signature of the certificate request.</p> <p><code>csr:get_signature_digest_name</code> returns the short name of the digest algorithm used to sign the certificate.</p>"},{"location":"lua/openssl/#csrget_extension","title":"csr:get_extension","text":"<p>syntax: extension, pos, err = csr:get_extension(nid_or_txt, pos?)</p> <p>Get X.509 <code>extension</code> matching the given NID to certificate, returns a resty.openssl.x509.extension instance and the found position.</p> <p>If <code>last_pos</code> is defined, the function searchs from that position; otherwise it finds from beginning. Index is 1-based.</p> <pre><code>local ext, pos, err = csr:get_extension(\"basicConstraints\")\n</code></pre>"},{"location":"lua/openssl/#csrget_extensions","title":"csr:get_extensions","text":"<p>syntax: extensions, err = csr:get_extensions()</p> <p>Return all extensions as a resty.openssl.x509.extensions instance.</p>"},{"location":"lua/openssl/#csradd_extension","title":"csr:add_extension","text":"<p>syntax: ok, err = csr:add_extension(extension)</p> <p>Adds an X.509 <code>extension</code> to csr, the first argument must be a resty.openssl.x509.extension instance.</p>"},{"location":"lua/openssl/#csrset_extension","title":"csr:set_extension","text":"<p>syntax: ok, err = csr:set_extension(extension)</p> <p>Adds an X.509 <code>extension</code> to csr, the first argument must be a resty.openssl.x509.extension instance. The difference from csr:add_extension is that in this function if a <code>extension</code> with same type already exists, the old extension will be replaced.</p> <p>Note this function is not thread-safe.</p>"},{"location":"lua/openssl/#csrget_extension_critical","title":"csr:get_extension_critical","text":"<p>syntax: ok, err = csr:get_extension_critical(nid_or_txt)</p> <p>Get critical flag of the X.509 <code>extension</code> matching the given NID from csr.</p>"},{"location":"lua/openssl/#csrset_extension_critical","title":"csr:set_extension_critical","text":"<p>syntax: ok, err = csr:set_extension_critical(nid_or_txt, crit?)</p> <p>Set critical flag of the X.509 <code>extension</code> matching the given NID to csr.</p>"},{"location":"lua/openssl/#csrsign","title":"csr:sign","text":"<p>syntax: ok, err = csr:sign(pkey, digest?)</p> <p>Sign the certificate request using the private key specified by <code>pkey</code>, which must be a  resty.openssl.pkey that stores private key. Optionally accept <code>digest</code> parameter to set digest method, whichmust be a resty.openssl.digest instance. Returns a boolean indicating if signing is successful and error if any.</p>"},{"location":"lua/openssl/#csrverify","title":"csr:verify","text":"<p>syntax: ok, err = csr:verify(pkey)</p> <p>Verify the CSR signature using the public key specified by <code>pkey</code>, which must be a resty.openssl.pkey. Returns a boolean indicating if verification is successful and error if any.</p>"},{"location":"lua/openssl/#csrtostring","title":"csr:tostring","text":"<p>syntax: str, err = csr:tostring(fmt?)</p> <p>Outputs certificate request in PEM-formatted text or DER-formatted binary. The first argument can be a choice of <code>PEM</code> or <code>DER</code>; when omitted, this function outputs PEM by default.</p>"},{"location":"lua/openssl/#csrto_pem","title":"csr:to_PEM","text":"<p>syntax: pem, err = csr:to_PEM(?)</p> <p>Outputs CSR in PEM-formatted text.</p>"},{"location":"lua/openssl/#restyopensslx509crl","title":"resty.openssl.x509.crl","text":"<p>Module to interact with X509_CRL(certificate revocation list).</p>"},{"location":"lua/openssl/#crlnew","title":"crl.new","text":"<p>syntax: crt, err = crl.new(txt?, fmt?, properties?)</p> <p>Creates a <code>crl</code> instance. <code>txt</code> can be PEM or DER formatted text; <code>fmt</code> is a choice of <code>PEM</code>, <code>DER</code> to load specific format, or <code>*</code> for auto detect.</p> <p>When <code>txt</code> is omitted, <code>new()</code> creates an empty <code>crl</code> instance.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#crldup","title":"crl.dup","text":"<p>syntax: crl, err = crl.dup(crl_ptr_cdata)</p> <p>Duplicates a <code>X509_CRL*</code> to create a new <code>crl</code> instance.</p>"},{"location":"lua/openssl/#crlistype","title":"crl.istype","text":"<p>syntax: ok = crl.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>crl</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#crlget_-crlset_","title":"crl:get_*, crl:set_*","text":"<p>syntax: ok, err = crl:set_attribute(instance)</p> <p>syntax: instance, err = crl:get_attribute()</p> <p>Setters and getters for crl attributes share the same syntax.</p> Attribute name Type Description issuer_name x509.name Issuer of the CRL last_update number Unix timestamp when CRL is not valid before next_update number Unix timestamp when CRL is not valid after version number Version of the certificate, value is one less than version. For example, <code>2</code> represents <code>version 3</code> <p>Additionally, getters and setters for extensions are also available:</p> Extension name Type Description <p>For all extensions, <code>get_{extension}_critical</code> and <code>set_{extension}_critical</code> is also supported to access the <code>critical</code> flag of the extension.</p> <p>If the attribute is not found, getter will return <code>nil, nil</code>.</p> <pre><code>local crl, err = require(\"resty.openssl.crl\").new()\nerr = crl:set_next_update(ngx.time())\nlocal not_before, err = crl:get_next_update()\nngx.say(not_before)\n-- outputs 1571875065\n</code></pre> <p>Note that user may also access the certain extension by crl:get_extension and crl:set_extension, while the later two function returns or requires extension instead. User may use getter and setters listed here if modification of current extensions is needed; use crl:get_extension or crl:set_extension if user are adding or replacing the whole extension or getters/setters are not implemented. If the getter returned a type of <code>crl.*</code> instance, it can be converted to a extension instance by extension:from_data, and thus used by crl:get_extension and crl:set_extension </p>"},{"location":"lua/openssl/#crlget_signature_name-crlget_signature_nid-crlget_signature_digest_name","title":"crl:get_signature_name, crl:get_signature_nid, crl:get_signature_digest_name","text":"<p>syntax: sn, err = crl:get_signature_name()</p> <p>syntax: nid, err = crl:get_signature_nid()</p> <p>syntax: sn, err = crl:get_signature_digest_name()</p> <p>Return the NID or the short name (SN) of the signature of the CRL.</p> <p><code>crl:get_signature_digest_name</code> returns the short name of the digest algorithm used to sign the certificate.</p>"},{"location":"lua/openssl/#crlget_by_serial","title":"crl:get_by_serial","text":"<p>syntax: found_revoked, err = crl:get_by_serial(serial)</p> <p>Find if given <code>serial</code> is in the CRL, <code>serial</code> can be bn instance, or a hexadecimal string. Returns a table if found where:</p> <pre><code>{\n  serial_number: serial number of the revoked cert in hexadecimal string,\n  revoked_date: revoked date of the cert as unix timestamp\n}\n</code></pre> <p>Returns <code>false</code> if not found; specially if a serial number is removed from CRL, then <code>false, \"not revoked (removeFromCRL)\"</code> is returned.</p>"},{"location":"lua/openssl/#crlget_extension","title":"crl:get_extension","text":"<p>syntax: extension, pos, err = crl:get_extension(nid_or_txt, last_pos?)</p> <p>Get X.509 <code>extension</code> matching the given NID to CRL, returns a resty.openssl.x509.extension instance and the found position.</p> <p>If <code>last_pos</code> is defined, the function searchs from that position; otherwise it finds from beginning. Index is 1-based.</p>"},{"location":"lua/openssl/#crladd_extension","title":"crl:add_extension","text":"<p>syntax: ok, err = crl:add_extension(extension)</p> <p>Adds an X.509 <code>extension</code> to CRL, the first argument must be a resty.openssl.x509.extension instance.</p>"},{"location":"lua/openssl/#crlset_extension","title":"crl:set_extension","text":"<p>syntax: ok, err = crl:set_extension(extension, last_pos?)</p> <p>Adds an X.509 <code>extension</code> to CRL, the first argument must be a resty.openssl.x509.extension instance. The difference from crl:add_extension is that in this function if a <code>extension</code> with same type already exists, the old extension will be replaced.</p> <p>If <code>last_pos</code> is defined, the function replaces the same extension from that position; otherwise it finds from beginning. Index is 1-based. Returns <code>nil, nil</code> if not found.</p> <p>Note this function is not thread-safe.</p>"},{"location":"lua/openssl/#crlget_extension_critical","title":"crl:get_extension_critical","text":"<p>syntax: ok, err = crl:get_extension_critical(nid_or_txt)</p> <p>Get critical flag of the X.509 <code>extension</code> matching the given NID from CRL.</p>"},{"location":"lua/openssl/#crlset_extension_critical","title":"crl:set_extension_critical","text":"<p>syntax: ok, err = crl:set_extension_critical(nid_or_txt, crit?)</p> <p>Set critical flag of the X.509 <code>extension</code> matching the given NID to CRL.</p>"},{"location":"lua/openssl/#crladd_revoked","title":"crl:add_revoked","text":"<p>syntax: ok, err = crl:add_revoked(revoked)</p> <p>Adds a resty.openssl.x509.revoked instance to the CRL.</p>"},{"location":"lua/openssl/#crlsign","title":"crl:sign","text":"<p>syntax: ok, err = crl:sign(pkey, digest?)</p> <p>Sign the CRL using the private key specified by <code>pkey</code>, which must be a  resty.openssl.pkey that stores private key. Optionally accept <code>digest</code> parameter to set digest method, whichmust be a resty.openssl.digest instance. Returns a boolean indicating if signing is successful and error if any.</p>"},{"location":"lua/openssl/#crlverify","title":"crl:verify","text":"<p>syntax: ok, err = crl:verify(pkey)</p> <p>Verify the CRL signature using the public key specified by <code>pkey</code>, which must be a resty.openssl.pkey. Returns a boolean indicating if verification is successful and error if any.</p>"},{"location":"lua/openssl/#crltostring","title":"crl:tostring","text":"<p>syntax: str, err = crl:tostring(fmt?)</p> <p>Outputs CRL in PEM-formatted text or DER-formatted binary. The first argument can be a choice of <code>PEM</code> or <code>DER</code>; when omitted, this function outputs PEM by default.</p>"},{"location":"lua/openssl/#crltext","title":"crl:text","text":"<p>syntax: str, err = crl:text()</p> <p>Outputs CRL in a human-readable format.</p>"},{"location":"lua/openssl/#crlto_pem","title":"crl:to_PEM","text":"<p>syntax: pem, err = crl:to_PEM()</p> <p>Outputs the CRL in PEM-formatted text.</p>"},{"location":"lua/openssl/#crl__metamethods","title":"crl:__metamethods","text":"<p>syntax: for i, revoked in ipairs(crl)</p> <p>syntax: len = #crl</p> <p>syntax: revoked = crl[i]</p> <p>Access the revoked list as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p> <p>Each returned object is a table where:</p> <pre><code>{\n  serial_number: serial number of the revoked cert in hexadecimal string,\n  revoked_date: revoked date of the cert as unix timestamp\n}\n</code></pre> <pre><code>local f = io.open(\"t/fixtures/TrustAsiaEVTLSProCAG2.crl\"):read(\"*a\")\nlocal crl = assert(require(\"resty.openssl.x509.crl\").new(f))\n\nfor _, obj in ipairs(crl) do\n  ngx.say(require(\"cjson\").encode(obj))\nend\n-- outputs '{\"revocation_date\":1577753344,\"serial_number\":\"09159859CAC0C90203BB34C5A012C2A3\"}'\n</code></pre>"},{"location":"lua/openssl/#restyopensslx509name","title":"resty.openssl.x509.name","text":"<p>Module to interact with X.509 names.</p>"},{"location":"lua/openssl/#namenew","title":"name.new","text":"<p>syntax: name, err = name.new()</p> <p>Creates an empty <code>name</code> instance.</p>"},{"location":"lua/openssl/#namedup","title":"name.dup","text":"<p>syntax: name, err = name.dup(name_ptr_cdata)</p> <p>Duplicates a <code>X509_NAME*</code> to create a new <code>name</code> instance.</p>"},{"location":"lua/openssl/#nameistype","title":"name.istype","text":"<p>syntax: ok = name.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>name</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#nameadd","title":"name:add","text":"<p>syntax: name, err = name:add(nid_text, txt)</p> <p>Adds an ASN.1 object to <code>name</code>. First arguments in the text representation of NID. Second argument is the plain text value for the ASN.1 object.</p> <p>Returns the name instance itself on success, or <code>nil</code> and an error on failure.</p> <p>This function can be called multiple times in a chained fashion.</p> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n\n_, err = name\n    :add(\"C\", \"US\")\n    :add(\"ST\", \"California\")\n    :add(\"L\", \"San Francisco\")\n</code></pre>"},{"location":"lua/openssl/#namefind","title":"name:find","text":"<p>syntax: obj, pos, err = name:find(nid_text, last_pos?)</p> <p>Finds the ASN.1 object with the given text representation of NID from the postition of <code>last_pos</code>. By omitting the <code>last_pos</code> parameter, <code>find</code> finds from the beginning.</p> <p>Returns the object in a table as same format as decribed here, the position of the found object and error if any. Index is 1-based. Returns <code>nil, nil</code> if not found.</p> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n                    :add(\"CN\", \"example2.com\")\n\nlocal obj, pos, err = name:find(\"CN\")\nngx.say(obj.blob, \" at \", pos)\n-- outputs \"example.com at 1\"\nlocal obj, pos, err = name:find(\"2.5.4.3\", 1)\nngx.say(obj.blob, \" at \", pos)\n-- outputs \"example2.com at 2\"\n</code></pre>"},{"location":"lua/openssl/#nametostring","title":"name:tostring","text":"<p>syntax: txt = name:tostring()</p> <p>Outputs name in a text representation.</p> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n                    :add(\"CN\", \"example2.com\")\n\nngx.say(name:tostring())\n-- outputs \"CN=example.com/CN=example2.com\"\n</code></pre>"},{"location":"lua/openssl/#name__metamethods","title":"name:__metamethods","text":"<p>syntax: for k, obj in pairs(name)</p> <p>syntax: len = #name</p> <p>syntax: k, v = name[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p> <p>Each returned object is a table where:</p> <pre><code>{\n  id: OID of the object,\n  nid: NID of the object,\n  sn: short name of the object,\n  ln: long name of the object,\n  blob: value of the object,\n}\n</code></pre> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n\nfor k, obj in pairs(name) do\n  ngx.say(k, \":\", require(\"cjson\").encode(obj))\nend\n-- outputs 'CN: {\"sn\":\"CN\",\"id\":\"2.5.4.3\",\"nid\":13,\"blob\":\"3.example.com\",\"ln\":\"commonName\"}'\n</code></pre>"},{"location":"lua/openssl/#restyopensslx509altname","title":"resty.openssl.x509.altname","text":"<p>Module to interact with GENERAL_NAMES, an extension to X.509 names.</p>"},{"location":"lua/openssl/#altnamenew","title":"altname.new","text":"<p>syntax: altname, err = altname.new()</p> <p>Creates an empty <code>altname</code> instance.</p>"},{"location":"lua/openssl/#altnamedup","title":"altname.dup","text":"<p>syntax: altname, err = altname.dup(altname_ptr_cdata)</p> <p>Duplicates a <code>STACK_OF(GENERAL_NAMES)</code> to create a new <code>altname</code> instance. The function creates a new stack but won't duplicates elements in the stack.</p>"},{"location":"lua/openssl/#altnameistype","title":"altname.istype","text":"<p>syntax: altname = digest.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>altname</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#altnameadd","title":"altname:add","text":"<p>syntax: altname, err = altname:add(key, value)</p> <p>Adds a name to altname stack, first argument is case-insensitive and can be one of</p> <pre><code>RFC822Name\nRFC822\nEmail\nUniformResourceIdentifier\nURI\nDNSName\nDNS\nIP\nIPAddress\n</code></pre> <p>This function can be called multiple times in a chained fashion.</p>"},{"location":"lua/openssl/#altnametostring","title":"altname:tostring","text":"<p>syntax: txt = altname:tostring()</p> <p>Outputs altname in a text representation.</p> <pre><code>local altname, err = require(\"resty.openssl.x509.altname\").new()\n\n_, err = altname\n    :add(\"DNS\", \"2.example.com\")\n    :add(\"DnS\", \"3.example.com\")\n\nngx.say(altname:tostring())\n-- outputs \"DNS=2.example.com/DNS=3.example.com\"\n</code></pre>"},{"location":"lua/openssl/#altname__metamethods","title":"altname:__metamethods","text":"<p>syntax: for k, obj in pairs(altname)</p> <p>syntax: len = #altname</p> <p>syntax: k, v = altname[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p> <p>Only the following types are decoded, other types are decoded as <code>\"TYPE:&lt;unsupported&gt;\"</code>:</p> <pre><code>RFC822Name / Email\nURI\nDNS\nDirName\n</code></pre>"},{"location":"lua/openssl/#restyopensslx509extension","title":"resty.openssl.x509.extension","text":"<p>Module to interact with every X.509 extensions.</p> <p>This module is particular useful to create extensions not supported by <code>x509.*</code> modules or custom extensions.</p>"},{"location":"lua/openssl/#extensionnew","title":"extension.new","text":"<p>syntax: ext, err = extension.new(name, value, data?)</p> <p>Creates a new <code>extension</code> instance. <code>name</code> and <code>value</code> are strings in OpenSSL arbitrary extension format.</p> <p><code>data</code> can be a table, string or nil. Where <code>data</code> is a table, the following key will be looked up:</p> <pre><code>data = {\n  issuer = resty.openssl.x509 instance,\n  subject = resty.openssl.x509 instance,\n  request = resty.openssl.x509.csr instance,\n  crl = resty.openssl.x509.crl instance,\n  issuer_pkey = resty.openssl.pkey instance, -- &gt;= OpenSSL 3.0\n}\n</code></pre> <p>From OpenSSL 3.0, <code>issuer_pkey</code> can be specified as a fallback source for generating the authority key identifier extension when <code>issuer</code> is same as <code>subject</code>.</p> <p>When <code>data</code> is a string, it's the full nconf string. Using section lookup from <code>value</code> to <code>data</code> is also supported.</p> Example usages: <pre><code>local extension = require(\"resty.openssl.x509.extension\")\n-- extendedKeyUsage=serverAuth,clientAuth\nlocal ext, err = extension.new(\"extendedKeyUsage\", \"serverAuth,clientAuth\")\n-- crlDistributionPoints=URI:http://myhost.com/myca.crl\next, err = extension.new(\"crlDistributionPoints\", \"URI:http://myhost.com/myca.crl\")\n-- with section lookup\next, err = extension.new(\n  \"crlDistributionPoints\", \"crldp1_section\",\n  [[\n  [crldp1_section]\n  fullname=URI:http://myhost.com/myca.crl\n  CRLissuer=dirName:issuer_sect\n  reasons=keyCompromise, CACompromise\n\n  [issuer_sect]\n  C=UK\n  O=Organisation\n  CN=Some Name\n  ]]\n)\n-- combine section lookup with other value\next, err = extension.new(\n\"certificatePolicies\", \"ia5org,1.2.3.4,1.5.6.7.8,@polsect\",\n  [[\n  [polsect]\n  policyIdentifier = 1.3.5.8\n  CPS.1=\"http://my.host.name/\"\n  CPS.2=\"http://my.your.name/\"\n  userNotice.1=@notice\n\n  [notice]\n  explicitText=\"Explicit Text Here\"\n  organization=\"Organisation Name\"\n  noticeNumbers=1,2,3,4\n ]]\n))\n-- subjectKeyIdentifier=hash\nlocal x509, err = require(\"resty.openssl.x509\").new()\next, err =  extension.new(\"subjectKeyIdentifier\", \"hash\", {\n    subject = x509\n})\n</code></pre> <p>See examples/tls-alpn-01.lua for an example to create extension with an unknown nid.</p>"},{"location":"lua/openssl/#extensiondup","title":"extension.dup","text":"<p>syntax: ext, err = extension.dup(extension_ptr_cdata)</p> <p>Creates a new <code>extension</code> instance from <code>X509_EXTENSION*</code> pointer.</p>"},{"location":"lua/openssl/#extensionfrom_der","title":"extension.from_der","text":"<p>syntax: ext, ok = extension.from_der(der, nid_or_txt, crit?)</p> <p>Creates a new <code>extension</code> instance. <code>der</code> is the ASN.1 encoded string to be set for the extension.</p> <p><code>nid_or_txt</code> is a number or text representation of NID and <code>crit</code> is the critical flag of the extension.</p> <p>See examples/tls-alpn-01.lua for an example to create extension with an unknown nid.</p>"},{"location":"lua/openssl/#extensionto_der","title":"extension:to_der","text":"<p>syntax: der, ok = extension:to_der()</p> <p>Returns the ASN.1 encoded (DER) value of the extension.</p> <p><code>nid_or_txt</code> is a number or text representation of NID. Note <code>DER</code> is a binary encoding format. Consider using extension:text for human readable or printable output.</p>"},{"location":"lua/openssl/#extensionfrom_data","title":"extension.from_data","text":"<p>syntax: ext, ok = extension.from_data(table, nid_or_txt, crit?)</p> <p>Creates a new <code>extension</code> instance. <code>table</code> can be instance of:</p> <ul> <li>x509.altname</li> <li>x509.extension.info_access</li> <li>x509.extension.dist_points</li> </ul> <p><code>nid_or_txt</code> is a number or text representation of NID and <code>crit</code> is the critical flag of the extension.</p>"},{"location":"lua/openssl/#extensionto_data","title":"extension.to_data","text":"<p>syntax: ext, ok = extension:to_data(nid_or_txt)</p> <p>Convert the <code>extension</code> to another wrapper instance. Currently supported following:</p> <ul> <li>x509.altname</li> </ul> <p><code>nid_or_txt</code> is a number or text representation of NID.</p>"},{"location":"lua/openssl/#extensionistype","title":"extension.istype","text":"<p>syntax: ok = extension.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>extension</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#extensionget_extension_critical","title":"extension:get_extension_critical","text":"<p>syntax: crit, err = extension:get_extension_critical()</p> <p>Returns <code>true</code> if extension is critical. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#extensionset_extension_critical","title":"extension:set_extension_critical","text":"<p>syntax: ok, err = extension:set_extension_critical(crit)</p> <p>Set the critical flag of the extension.</p>"},{"location":"lua/openssl/#extensionget_object","title":"extension:get_object","text":"<p>syntax: obj = extension:get_object()</p> <p>Returns the name of extension as ASN.1 Object. User can further use helper functions in resty.openssl.objects to print human readable texts.</p>"},{"location":"lua/openssl/#extensiontext","title":"extension:text","text":"<p>syntax: txt, err = extension:text()</p> <p>Returns the text representation of extension. This functions calls <code>X509V3_EXT_print</code> under the hood, and fallback to <code>ASN1_STRING_print</code> if the former failed. It thus has exact same output with that of <code>openssl x509 -text</code>.</p> <pre><code>local objects = require \"resty.openssl.objects\"\nngx.say(cjson.encode(objects.obj2table(extension:get_object())))\n-- outputs '{\"ln\":\"X509v3 Subject Key Identifier\",\"nid\":82,\"sn\":\"subjectKeyIdentifier\",\"id\":\"2.5.29.14\"}'\nngx.say(extension:text())\n-- outputs \"C9:C2:53:61:66:9D:5F:AB:25:F4:26:CD:0F:38:9A:A8:49:EA:48:A9\"\n</code></pre>"},{"location":"lua/openssl/#extensiontostring","title":"extension:tostring","text":"<p>syntax: txt, err = extension:tostring()</p> <p>Same as extension:text.</p>"},{"location":"lua/openssl/#restyopensslx509extensiondist_points","title":"resty.openssl.x509.extension.dist_points","text":"<p>Module to interact with CRL Distribution Points(DIST_POINT stack).</p>"},{"location":"lua/openssl/#dist_pointsnew","title":"dist_points.new","text":"<p>syntax: dp, err = dist_points.new()</p> <p>Creates a new <code>dist_points</code> instance.</p>"},{"location":"lua/openssl/#dist_pointsdup","title":"dist_points.dup","text":"<p>syntax: dp, err = dist_points.dup(dist_points_ptr_cdata)</p> <p>Duplicates a <code>STACK_OF(DIST_POINT)</code> to create a new <code>dist_points</code> instance. The function creates a new stack but won't duplicates elements in the stack.</p>"},{"location":"lua/openssl/#dist_pointsistype","title":"dist_points.istype","text":"<p>syntax: ok = dist_points.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>dist_points</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#dist_points__metamethods","title":"dist_points:__metamethods","text":"<p>syntax: for i, obj in ipairs(dist_points)</p> <p>syntax: len = #dist_points</p> <p>syntax: obj = dist_points[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p> <p>Each object returned when iterrating dist_points instance is a x509.altname instance.</p> <pre><code>local x = x509.new(io.open(\"/path/to/a_cert_has_dist_points.crt\"):read(\"*a\"))\n\nlocal cdp = x:get_crl_distribution_points()\n\nlocal an = cdp[1]\nngx.say(an:tostring())\n-- or any other function for resty.openssl.x509.altname\n\nfor _, an in ipairs(cdp) do\n  ngx.say(an:tostring())\nend\n</code></pre>"},{"location":"lua/openssl/#restyopensslx509extensioninfo_access","title":"resty.openssl.x509.extension.info_access","text":"<p>Module to interact with Authority Information Access data (AUTHORITY_INFO_ACCESS, ACCESS_DESCRIPTION stack).</p>"},{"location":"lua/openssl/#info_accessnew","title":"info_access.new","text":"<p>syntax: aia, err = info_access.new()</p> <p>Creates a new <code>info_access</code> instance.</p>"},{"location":"lua/openssl/#info_accessdup","title":"info_access.dup","text":"<p>syntax: aia, err = info_access.dup(info_access_ptr_cdata)</p> <p>Duplicates a <code>AUTHORITY_INFO_ACCESS</code> to create a new <code>info_access</code> instance. The function creates a new stack but won't duplicates elements in the stack.</p>"},{"location":"lua/openssl/#info_accessistype","title":"info_access.istype","text":"<p>syntax: ok = info_access.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>info_access</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#info_accessadd","title":"info_access:add","text":"<p>syntax: ok, err = info_access:add(x509)</p> <p>Add a <code>x509</code> object to the info_access. The first argument must be a resty.openssl.x509 instance.</p>"},{"location":"lua/openssl/#info_access__metamethods","title":"info_access:__metamethods","text":"<p>syntax: for i, obj in ipairs(info_access)</p> <p>syntax: len = #info_access</p> <p>syntax: obj = info_access[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p> <p>Each object returned when iterrating dist_points instance is a table of NID type and values.</p> <pre><code>local cjson = require(\"cjosn\")\nlocal x509 = require(\"resty.openssl.x509\")\nlocal crt = x509.new(io.open(\"/path/to/a_cert_has_info_access.crt\"):read(\"*a\"))\n\nlocal aia = crt:get_info_access()\n\nngx.say(cjson.encode(aia[1]))\n-- outputs '[178,\"URI\",\"http:\\/\\/ocsp.starfieldtech.com\\/\"]'\n\nfor _, a in ipairs(aia) do\n  ngx.say(cjson.encode(a))\nend\n</code></pre>"},{"location":"lua/openssl/#restyopensslx509extensions","title":"resty.openssl.x509.extensions","text":"<p>Module to interact with X.509 Extension stack.</p>"},{"location":"lua/openssl/#extensionsnew","title":"extensions.new","text":"<p>syntax: ch, err = extensions.new()</p> <p>Creates a new <code>extensions</code> instance.</p>"},{"location":"lua/openssl/#extensionsdup","title":"extensions.dup","text":"<p>syntax: ch, err = extensions.dup(extensions_ptr_cdata)</p> <p>Duplicates a <code>STACK_OF(X509_EXTENSION)</code> to create a new <code>extensions</code> instance. The function creates a new stack but won't duplicates elements in the stack.</p>"},{"location":"lua/openssl/#extensionsistype","title":"extensions.istype","text":"<p>syntax: ok = extensions.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>extensions</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#extensionsadd","title":"extensions:add","text":"<p>syntax: ok, err = extensions:add(x509)</p> <p>Add a <code>x509</code> object to the extensions. The first argument must be a resty.openssl.x509 instance.</p>"},{"location":"lua/openssl/#extensions__metamethods","title":"extensions:__metamethods","text":"<p>syntax: for i, obj in ipairs(extensions)</p> <p>syntax: len = #extensions</p> <p>syntax: obj = extensions[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p>"},{"location":"lua/openssl/#restyopensslx509chain","title":"resty.openssl.x509.chain","text":"<p>Module to interact with X.509 stack.</p>"},{"location":"lua/openssl/#chainnew","title":"chain.new","text":"<p>syntax: ch, err = chain.new()</p> <p>Creates a new <code>chain</code> instance.</p>"},{"location":"lua/openssl/#chaindup","title":"chain.dup","text":"<p>syntax: ch, err = chain.dup(chain_ptr_cdata)</p> <p>Duplicates a <code>STACK_OF(X509)</code> to create a new <code>chain</code> instance. The function creates a new stack and increases reference count for all elements by 1. But it won't duplicate the elements themselves.</p>"},{"location":"lua/openssl/#chainistype","title":"chain.istype","text":"<p>syntax: ok = chain.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>chain</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#chainadd","title":"chain:add","text":"<p>syntax: ok, err = chain:add(x509)</p> <p>Add a <code>x509</code> object to the chain. The first argument must be a resty.openssl.x509 instance.</p>"},{"location":"lua/openssl/#chain__metamethods","title":"chain:__metamethods","text":"<p>syntax: for i, obj in ipairs(chain)</p> <p>syntax: len = #chain</p> <p>syntax: obj = chain[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag; otherwise use <code>all</code>, <code>each</code>, <code>index</code> and <code>count</code> instead.</p> <p>See also functions for stack-like objects.</p>"},{"location":"lua/openssl/#restyopensslx509store","title":"resty.openssl.x509.store","text":"<p>Module to interact with X.509 certificate store (X509_STORE).</p>"},{"location":"lua/openssl/#storenew","title":"store.new","text":"<p>syntax: st, err = store.new(properties?)</p> <p>Creates a new <code>store</code> instance.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#storeistype","title":"store.istype","text":"<p>syntax: ok = store.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>store</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#storeuse_default","title":"store:use_default","text":"<p>syntax: ok, err = store:use_default(properties?)</p> <p>Loads certificates into the X509_STORE from the hardcoded default paths.</p> <p>Note that to load \"default\" CAs correctly, usually you need to install a CA certificates bundle. For example, the package in Debian/Ubuntu is called <code>ca-certificates</code>.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#storeadd","title":"store:add","text":"<p>syntax: ok, err = store:add(x509_or_crl, skip_set_crl_check_flags?)</p> <p>Adds a X.509 or a CRL object into store. The argument must be a resty.openssl.x509 instance or a resty.openssl.x509.crl instance.</p> <p>By default, adding a CRL object will automatically set the flag to store <code>X509_V_FLAG_CRL_CHECK</code>. Setting the second optional argument to <code>true</code> will skip settting the flags.</p>"},{"location":"lua/openssl/#storeload_file","title":"store:load_file","text":"<p>syntax: ok, err = store:load_file(path, properties?)</p> <p>Loads a X.509 certificate on file system into store.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#storeload_directory","title":"store:load_directory","text":"<p>syntax: ok, err = store:load_directory(path, properties?)</p> <p>Loads a directory of X.509 certificates on file system into store. The certificates in the directory must be in hashed form, as documented in X509_LOOKUP_hash_dir(3).</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p>"},{"location":"lua/openssl/#storeset_purpose","title":"store:set_purpose","text":"<p>syntax: ok, err = store:set_purpose(purpose)</p> <p>Set the X509_STORE to match Key Usage and Extendend Key Usage when verifying the cert. Possible values are:</p> <pre><code>    sslclient   SSL client\n    sslserver   SSL server\n    nssslserver Netscape SSL server\n    smimesign   S/MIME signing\n    smimeencrypt    S/MIME encryption\n    crlsign     CRL signing\n    any         Any Purpose\n    ocsphelper  OCSP helper\n    timestampsign   Time Stamp signing\n</code></pre> <p>Normally user should use <code>verify_method</code> parameter of store:verify unless the purpose is not included in the default verify methods.</p>"},{"location":"lua/openssl/#storeset_depth","title":"store:set_depth","text":"<p>syntax: ok, err = store:set_depth(depth)</p> <p>Set the verify depth.</p>"},{"location":"lua/openssl/#storeset_flags","title":"store:set_flags","text":"<p>syntax: ok, err = store:set_flags(flag1, flag2, ...)</p> <p>Set the verify flags, available via <code>store.verify_flags</code> table:</p> <pre><code>    X509_V_FLAG_CB_ISSUER_CHECK              = 0x0,   -- Deprecated\n    X509_V_FLAG_USE_CHECK_TIME               = 0x2,\n    X509_V_FLAG_CRL_CHECK                    = 0x4,\n    X509_V_FLAG_CRL_CHECK_ALL                = 0x8,\n    X509_V_FLAG_IGNORE_CRITICAL              = 0x10,\n    X509_V_FLAG_X509_STRICT                  = 0x20,\n    X509_V_FLAG_ALLOW_PROXY_CERTS            = 0x40,\n    X509_V_FLAG_POLICY_CHECK                 = 0x80,\n    X509_V_FLAG_EXPLICIT_POLICY              = 0x100,\n    X509_V_FLAG_INHIBIT_ANY                  = 0x200,\n    X509_V_FLAG_INHIBIT_MAP                  = 0x400,\n    X509_V_FLAG_NOTIFY_POLICY                = 0x800,\n    X509_V_FLAG_EXTENDED_CRL_SUPPORT         = 0x1000,\n    X509_V_FLAG_USE_DELTAS                   = 0x2000,\n    X509_V_FLAG_CHECK_SS_SIGNATURE           = 0x4000,\n    X509_V_FLAG_TRUSTED_FIRST                = 0x8000,\n    X509_V_FLAG_SUITEB_128_LOS_ONLY          = 0x10000,\n    X509_V_FLAG_SUITEB_192_LOS               = 0x20000,\n    X509_V_FLAG_SUITEB_128_LOS               = 0x30000,\n    X509_V_FLAG_PARTIAL_CHAIN                = 0x80000,\n    X509_V_FLAG_NO_ALT_CHAINS                = 0x100000,\n    X509_V_FLAG_NO_CHECK_TIME                = 0x200000,\n</code></pre> <pre><code>store:set_flags(store.verify_flags.X509_V_FLAG_PARTIAL_CHAIN)\n\nstore:set_flags(store.verify_flags.X509_V_FLAG_PARTIAL_CHAIN,\n                store.verify_flags.X509_V_FLAG_NO_CHECK_TIME)\n\nstore:set_flags(store.verify_flags.X509_V_FLAG_PARTIAL_CHAIN +\n                store.verify_flags.X509_V_FLAG_NO_CHECK_TIME)\n</code></pre> <p>See X509_VERIFY_PARAM_set_flags(3) for explanation of each flag.</p>"},{"location":"lua/openssl/#storeverify","title":"store:verify","text":"<p>syntax: chain, err = store:verify(x509, chain?, return_chain?, properties?, verify_method?, verify_flags?)</p> <p>Verifies a X.509 object with the store. The first argument must be resty.openssl.x509 instance. Optionally accept a validation chain as second argument, which must be a resty.openssl.x509.chain instance.</p> <p>If verification succeed, and <code>return_chain</code> is set to true, returns the proof of validation as a  resty.openssl.x509.chain; otherwise returns <code>true</code> only. If verification failed, returns <code>nil</code> and error explaining the reason.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p> <p><code>verify_method</code> can be set to use predefined verify parameters such as <code>\"default\"</code>, <code>\"pkcs7\"</code>, <code>\"smime_sign\"</code>, <code>\"ssl_client\"</code> and <code>\"ssl_server\"</code>. This set corresponding <code>purpose</code>, <code>trust</code> and couple of other defaults but does not override the parameters set from store:set_purpose.</p> <p><code>verify_flags</code> paramter is the additional verify flags to be set. See store:set_flags for all available flags.</p>"},{"location":"lua/openssl/#storecheck_revocation","title":"store:check_revocation","text":"<p>syntax: ok, err = store:check_revocation(verified_chain, properties?)</p> <p>Only does the revocation check. The first argument <code>verified_chain</code> must be a resty.openssl.x509.chain instance which could be returned from <code>store_ctx:verify</code> or be built by yourself. Note the first cert needs to be the end entity certificate you want to check and the second cert needs to be its issuer.</p> <p>Staring from OpenSSL 3.0, this function accepts an optional <code>properties</code> parameter to explictly select provider to fetch algorithms.</p> <p>Returns <code>true</code> when the certificate isn't revoked, otherwise returns <code>nil</code> and error explaining the reason.</p>"},{"location":"lua/openssl/#restyopensslx509revoked","title":"resty.openssl.x509.revoked","text":"<p>Module to interact with X509_REVOKED.</p>"},{"location":"lua/openssl/#revokednew","title":"revoked.new","text":"<p>syntax: ch, err = revoked.new(serial_number, time, reason)</p> <p>Creates a new <code>revoked</code> instance. <code>serial_number</code> can be either a resty.openssl.bn instance or a number. <code>time</code> and <code>reason</code> must be numbers.</p>"},{"location":"lua/openssl/#revokedistype","title":"revoked.istype","text":"<p>syntax: ok = revoked.istype(table)</p> <p>Returns <code>true</code> if table is an instance of <code>revoked</code>. Returns <code>false</code> otherwise.</p>"},{"location":"lua/openssl/#restyopensslssl","title":"resty.openssl.ssl","text":"<p>Module to interact with SSL connection.</p> <p>This module is currently considered experimental.</p> <p>Note: to use this module in production, user is encouraged to compile lua-resty-openssl-aux-module.</p>"},{"location":"lua/openssl/#sslfrom_request","title":"ssl.from_request","text":"<p>syntax: sess, err = ssl.from_request()</p> <p>Wraps the <code>SSL*</code> instance from current downstream request.</p>"},{"location":"lua/openssl/#sslfrom_socket","title":"ssl.from_socket","text":"<p>syntax: sess, err = ssl.from_socket(sock)</p> <p>Wraps the <code>SSL*</code> instance from a TCP cosocket, the cosocket must have already been called <code>sslhandshake</code>.</p>"},{"location":"lua/openssl/#sslget_peer_certificate","title":"ssl:get_peer_certificate","text":"<p>syntax: x509, err = ssl:get_peer_certificate()</p> <p>Return the peer certificate as a x509 instance. Depending on the type of <code>ssl</code>, peer certificate means the server certificate on client side, or the client certificate on server side.</p> <p>This function should be called after SSL handshake.</p>"},{"location":"lua/openssl/#sslget_peer_cert_chain","title":"ssl:get_peer_cert_chain","text":"<p>syntax: chain, err = ssl:get_peer_certificate()</p> <p>Return the whole peer certificate chain as a x509.chain instance. Depending on the type of <code>ssl</code>, peer certificate means the server certificate on client side, or the client certificate on server side.</p> <p>This function should be called after SSL handshake.</p>"},{"location":"lua/openssl/#sslset_ciphersuites-sslset_cipher_list","title":"ssl:set_ciphersuites, ssl:set_cipher_list","text":"<p>syntax: ok, err = ssl:set_ciphersuites(cipher_suite) syntax: ok, err = ssl:set_cipher_list(cipher_list)</p> <p>Set the cipher suites string used in handshake. Use <code>ssl:set_ciphersuites for TLSv1.3 and</code>ssl:set_cipher_list` for lower.</p> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_certificate_by</code> or <code>ssl_client_hello_by</code> phases.</p>"},{"location":"lua/openssl/#sslget_ciphers","title":"ssl:get_ciphers","text":"<p>syntax: ciphers, err = ssl:get_ciphers()</p> <p>Get the cipher list string used in handshake as a string.</p>"},{"location":"lua/openssl/#sslget_cipher_name","title":"ssl:get_cipher_name","text":"<p>syntax: cipher_name, err = ssl:get_cipher_name()</p> <p>Get the negotiated cipher name as a string.</p> <p>This function should be called after SSL handshake.</p>"},{"location":"lua/openssl/#sslset_timeout","title":"ssl:set_timeout","text":"<p>syntax: ok, err = ssl:set_timeout(tm)</p> <p>Set the timeout value for current session in seconds <code>tm</code>.</p>"},{"location":"lua/openssl/#sslget_timeout","title":"ssl:get_timeout","text":"<p>syntax: tm, err = ssl:set_timeout(tm)</p> <p>Get the timeout value for current session in seconds.</p>"},{"location":"lua/openssl/#sslset_verify","title":"ssl:set_verify","text":"<p>syntax: ok, err = ssl:set_verify(mode)</p> <p>Set the verify mode in current session. Available modes are:</p> <pre><code>  ssl.SSL_VERIFY_NONE                 = 0x00,\n  ssl.SSL_VERIFY_PEER                 = 0x01,\n  ssl.SSL_VERIFY_FAIL_IF_NO_PEER_CERT = 0x02,\n  ssl.SSL_VERIFY_CLIENT_ONCE          = 0x04,\n  ssl.SSL_VERIFY_POST_HANDSHAKE       = 0x08,\n</code></pre> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_certificate_by</code> or <code>ssl_client_hello_by</code> phases.</p>"},{"location":"lua/openssl/#ssladd_client_ca","title":"ssl:add_client_ca","text":"<p>syntax: ok, err = ssl:add_client_ca(x509)</p> <p>Add the CA name extracted from <code>x509</code> to the list of CAs sent to the client when requesting a client certificate. <code>x509</code> is a x509 instance. This function doesn't affect the verification result of client certificate.</p> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_certificate_by</code> or <code>ssl_client_hello_by</code> phases.</p>"},{"location":"lua/openssl/#sslset_options","title":"ssl:set_options","text":"<p>syntax: bitmask, err = ssl:set_options(option, ...)</p> <p>Set one or more options in current session. Available options are:</p> SSL options <pre><code>  ssl.SSL_OP_NO_EXTENDED_MASTER_SECRET                = 0x00000001,\n  ssl.SSL_OP_CLEANSE_PLAINTEXT                        = 0x00000002,\n  ssl.SSL_OP_LEGACY_SERVER_CONNECT                    = 0x00000004,\n  ssl.SSL_OP_TLSEXT_PADDING                           = 0x00000010,\n  ssl.SSL_OP_SAFARI_ECDHE_ECDSA_BUG                   = 0x00000040,\n  ssl.SSL_OP_IGNORE_UNEXPECTED_EOF                    = 0x00000080,\n  ssl.SSL_OP_DISABLE_TLSEXT_CA_NAMES                  = 0x00000200,\n  ssl.SSL_OP_ALLOW_NO_DHE_KEX                         = 0x00000400,\n  ssl.SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS              = 0x00000800,\n  ssl.SSL_OP_NO_QUERY_MTU                             = 0x00001000,\n  ssl.SSL_OP_COOKIE_EXCHANGE                          = 0x00002000,\n  ssl.SSL_OP_NO_TICKET                                = 0x00004000,\n  ssl.SSL_OP_CISCO_ANYCONNECT                         = 0x00008000,\n  ssl.SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION   = 0x00010000,\n  ssl.SSL_OP_NO_COMPRESSION                           = 0x00020000,\n  ssl.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION        = 0x00040000,\n  ssl.SSL_OP_NO_ENCRYPT_THEN_MAC                      = 0x00080000,\n  ssl.SSL_OP_ENABLE_MIDDLEBOX_COMPAT                  = 0x00100000,\n  ssl.SSL_OP_PRIORITIZE_CHACHA                        = 0x00200000,\n  ssl.SSL_OP_CIPHER_SERVER_PREFERENCE                 = 0x00400000,\n  ssl.SSL_OP_TLS_ROLLBACK_BUG                         = 0x00800000,\n  ssl.SSL_OP_NO_ANTI_REPLAY                           = 0x01000000,\n  ssl.SSL_OP_NO_SSLv3                                 = 0x02000000,\n  ssl.SSL_OP_NO_TLSv1                                 = 0x04000000,\n  ssl.SSL_OP_NO_TLSv1_2                               = 0x08000000,\n  ssl.SSL_OP_NO_TLSv1_1                               = 0x10000000,\n  ssl.SSL_OP_NO_TLSv1_3                               = 0x20000000,\n  ssl.SSL_OP_NO_DTLSv1                                = 0x04000000,\n  ssl.SSL_OP_NO_DTLSv1_2                              = 0x08000000,\n  ssl.SSL_OP_NO_RENEGOTIATION                         = 0x40000000,\n  ssl.SSL_OP_CRYPTOPRO_TLSEXT_BUG                     = 0x80000000,\n</code></pre> <p>Multiple options can be passed in seperatedly, or in a bitwise or bitmask.</p> <pre><code>assert(ssl:set_options(bit.bor(ssl.SSL_OP_NO_TLSv1_1, ssl.SSL_OP_NO_TLSv1_2)))\n-- same as\nassert(ssl:set_options(ssl.SSL_OP_NO_TLSv1_1, ssl.SSL_OP_NO_TLSv1_2))\n</code></pre> <p>Returns the options of current session in bitmask.</p> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_client_hello_by</code> phase.</p>"},{"location":"lua/openssl/#sslget_options","title":"ssl:get_options","text":"<p>syntax: bitmask, err = ssl:get_options(readable?)</p> <p>Get the options for current session. If <code>readable</code> is not set or set to <code>false</code>, the function return the bit mask for all optinos; if <code>readable</code> is set to <code>true,</code> the function returns a sorted Lua table containing literals for all options.</p>"},{"location":"lua/openssl/#sslclear_options","title":"ssl:clear_options","text":"<p>syntax: bitmask, err = ssl:clear_options(option, ...)</p> <p>Clear one or more options in current session. Available options are same as that in ssl:set_options.</p> <p>Multiple options can be passed in seperatedly, or in a bitwise or bitmask.</p> <pre><code>assert(ssl:clear_options(bit.bor(ssl.SSL_OP_NO_TLSv1_1, ssl.SSL_OP_NO_TLSv1_2)))\n-- same as\nassert(ssl:clear_options(ssl.SSL_OP_NO_TLSv1_1, ssl.SSL_OP_NO_TLSv1_2))\n</code></pre> <p>Returns the options of current session in bitmask.</p> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_client_hello_by</code> phase.</p>"},{"location":"lua/openssl/#sslset_protocols","title":"ssl:set_protocols","text":"<p>syntax: bitmask, err = ssl:set_protocols(protocol, ...)</p> <p>Set avaialable protocols for handshake, this is a convenient function that calls ssl:set_options and ssl:clear_options to set appropriate options.</p> <p>Returns the options of current session in bitmask.</p> <p>This function should be called before SSL handshake; for server this means this function is only effective in <code>ssl_client_hello_by</code> phase.</p> <pre><code>assert(ssl:set_protocols(\"TLSv1.1\", \"TLSv1.2\"))\n-- same as\nassert(ssl:set_options(ssl.SSL_OP_NO_SSL_MASK))\nassert(ssl:clear_options(ssl.SSL_OP_NO_TLSv1_1, ssl.SSL_OP_NO_TLSv1_2))\n</code></pre>"},{"location":"lua/openssl/#restyopensslssl_ctx","title":"resty.openssl.ssl_ctx","text":"<p>Module to interact with SSL_CTX context.</p> <p>This module is currently considered experimental.</p> <p>Note: to use this module in production, user is encouraged to compile lua-resty-openssl-aux-module.</p>"},{"location":"lua/openssl/#ssl_ctxfrom_request","title":"ssl_ctx.from_request","text":"<p>syntax: ctx, err = ssl_ctx.from_request()</p> <p>Wraps the <code>SSL_CTX*</code> instance from current downstream request.</p>"},{"location":"lua/openssl/#ssl_ctxfrom_socket","title":"ssl_ctx.from_socket","text":"<p>syntax: sess, err = ssl_ctx.from_socket(sock)</p> <p>Wraps the <code>SSL_CTX*</code> instance from a TCP cosocket, the cosocket must have already been called <code>sslhandshake</code>.</p>"},{"location":"lua/openssl/#ssl_ctxset_alpns","title":"ssl_ctx:set_alpns","text":"<p>syntax: ok, err = ssl_ctx:set_alpns(alpn, ...)</p> <p>Set the ALPN list to be negotiated with peer. Each <code>alpn</code> is the plaintext literal for the protocol, like <code>\"h2\"</code>.</p>"},{"location":"lua/openssl/#restyopensslcrypto","title":"resty.openssl.crypto","text":"<p>Module to interact with utility openssl functions.</p>"},{"location":"lua/openssl/#cryptomemcmp","title":"crypto.memcmp","text":"<p>syntax: res, err = crypto.memcmp(a, b, len)</p> <p>Performs constant-time comparison of 2 memory regions a and b with len bytes. See CRYPTO_memcmp for more info. The 2 memory regions must be of type string or cdata.</p> <p>Returns 0 if the memory regions are equal and nonzero otherwise.</p>"},{"location":"lua/openssl/#functions-for-stack-like-objects","title":"Functions for stack-like objects","text":""},{"location":"lua/openssl/#metamethods","title":"metamethods","text":"<p>syntax: for k, obj in pairs(x)</p> <p>syntax: for k, obj in ipairs(x)</p> <p>syntax: len = #x</p> <p>syntax: obj = x[i]</p> <p>Access the underlying objects as it's a Lua table. Make sure your LuaJIT compiled with <code>-DLUAJIT_ENABLE_LUA52COMPAT</code> flag.</p> <p>Each object may only support either <code>pairs</code> or <code>ipairs</code>. Index is 1-based.</p> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n\nfor k, obj in pairs(name) do\n  ngx.say(k, \":\", require(\"cjson\").encode(obj))\nend\n-- outputs 'CN: {\"sn\":\"CN\",\"id\":\"2.5.4.3\",\"nid\":13,\"blob\":\"3.example.com\",\"ln\":\"commonName\"}'\n</code></pre>"},{"location":"lua/openssl/#each","title":"each","text":"<p>syntax: iter = x:each()</p> <p>Return an iterator to traverse objects. Use this while <code>LUAJIT_ENABLE_LUA52COMPAT</code> is not enabled.</p> <pre><code>local name, err = require(\"resty.openssl.x509.name\").new()\nlocal _, err = name:add(\"CN\", \"example.com\")\n\nlocal iter = name:each()\nwhile true do\n  local k, obj = iter()\n  if not k then\n    break\n  end\nend\n</code></pre>"},{"location":"lua/openssl/#all","title":"all","text":"<p>syntax: objs, err = x:all()</p> <p>Returns all objects in the table. Use this while <code>LUAJIT_ENABLE_LUA52COMPAT</code> is not enabled.</p>"},{"location":"lua/openssl/#count","title":"count","text":"<p>syntax: len = x:count()</p> <p>Returns count of objects of the table. Use this while <code>LUAJIT_ENABLE_LUA52COMPAT</code> is not enabled.</p>"},{"location":"lua/openssl/#index","title":"index","text":"<p>syntax: obj = x:index(i)</p> <p>Returns objects at index of <code>i</code> of the table, index is 1-based. If index is out of bound, <code>nil</code> is returned.</p>"},{"location":"lua/openssl/#general-rules-on-garbage-collection","title":"General rules on garbage collection","text":"<ul> <li>When a type is added or returned to another type, it's internal cdata is always copied. <pre><code>local name = require(\"resty.openssl.x509.name\"):add(\"CN\", \"example.com\")\nlocal x509 = require(\"resty.openssl.x509\").new()\n-- `name` is copied when added to x509\nx509:set_subject_name(name)\n\nname:add(\"L\", \"Mars\")\n-- subject_name in x509 will not be modified\n</code></pre></li> <li>The creator set the GC handler; the user must not free it.</li> <li>For a stack:</li> <li>If it's created by <code>new()</code>: set GC handler to sk_TYPE_pop_free <ul> <li>The gc handler for elements being added to stack should not be set. Instead, rely on the gc   handler of the stack to free each individual elements.</li> </ul> </li> <li>If it's created by <code>dup()</code> (shallow copy):<ul> <li>If elements support reference counter (like X509): increase ref count for all elements by 1;   set GC handler to sk_TYPE_pop_free.</li> <li>If not, set GC handler to sk_free</li> <li>Additionally, the stack duplicates the element when it's added to stack, a GC handler for the duplicate     must be set. But a reference should be kept in Lua land to prevent premature     gc of individual elements. (See x509.altname).</li> <li>Shallow copy for stack is fine because in current design user can't modify the element in the   stack directly. Each elemente is duplicated when added to stack and when returned.</li> </ul> </li> </ul>"},{"location":"lua/openssl/#generic-evp-parameter-gettersetter","title":"Generic EVP parameter getter/setter","text":"<p>Starting from OpenSSL 3.0, this library provides a genric interface to get and set abitrary parameters from underlying implementation. This works for cipher, pkey, digest, mac and kdf.</p> <p>Some can be used to provide equal results with existing functions, for example the following code produces same result.</p> <pre><code>local pkey = require(\"resty.openssl.pkey\").new({ type = \"EC\" })\npkey:get_param(\"priv\", nil, \"bn\") == pkey:get_parameters().private\n\nlocal cipher = require(\"resty.openssl.cipher\").new(\"aes-256-gcm\")\ncipher:encrypt(string.rep(\"0\", 32), string.rep(\"0\", \"12\"), \"secret\", false, \"aad\")\ncipher:get_param(\"tag\", 16) == cipher:get_aead_tag()\n</code></pre>"},{"location":"lua/openssl/#gettable_params","title":"gettable_params","text":"<p>syntax: schema, err = x:gettable_params(raw?)</p> <p>Returns the readable schema as a Lua table for all gettable params. When <code>raw</code> is set to true, the function returns the raw schema instead.</p>"},{"location":"lua/openssl/#settable_params","title":"settable_params","text":"<p>syntax: schema, err = x:settable_params(raw?)</p> <p>Returns the readable schema as a Lua table for all settable params. When <code>raw</code> is set to true, the function returns the raw schema instead.</p> <pre><code>local c = require(\"resty.openssl.cipher\").new(\"aes-256-gcm\")\nprint(cjson.encode(c:settable_params()))\n-- outputs [[\"ivlen\",\"unsigned integer (max 8 bytes large)\"],[\"tag\",\"octet string (arbitrary size)\"],[\"tlsaad\",\"octet string (arbitrary size)\"],[\"tlsivfixed\",\"octet string (arbitrary size)\"],[\"tlsivinv\",\"octet string (arbitrary size)\"]]\nprint(cjson.encode(c:gettable_params()))\n-- outputs [[\"keylen\",\"unsigned integer (max 8 bytes large)\"],[\"ivlen\",\"unsigned integer (max 8 bytes large)\"],[\"taglen\",\"unsigned integer (max 8 bytes large)\"],[\"iv\",\"octet string (arbitrary size)\"],[\"updated-iv\",\"octet string (arbitrary size)\"],[\"tag\",\"octet string (arbitrary size)\"],[\"tlsaadpad\",\"unsigned integer (max 8 bytes large)\"],[\"tlsivgen\",\"octet string (arbitrary size)\"]]\n</code></pre>"},{"location":"lua/openssl/#get_param","title":"get_param","text":"<p>syntax: value, err = x:get_param(key, want_size?, want_type?)</p> <p>Read the param <code>key</code> and return its value. The return value is a Lua number or a string. Certain params requires exact size to be set, in such case, <code>want_size</code> should be specified; if <code>want_size</code> is not specified and, the library use a buffer of 100 bytes to hold the return value. Certain params returns a special type, user should explictly set <code>want_type</code> as a string to correctly decode them. Currently <code>want_type</code> can only be <code>\"bn\"</code> or unset. Note it may also be necessary to increase temporary buffer size <code>want_size</code> when <code>want_type</code> is <code>\"bn\"</code>.</p> <pre><code>local c = require(\"resty.openssl.cipher\").new(\"aes-256-gcm\")\nprint(c:get_param(\"taglen\"))\n-- outputs 16\nprint(c:get_param(\"tag\"))\n-- returns error, tag must have a explict size\nprint(c:get_param(\"tag\", 16))\n-- outputs the tag\nlocal p = require(\"resty.openssl.pkey\").new())\nprint(p:get_param(\"d\"):to_hex())\n-- returns error, d (private exponent) is a BIGNUM\nprint(p:get_param(\"d\", 256, \"bn\"):to_hex())\n-- returns d as resty.openssl.bn instance\n</code></pre>"},{"location":"lua/openssl/#set_params","title":"set_params","text":"<p>syntax: ok, err = x:set_params(params)</p> <p>Set params passed in with Lua table <code>params</code>. The library does limited type check, user is responsible for validity of input.</p> <pre><code>local k = require(\"resty.openssl.kdf\").new(\"HKDF\")\nk:set_params({\n    digest = \"md5\",\n    salt = \"salt\",\n    info = \"some info\",\n    mode = kdf.HKDEF_MODE_EXPAND_ONLY,\n    -- as HKDF also accepts mode as string, use the literal below also works\n    -- mode = \"EXPAND_ONLY\"\n}))\n</code></pre>"},{"location":"lua/openssl/#code-generation","title":"Code generation","text":"<p>Lots of functions and tests for X509, CSR and CRL are generated from templates under scripts directory. Those functions and tests are either commented with <code>AUTO GENERATED</code> or <code>AUTOGEN</code>.</p> <p>When making changes to them, please update the template under <code>scripts/templates</code> instead. Then regenerate them again.</p> <pre><code>cd scripts\npip3 install -r requirements.txt\npython3 ./x509_autogen.py\n</code></pre>"},{"location":"lua/openssl/#see-also","title":"See Also","text":"<ul> <li>luaossl</li> <li>API/ABI changes review for OpenSSL</li> <li>OpenSSL API manual</li> </ul>"},{"location":"lua/openssl/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-openssl.</p>"},{"location":"lua/perf/","title":"perf: A small ngx resty lua library to benchmark memory and throughput of a function","text":""},{"location":"lua/perf/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/perf/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-perf\n</code></pre>"},{"location":"lua/perf/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-perf\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-perf v1.0.4  released on Apr 14 2021.</p> <p>A simple resty lua library to benchmark memory and throughput of a function.</p> <p><pre><code>local function mycode()\n  local x = {}\n  for i = 1, 1e3 do\n    local now = ngx.now()\n    now = now - 45 + i\n    x[i] = now\n  end\n  return x\nend\n\nperf.perf_time(\"mycode cpu profiling\", function()\n   mycode()\nend)\n\nperf.perf_mem(\"mycode memory profiling\", function()\n   mycode()\nend)\n</code></pre> To run it, you can use the openresty docker image:</p> <pre><code>docker run -it --rm -v ${PWD}/test.lua:/test.lua -v ${PWD}/lib/resty/perf.lua:/lib/resty/perf.lua openresty/openresty:xenial resty /test.lua\n</code></pre> <p></p>"},{"location":"lua/perf/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-perf.</p>"},{"location":"lua/prettycjson/","title":"prettycjson: Lua cJSON Pretty Formatter","text":""},{"location":"lua/prettycjson/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/prettycjson/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-prettycjson\n</code></pre>"},{"location":"lua/prettycjson/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-prettycjson\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-prettycjson v1.6  released on Sep 29 2016.</p> <p><code>lua-resty-prettycjson</code> is a JSON Pretty Formatter for Lua cJSON.</p>"},{"location":"lua/prettycjson/#lua-api","title":"Lua API","text":""},{"location":"lua/prettycjson/#string-functiondt-lf-n-id-t-ac-ec-function","title":"string function(dt, [lf = \"\\n\", [id = \"\\t\", [ac = \" \", [ec = function]]]])","text":"<p>Pretty formats the JSON output. You may pass <code>lf</code> (line feed) if you want to use different linefeed than the default <code>\\n</code>. If you want to indent (<code>id</code> argument) with something else than <code>\\t</code> (a tab) you can pass that as arguments as well. And if you want to have something else than <code></code> (single space) after colons <code>:</code> (<code>ac</code> argument) in json, you can change that as well, try for example <code>\\n</code>. If you'd like to use an encoder other than cJSON, pass the encoding function as the 5th argument (<code>ec</code>). It should accept anything as input parameter, and if there is a problem with encoding this function should return <code>nil</code> and an error message, such as:</p> <pre><code>nil, \"Cannot serialise function: type not supported\"\n</code></pre> <p>For input argument <code>dt</code> it accepts anything that <code>cjson.encode</code> accepts (or whatever the custom encoding function accepts).</p>"},{"location":"lua/prettycjson/#example","title":"Example","text":"<pre><code>local pretty = require \"resty.prettycjson\"\n\nprint(pretty({\n    key1 = \"data\",\n    key2 = 27,\n    key3 = {\n        key3_1 = \"something\",\n        key3_2 = \"something else\"\n    },\n    key4 = {\n        \"item1\",\n        \"item2\"\n    },\n    key5 = {},\n    key5 = {{''}, {'',''}, {{},{}}},\n    key6 = { '' },\n    key7 = {{{{ test = \"value\", {{{{{{}}},{{},{},{}},{},{}}}}}}}}\n}))\n</code></pre> <p>That will output:</p> <pre><code>{\n    \"key6\": [\n        \"\"\n    ],\n    \"key3\": {\n        \"key3_1\": \"something\",\n        \"key3_2\": \"something else\"\n    },\n    \"key7\": [\n        [\n            [\n                {\n                    \"1\": [\n                        [\n                            [\n                                [\n                                    [\n                                        {}\n                                    ]\n                                ],\n                                [\n                                    {},\n                                    {},\n                                    {}\n                                ],\n                                {},\n                                {}\n                            ]\n                        ]\n                    ],\n                    \"test\": \"value\"\n                }\n            ]\n        ]\n    ],\n    \"key1\": \"data\",\n    \"key5\": [\n        [\n            \"\"\n        ],\n        [\n            \"\",\n            \"\"\n        ],\n        [\n            {},\n            {}\n        ]\n    ],\n    \"key2\": 27,\n    \"key4\": [\n        \"item1\",\n        \"item2\"\n    ]\n}\n</code></pre>"},{"location":"lua/prettycjson/#changes","title":"Changes","text":"<p>The changes of every release of this module is recorded in Changes.md file.</p>"},{"location":"lua/prettycjson/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-prettycjson.</p>"},{"location":"lua/pubsub/","title":"pubsub: Lua Pubsub client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/pubsub/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/pubsub/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-pubsub\n</code></pre>"},{"location":"lua/pubsub/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-pubsub\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-pubsub v1.5  released on Nov 13 2024.</p> <p>Lua Pubsub client driver for the <code>ngx_lua</code> based on the cosocket API.</p> <p> </p>"},{"location":"lua/pubsub/#description","title":"Description","text":"<p>This Lua library is a Pubsub client driver for the ngx_lua nginx module: http://wiki.nginx.org/HttpLuaModule</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior. This library pushes messages (with attributes) to Google Cloud pubsub using nginx timers and http requests.</p> <p>Note that at least ngx_lua 0.9.3 or ngx_openresty 1.4.3.7 is required, and unfortunately only LuaJIT supported (<code>--with-luajit</code>).</p>"},{"location":"lua/pubsub/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location = /publish {\n            resolver 8.8.8.8 ipv6=off;\n\n            content_by_lua_block {\n                local cjson = require \"cjson\"\n                local pubsub_producer = require \"resty.pubsub.producer\"\n                local OAUTH_TOKEN = ngx.shared.OAUTH_TOKEN -- A different dictionary can also be provided\n\n                -- A callback which will recieve messages if gets successfully sent\n                -- Types of messages &amp; err are a table\n                local success_callback = function (topic, err, messages)\n                    ngx.log(ngx.INFO, \"Messages: \", cjson.encode(messages), \" successfully pushed to topic: \", topic)\n                end\n\n                -- A callback which will recieve messages if gets failed\n                -- Types of messages &amp; err are a table\n                local error_callback = function (topic, err, messages)\n                    for _, message in ipairs(messages) do\n                        ngx.log(ngx.ERR, \"Failed to send Message : \", cjson.encode(message), \" with err: \", cjson.encode(err))\n                    end\n                end\n\n                local publish = function()\n\n                    -- Pubsub Producer Config\n                    local pubsub_config = {\n                        project_id = \"demo-project\",\n                        topic = \"demo-topic\",\n                        pubsub_base_domain = \"pubsub.googleapis.com\",\n                        pubsub_base_port = 443,\n                        is_emulator = false,\n                        producer_config = {\n                            max_batch_size = 200, -- number of packets\n                            max_buffering = 5000, -- max number of packets in buffer\n                            timer_interval = 10000, -- in milliseconds\n                            last_flush_interval = 5000, -- in milliseconds\n                            http_timeout = 6000, -- in milliseconds\n                            keepalive_max_idle_timeout = 2000, -- in milliseconds\n                            keepalive_pool_size = 50\n                        },\n                        oauth_config = {\n                            service_account_key_path = \"/etc/key.json\", -- Replace this with your own key path\n                            oauth_base_uri = \"https://www.googleapis.com/oauth2/v4/token\",\n                            oauth_scopes = {\n                                \"https://www.googleapis.com/auth/pubsub\"\n                            },\n                            oauth_token_dict = OAUTH_TOKEN\n                        },\n                        success_callback = success_callback,\n                        error_callback = error_callback\n                    }\n\n                    -- Create the producer object\n                    -- No matter how many times you call new, the producer instance will always be generated once per topic per worker process\n                    local producer, err = pubsub_producer:new(pubsub_config)\n\n                    -- Also check if there is any error while initializing producer\n                    if err ~= nil then\n                        ngx.log(ngx.ERR, \"Unable to create pubsub producer \", err)\n                        return\n                    end\n\n                    -- Finally send the message with attributes.\n                    local ok, send_err = producer:send(\"Some Random Text\", {\n                        attr1 = \"Test1\",\n                        attr2 = \"Test2\"\n                    }, \"optional_ordering_key\")\n\n                    -- Also check if there is any error while sending message\n                    if send_err ~= nil then\n                        ngx.log(ngx.ERR, \"Unable to send data to pubsub: \", send_err)\n                        return\n                    end\n\n                end\n\n                -- Publish Message\n                publish()\n            }\n\n        }\n    }\n</code></pre>"},{"location":"lua/pubsub/#configs","title":"Configs","text":""},{"location":"lua/pubsub/#producer-configs","title":"Producer Configs","text":"Property Data Type Description Default Value project_id string Specifies the project id as a string of your Pub/Sub project none (Required) topic string Specifies the topic in which the data needs to be send none (Required) pubsub_base_domain string Specifies the base domain through which the http connection is made. pubsub.googleapis.com pubsub_base_port number Specifies the base domain port through which the http connection is made. 443 is_emulator boolean Specifies a boolean value. true if you are communicating with. false producer_config.max_batch_size number Specifies the max batch size that will be pushed to pubsub. 200 producer_config.max_buffering number Specifies the max size of the buffer which will hold the data for a specific duration of time. 5000 producer_config.timer_interval number (milliseconds) Specifies the time interval in which the stale messages in buffer are checked for publishing. 10000 producer_config.last_flush_interval number (milliseconds) Specifies the max interval between the last flush time and current time. Used when packets in buffer are less than the batch size for a longer period of time. 10000 producer_config.http_timeout number (milliseconds) Sets the timeout protection for subsequent operations, including the connect method. 5000 producer_config.keepalive_max_idle_timeout number (milliseconds) Used in httpc:set_keepalive which attempts to puts the current connection into the ngx_lua cosocket connection pool. 2000 producer_config.keepalive_pool_size number Used in httpc:set_keepalive which attempts to puts the current connection into the ngx_lua cosocket connection pool. 50 oauth_config.service_account_key_path string Specifies the path for service account key that are used to authenticate to pub/sub project. none (Required) oauth_config.oauth_base_uri string Specifies the base uri to which request is made to Google authorization server for a token that will be used in subsequent requests. https://www.googleapis.com/oauth2/v4/token oauth_config.oauth_scopes list of string Specifies a table comprising of OAuth 2.0 scopes that you might need to request to access Google APIs, depending on the level of access you need. {\"https://www.googleapis.com/auth/pubsub\"} oauth_config.oauth_token_dict lua_shared_dict Specifies a shared memory zone across workers, to serve as a storage for the oauth token. ngx.shared.OAUTH_TOKEN success_handler function This is a callback function which will be provided with all the messages with their attributes which are successfully pushed to pubsub. none (Optional) error_handler function This is a callback function which will be executed when a batch fails. none (Optional)"},{"location":"lua/pubsub/#modules","title":"Modules","text":""},{"location":"lua/pubsub/#restypubsubproducer","title":"resty.pubsub.producer","text":"<p>To load this module, just do this</p> <pre><code>    local producer = require \"resty.pubsub.producer\"\n</code></pre>"},{"location":"lua/pubsub/#methods","title":"Methods","text":""},{"location":"lua/pubsub/#new","title":"new","text":"<p><code>syntax: local p, err = producer:new(pubsub_config)</code></p>"},{"location":"lua/pubsub/#send","title":"send","text":"<p><code>syntax: p:send(message, attributes[, ordering_key])</code></p> <ul> <li>Requires a message of type string, attributes of type table and an optional ordering_key of type string</li> </ul>"},{"location":"lua/pubsub/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/pubsub/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-pubsub.</p>"},{"location":"lua/qless-web/","title":"qless-web: Port of Qless' web interface to nginx-module-lua environment","text":""},{"location":"lua/qless-web/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/qless-web/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-qless-web\n</code></pre>"},{"location":"lua/qless-web/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-qless-web\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-qless-web v0.5  released on Sep 20 2016.</p>"},{"location":"lua/qless-web/#overview","title":"Overview","text":"<p>Port of Moz's qless web interface to the Openresty environment.</p>"},{"location":"lua/qless-web/#methods","title":"Methods","text":""},{"location":"lua/qless-web/#new","title":"new","text":"<p><code>syntax: ok, err = Qless_web:new(opts)</code></p> <p><code>opts</code> is a table of options  * <code>client</code> must be an instance of lua-resty-qless  * <code>uri_prefix</code> defaults to <code>/</code>, sets the value prepended to all URIs</p>"},{"location":"lua/qless-web/#run","title":"run","text":"<p><code>syntax: ok, err = qless_web:run()</code></p> <p>Performs routing based on current uri. Requires a sub-location <code>/__static</code> configure to serve static assets</p>"},{"location":"lua/qless-web/#config","title":"Config","text":"<p>``` init_by_lua '     -- Require here to compile templates     local Qless_Web = require(\"resty.qless-web\") ';</p> <p>location /web {</p> <pre><code>default_type text/html;\nlocation /web/__static {\n    internal;\n    rewrite ^/web/__static(.*) $1 break;\n    root /path/to/lua-resty-qless-web/static/;\n}\n\ncontent_by_lua '\n    -- Connect Qless client\n    local resty_qless = require \"resty.qless\"\n    local qless, err = resty_qless.new(\n        {\n            redis = { host = \"127.0.0.1\", port = 6379 }\n        },\n        { database = 1 }\n    )\n    if not qless then\n        return ngx.say(\"Qless.new(): \", err)\n    end\n\n    -- Create and run qless web\n    local Qless_Web = require(\"resty.qless-web\")\n    local web = Qless_Web:new({ client = qless, uri_prefix = \"/web\" })\n\n    web:run()\n';\n</code></pre> <p>}</p>"},{"location":"lua/qless-web/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-qless-web.</p>"},{"location":"lua/qless/","title":"qless: Lua binding to Qless (Queue / Pipeline management) for nginx-module-lua / Redis","text":""},{"location":"lua/qless/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/qless/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-qless\n</code></pre>"},{"location":"lua/qless/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-qless\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-qless v0.12  released on Jul 08 2022.</p> <p>lua-resty-qless is a binding to qless-core from Moz - a powerful Redis based job queueing system inspired by resque, but instead implemented as a collection of Lua scripts for Redis.</p> <p>This binding provides a full implementation of Qless via Lua script running in OpenResty / lua-nginx-module, including workers which can be started during the <code>init_worker_by_lua</code> phase.</p> <p>Essentially, with this module and a modern Redis instance, you can turn your OpenResty server into a quite sophisticated yet lightweight job queuing system, which is also compatible with the reference Ruby implementation, Qless.</p> <p>Note: This module is not designed to work in a pure Lua environment.</p>"},{"location":"lua/qless/#status","title":"Status","text":"<p>This module should be considered experimental.</p>"},{"location":"lua/qless/#philosophy-and-nomenclature","title":"Philosophy and Nomenclature","text":"<p>A <code>job</code> is a unit of work identified by a job id or <code>jid</code>. A <code>queue</code> can contain several jobs that are scheduled to be run at a certain time, several jobs that are waiting to run, and jobs that are currently running. A <code>worker</code> is a process on a host, identified uniquely, that asks for jobs from the queue, performs some process associated with that job, and then marks it as complete. When it's completed, it can be put into another queue.</p> <p>Jobs can only be in one queue at a time. That queue is whatever queue they were last put in. So if a worker is working on a job, and you move it, the worker's request to complete the job will be ignored.</p> <p>A job can be <code>canceled</code>, which means it disappears into the ether, and we'll never pay it any mind ever again. A job can be <code>dropped</code>, which is when a worker fails to heartbeat or complete the job in a timely fashion, or a job can be <code>failed</code>, which is when a host recognizes some systematically problematic state about the job. A worker should only fail a job if the error is likely not a transient one; otherwise, that worker should just drop it and let the system reclaim it.</p>"},{"location":"lua/qless/#features","title":"Features","text":"<ol> <li>Jobs don't get dropped on the floor Sometimes workers drop jobs. Qless   automatically picks them back up and gives them to another worker</li> <li>Tagging / Tracking Some jobs are more interesting than others. Track those   jobs to get updates on their progress.</li> <li>Job Dependencies One job might need to wait for another job to complete</li> <li>Stats Qless automatically keeps statistics about how long jobs wait   to be processed and how long they take to be processed. Currently, we keep   track of the count, mean, standard deviation, and a histogram of these times.</li> <li>Job data is stored temporarily Job info sticks around for a configurable   amount of time so you can still look back on a job's history, data, etc.</li> <li>Priority Jobs with the same priority get popped in the order they were   inserted; a higher priority means that it gets popped faster</li> <li>Retry logic Every job has a number of retries associated with it, which are   renewed when it is put into a new queue or completed. If a job is repeatedly   dropped, then it is presumed to be problematic, and is automatically failed.</li> <li>Web App lua-resty-qless-web gives you visibility and control over certain operational issues</li> <li>Scheduled Work Until a job waits for a specified delay (defaults to 0),   jobs cannot be popped by workers</li> <li>Recurring Jobs Scheduling's all well and good, but we also support   jobs that need to recur periodically.</li> <li>Notifications Tracked jobs emit events on pubsub channels as they get   completed, failed, put, popped, etc. Use these events to get notified of   progress on jobs you're interested in.</li> </ol>"},{"location":"lua/qless/#connecting","title":"Connecting","text":"<p>First things first, require <code>resty.qless</code> and create a client, specifying your Redis connection details.</p> <pre><code>local qless = require(\"resty.qless\").new({\n    host = \"127.0.0.1\",\n    port = 6379,\n})\n</code></pre> <p>Parameters passed to <code>new</code> are forwarded to lua-resty-redis-connector. Please review the documentation there for connection options, including how to use Redis Sentinel etc.</p> <p>Additionally, if your application has a Redis connection that you wish to reuse, there are two ways you can integrate this:</p> <p>1) Using an already established connection directly</p> <pre><code>local qless = require(\"resty.qless\").new({\n    redis_client = my_redis,\n})\n</code></pre> <p>2) Providing callbacks for connecting and closing the connection</p> <pre><code>local qless = require(\"resty.qless\").new({\n    get_redis_client = my_connection_callback,\n    close_redis_client = my_close_callback,\n})\n</code></pre> <p>When finished with Qless, you should call <code>qless:set_keepalive()</code> which will attempt to put Redis back on the keepalive pool, either using settings you provide directly, or via parameters sent to <code>lua-resty-redis-connector</code>, or by calling your <code>close_redis_client</code> callback.</p>"},{"location":"lua/qless/#enqueing-jobs","title":"Enqueing Jobs","text":"<p>Jobs themselves are modules, which must be loadable via <code>require</code> and provide a <code>perform</code> function, which accepts a single <code>job</code> argument.</p> <pre><code>-- my/test/job.lua (the job's \"klass\" becomes \"my.test.job\")\n\nlocal _M = {}\n\nfunction _M.perform(job)\n    -- job is an instance of Qless_Job and provides access to\n    -- job.data (which is a Lua table), a means to cancel the\n    -- job (job:cancel()), and more.\n\n    -- return \"nil, err_type, err_msg\" to indicate an unexpected failure\n\n    if not job.data then\n        return nil, \"job-error\", \"data missing\"\n    end\n\n    -- Do work\nend\n\nreturn _M\n</code></pre> <p>Now you can access a queue, and add a job to that queue.</p> <pre><code>-- This references a new or existing queue 'testing'\nlocal queue = qless.queues['testing']\n\n-- Let's add a job, with some data. Returns Job ID\nlocal jid = queue:put(\"my.test.job\", { hello = \"howdy\" })\n-- = \"0c53b0404c56012f69fa482a1427ab7d\"\n\n-- Now we can ask for a job\nlocal job = queue:pop()\n\n-- And we can do the work associated with it!\njob:perform()\n</code></pre> <p>The job data must be a table (which is serialised to JSON internally).</p> <p>The value returned by <code>queue:put()</code> is the job ID, or jid. Every Qless job has a unique jid, and it provides a means to interact with an existing job:</p> <pre><code>-- find an existing job by it's jid\nlocal job = qless.jobs:get(jid)\n\n-- Query it to find out details about it:\njob.klass -- the class of the job\njob.queue -- the queue the job is in\njob.data  -- the data for the job\njob.history -- the history of what has happened to the job sofar\njob.dependencies -- the jids of other jobs that must complete before this one\njob.dependents -- the jids of other jobs that depend on this one\njob.priority -- the priority of this job\njob.tags -- table of tags for this job\njob.original_retries -- the number of times the job is allowed to be retried\njob.retries_left -- the number of retries left\n\n-- You can also change the job in various ways:\njob:requeue(\"some_other_queue\") -- move it to a new queue\njob:cancel() -- cancel the job\njob:tag(\"foo\") -- add a tag\njob:untag(\"foo\") -- remove a tag\n</code></pre>"},{"location":"lua/qless/#running-workers","title":"Running Workers","text":"<p>Traditionally, Qless offered a forking Ruby worker script inspired by Resque.</p> <p>In lua-resty-qless, we take advantage of the <code>init_lua_by_worker</code> phase  and <code>ngx.timer.at</code> API in order run workers in independent \"light threads\", scalable across your worker processes.</p> <p>You can run many light threads concurrently per worker process, which Nginx will schedule for you.</p> <pre><code>init_worker_by_lua '\n    local resty_qless_worker = require \"resty.qless.worker\"\n\n    local worker = resty_qless_worker.new(redis_params)\n\n    worker:start({\n        interval = 1,\n        concurrency = 4,\n        reserver = \"ordered\",\n        queues = { \"my_queue\", \"my_other_queue\" },\n    })\n';\n</code></pre> <p>Workers support three strategies (reservers) for what order to pop jobs off the queues: ordered, round-robin and shuffled round-robin.</p> <p>The ordered reserver will keep popping jobs off the first queue until it is empty, before trying to pop jobs off the second queue. The round-robin reserver will pop a job off the first queue, then the second queue, and so on. Shuffled simply ensures the rounb-robin selection is unpredictable.</p> <p>You could also easily implement your own. Follow the other reservers as a guide, and ensure yours is \"requireable\" with <code>require \"resty.qless.reserver.myreserver\"</code>.</p>"},{"location":"lua/qless/#middleware","title":"Middleware","text":"<p>Workers also support middleware which can be used to inject logic around the processing of a single job. This can be useful, for example, when you need to re-establish a database connection.</p> <p>To do this you set the worker's <code>middleware</code> to a function, and call <code>coroutine.yield</code> where you want the job to be performed.</p> <pre><code>local worker = resty_qless_worker.new(redis_params)\n\nworker.middleware = function(job)\n    -- Do pre job work\n    coroutine.yield()\n    -- Do post job work\nend\n\nworker:start({ queues = \"my_queue\" })\n</code></pre>"},{"location":"lua/qless/#job-dependencies","title":"Job Dependencies","text":"<p>Let's say you have one job that depends on another, but the task definitions are fundamentally different. You need to cook a turkey, and you need to make stuffing, but you can't make the turkey until the stuffing is made:</p> <pre><code>local queue = qless.queues['cook']\nlocal stuffing_jid = queue:put(\"jobs.make.stuffing\", \n  { lots = \"of butter\" }\n)\nlocal turkey_jid  = queue:put(\"jobs.make.turkey\", \n  { with = \"stuffing\" }, \n  { depends = stuffing_jid }\n)\n</code></pre> <p>When the stuffing job completes, the turkey job is unlocked and free to be processed.</p>"},{"location":"lua/qless/#priority","title":"Priority","text":"<p>Some jobs need to get popped sooner than others. Whether it's a trouble ticket, or debugging, you can do this pretty easily when you put a job in a queue:</p> <pre><code>queue:put(\"jobs.test\", { foo = \"bar\" }, { priority = 10 })\n</code></pre> <p>What happens when you want to adjust a job's priority while it's still waiting in a queue?</p> <pre><code>local job = qless.jobs:get(\"0c53b0404c56012f69fa482a1427ab7d\")\njob.priority = 10\n-- Now this will get popped before any job of lower priority\n</code></pre> <p>Note: Setting the priority field above is all you need to do, thanks to Lua metamethods which are invoked to update Redis. This may look a little \"auto-magic\", but the intention is to retain API design compatibility with the Ruby client as much as possible.</p>"},{"location":"lua/qless/#scheduled-jobs","title":"Scheduled Jobs","text":"<p>If you don't want a job to be run right away but some time in the future, you can specify a delay:</p> <pre><code>-- Run at least 10 minutes from now\nqueue:put(\"jobs.test\", { foo = \"bar\" }, { delay = 600 })\n</code></pre> <p>This doesn't guarantee that job will be run exactly at 10 minutes. You can accomplish this by changing the job's priority so that once 10 minutes has elapsed, it's put before lesser-priority jobs:</p> <pre><code>-- Run in 10 minutes\nqueue:put(\"jobs.test\", \n  { foo = \"bar\" }, \n  { delay = 600, priority = 100 }\n)\n</code></pre>"},{"location":"lua/qless/#recurring-jobs","title":"Recurring Jobs","text":"<p>Sometimes it's not enough simply to schedule one job, but you want to run jobs regularly. In particular, maybe you have some batch operation that needs to get run once an hour and you don't care what worker runs it. Recurring jobs are specified much like other jobs:</p> <pre><code>-- Run every hour\nlocal recurring_jid = queue:recur(\"jobs.test\", { widget = \"warble\" }, 3600)\n-- = 22ac75008a8011e182b24cf9ab3a8f3b\n</code></pre> <p>You can even access them in much the same way as you would normal jobs:</p> <pre><code>local job = qless.jobs:get(\"22ac75008a8011e182b24cf9ab3a8f3b\")\n</code></pre> <p>Changing the interval at which it runs after the fact is trivial:</p> <pre><code>-- I think I only need it to run once every two hours\njob.interval = 7200\n</code></pre> <p>If you want it to run every hour on the hour, but it's 2:37 right now, you can specify an offset which is how long it should wait before popping the first job:</p> <pre><code>-- 23 minutes of waiting until it should go\nqueue:recur(\"jobs.test\", \n  { howdy = \"hello\" }, \n  3600,\n  { offset = (23 * 60) }\n)\n</code></pre> <p>Recurring jobs also have priority, a configurable number of retries, and tags. These settings don't apply to the recurring jobs, but rather the jobs that they spawn. In the case where more than one interval passes before a worker tries to pop the job, more than one job is created. The thinking is that while it's completely client-managed, the state should not be dependent on how often workers are trying to pop jobs.</p> <pre><code>-- Recur every minute\nqueue:recur(\"jobs.test\", { lots = \"of jobs\" }, 60)\n\n-- Wait 5 minutes\n\nlocal jobs = queue:pop(10)\nngx.say(#jobs, \" jobs got popped\")\n\n-- = 5 jobs got popped\n</code></pre>"},{"location":"lua/qless/#configuration-options","title":"Configuration Options","text":"<p>You can get and set global (in the context of the same Redis instance) configuration to change the behaviour for heartbeating, and so forth. There aren't a tremendous number of configuration options, but an important one is how long job data is kept around. Job data is expired after it has been completed for <code>jobs-history</code> seconds, but is limited to the last <code>jobs-history-count</code> completed jobs. These default to 50k jobs, and 30 days, but depending on volume, your needs may change. To only keep the last 500 jobs for up to 7 days:</p> <pre><code>qless:config_set(\"jobs-history\", 7 * 86400)\nqless:config_get(\"jobs-history-count\", 500)\n</code></pre>"},{"location":"lua/qless/#tagging-tracking","title":"Tagging / Tracking","text":"<p>In qless, 'tracking' means flagging a job as important. Tracked jobs emit subscribable events as they make progress (more on that below).</p> <pre><code>local job = qless.jobs:get(\"b1882e009a3d11e192d0b174d751779d\")\njob:track()\n</code></pre> <p>Jobs can be tagged with strings which are indexed for quick searches. For example, jobs might be associated with customer accounts, or some other key that makes sense for your project.</p> <pre><code>queue:put(\"jobs.test\", {}, \n  { tags = { \"12345\", \"foo\", \"bar\" } }\n)\n</code></pre> <p>This makes them searchable in the Ruby / Sinatra web interface, or from code:</p> <pre><code>local jids = qless.jobs:tagged(\"foo\")\n</code></pre> <p>You can add or remove tags at will, too:</p> <pre><code>local job = qless.jobs:get('b1882e009a3d11e192d0b174d751779d')\njob:tag(\"howdy\", \"hello\")\njob:untag(\"foo\", \"bar\")\n</code></pre>"},{"location":"lua/qless/#notifications","title":"Notifications","text":"<p>Tracked jobs emit events on specific pubsub channels as things happen to them. Whether it's getting popped off of a queue, completed by a worker, etc.</p> <p>Those familiar with Redis pub/sub will note that a Redis connection can only be used for pubsub-y commands once listening. For this reason, the events module is passed Redis connection parameters independently.</p> <pre><code>local events = qless.events(redis_params)\n\nevents:listen({ \"canceled\", \"failed\" }, function(channel, jid)\n    ngx.log(ngx.INFO, jid, \": \", channel)\n    -- logs \"b1882e009a3d11e192d0b174d751779d: canceled\" etc.\nend\n</code></pre> <p>You can also listen to the \"log\" channel, whilch gives a JSON structure of all logged events.</p> <pre><code>local events = qless.events(redis_params)\n\nevents:listen({ \"log\" }, function(channel, message)\n    local message = cjson.decode(message)\n    ngx.log(ngx.INFO, message.event, \" \", message.jid)\nend\n</code></pre>"},{"location":"lua/qless/#heartbeating","title":"Heartbeating","text":"<p>When a worker is given a job, it is given an exclusive lock to that job. That means that job won't be given to any other worker, so long as the worker checks in with progress on the job. By default, jobs have to either report back progress every 60 seconds, or complete it, but that's a configurable option. For longer jobs, this may not make sense.</p> <pre><code>-- Hooray! We've got a piece of work!\nlocal job = queue:pop()\n\n-- How long until I have to check in?\njob:ttl()\n-- = 59\n\n-- Hey! I'm still working on it!\njob:heartbeat()\n-- = 1331326141.0\n\n-- Ok, I've got some more time. Oh! Now I'm done!\njob:complete()\n</code></pre> <p>If you want to increase the heartbeat in all queues,</p> <pre><code>-- Now jobs get 10 minutes to check in\nqless:set_config(\"heartbeat\", 600)\n\n-- But the testing queue doesn't get as long.\nqless.queues[\"testing\"].heartbeat = 300\n</code></pre> <p>When choosing a heartbeat interval, note that this is the amount of time that can pass before qless realizes if a job has been dropped. At the same time, you don't want to burden qless with heartbeating every 10 seconds if your job is expected to take several hours.</p> <p>An idiom you're encouraged to use for long-running jobs that want to check in their progress periodically:</p> <pre><code>-- Wait until we have 5 minutes left on the heartbeat, and if we find that\n-- we've lost our lock on a job, then honorably fall on our sword\nif job:ttl() &lt; 300 and not job:heartbeat() then\n  -- exit\nend\n</code></pre>"},{"location":"lua/qless/#stats","title":"Stats","text":"<p>One nice feature of Qless is that you can get statistics about usage. Stats are aggregated by day, so when you want stats about a queue, you need to say what queue and what day you're talking about. By default, you just get the stats for today. These stats include information about the mean job wait time, standard deviation, and histogram. This same data is also provided for job completion:</p> <pre><code>-- So, how're we doing today?\nlocal stats = queue:stats()\n-- = { 'run' = { 'mean' = ..., }, 'wait' = {'mean' = ..., } }\n</code></pre>"},{"location":"lua/qless/#time","title":"Time","text":"<p>It's important to note that Redis doesn't allow access to the system time if you're going to be making any manipulations to data (which our scripts do). And yet, we have heartbeating. This means that the clients actually send the current time when making most requests, and for consistency's sake, means that your workers must be relatively synchronized. This doesn't mean down to the tens of milliseconds, but if you're experiencing appreciable clock drift, you should investigate NTP.</p>"},{"location":"lua/qless/#ensuring-job-uniqueness","title":"Ensuring Job Uniqueness","text":"<p>As mentioned above, Jobs are uniquely identied by an id--their jid. Qless will generate a UUID for each enqueued job or you can specify one manually:</p> <pre><code>queue:put(\"jobs.test\", { hello = 'howdy' }, { jid = 'my-job-jid' })\n</code></pre> <p>This can be useful when you want to ensure a job's uniqueness: simply create a jid that is a function of the Job's class and data, it'll guaranteed that Qless won't have multiple jobs with the same class and data.</p>"},{"location":"lua/qless/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-qless.</p>"},{"location":"lua/rabbitmqstomp/","title":"rabbitmqstomp: Opinionated Lua RabbitMQ client library for nginx-module-lua apps based on the cosocket API","text":""},{"location":"lua/rabbitmqstomp/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/rabbitmqstomp/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-rabbitmqstomp\n</code></pre>"},{"location":"lua/rabbitmqstomp/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-rabbitmqstomp\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-rabbitmqstomp v0.1  released on Jun 01 2013.</p> <p>lua-resty-rabbitmqstomp - Lua RabbitMQ client library which uses cosocket api for communication over STOMP 1.2 with a RabbitMQ broker which has the STOMP plugin.</p>"},{"location":"lua/rabbitmqstomp/#limitations","title":"Limitations","text":"<p>This library is opinionated and has certain assumptions and limitations which may be addressed in future;</p> <ul> <li>RabbitMQ server should have the STOMP adapter enabled that supports STOMP v1.2</li> <li>Assumption that users, vhost, exchanges, queues and bindings are already setup</li> </ul>"},{"location":"lua/rabbitmqstomp/#status","title":"Status","text":"<p>This library is considered production ready for publishing reliable messages to RabbitMQ.</p>"},{"location":"lua/rabbitmqstomp/#stomp-v12-client-implementation","title":"STOMP v1.2 Client Implementation","text":"<p>This library uses STOMP 1.2 for communication with RabbitMQ broker and implements extensions and restrictions of the RabbitMQ Stomp plugin.</p> <p>Internally, RabbitMQ uses AMQP to communicate further. This way the library enables implementation of consumers and producers which communicate with the RabbitMQ broker over STOMP, over AMQP. The protocol is frame based and has a command, headers and body terminated by an EOL (^@) which consists of <code>\\r</code> (013) and required <code>\\n</code> (010) over a TCP stream:</p> <pre><code>COMMAND\nheader1:value1\nheader2: value2\n\nBODY^@\n</code></pre> <p>COMMAND is followed by EOL, then EOL separated header in key:value pair format and then a blank line which is where the BODY starts and the frame is terminated by ^@ EOL. COMMAND and headers are UTF-8 encoded.</p>"},{"location":"lua/rabbitmqstomp/#connection","title":"Connection","text":"<p>To connect we create and send a CONNECT frame over a TCP socket provided by the cosocket api connecting to the broker IP, both IPv4 and IPv6 are supported. In the frame we use login, passcode for authentication, accept-version to enforce client STOMP version support and host to select the VHOST of the broker.</p> <pre><code>CONNECT\naccept-version:1.2\nlogin:guest\npasscode:guest\nhost:/devnode\nheart-beat:optional\n\n^@\n</code></pre> <p>On error, an ERROR frame is returned for example:</p> <pre><code>ERROR\nmessage:Bad CONNECT\ncontent-type:text/plain\nversion:1.0,1.1,1.2\ncontent-length:32\n\nAccess refused for user 'admin'^@\n</code></pre> <p>On successful connection, we are returned a CONNECTED frame by the broker, for example:</p> <pre><code>CONNECTED\nsession:session-sGF0vjCKH1bLhFr6w9QwuQ\nheart-beat:0,0\nserver:RabbitMQ/3.0.4\nversion:1.2\n</code></pre> <p>For creating a connection, username, password, vhost, heartbeat, broker host and port should be provided.</p>"},{"location":"lua/rabbitmqstomp/#publishing","title":"Publishing","text":"<p>We can publish messages to an exchange with a routing key, persistence mode, delivery mode and other header using the SEND command:</p> <pre><code>SEND\ndestination:/exchange/exchange_name/routing_key\napp-id: luaresty\ndelivery-mode:2\npersistent:true\ncontent-type:json/application\ncontent-length:5\n\nhello^@\n</code></pre> <p>Note that content-length includes the message and EOL byte.</p>"},{"location":"lua/rabbitmqstomp/#methods","title":"Methods","text":""},{"location":"lua/rabbitmqstomp/#new","title":"new","text":"<p><code>syntax: rabbit, err = rabbitmqstomp:new()</code></p> <p>Creates a RabbitMQ object. In case of failures, returns nil and a string describing the error.</p>"},{"location":"lua/rabbitmqstomp/#set_timeout","title":"set_timeout","text":"<p><code>syntax: rabbit:set_timeout(time)</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the connect method. Note timeout should be set before calling any other method after creating the object.</p>"},{"location":"lua/rabbitmqstomp/#connect","title":"connect","text":"<p><code>syntax: ok, err = red:connect{host=host, port=port, username=username, password=password, vhost=vhost}</code></p> <p>Attempts to connect to a stomp broker the RabbitMQ STOMP adapter on a host, port is listening on.</p> <p>If none of the values are supplied default values are assumed:</p> <ul> <li>host: localhost</li> <li>port: 61613</li> <li>username: guest</li> <li>password: guest</li> <li>vhost: /</li> </ul> <p><code>pool</code> can be given to be used for a custom name for the connection pool being used.</p>"},{"location":"lua/rabbitmqstomp/#send","title":"send","text":"<p><code>syntax: rabbit:send(msg, headers)</code></p> <p>Publishers message with a set of headers.</p> <p>Some header values which can be set:</p> <p><code>destination</code>: Destination of the message, for example /exchange/name/binding<code></code>persistent<code>: To delivery a persistent message, value should be \"true\" if declared</code>receipt<code>: Receipt for confirmed delivery</code>content-type`: Type of message, for example application/json</p> <p>For list of supported headers see the STOMP protocol extensions and restriction page: <code>https://www.rabbitmq.com/stomp.html</code></p>"},{"location":"lua/rabbitmqstomp/#subscribe","title":"subscribe","text":"<p><code>syntax: rabbit:subscribe(headers)</code></p> <p>Subscribe to a queue by using <code>headers</code>. It should have a id when persistent is true. On successful subscription MESSAGE frames are sent by the broker.</p>"},{"location":"lua/rabbitmqstomp/#unsubscribe","title":"unsubscribe","text":"<p><code>syntax: rabbit:unsubscribe(headers)</code></p> <p>Unsubscribes from a queue by using <code>headers</code>. On successful unsubscription MESSAGE frames will stop coming from the broker.</p>"},{"location":"lua/rabbitmqstomp/#receive","title":"receive","text":"<p><code>syntax: rabbit:receive())</code></p> <p>Tries to read any MESSAGE frames received and returns the message. Trying to receive without a valid subscription will lead to errors.</p>"},{"location":"lua/rabbitmqstomp/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: times, err = rabbit:get_reused_times()</code></p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns nil and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns 0, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p>"},{"location":"lua/rabbitmqstomp/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = rabbit:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Puts the current RabbitMQ connection immediately into the ngx_lua cosocket connection pool.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns 1. In case of errors, returns nil with a string describing the error.</p> <p>Only call this method in the place you would have called the close method instead. Calling this method will immediately turn the current redis object into the closed state. Any subsequent operations other than connect() on the current objet will return the closed error.</p>"},{"location":"lua/rabbitmqstomp/#close","title":"close","text":"<p><code>syntax: ok, err = rabbit:close()</code></p> <p>Closes the current RabbitMQ connection gracefully by sending a DISCONNECT to the RabbitMQ STOMP broker and returns the status.</p> <p>In case of success, returns 1. In case of errors, returns nil with a string describing the error.</p>"},{"location":"lua/rabbitmqstomp/#example","title":"Example","text":"<p>A simple producer that can send reliable persistent message to an exchange with some binding:</p> <pre><code>local rabbitmq = require \"resty.rabbitmqstomp\"\nlocal mq, err = rabbitmq:new()\nif not mq then\n      return\nend\n\nmq:set_timeout(10000)\n\nlocal ok, err = mq:connect {\n                    host = \"127.0.0.1\",\n                    port = 61613,\n                    username = \"guest\",\n                    password = \"guest\",\n                    vhost = \"/\"\n                }\nif not ok then\n    return\nend\n\nlocal strlen =  string.len\n\nlocal msg = \"{'key': 'value'}\"\nlocal headers = {}\nheaders[\"destination\"] = \"/exchange/test/binding\"\nheaders[\"receipt\"] = \"msg#1\"\nheaders[\"app-id\"] = \"luaresty\"\nheaders[\"persistent\"] = \"true\"\nheaders[\"content-type\"] = \"application/json\"\n\nlocal ok, err = mq:send(msg, headers)\nif not ok then\n    return\nend\nngx.log(ngx.INFO, \"Published: \" .. msg)\n\nlocal headers = {}\nheaders[\"destination\"] = \"/amq/queue/queuename\"\nheaders[\"persistent\"] = \"true\"\nheaders[\"id\"] = \"123\"\n\nlocal ok, err = mq:subscribe(headers)\nif not ok then\n    return\nend\n\nlocal data, err = mq:receive()\nif not ok then\n    return\nend\nngx.log(ngx.INFO, \"Consumed: \" .. data)\n\nlocal headers = {}\nheaders[\"persistent\"] = \"true\"\nheaders[\"id\"] = \"123\"\n\nlocal ok, err = mq:unsubscribe(headers)\n\nlocal ok, err = mq:set_keepalive(10000, 10000)\nif not ok then\n    return\nend\n</code></pre>"},{"location":"lua/rabbitmqstomp/#see-also","title":"See Also","text":"<ul> <li>STOMP 1.2 Spec</li> <li>The lua-resty-mysql library</li> <li>Openresty google group</li> </ul>"},{"location":"lua/rabbitmqstomp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-rabbitmqstomp.</p>"},{"location":"lua/rack/","title":"rack: A simple and extensible HTTP server framework for nginx-module-lua","text":""},{"location":"lua/rack/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/rack/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-rack\n</code></pre>"},{"location":"lua/rack/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-rack\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-rack v0.3  released on Jul 12 2012.</p> <p>A simple and extensible HTTP server framework for OpenResty, providing a clean method for loading Lua HTTP applications (\"resty\" modules) into Nginx.</p> <p>Drawing inspiration from Rack and also Connect, lua-resty-rack allows you to load your application as a piece of middleware, alongside other middleware. Your application can either; ignore the current request, modify the request or response in some way and pass on to other middleware, or take responsibiliy for the request by generating a response. </p>"},{"location":"lua/rack/#status","title":"Status","text":"<p>This library is considered experimental and the API may change without notice. Please feel free to offer suggestions or raise issues here on Github.</p>"},{"location":"lua/rack/#using-middleware","title":"Using Middleware","text":"<p>To install middleware for a given <code>location</code>, you simply call <code>rack.use(middleware)</code> in the order you wish the modules to run, and then finally call <code>rack.run()</code>.</p> <pre><code>server {\n    location / {\n        content_by_lua '\n            local rack = require \"resty.rack\"\n\n            rack.use(rack.middleware.method_override)\n            rack.use(require \"my.module\")\n            rack.run()\n        ';\n    }\n}\n</code></pre>"},{"location":"lua/rack/#rackuse","title":"rack.use(...)","text":"<p>Syntax: <code>rack.use(route?, middleware, options?)</code></p> <p>If <code>route</code> is supplied, the middleware will only be run for requests where <code>route</code> is in the path (<code>ngx.var.uri</code>). If the middleware requires any options to be selected they can be provided, usually as a table, as the third parameter.</p> <pre><code>rack.use('/some/path', app, { foo = 'bar' })\n</code></pre> <p>For simple cases, the <code>middleware</code> parameter can also be a simple function rather than a Lua module. Your function should accept <code>req</code>, <code>res</code>, and <code>next</code> as parameters. See below for instructions on writing middleware.</p> <pre><code>rack.use(function(req, res, next)\n    res.header[\"X-Homer\"] = \"Doh!\"\n    next()\nend)\n</code></pre>"},{"location":"lua/rack/#rackrun","title":"rack.run()","text":"<p>Syntax: <code>rack.run()</code></p> <p>Runs each of the middleware in order, until one chooses to handle the response. Thus, the order in which you call <code>rack.use()</code> is important.</p>"},{"location":"lua/rack/#bundled-middleware","title":"Bundled Middleware","text":""},{"location":"lua/rack/#method_override","title":"method_override","text":"<pre><code>rack.use(rack.middleware.method_override, { key = \"METHOD\" })\n</code></pre> <p>Override the HTTP method using a querystring value. The default argument name is \"_method\" but this can be overriden by setting the option \"key\".</p>"},{"location":"lua/rack/#read_request_headers","title":"read_request_headers","text":"<pre><code>rack.use(rack.middleware.read_request_headers, { max = 50 })\n</code></pre> <p>This is only needed if you wish to iterate over the HTTP request headers. They will be lazy loaded when accessed via <code>req.header</code>.</p> <p>You may specify a limit to the number of request headers to be read, which defaults to <code>100</code>. The limit can be removed by specifying a max of <code>0</code>, but is strongly discouraged.</p>"},{"location":"lua/rack/#read_body","title":"read_body","text":"<pre><code>rack.use(rack.middleware.read_body)\n</code></pre> <p>Explicitly reads the request body (raw).</p>"},{"location":"lua/rack/#creating-middleware","title":"Creating Middleware","text":"<p>Middleware applications are simply Lua modules which use the HTTP request and response as a minimal interface. They must implement the function <code>call(options)</code> which returns a function. The parameters <code>(req, res, next)</code> are defined below.</p> <pre><code>module(\"resty.rack.method_override\", package.seeall)\n\n_VERSION = '0.01'\n\nfunction call(options)\n    return function(req, res, next)\n        local key = options['key'] or '_method'\n        req.method = string.upper(req.args[key] or req.method)\n        next()\n    end\nend\n</code></pre>"},{"location":"lua/rack/#api","title":"API","text":""},{"location":"lua/rack/#reqmethod","title":"req.method","text":"<p>The HTTP method, e.g. <code>GET</code>, set from <code>ngx.var.request_method</code>.</p>"},{"location":"lua/rack/#reqscheme","title":"req.scheme","text":"<p>The protocol scheme <code>http|https</code>, set from <code>ngx.var.scheme</code>.</p>"},{"location":"lua/rack/#requri","title":"req.uri","text":"<p>e.g. <code>/my/uri</code>, set from <code>ngx.var.uri</code>.</p>"},{"location":"lua/rack/#reqhost","title":"req.host","text":"<p>The hostname, e.g. <code>example.com</code>, set from <code>ngx.var.host</code>.</p>"},{"location":"lua/rack/#reqquery","title":"req.query","text":"<p>The querystring, e.g. <code>var1=1&amp;var2=2</code>, set from <code>ngx.var.query_string</code>.</p>"},{"location":"lua/rack/#reqargs","title":"req.args","text":"<p>The query args, as a <code>table</code>, set from <code>ngx.req.get_uri_args()</code>.</p>"},{"location":"lua/rack/#reqheader","title":"req.header","text":"<p>A table containing the request headers. Keys are matched case insensitvely, and optionally with underscores instead of hyphens. e.g.</p> <pre><code>req.header[\"X-Foo\"] = \"bar\"\nres.body = req.header.x_foo\n    --&gt; \"bar\"\n</code></pre> <p>HTTP Request headers are read on demand and so cannot be iterated over unless the <code>read_request_headers</code> middleware is in use).</p>"},{"location":"lua/rack/#reqbody","title":"req.body","text":"<p>An empty string until read with the <code>read_body</code> middleware.</p>"},{"location":"lua/rack/#resstatus","title":"res.status","text":"<p>The HTTP status code to return. There are constants defined for common statuses.</p>"},{"location":"lua/rack/#resheader","title":"res.header","text":"<p>A table of response headers, which can be matched case insensitively and optionally with underscores instead of hyphens (see <code>req.header</code> above).</p>"},{"location":"lua/rack/#resbody","title":"res.body","text":"<p>The response body.</p>"},{"location":"lua/rack/#next","title":"next","text":"<p>This parameter is a function provided to the middleware, which may be called to indicate rack should try the next middleware. If your application does not intend to send the response to the browser, it must call this function. If however your application is taking responsibility for the response, simply return without calling next.</p> <p>Example purely modifying the request. <pre><code>function call(options)\n    return function(req, res, next)\n        local key = options['key'] or '_method'\n        req.method = string.upper(req.args[key] or req.method)\n        next()\n    end\nend\n</code></pre></p> <p>Example generating a response. <pre><code>function call(options)\n    return function(req, res)\n        res.status = 200\n        res.header['Content-Type'] = \"text/plain\"\n        res.body = \"Hello World\"\n    end\nend\n</code></pre></p>"},{"location":"lua/rack/#enhancing-req-res","title":"Enhancing req / res","text":"<p>Your application can add new fields or even functions to the req / res tables where appropriate, which could be used by other middleware so long as the dependencies are clear (and one calls <code>use()</code> in the correct order). </p>"},{"location":"lua/rack/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-rack.</p>"},{"location":"lua/radixtree/","title":"radixtree: Adaptive Radix Trees implemented in Lua / LuaJIT","text":""},{"location":"lua/radixtree/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/radixtree/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-radixtree\n</code></pre>"},{"location":"lua/radixtree/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-radixtree\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-radixtree v2.9.2  released on Nov 28 2024.</p> <p>Radix tree implementation based on rax.</p>"},{"location":"lua/radixtree/#status","title":"Status","text":"<p>Dependencies:</p> <ul> <li>lua-resty-ipmatcher</li> <li>lua-resty-expr</li> </ul> <p>Used by:</p> <ul> <li>Apache APISIX: A high-performance cloud native API gateway.</li> </ul> <p>Developed by API7.ai.</p> <p>Note</p> <p>API7.ai provides technical support for the software it maintains like this library and Apache APISIX. Please contact us to learn more.</p>"},{"location":"lua/radixtree/#synopsis","title":"Synopsis","text":"<pre><code>location / {\n  set $arg_access 'admin';\n  content_by_lua_block {\n    local radix = require(\"resty.radixtree\")\n    local rx = radix.new({\n        {\n            paths = { \"/login/*action\" },\n            metadata = { \"metadata /login/action\" },\n            methods = { \"GET\", \"POST\", \"PUT\" },\n            remote_addrs = { \"127.0.0.1\", \"192.168.0.0/16\", \"::1\", \"fe80::/32\" }\n        },\n        {\n            paths = { \"/user/:name\" },\n            metadata = { \"metadata /user/name\" },\n            methods = { \"GET\" },\n        },\n        {\n            paths = { \"/admin/:name\", \"/superuser/:name\" },\n            metadata = { \"metadata /admin/name\" },\n            methods = { \"GET\", \"POST\", \"PUT\" },\n            filter_fun = function(vars, opts)\n                return vars[\"arg_access\"] == \"admin\"\n            end\n        }\n    })\n\n    local opts = {\n        method = \"POST\",\n        remote_addr = \"127.0.0.1\",\n        matched = {}\n    }\n\n    -- matches the first route\n    ngx.say(rx:match(\"/login/update\", opts))   -- metadata /login/action\n    ngx.say(\"action: \", opts.matched.action)   -- action: update\n\n    ngx.say(rx:match(\"/login/register\", opts)) -- metadata /login/action\n    ngx.say(\"action: \", opts.matched.action)   -- action: register\n\n    local opts = {\n        method = \"GET\",\n        matched = {}\n    }\n\n    -- matches the second route\n    ngx.say(rx:match(\"/user/john\", opts)) -- metadata /user/name\n    ngx.say(\"name: \", opts.matched.name)  -- name: john\n\n    local opts = {\n        method = \"POST\",\n        vars = ngx.var,\n        matched = {}\n    }\n\n    -- matches the third route\n    ngx.say(rx:match(\"/admin/jane\", opts))     -- metadata /admin/name\n    ngx.say(\"admin name: \", opts.matched.name) -- admin name: jane\n    }\n}\n</code></pre>"},{"location":"lua/radixtree/#methods","title":"Methods","text":""},{"location":"lua/radixtree/#new","title":"new","text":"<p>Creates a new radix tree to store routes.</p>"},{"location":"lua/radixtree/#usage","title":"Usage","text":"<pre><code>rx, err = radix.new(routes, opts)\n</code></pre>"},{"location":"lua/radixtree/#attributes","title":"Attributes","text":"<p><code>routes</code> is an array (<code>{ {...}, {...}, {...} }</code>) where each element is a route.</p> <p>Each route can have the following attributes:</p> Name Required? Description Example paths Required List of request paths to match the route. By default does a full match. Adding <code>*</code> at the end will result in prefix match. For example, <code>/foo*</code> can match requests with paths <code>/foo/bar</code> and <code>/foo/car/far</code>. {\"/\", \"/foo\", \"/bar/*\"} hosts Optional List of host addresses to match the route. Supports wildcards. For example <code>*.bar.com</code> can match <code>foo.bar.com</code> and <code>car.bar.com</code>. {\"foo.com\", \"*.bar.com\"} remote_addrs Optional List of remote addresses (IPv4 or IPv6) to match the route. Supports CIDR format. {\"127.0.0.1\", \"192.0.0.0/8\", \"::1\", \"fe80::/32\"} methods Optional List of HTTP methods to match the route. Valid values: \"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\", \"HEAD\", \"OPTIONS\", \"CONNECT\" and \"TRACE\". {\"GET\", \"POST\"} vars Optional DSL to evaluate with the provided <code>opts.vars</code> or <code>ngx.var</code>. See: lua-resty-expr. {{\"arg_name\", \"==\", \"json\"}, {\"arg_age\", \"&gt;\", 18}} filter_fun Optional User defined filter function to match the route. Can be used for custom matching scenarios. <code>vars</code> and <code>opts</code> will be passed to the function when matching a route. function(vars) return vars[\"arg_name\"] == \"json\" end priority Optional Route priority. Defaults to 0. priority = 100 metadata Optional <code>metadata</code> will be returned when a route matches while using <code>rx:match</code>. handler Optional <code>handler</code> function will be called when a route matches while using <code>rx:dispatch</code>. <p><code>opts</code> is an optional configuration that controls the behavior of a match. It can have the following attribute:</p> Name Description Default no_param_match Disables Parameters in path. false"},{"location":"lua/radixtree/#match","title":"match","text":"<p>Matches client request with routes and returns <code>metadata</code> if successful.</p>"},{"location":"lua/radixtree/#usage_1","title":"Usage","text":"<pre><code>metadata = rx:match(path, opts)\n</code></pre>"},{"location":"lua/radixtree/#attributes_1","title":"Attributes","text":"<p><code>path</code> is the client request path. For example, <code>\"/foo/bar\"</code>, <code>/user/john/send</code>.</p> <p><code>opts</code> is an optional attribute and a table. It can have the following attributes:</p> Name Required? Description method Optional HTTP method of the client request. host Optional Host address of the client request. remote_addr Optional Remote address (IPv4 or IPv6) of the client. Supports CIDR format. paths Optional A list of client request paths. vars Optional A table to fetch variables. Defaults to <code>ngx.var</code> to fetch built-in Nginx variables."},{"location":"lua/radixtree/#dispatch","title":"dispatch","text":"<p>Matches client requests with routes and calls the <code>handler</code> function if successful.</p>"},{"location":"lua/radixtree/#usage_2","title":"Usage","text":"<pre><code>ok = rx:dispatch(path, opts, ...)\n</code></pre>"},{"location":"lua/radixtree/#attributes_2","title":"Attributes","text":"<p><code>path</code> is the client request path. For example, <code>\"/api/metrics\"</code>, <code>/admin/john/login</code>.</p> <p><code>opts</code> is an optional attribute and a table. It can have the following attributes:</p> Name Required? Description method Optional HTTP method of the client request. host Optional Host address of the client request. remote_addr Optional Remote address (IPv4 or IPv6) of the client. Supports CIDR format. paths Optional A list of client request paths. vars Optional A table to fetch variables. Defaults to <code>ngx.var</code> to fetch built-in Nginx variables."},{"location":"lua/radixtree/#examples","title":"Examples","text":""},{"location":"lua/radixtree/#full-path-match","title":"Full Path Match","text":"<p>Matching full paths with multiple paths specified:</p> <pre><code>local rx = radix.new({\n    {\n        paths = {\"/foo\", \"/bar/car\", \"/doo/soo/index.html\"},\n        metadata = \"metadata /foo\",\n    },\n    {\n        paths = {\"/example\"},\n        metadata = \"metadata /example\",\n    },\n    {\n        paths = {\"/index.html\"},\n        metadata = \"metadata /index.html\",\n    },\n})\n</code></pre>"},{"location":"lua/radixtree/#prefix-match","title":"Prefix Match","text":"<p>Matching based on prefix with multiple paths specified:</p> <pre><code>local rx = radix.new({\n    {\n        paths = {\"/foo/*\", \"/bar/car/*\"}, -- matches with `/foo/boo`, `/bar/car/sar/far`, etc.\n        metadata = \"metadata /foo\",\n    },\n    {\n        paths = {\"/example/*\"}, -- matches with `/example/boo`, `/example/car/sar/far`, etc.\n        metadata = \"metadata /example\",\n    },\n})\n</code></pre>"},{"location":"lua/radixtree/#parameters-in-path","title":"Parameters in Path","text":"<p>You can specify parameters on a path. These can then be dynamically obtained from <code>opts.matched.parameter-name</code>:</p> <pre><code>local rx = radix.new({\n    {\n        -- matches with `/user/john` but not `/user/` or `/user`\n        paths = {\"/user/:user\"}, -- for `/user/john`, `opts.matched.user` will be `john`\n        metadata = \"metadata /user\",\n    },\n    {\n        -- But this will match `/user/john/` and also `/user/john/send`\n        paths = {\"/user/:user/*action\"}, -- for `/user/john/send`, `opts.matched.user` will be `john` and `opts.matched.action` will be `send`\n        metadata = \"metadata action\",\n    },\n})\n</code></pre>"},{"location":"lua/radixtree/#development","title":"Development","text":"<p>To install dependencies, run:</p> <pre><code>make deps\n</code></pre>"},{"location":"lua/radixtree/#benchmarks","title":"Benchmarks","text":"<p>These are simple benchmarks.</p> <p>Environment: MacBook Pro (16-inch, 2019), CPU 2.3 GHz Intel Core i9.</p> <p>To start benchmarking, run:</p> <pre><code>make\n</code></pre> <pre><code>make bench\n</code></pre> <p>Results:</p> <pre><code>resty -I=./lib -I=./deps/share/lua/5.1 benchmark/match-parameter.lua\nmatched res: 1\nroute count: 100000\nmatch times: 10000000\ntime used  : 3.1400001049042 sec\nQPS        : 3184713\neach time  : 0.31400001049042 ns\n\nresty -I=./lib -I=./deps/share/lua/5.1 benchmark/match-prefix.lua\nmatched res: 500\nroute count: 100000\nmatch times: 1000000\ntime used  : 0.42700004577637 sec\nQPS        : 2341920\n\nresty -I=./lib -I=./deps/share/lua/5.1 benchmark/match-static.lua\nmatched res: 500\nroute count: 100000\nmatch times: 10000000\ntime used  : 0.95000004768372 sec\nQPS        : 10526315\n\nresty -I=./lib -I=./deps/share/lua/5.1 benchmark/match-hosts.lua\nmatched res: 500\nroute count: 1000\nmatch times: 100000\ntime used  : 0.60199999809265 sec\nQPS        : 166112\n\nresty -I=./lib -I=./deps/share/lua/5.1 benchmark/match-wildcard-hosts.lua\nmatched res: 500\nroute count: 1000\nmatch times: 50000\ntime used  : 0.47900009155273 sec\nQPS        : 104384\n</code></pre>"},{"location":"lua/radixtree/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-radixtree.</p>"},{"location":"lua/redis-connector/","title":"redis-connector: Connection utilities for lua-resty-redis","text":""},{"location":"lua/redis-connector/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/redis-connector/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-redis-connector\n</code></pre>"},{"location":"lua/redis-connector/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-redis-connector\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-redis-connector v0.11.0  released on Jul 13 2021.</p> <p>Connection utilities for lua-resty-redis, making it easy and reliable to connect to Redis hosts, either directly or via Redis Sentinel.</p>"},{"location":"lua/redis-connector/#synopsis","title":"Synopsis","text":"<p>Quick and simple authenticated connection on localhost to DB 2:</p> <pre><code>local redis, err = require(\"resty.redis.connector\").new({\n    url = \"redis://PASSWORD@127.0.0.1:6379/2\",\n}):connect()\n</code></pre> <p>More verbose configuration, with timeouts and a default password:</p> <pre><code>local rc = require(\"resty.redis.connector\").new({\n    connect_timeout = 50,\n    send_timeout = 5000,\n    read_timeout = 5000,\n    keepalive_timeout = 30000,\n    password = \"mypass\",\n})\n\nlocal redis, err = rc:connect({\n    url = \"redis://127.0.0.1:6379/2\",\n})\n\n-- ...\n\nlocal ok, err = rc:set_keepalive(redis)  -- uses keepalive params\n</code></pre> <p>Keep all config in a table, to easily create / close connections as needed:</p> <pre><code>local rc = require(\"resty.redis.connector\").new({\n    connect_timeout = 50,\n    send_timeout = 5000,\n    read_timeout = 5000,\n    keepalive_timeout = 30000,\n\n    host = \"127.0.0.1\",\n    port = 6379,\n    db = 2,\n    password = \"mypass\",\n})\n\nlocal redis, err = rc:connect()\n\n-- ...\n\nlocal ok, err = rc:set_keepalive(redis)\n</code></pre> <p>connect can be used to override some defaults given in new, which are pertinent to this connection only.</p> <pre><code>local rc = require(\"resty.redis.connector\").new({\n    host = \"127.0.0.1\",\n    port = 6379,\n    db = 2,\n})\n\nlocal redis, err = rc:connect({\n    db = 5,\n})\n</code></pre>"},{"location":"lua/redis-connector/#dsn-format","title":"DSN format","text":"<p>If the <code>params.url</code> field is present then it will be parsed to set the other params. Any manually specified params will override values given in the DSN.</p> <p>Note: this is a behaviour change as of v0.06. Previously, the DSN values would take precedence.</p>"},{"location":"lua/redis-connector/#direct-redis-connections","title":"Direct Redis connections","text":"<p>The format for connecting directly to Redis is:</p> <p><code>redis://USERNAME:PASSWORD@HOST:PORT/DB</code></p> <p>The <code>USERNAME</code>, <code>PASSWORD</code> and <code>DB</code> fields are optional, all other components are required.</p> <p>Use of username requires Redis 6.0.0 or newer.</p>"},{"location":"lua/redis-connector/#connections-via-redis-sentinel","title":"Connections via Redis Sentinel","text":"<p>When connecting via Redis Sentinel, the format is as follows:</p> <p><code>sentinel://USERNAME:PASSWORD@MASTER_NAME:ROLE/DB</code></p> <p>Again, <code>USERNAME</code>, <code>PASSWORD</code> and <code>DB</code> are optional. <code>ROLE</code> must be either <code>m</code> or <code>s</code> for master / slave respectively.</p> <p>On versions of Redis newer than 5.0.1, Sentinels can optionally require their own password. If enabled, provide this password in the <code>sentinel_password</code> parameter. On Redis 6.2.0 and newer you can pass username using <code>sentinel_username</code> parameter.</p> <p>A table of <code>sentinels</code> must also be supplied. e.g.</p> <pre><code>local redis, err = rc:connect{\n    url = \"sentinel://mymaster:a/2\",\n    sentinels = {\n        { host = \"127.0.0.1\", port = 26379 },\n    },\n    sentinel_username = \"default\",\n    sentinel_password = \"password\"\n}\n</code></pre>"},{"location":"lua/redis-connector/#proxy-mode","title":"Proxy Mode","text":"<p>Enable the <code>connection_is_proxied</code> parameter if connecting to Redis through a proxy service (e.g. Twemproxy). These proxies generally only support a limited sub-set of Redis commands, those which do not require state and do not affect multiple keys. Databases and transactions are also not supported.</p> <p>Proxy mode will disable switching to a DB on connect. Unsupported commands (defaults to those not supported by Twemproxy) will return <code>nil, err</code> immediately rather than being sent to the proxy, which can result in dropped connections.</p> <p><code>discard</code> will not be sent when adding connections to the keepalive pool</p>"},{"location":"lua/redis-connector/#disabled-commands","title":"Disabled commands","text":"<p>If configured as a table of commands, the command methods will be replaced by a function which immediately returns <code>nil, err</code> without forwarding the command to the server</p>"},{"location":"lua/redis-connector/#default-parameters","title":"Default Parameters","text":"<pre><code>{\n    connect_timeout = 100,\n    send_timeout = 1000,\n    read_timeout = 1000,\n    keepalive_timeout = 60000,\n    keepalive_poolsize = 30,\n\n    -- ssl, ssl_verify, server_name, pool, pool_size, backlog\n    -- see: https://github.com/openresty/lua-resty-redis#connect\n    connection_options = {},\n\n    host = \"127.0.0.1\",\n    port = \"6379\",\n    path = \"\",  -- unix socket path, e.g. /tmp/redis.sock\n    username = \"\",\n    password = \"\",\n    sentinel_username = \"\",\n    sentinel_password = \"\",\n    db = 0,\n\n    master_name = \"mymaster\",\n    role = \"master\",  -- master | slave\n    sentinels = {},\n\n    connection_is_proxied = false,\n\n    disabled_commands = {},\n}\n</code></pre>"},{"location":"lua/redis-connector/#api","title":"API","text":"<ul> <li>new</li> <li>connect</li> <li>set_keepalive</li> <li>Utilities<ul> <li>connect_via_sentinel</li> <li>try_hosts</li> <li>connect_to_host</li> <li>sentinel.get_master</li> <li>sentinel.get_slaves</li> </ul> </li> </ul>"},{"location":"lua/redis-connector/#new","title":"new","text":"<p><code>syntax: rc = redis_connector.new(params)</code></p> <p>Creates the Redis Connector object, overring default params with the ones given. In case of failures, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/redis-connector/#connect","title":"connect","text":"<p><code>syntax: redis, err = rc:connect(params)</code></p> <p>Attempts to create a connection, according to the params supplied, falling back to defaults given in <code>new</code> or the predefined defaults. If a connection cannot be made, returns <code>nil</code> and a string describing the reason.</p> <p>Note that <code>params</code> given here do not change the connector's own configuration, and are only used to alter this particular connection operation. As such, the following parameters have no meaning when given in <code>connect</code>.</p> <ul> <li><code>keepalive_poolsize</code></li> <li><code>keepalive_timeout</code></li> <li><code>connection_is_proxied</code></li> <li><code>disabled_commands</code></li> </ul>"},{"location":"lua/redis-connector/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = rc:set_keepalive(redis)</code></p> <p>Attempts to place the given Redis connection on the keepalive pool, according to timeout and poolsize params given in <code>new</code> or the predefined defaults.</p> <p>This allows an application to release resources without having to keep track of application wide keepalive settings.</p> <p>Returns <code>1</code> or in the case of error, <code>nil</code> and a string describing the error.</p>"},{"location":"lua/redis-connector/#utilities","title":"Utilities","text":"<p>The following methods are not typically needed, but may be useful if a custom interface is required.</p>"},{"location":"lua/redis-connector/#connect_via_sentinel","title":"connect_via_sentinel","text":"<p><code>syntax: redis, err = rc:connect_via_sentinel(params)</code></p> <p>Returns a Redis connection by first accessing a sentinel as supplied by the <code>params.sentinels</code> table, and querying this with the <code>params.master_name</code> and <code>params.role</code>.</p>"},{"location":"lua/redis-connector/#try_hosts","title":"try_hosts","text":"<p><code>syntax: redis, err = rc:try_hosts(hosts)</code></p> <p>Tries the hosts supplied in order and returns the first successful connection.</p>"},{"location":"lua/redis-connector/#connect_to_host","title":"connect_to_host","text":"<p><code>syntax: redis, err = rc:connect_to_host(host)</code></p> <p>Attempts to connect to the supplied <code>host</code>.</p>"},{"location":"lua/redis-connector/#sentinelget_master","title":"sentinel.get_master","text":"<p><code>syntax: master, err = sentinel.get_master(sentinel, master_name)</code></p> <p>Given a connected Sentinel instance and a master name, will return the current master Redis instance.</p>"},{"location":"lua/redis-connector/#sentinelget_slaves","title":"sentinel.get_slaves","text":"<p><code>syntax: slaves, err = sentinel.get_slaves(sentinel, master_name)</code></p> <p>Given a connected Sentinel instance and a master name, will return a list of registered slave Redis instances.</p>"},{"location":"lua/redis-connector/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-redis-connector.</p>"},{"location":"lua/redis-ratelimit/","title":"redis-ratelimit: Limit the request processing rate between multiple NGINX instances backed by Redis","text":""},{"location":"lua/redis-ratelimit/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/redis-ratelimit/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-redis-ratelimit\n</code></pre>"},{"location":"lua/redis-ratelimit/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-redis-ratelimit\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-redis-ratelimit v0.3  released on Oct 03 2019.</p> <p>lua-resty-redis-ratelimit - Limit the request processing rate between multiple NGINX instances backed by Redis.</p>"},{"location":"lua/redis-ratelimit/#status","title":"Status","text":"<p>Ready for testing. Probably production ready in most cases, though not yet proven in the wild. Please check the issues list and let me know if you have any problems / questions.</p>"},{"location":"lua/redis-ratelimit/#description","title":"Description","text":"<p>This lua library is a request processing rate limit module for ngx_lua:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>It is used to limit the request processing rate per a defined key between multiple NGINX instances. The limitation is done using the \"leaky bucket\" method.</p> <p></p> <p>This module use Redis (&gt;= 2.6.0) as the backend storage, so you also need the lua-resty-redis library work with it.</p> <p>NOTICE: If you do not use the <code>duration</code> feature and the incoming traffic is evenly distrbuted, it is recommended that use the module resty.limit.req to avoid unnecessary network delays.</p>"},{"location":"lua/redis-ratelimit/#synopsis","title":"Synopsis","text":"<pre><code>server {\n\n    listen 9090;\n\n    location /t {\n        access_by_lua_block {\n            local ratelimit = require \"resty.redis.ratelimit\"\n\n            local lim, err = ratelimit.new(\"one\", \"2r/s\", 0, 2)\n            if not lim then\n                ngx.log(ngx.ERR,\n                        \"failed to instantiate a resty.redis.ratelimit object: \", err)\n                return ngx.exit(500)\n            end\n\n            -- NOTICE: the following call must be per-request.\n\n            -- local redis = require \"resty.redis\"\n            -- local red = redis:new()\n\n            -- red:set_timeout(1000)\n\n            -- local ok, err = red:connect(\"127.0.0.1\", 6379)\n            -- if not ok then\n            --     ngx.log(ngx.ERR, \"failed to connect redis: \", err)\n            --     return ngx.exit(500)\n            -- end\n\n            local red = { host = \"127.0.0.1\", port = 6379, timeout = 1 }\n\n            local key = ngx.var.binary_remote_addr\n            local delay, err = lim:incoming(key, red)\n            if not delay then\n                if err == \"rejected\" then\n                    return ngx.exit(503)\n                end\n                ngx.log(ngx.ERR, \"failed to limit req: \", err)\n                return ngx.exit(500)\n            end\n\n            if delay &gt;= 0.001 then\n                -- the 2nd return value holds the number of excess requests\n                -- per second for the specified key.\n                local excess = err\n\n                ngx.sleep(delay)\n            end\n        '}\n\n        echo Logged in;\n    }\n\n}\n</code></pre>"},{"location":"lua/redis-ratelimit/#methods","title":"Methods","text":""},{"location":"lua/redis-ratelimit/#new","title":"new","text":"<p>syntax: <code>obj, err = class.new(zone, rate, burst, duration)</code></p> <p>Instantiates an object of this class. The class value is returned by the call require <code>resty.redis.ratelimit</code>.</p> <p>This method takes the following arguments:</p> <ul> <li><code>zone</code>: Sets the namespace, in particular, we use <code>&lt;zone&gt;:&lt;key&gt;</code> string as a unique state identifier inside Redis.</li> <li><code>rate</code>: The rate is specified in requests per second (r/s). If a rate of less than one request per second is desired, it is specified in request per minute (r/m). For example, half-request per second is 30r/m.</li> <li><code>burst</code>: Defines how many requests can make in excess of the rate specified by the zone, default 0.</li> <li><code>duration</code>: The time delay (in seconds) before back to normal state, during this period, the request is always <code>rejected</code>, default 0.</li> </ul> <p>On failure, this method returns nil and a string describing the error.</p>"},{"location":"lua/redis-ratelimit/#incoming","title":"incoming","text":"<p>syntax: <code>delay, err = obj:incoming(key, redis)</code></p> <p>Fires a new request incoming event and calculates the delay needed (if any) for the current request upon the specified key or whether the user should reject it immediately.</p> <p>This method accepts the following arguments:</p> <ul> <li><code>key</code>: The key is any non-empty value of the specified variable.</li> <li><code>redis</code>: Sets the Redis configuration, <code>host</code>, <code>port</code>, <code>timeout</code> and so on (see below); Instead of the specific Redis configuration, you can also sets the connected Redis <code>object</code> directly.</li> </ul> <pre><code>- redis.host: Default 127.0.0.1.\n- redis.port: Default 80.\n- redis.timeout: Default 1s.\n- redis.pass: Request for authentication in a password-protected Redis server.\n- redis.dbid: Select the Redis logical database.\n</code></pre> <p>The return values depend on the following cases:</p> <ol> <li>If the request does not exceed the <code>rate</code> value specified in the new method, then this method returns <code>0</code> as the delay and the (zero) number of excessive requests per second at the current time.</li> <li>If the request exceeds the <code>rate</code> limit specified in the new method but not the <code>rate</code> + <code>burst</code> value, then this method returns a proper delay (in seconds) for the current request so that it still conform to the <code>rate</code> threshold as if it came a bit later rather than now. The 2nd return value indicating the number of excessive reqeusts per second at this point (including the current request).</li> <li>If the request exceeds the <code>rate</code> + <code>burst</code> limit, then this method returns <code>nil</code> and the error string <code>\"rejected\"</code>.</li> <li>If an error occurred, then this method returns <code>nil</code> and a string describing the error. Such as <code>\"failed to create redis - connection refused\"</code>.</li> </ol> <p>This method never sleeps itself. It simply returns a delay if necessary and requires the caller to later invoke the ngx.sleep method to sleep.</p>"},{"location":"lua/redis-ratelimit/#set_burst","title":"set_burst","text":"<p>syntax: <code>obj:set_burst(burst)</code></p> <p>Overwrites the <code>burst</code> threshold as specified in the new method.</p>"},{"location":"lua/redis-ratelimit/#see-also","title":"See Also","text":"<ul> <li>Rate Limiting with NGINX: https://www.nginx.com/blog/rate-limiting-nginx/</li> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>OpenResty: https://openresty.org/</li> </ul>"},{"location":"lua/redis-ratelimit/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-redis-ratelimit.</p>"},{"location":"lua/redis-util/","title":"redis-util: Nginx-module-lua-resty-redis \u5c01\u88c5\u5de5\u5177\u7c7b","text":""},{"location":"lua/redis-util/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/redis-util/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-redis-util\n</code></pre>"},{"location":"lua/redis-util/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-redis-util\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-redis-util v0.7  released on Dec 15 2021.</p>"},{"location":"lua/redis-util/#_1","title":"\u4ecb\u7ecd","text":"<p>\u672c\u9879\u76ee\u662f\u57fa\u4e8e[openresty/lua-resty-redis][] \u662f[\u7ae0\u4ea6\u6625\uff08agentzh\uff09][agentzh]\u5f00\u53d1\u7684openresty\u4e2d\u7684\u64cd\u4f5credis\u7684\u5e93\u3002\u8fdb\u884c\u4e8c\u6b21\u5c01\u88c5\u7684\u5de5\u5177\u5e93\u3002\u6838\u5fc3\u529f\u80fd\u8fd8\u662f\u7531[openresty/lua-resty-redis][]\u5b8c\u6210\u7684\u3002</p> <p>\u672c\u6587\u5047\u8bbe\u4f60\u5df2\u7ecf\u4e86\u89e3nginx+lua\u6216\u8005openresty\u5982\u4f55\u4f7f\u7528lua\u811a\u672c(e.g. <code>lua_package_path</code>\u914d\u7f6e,<code>*_by_lua_file</code>),\u57fa\u7840\u7684redis\u76f8\u5173\u77e5\u8bc6\uff0c\u4ee5\u53ca[openresty/lua-resty-redis][]\u7684\u57fa\u672c\u4f7f\u7528\u65b9\u6cd5([openresty/lua-resty-redis#README.md][README.md])\u3002</p>"},{"location":"lua/redis-util/#install","title":"\u5b89\u88c5(Install)","text":"<pre><code>opm get anjia0532/lua-resty-redis-util\n</code></pre>"},{"location":"lua/redis-util/#_2","title":"\u5bf9\u6bd4","text":"<p>\u622a\u53d6\u5b98\u65b9\u90e8\u5206\u4ee3\u7801\uff0c\u8fdb\u884c\u8bf4\u660e</p> <pre><code>    local redis = require \"resty.redis\"\n    local red = redis:new()\n\n    red:set_timeout(1000) -- 1 sec --\u8bbe\u7f6e\u8d85\u65f6\u65f6\u95f4\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379) --\u8bbe\u7f6eredis\u7684host\u548cport\n    if not ok then --\u5224\u65ad\u751f\u6210\u8fde\u63a5\u662f\u5426\u5931\u8d25\n        ngx.say(\"failed to connect: \", err)\n        return\n    end\n\n    ok, err = red:set(\"dog\", \"an animal\") --\u63d2\u5165\u952e\u503c(\u7c7b\u4f3c mysql insert)\n    if not ok then --\u5224\u65ad\u64cd\u4f5c\u662f\u5426\u6210\u529f\n        ngx.say(\"failed to set dog: \", err)\n        return\n    end\n\n    ngx.say(\"set result: \", ok) -- \u9875\u9762\u8f93\u51fa\u7ed3\u679c\n    -- put it into the connection pool of size 100,\n    -- with 10 seconds max idle time\n    local ok, err = red:set_keepalive(10000, 100) --\u5c06\u8fde\u63a5\u653e\u5165\u8fde\u63a5\u6c60,100\u4e2a\u8fde\u63a5\uff0c\u6700\u957f10\u79d2\u7684\u95f2\u7f6e\u65f6\u95f4\n    if not ok then --\u5224\u65ad\u653e\u6c60\u7ed3\u679c\n        ngx.say(\"failed to set keepalive: \", err)\n        return\n    end\n    -- \u5982\u679c\u4e0d\u653e\u6c60\uff0c\u7528\u5b8c\u5c31\u5173\u95ed\u7684\u8bdd\uff0c\u7528\u4e0b\u9762\u7684\u5199\u6cd5\n    -- or just close the connection right away:\n    -- local ok, err = red:close()\n    -- if not ok then\n    --     ngx.say(\"failed to close: \", err)\n    --     return\n    -- end\n</code></pre> <p>\u5982\u679c\u7528\u8fc7java\uff0cc#\u7b49\u9762\u5411\u5bf9\u8c61\u7684\u8bed\u8a00\uff0c\u5c31\u4f1a\u89c9\u5f97\u8fd9\u4e48\u5199\u592a\u3002\u3002\u3002\u3002\u4e86\uff0c\u5fc5\u987b\u91cd\u6784\u554a\uff0c\u66b4\u9732\u592a\u591a\u65e0\u5173\u7ec6\u8282\u4e86\uff0c\u5bfc\u81f4\u4ee3\u7801\u4e2d\u6709\u5927\u91cf\u91cd\u590d\u4ee3\u7801\u4e86\u3002</p> <p>\u540c\u6837\u7684\u5185\u5bb9\uff0c\u4f7f\u7528\u6211\u5c01\u88c5\u540e\u7684\u4ee3\u7801\u3002\u9690\u85cf\u4e86\u8bbe\u7f6e\u8fde\u63a5\u6c60\uff0c\u53d6\u8fde\u63a5\uff0c\u7528\u5b8c\u540e\u653e\u56de\u8fde\u63a5\u6c60\u7b49\u64cd\u4f5c\u3002</p> <pre><code>    -- \u4f9d\u8d56\u5e93\n    local redis = require \"resty.redis-util\"\n    -- \u521d\u59cb\u5316\n    local red = redis:new();\n    -- \u63d2\u5165\u952e\u503c\n    local ok,err = red:set(\"dog\",\"an animal\")\n    -- \u5224\u65ad\u7ed3\u679c\n    if not ok then\n      ngx.say(\"failed to set dog:\",err)\n      return\n    end\n    -- \u9875\u9762\u6253\u5370\u7ed3\u679c\n    ngx.say(\"set result: \", ok) -- \u9875\u9762\u8f93\u51fa\u7ed3\u679c\n</code></pre>"},{"location":"lua/redis-util/#note","title":"\u6ce8\u610f\u4e8b\u9879(Note)","text":""},{"location":"lua/redis-util/#default-value","title":"\u9ed8\u8ba4\u503c(Default Value)","text":"<pre><code>local red = redis:new();\n--\u4f7f\u7528\u4e86\u9ed8\u8ba4\u503c,\u7b49\u540c\u4e8e\nlocal red2 = redis:new({\n                            host='127.0.0.1',\n                            port=6379,\n                            db_index=0,\n                            password=nil,\n                            timeout=1000,\n                            keepalive=60000,\n                            pool_size=100\n                        });\n</code></pre> <ul> <li>host: redis host,default: 127.0.0.1</li> <li>port: redis port,default:6379</li> <li>db_index: redis\u5e93\u7d22\u5f15(\u9ed8\u8ba40-15 \u517116\u4e2a\u5e93)\uff0c\u9ed8\u8ba4\u7684\u5c31\u662f0\u5e93(\u5efa\u8bae\u7528\u4e0d\u540c\u7aef\u53e3\u5f00\u4e0d\u540c\u5b9e\u4f8b\u6216\u8005\u7528\u4e0d\u540c\u524d\u7f00\uff0c\u56e0\u4e3a\u6362\u5e93\u9700\u8981\u7528select\u547d\u4ee4),default:0</li> <li>password: redis auth \u8ba4\u8bc1\u7684\u5bc6\u7801</li> <li>timeout: reids\u8fde\u63a5\u8d85\u65f6\u65f6\u95f4,default: 1000 (1s)</li> <li>keepalive: redis\u8fde\u63a5\u6c60\u7684\u6700\u5927\u95f2\u7f6e\u65f6\u95f4, default: 60000 (1m)</li> <li>pool_size: redis\u8fde\u63a5\u6c60\u5927\u5c0f, default: 100</li> </ul>"},{"location":"lua/redis-util/#subscribe","title":"subscribe","text":"<p>\u56e0\u4e3a\u6ca1\u6709\u7528\u5230pub/sub\uff0c\u6240\u4ee5\u53ea\u662f\u7b80\u5355\u7684\u5b9e\u73b0\u4e86(un)subscribe\uff0c\u6ca1\u6709\u7ee7\u7eed\u5b9e\u73b0(un)psubscribe(\u6a21\u5f0f\u8ba2\u9605), \u53c2\u8003 [Redis \u63a5\u53e3\u7684\u4e8c\u6b21\u5c01\u88c5\uff08\u53d1\u5e03\u8ba2\u9605\uff09][linkRedis\u63a5\u53e3\u7684\u4e8c\u6b21\u5c01\u88c5\uff08\u53d1\u5e03\u8ba2\u9605\uff09]</p> <pre><code>    local cjson = require \"cjson\"\n    local red = redis:new();\n\n    -- \u8ba2\u9605dog\u9891\u9053\n    local func  = red:subscribe( \"dog\" )\n\n    -- \u5224\u65ad\u662f\u5426\u6210\u529f\u8ba2\u9605\n    if not func then\n      return nil\n    end\n\n    -- \u83b7\u53d6\u503c\n    local res, err = func() --func()=func(true)\n    -- \u5982\u679c\u5931\u8d25\uff0c\u53d6\u6d88\u8ba2\u9605\n    if err then\n        func(false)\n    end\n\n    -- \u5982\u679c\u53d6\u5230\u7ed3\u679c\uff0c\u8fdb\u884c\u9875\u9762\u8f93\u51fa\n    if res then\n        ngx.say(\"1: receive: \", cjson.encode(res))\n    end\n\n    -- \u518d\u6b21\u83b7\u53d6\n    res, err = func()\n\n    -- \u83b7\u53d6\u6210\u529f\u540e\uff0c\u53d6\u6d88\u8ba2\u9605 func(false)\n    if res then\n        ngx.say(\"2: receive: \", cjson.encode(res))\n        func(false)\n    end\n</code></pre>"},{"location":"lua/redis-util/#pipeline","title":"pipeline","text":"<p>\u53c2\u8003 [openresty/lua-resty-redis#Synopsis][]</p> <pre><code>    local cjson = require \"cjson\"\n    local red = redis:new();\n\n    red:init_pipeline()\n\n    red:set(\"cat\", \"Marry\")\n    red:set(\"horse\", \"Bob\")\n    red:get(\"cat\")\n    red:get(\"horse\")\n\n    local results, err = red:commit_pipeline()\n\n    if not results then\n        ngx.say(\"failed to commit the pipelined requests: \", err)\n        return\n    else\n        ngx.say(\"pipeline\",cjson.encode(results))\n    end\n    -- output pipeline[\"OK\",\"OK\",\"Marry\",\"Bob\"]\n</code></pre>"},{"location":"lua/redis-util/#script","title":"script","text":"<p>\u53c2\u8003 [script \u538b\u7f29\u590d\u6742\u8bf7\u6c42][linkScript\u538b\u7f29\u590d\u6742\u8bf7\u6c42]</p> <pre><code>    local red = redis:new();\n\n    local id = 1\n    local res, err = red:eval([[\n        -- \u6ce8\u610f\u5728 Redis \u6267\u884c\u811a\u672c\u7684\u65f6\u5019\uff0c\u4ece KEYS/ARGV \u53d6\u51fa\u6765\u7684\u503c\u7c7b\u578b\u4e3a string\n        local info = redis.call('get', KEYS[1])\n        info = cjson.decode(info)\n        local g_id = info.gid\n\n        local g_info = redis.call('get', g_id)\n        return g_info\n        ]], 1, id)\n\n    if not res then\n       ngx.say(\"failed to get the group info: \", err)\n       return\n    end\n\n    ngx.say(\"script\",res)\n</code></pre>"},{"location":"lua/redis-util/#thanks","title":"\u9e23\u8c22(Thanks)","text":"<p>\u672c\u5de5\u5177\u501f\u9274\u4e86 [lua-resty-redis/lib/resty/redis.lua][] \u548c [Redis \u63a5\u53e3\u7684\u4e8c\u6b21\u5c01\u88c5][linkRedis\u63a5\u53e3\u7684\u4e8c\u6b21\u5c01\u88c5] \u7684\u4ee3\u7801</p>"},{"location":"lua/redis-util/#feedback","title":"\u53cd\u9988(Feedback)","text":"<p>\u5982\u679c\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u63d0 [issues][]</p>"},{"location":"lua/redis-util/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-redis-util.</p>"},{"location":"lua/redis/","title":"redis: Lua redis client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/redis/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/redis/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-redis\n</code></pre>"},{"location":"lua/redis/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-redis\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-redis v0.33  released on Jul 09 2025.</p> <p>lua-resty-redis - Lua redis client driver for the ngx_lua based on the cosocket API</p>"},{"location":"lua/redis/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/redis/#description","title":"Description","text":"<p>This Lua library is a Redis client driver for the ngx_lua nginx module:</p> <p>https://github.com/openresty/lua-nginx-module/#readme</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.5.14 or OpenResty 1.2.1.14 is required.</p>"},{"location":"lua/redis/#synopsis","title":"Synopsis","text":"<pre><code>    # you do not need the following line if you are using\n    # the OpenResty bundle:\n    server {\n        location /test {\n            # need to specify the resolver to resolve the hostname\n            resolver 8.8.8.8;\n\n            content_by_lua_block {\n                local redis = require \"resty.redis\"\n                local red = redis:new()\n\n                red:set_timeouts(1000, 1000, 1000) -- 1 sec\n\n                -- or connect to a unix domain socket file listened\n                -- by a redis server:\n                --     local ok, err = red:connect(\"unix:/path/to/redis.sock\")\n\n                -- connect via ip address directly\n                local ok, err = red:connect(\"127.0.0.1\", 6379)\n\n                -- or connect via hostname, need to specify resolver just like above\n                local ok, err = red:connect(\"redis.openresty.com\", 6379)\n\n                if not ok then\n                    ngx.say(\"failed to connect: \", err)\n                    return\n                end\n\n                ok, err = red:set(\"dog\", \"an animal\")\n                if not ok then\n                    ngx.say(\"failed to set dog: \", err)\n                    return\n                end\n\n                ngx.say(\"set result: \", ok)\n\n                local res, err = red:get(\"dog\")\n                if not res then\n                    ngx.say(\"failed to get dog: \", err)\n                    return\n                end\n\n                if res == ngx.null then\n                    ngx.say(\"dog not found.\")\n                    return\n                end\n\n                ngx.say(\"dog: \", res)\n\n                red:init_pipeline()\n                red:set(\"cat\", \"Marry\")\n                red:set(\"horse\", \"Bob\")\n                red:get(\"cat\")\n                red:get(\"horse\")\n                local results, err = red:commit_pipeline()\n                if not results then\n                    ngx.say(\"failed to commit the pipelined requests: \", err)\n                    return\n                end\n\n                for i, res in ipairs(results) do\n                    if type(res) == \"table\" then\n                        if res[1] == false then\n                            ngx.say(\"failed to run command \", i, \": \", res[2])\n                        else\n                            -- process the table value\n                        end\n                    else\n                        -- process the scalar value\n                    end\n                end\n\n                -- put it into the connection pool of size 100,\n                -- with 10 seconds max idle time\n                local ok, err = red:set_keepalive(10000, 100)\n                if not ok then\n                    ngx.say(\"failed to set keepalive: \", err)\n                    return\n                end\n\n                -- or just close the connection right away:\n                -- local ok, err = red:close()\n                -- if not ok then\n                --     ngx.say(\"failed to close: \", err)\n                --     return\n                -- end\n            }\n        }\n    }\n</code></pre>"},{"location":"lua/redis/#methods","title":"Methods","text":"<p>All of the Redis commands have their own methods with the same name except all in lower case.</p> <p>You can find the complete list of Redis commands here:</p> <p>http://redis.io/commands</p> <p>You need to check out this Redis command reference to see what Redis command accepts what arguments.</p> <p>The Redis command arguments can be directly fed into the corresponding method call. For example, the \"GET\" redis command accepts a single key argument, then you can just call the \"get\" method like this:</p> <pre><code>    local res, err = red:get(\"key\")\n</code></pre> <p>Similarly, the \"LRANGE\" redis command accepts three arguments, then you should call the \"lrange\" method like this:</p> <pre><code>    local res, err = red:lrange(\"nokey\", 0, 1)\n</code></pre> <p>For example, \"SET\", \"GET\", \"LRANGE\", and \"BLPOP\" commands correspond to the methods \"set\", \"get\", \"lrange\", and \"blpop\".</p> <p>Here are some more examples:</p> <pre><code>    -- HMGET myhash field1 field2 nofield\n    local res, err = red:hmget(\"myhash\", \"field1\", \"field2\", \"nofield\")\n</code></pre> <pre><code>    -- HMSET myhash field1 \"Hello\" field2 \"World\"\n    local res, err = red:hmset(\"myhash\", \"field1\", \"Hello\", \"field2\", \"World\")\n</code></pre> <p>All these command methods returns a single result in success and <code>nil</code> otherwise. In case of errors or failures, it will also return a second value which is a string describing the error.</p> <p>A Redis \"status reply\" results in a string typed return value with the \"+\" prefix stripped.</p> <p>A Redis \"integer reply\" results in a Lua number typed return value.</p> <p>A Redis \"error reply\" results in a <code>false</code> value and a string describing the error.</p> <p>A non-nil Redis \"bulk reply\" results in a Lua string as the return value. A nil bulk reply results in a <code>ngx.null</code> return value.</p> <p>A non-nil Redis \"multi-bulk reply\" results in a Lua table holding all the composing values (if any). If any of the composing value is a valid redis error value, then it will be a two element table <code>{false, err}</code>.</p> <p>A nil multi-bulk reply returns in a <code>ngx.null</code> value.</p> <p>See http://redis.io/topics/protocol for details regarding various Redis reply types.</p> <p>In addition to all those redis command methods, the following methods are also provided:</p>"},{"location":"lua/redis/#new","title":"new","text":"<p><code>syntax: red, err = redis:new()</code></p> <p>Creates a redis object. In case of failures, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/redis/#connect","title":"connect","text":"<p><code>syntax: ok, err = red:connect(host, port, options_table?)</code></p> <p><code>syntax: ok, err = red:connect(\"unix:/path/to/unix.sock\", options_table?)</code></p> <p>Attempts to connect to the remote host and port that the redis server is listening to or a local unix domain socket file listened by the redis server.</p> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p> <p>The optional <code>options_table</code> argument is a Lua table holding the following keys:</p> <ul> <li> <p><code>ssl</code></p> <p>If set to true, then uses SSL to connect to redis (defaults to false).</p> </li> <li> <p><code>ssl_verify</code></p> <p>If set to true, then verifies the validity of the server SSL certificate (defaults to false). Note that you need to configure the lua_ssl_trusted_certificate to specify the CA (or server) certificate used by your redis server. You may also need to configure lua_ssl_verify_depth accordingly.</p> </li> <li> <p><code>server_name</code></p> <p>Specifies the server name for the new TLS extension Server Name Indication (SNI) when connecting over SSL.</p> </li> <li> <p><code>pool</code></p> <p>Specifies a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template <code>&lt;host&gt;:&lt;port&gt;</code> or <code>&lt;unix-socket-path&gt;</code>.</p> </li> <li> <p><code>pool_size</code></p> <p>Specifies the size of the connection pool. If omitted and no <code>backlog</code> option was provided, no pool will be created. If omitted but <code>backlog</code> was provided, the pool will be created with a default size equal to the value of the lua_socket_pool_size directive. The connection pool holds up to <code>pool_size</code> alive connections ready to be reused by subsequent calls to connect, but note that there is no upper limit to the total number of opened connections outside of the pool. If you need to restrict the total number of opened connections, specify the <code>backlog</code> option. When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so the size limit specified here also applies to every single Nginx worker process. Also note that the size of the connection pool cannot be changed once it has been created. Note that at least ngx_lua 0.10.14 is required to use this options.</p> </li> <li> <p><code>backlog</code></p> <p>If specified, this module will limit the total number of opened connections for this pool. No more connections than <code>pool_size</code> can be opened for this pool at any time. If the connection pool is full, subsequent connect operations will be queued into a queue equal to this option's value (the \"backlog\" queue). If the number of queued connect operations is equal to <code>backlog</code>, subsequent connect operations will fail and return nil plus the error string <code>\"too many waiting connect operations\"</code>. The queued connect operations will be resumed once the number of connections in the pool is less than <code>pool_size</code>. The queued connect operation will abort once they have been queued for more than <code>connect_timeout</code>, controlled by set_timeout, and will return nil plus the error string \"timeout\". Note that at least ngx_lua 0.10.14 is required to use this options.</p> </li> </ul>"},{"location":"lua/redis/#set_timeout","title":"set_timeout","text":"<p><code>syntax: red:set_timeout(time)</code></p> <p>Sets the timeout (in ms) protection for subsequent operations, including the <code>connect</code> method.</p> <p>Since version <code>v0.28</code> of this module, it is advised that set_timeouts be used in favor of this method.</p>"},{"location":"lua/redis/#set_timeouts","title":"set_timeouts","text":"<p><code>syntax: red:set_timeouts(connect_timeout, send_timeout, read_timeout)</code></p> <p>Respectively sets the connect, send, and read timeout thresholds (in ms), for subsequent socket operations. Setting timeout thresholds with this method offers more granularity than set_timeout. As such, it is preferred to use set_timeouts over set_timeout.</p> <p>This method was added in the <code>v0.28</code> release.</p>"},{"location":"lua/redis/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = red:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Puts the current Redis connection immediately into the ngx_lua cosocket connection pool.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p> <p>Only call this method in the place you would have called the <code>close</code> method instead. Calling this method will immediately turn the current redis object into the <code>closed</code> state. Any subsequent operations other than <code>connect()</code> on the current object will return the <code>closed</code> error.</p>"},{"location":"lua/redis/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: times, err = red:get_reused_times()</code></p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p>"},{"location":"lua/redis/#close","title":"close","text":"<p><code>syntax: ok, err = red:close()</code></p> <p>Closes the current redis connection and returns the status.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p>"},{"location":"lua/redis/#init_pipeline","title":"init_pipeline","text":"<p><code>syntax: red:init_pipeline()</code></p> <p><code>syntax: red:init_pipeline(n)</code></p> <p>Enable the redis pipelining mode. All subsequent calls to Redis command methods will automatically get cached and will send to the server in one run when the <code>commit_pipeline</code> method is called or get cancelled by calling the <code>cancel_pipeline</code> method.</p> <p>This method always succeeds.</p> <p>If the redis object is already in the Redis pipelining mode, then calling this method will discard existing cached Redis queries.</p> <p>The optional <code>n</code> argument specifies the (approximate) number of commands that are going to add to this pipeline, which can make things a little faster.</p>"},{"location":"lua/redis/#commit_pipeline","title":"commit_pipeline","text":"<p><code>syntax: results, err = red:commit_pipeline()</code></p> <p>Quits the pipelining mode by committing all the cached Redis queries to the remote server in a single run. All the replies for these queries will be collected automatically and are returned as if a big multi-bulk reply at the highest level.</p> <p>This method returns <code>nil</code> and a Lua string describing the error upon failures.</p>"},{"location":"lua/redis/#cancel_pipeline","title":"cancel_pipeline","text":"<p><code>syntax: red:cancel_pipeline()</code></p> <p>Quits the pipelining mode by discarding all existing cached Redis commands since the last call to the <code>init_pipeline</code> method.</p> <p>This method always succeeds.</p> <p>If the redis object is not in the Redis pipelining mode, then this method is a no-op.</p>"},{"location":"lua/redis/#hmset","title":"hmset","text":"<p><code>syntax: res, err = red:hmset(myhash, field1, value1, field2, value2, ...)</code></p> <p><code>syntax: res, err = red:hmset(myhash, { field1 = value1, field2 = value2, ... })</code></p> <p>Special wrapper for the Redis \"hmset\" command.</p> <p>When there are only three arguments (including the \"red\" object itself), then the last argument must be a Lua table holding all the field/value pairs.</p>"},{"location":"lua/redis/#array_to_hash","title":"array_to_hash","text":"<p><code>syntax: hash = red:array_to_hash(array)</code></p> <p>Auxiliary function that converts an array-like Lua table into a hash-like table.</p> <p>This method was first introduced in the <code>v0.11</code> release.</p>"},{"location":"lua/redis/#read_reply","title":"read_reply","text":"<p><code>syntax: res, err = red:read_reply()</code></p> <p>Reading a reply from the redis server. This method is mostly useful for the Redis Pub/Sub API, for example,</p> <pre><code>    local cjson = require \"cjson\"\n    local redis = require \"resty.redis\"\n\n    local red = redis:new()\n    local red2 = redis:new()\n\n    red:set_timeouts(1000, 1000, 1000) -- 1 sec\n    red2:set_timeouts(1000, 1000, 1000) -- 1 sec\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"1: failed to connect: \", err)\n        return\n    end\n\n    ok, err = red2:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"2: failed to connect: \", err)\n        return\n    end\n\n    local res, err = red:subscribe(\"dog\")\n    if not res then\n        ngx.say(\"1: failed to subscribe: \", err)\n        return\n    end\n\n    ngx.say(\"1: subscribe: \", cjson.encode(res))\n\n    res, err = red2:publish(\"dog\", \"Hello\")\n    if not res then\n        ngx.say(\"2: failed to publish: \", err)\n        return\n    end\n\n    ngx.say(\"2: publish: \", cjson.encode(res))\n\n    res, err = red:read_reply()\n    if not res then\n        ngx.say(\"1: failed to read reply: \", err)\n        return\n    end\n\n    ngx.say(\"1: receive: \", cjson.encode(res))\n\n    red:close()\n    red2:close()\n</code></pre> <p>Running this example gives the output like this:</p> <pre><code>1: subscribe: [\"subscribe\",\"dog\",1]\n2: publish: 1\n1: receive: [\"message\",\"dog\",\"Hello\"]\n</code></pre> <p>The following class methods are provided:</p>"},{"location":"lua/redis/#add_commands","title":"add_commands","text":"<p><code>syntax: hash = redis.add_commands(cmd_name1, cmd_name2, ...)</code></p> <p>WARNING this method is now deprecated since we already do automatic Lua method generation for any redis commands the user attempts to use and thus we no longer need this.</p> <p>Adds new redis commands to the <code>resty.redis</code> class. Here is an example:</p> <pre><code>    local redis = require \"resty.redis\"\n\n    redis.add_commands(\"foo\", \"bar\")\n\n    local red = redis:new()\n\n    red:set_timeouts(1000, 1000, 1000) -- 1 sec\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"failed to connect: \", err)\n        return\n    end\n\n    local res, err = red:foo(\"a\")\n    if not res then\n        ngx.say(\"failed to foo: \", err)\n    end\n\n    res, err = red:bar()\n    if not res then\n        ngx.say(\"failed to bar: \", err)\n    end\n</code></pre>"},{"location":"lua/redis/#redis-authentication","title":"Redis Authentication","text":"<p>Redis uses the <code>AUTH</code> command to do authentication: http://redis.io/commands/auth</p> <p>There is nothing special for this command as compared to other Redis commands like <code>GET</code> and <code>SET</code>. So one can just invoke the <code>auth</code> method on your <code>resty.redis</code> instance. Here is an example:</p> <pre><code>    local redis = require \"resty.redis\"\n    local red = redis:new()\n\n    red:set_timeouts(1000, 1000, 1000) -- 1 sec\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"failed to connect: \", err)\n        return\n    end\n\n    local res, err = red:auth(\"foobared\")\n    if not res then\n        ngx.say(\"failed to authenticate: \", err)\n        return\n    end\n</code></pre> <p>where we assume that the Redis server is configured with the password <code>foobared</code> in the <code>redis.conf</code> file:</p> <pre><code>requirepass foobared\n</code></pre> <p>If the password specified is wrong, then the sample above will output the following to the HTTP client:</p> <pre><code>failed to authenticate: ERR invalid password\n</code></pre>"},{"location":"lua/redis/#redis-transactions","title":"Redis Transactions","text":"<p>This library supports the Redis transactions. Here is an example:</p> <pre><code>    local cjson = require \"cjson\"\n    local redis = require \"resty.redis\"\n    local red = redis:new()\n\n    red:set_timeouts(1000, 1000, 1000) -- 1 sec\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"failed to connect: \", err)\n        return\n    end\n\n    local ok, err = red:multi()\n    if not ok then\n        ngx.say(\"failed to run multi: \", err)\n        return\n    end\n    ngx.say(\"multi ans: \", cjson.encode(ok))\n\n    local ans, err = red:set(\"a\", \"abc\")\n    if not ans then\n        ngx.say(\"failed to run sort: \", err)\n        return\n    end\n    ngx.say(\"set ans: \", cjson.encode(ans))\n\n    local ans, err = red:lpop(\"a\")\n    if not ans then\n        ngx.say(\"failed to run sort: \", err)\n        return\n    end\n    ngx.say(\"set ans: \", cjson.encode(ans))\n\n    ans, err = red:exec()\n    ngx.say(\"exec ans: \", cjson.encode(ans))\n\n    red:close()\n</code></pre> <p>Then the output will be</p> <pre><code>multi ans: \"OK\"\nset ans: \"QUEUED\"\nset ans: \"QUEUED\"\nexec ans: [\"OK\",[false,\"ERR Operation against a key holding the wrong kind of value\"]]\n</code></pre>"},{"location":"lua/redis/#redis-module","title":"Redis Module","text":"<p>This library supports the Redis module. Here is an example with RedisBloom module:</p> <pre><code>    local cjson = require \"cjson\"\n    local redis = require \"resty.redis\"\n    -- register the module prefix \"bf\" for RedisBloom\n    redis.register_module_prefix(\"bf\")\n\n    local red = redis:new()\n\n    local ok, err = red:connect(\"127.0.0.1\", 6379)\n    if not ok then\n        ngx.say(\"failed to connect: \", err)\n        return\n    end\n\n    -- call BF.ADD command with the prefix 'bf'\n    res, err = red:bf():add(\"dog\", 1)\n    if not res then\n        ngx.say(err)\n        return\n    end\n    ngx.say(\"receive: \", cjson.encode(res))\n\n    -- call BF.EXISTS command\n    res, err = red:bf():exists(\"dog\")\n    if not res then\n        ngx.say(err)\n        return\n    end\n    ngx.say(\"receive: \", cjson.encode(res))\n</code></pre>"},{"location":"lua/redis/#load-balancing-and-failover","title":"Load Balancing and Failover","text":"<p>You can trivially implement your own Redis load balancing logic yourself in Lua. Just keep a Lua table of all available Redis backend information (like host name and port numbers) and pick one server according to some rule (like round-robin or key-based hashing) from the Lua table at every request. You can keep track of the current rule state in your own Lua module's data, see https://github.com/openresty/lua-nginx-module/#data-sharing-within-an-nginx-worker</p> <p>Similarly, you can implement automatic failover logic in Lua at great flexibility.</p>"},{"location":"lua/redis/#debugging","title":"Debugging","text":"<p>It is usually convenient to use the lua-cjson library to encode the return values of the redis command methods to JSON. For example,</p> <pre><code>    local cjson = require \"cjson\"\n    ...\n    local res, err = red:mget(\"h1234\", \"h5678\")\n    if res then\n        print(\"res: \", cjson.encode(res))\n    end\n</code></pre>"},{"location":"lua/redis/#automatic-error-logging","title":"Automatic Error Logging","text":"<p>By default the underlying ngx_lua module does error logging when socket errors happen. If you are already doing proper error handling in your own Lua code, then you are recommended to disable this automatic error logging by turning off ngx_lua's lua_socket_log_errors directive, that is,</p> <pre><code>    lua_socket_log_errors off;\n</code></pre>"},{"location":"lua/redis/#check-list-for-issues","title":"Check List for Issues","text":"<ol> <li>Ensure you configure the connection pool size properly in the set_keepalive. Basically if your Redis can handle <code>n</code> concurrent connections and your NGINX has <code>m</code> workers, then the connection pool size should be configured as <code>n/m</code>. For example, if your Redis usually handles 1000 concurrent requests and you have 10 NGINX workers, then the connection pool size should be 100. Similarly if you have <code>p</code> different NGINX instances, then connection pool size should be <code>n/m/p</code>.</li> <li>Ensure the backlog setting on the Redis side is large enough. For Redis 2.8+, you can directly tune the <code>tcp-backlog</code> parameter in the <code>redis.conf</code> file (and also tune the kernel parameter <code>SOMAXCONN</code> accordingly at least on Linux). You may also want to tune the <code>maxclients</code> parameter in <code>redis.conf</code>.</li> <li>Ensure you are not using too short timeout setting in the set_timeout or set_timeouts methods. If you have to, try redoing the operation upon timeout and turning off automatic error logging (because you are already doing proper error handling in your own Lua code).</li> <li>If your NGINX worker processes' CPU usage is very high under load, then the NGINX event loop might be blocked by the CPU computation too much. Try sampling a C-land on-CPU Flame Graph and Lua-land on-CPU Flame Graph for a typical NGINX worker process. You can optimize the CPU-bound things according to these Flame Graphs.</li> <li>If your NGINX worker processes' CPU usage is very low under load, then the NGINX event loop might be blocked by some blocking system calls (like file IO system calls). You can confirm the issue by running the epoll-loop-blocking-distr tool against a typical NGINX worker process. If it is indeed the case, then you can further sample a C-land off-CPU Flame Graph for a NGINX worker process to analyze the actual blockers.</li> <li>If your <code>redis-server</code> process is running near 100% CPU usage, then you should consider scale your Redis backend by multiple nodes or use the C-land on-CPU Flame Graph tool to analyze the internal bottlenecks within the Redis server process.</li> </ol>"},{"location":"lua/redis/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like init_by_lua, set_by_lua, log_by_lua, and header_filter_by_lua where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.redis</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see https://github.com/openresty/lua-nginx-module/#data-sharing-within-an-nginx-worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.redis</code> instance (you would see the \"bad request\" or \"socket busy\" error to be returned from the method calls). You should always initiate <code>resty.redis</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/redis/#clone-latest-release-assuming-v029","title":"Clone latest release , assuming v0.29","text":"<p>wget https://github.com/openresty/lua-resty-redis/archive/refs/tags/v0.29.tar.gz</p>"},{"location":"lua/redis/#extract","title":"Extract","text":"<p>tar -xvzf v0.29.tar.gz</p>"},{"location":"lua/redis/#go-into-directory","title":"go into directory","text":"<p>cd lua-resty-redis-0.29</p> <p>export LUA_LIB_DIR=/usr/local/openresty/site/lualib</p>"},{"location":"lua/redis/#compile-and-install","title":"Compile and Install","text":"<p>make install</p>"},{"location":"lua/redis/#now-compiled-path-will-be-outputted","title":"Now compiled path will be outputted","text":""},{"location":"lua/redis/#usrlocallibluaresty-lua_package_path-in-nginx-conf","title":"/usr/local/lib/lua/resty = lua_package_path in nginx conf","text":"<p>```</p>"},{"location":"lua/redis/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module/#readme</li> <li>the redis wired protocol specification: http://redis.io/topics/protocol</li> <li>the lua-resty-memcached library</li> <li>the lua-resty-mysql library</li> </ul>"},{"location":"lua/redis/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-redis.</p>"},{"location":"lua/repl/","title":"repl: Interactive console (REPL) for nginx-module-lua and luajit code","text":""},{"location":"lua/repl/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/repl/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-repl\n</code></pre>"},{"location":"lua/repl/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-repl\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-repl v0.0.1  released on Aug 29 2016.</p>"},{"location":"lua/repl/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-repl.</p>"},{"location":"lua/reqargs/","title":"reqargs: Read application/x-www-form-urlencoded, multipart/form-data, and application/json request args","text":""},{"location":"lua/reqargs/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/reqargs/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-reqargs\n</code></pre>"},{"location":"lua/reqargs/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-reqargs\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-reqargs v1.4  released on Jan 07 2017.</p> <p>Helper to Retrieve <code>application/x-www-form-urlencoded</code>, <code>multipart/form-data</code>, and <code>application/json</code> Request Arguments.</p>"},{"location":"lua/reqargs/#synopsis","title":"Synopsis","text":"<pre><code>local get, post, files = require \"resty.reqargs\"()\nif not get then\n    error(post)\nend\n-- Use get, post, and files...\n</code></pre>"},{"location":"lua/reqargs/#api","title":"API","text":"<p>This module has only one function, and that function is loaded with require:</p> <pre><code>local reqargs = require \"resty.reqargs\"\n</code></pre>"},{"location":"lua/reqargs/#get-post-files-regargsoptions","title":"get, post, files regargs(options)","text":"<p>When you call the function (<code>reqargs</code>) you can pass it <code>options</code>. These options override whatever you may have defined in your Nginx configuration (or the defaults). You may use the following options:</p> <pre><code>{\n    tmp_dir          = \"/tmp\",\n    timeout          = 1000,\n    chunk_size       = 4096,\n    max_get_args     = 100,\n    mas_post_args    = 100,\n    max_line_size    = 512,\n    max_file_uploads = 10\n}\n</code></pre> <p>This function will return three (3) return values, and they are called <code>get</code>, <code>post</code>,  and <code>files</code>. These are Lua tables containing the data that was (HTTP) requested. <code>get</code> contains HTTP request GET arguments retrieved with ngx.req.get_uri_args. <code>post</code> contains either HTTP request POST arguments retrieved with ngx.req.get_post_args, or in case of <code>application/json</code> (as a content type header for the request), it will read the request body and decode the JSON, and the <code>post</code> will then contain the decoded JSON structure presented as Lua tables. The last return value <code>files</code> contains all the files uploaded. The <code>files</code> return value will only contain data when there are actually files uploaded and that the request content type is set to <code>multipart/form-data</code>. <code>files</code> has the same structure as <code>get</code> and <code>post</code> for the keys, but the values are presented as a Lua tables, that look like this (think about PHP's <code>$_FILES</code>):</p> <pre><code>{\n    -- The name of the file upload form field (same as the key)\n    name = \"photo\",\n    -- The name of the file that the user selected for the upload\n    file = \"cat.jpg\",\n    -- The mimetype of the uploaded file\n    type = \"image/jpeg\"\n    -- The file size of the uploaded file (in bytes)\n    size = 123465\n    -- The location where the uploaded file was streamed\n    temp = \"/tmp/????\"\n}\n</code></pre> <p>In case of error, this function will return <code>nil</code>, <code>error message</code>.</p>"},{"location":"lua/reqargs/#nginx-configuration-variables","title":"Nginx Configuration Variables","text":"<p>You can configure several aspects of <code>lua-resty-reqargs</code> directly from the Nginx configuration, here are the configuration values that you may use, and their default values:</p> <pre><code>## the default is the system temp dir\nset $reqargs_tmp_dir           /tmp;\n## see https://github.com/openresty/lua-resty-upload\nset $reqargs_timeout           1000;\n## see https://github.com/openresty/lua-resty-upload\nset $reqargs_chunk_size        4096;\n## see https://github.com/openresty/lua-nginx-module#ngxreqget_uri_args\nset $reqargs_max_get_args      100;\n## see https://github.com/openresty/lua-nginx-module#ngxreqget_post_args\nset $reqargs_max_post_args     100;\n## see https://github.com/openresty/lua-resty-upload\nset $reqargs_max_line_size     512;  \n## the default is unlimited\nset $reqargs_max_file_uploads  10;\n</code></pre>"},{"location":"lua/reqargs/#changes","title":"Changes","text":"<p>The changes of every release of this module is recorded in Changes.md file.</p>"},{"location":"lua/reqargs/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-reqargs.</p>"},{"location":"lua/requests/","title":"requests: Yet Another HTTP library for nginx-module-lua - For human beings!","text":""},{"location":"lua/requests/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/requests/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-requests\n</code></pre>"},{"location":"lua/requests/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-requests\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-requests v0.7.3  released on Jul 18 2019.</p> <p>lua-resty-requests - Yet Another HTTP Library for OpenResty.</p> <p></p> <pre><code>resty -e 'print(require \"resty.requests\".get{ url = \"https://github.com\", stream = false }.content)'\n</code></pre>"},{"location":"lua/requests/#status","title":"Status","text":"<p>This Lua module now can be considered as production ready.</p> <p>Note since the <code>v0.7.1</code> release, this module started using lua-resty-socket, for working in the non-yieldable phases, but still more efforts are needed, so DONOT use it in the <code>init</code> or <code>init_worker</code> phases (or other non-yieldable phases).</p>"},{"location":"lua/requests/#features","title":"Features","text":"<ul> <li>HTTP/1.0, HTTP/1.1 and HTTP/2 (WIP).</li> <li>SSL/TLS support.</li> <li>Chunked data support.</li> <li>Convenient interfaces to support features like json, authorization and etc.</li> <li>Stream interfaces to read body.</li> <li>HTTP/HTTPS proxy.</li> <li>Latency metrics.</li> <li>Session support.</li> </ul>"},{"location":"lua/requests/#synopsis","title":"Synopsis","text":"<pre><code>local requests = require \"resty.requests\"\n\n-- example url\nlocal url = \"http://example.com/index.html\"\n\nlocal r, err = requests.get(url)\nif not r then\n    ngx.log(ngx.ERR, err)\n    return\nend\n\n-- read all body\nlocal body = r:body()\nngx.print(body)\n\n-- or you can iterate the response body\n-- while true do\n--     local chunk, err = r:iter_content(4096)\n--     if not chunk then\n--         ngx.log(ngx.ERR, err)\n--         return\n--     end\n--\n--     if chunk == \"\" then\n--         break\n--     end\n--\n--     ngx.print(chunk)\n-- end\n\n-- you can also use the non-stream mode\n-- local opts = {\n--     stream = false\n-- }\n--\n-- local r, err = requests.get(url, opts)\n-- if not r then\n--     ngx.log(ngx.ERR, err)\n-- end\n--\n-- ngx.print(r.content)\n\n-- or you can use the shortcut way to make the code cleaner.\nlocal r, err = requests.get { url = url, stream = false }\n</code></pre>"},{"location":"lua/requests/#methods","title":"Methods","text":""},{"location":"lua/requests/#request","title":"request","text":"<p>syntax: local r, err = requests.request(method, url, opts?) syntax: *local r, err = requests.request { method = method, url = url, ... }</p> <p>This is the pivotal method in <code>lua-resty-requests</code>, it will return a response object <code>r</code>. In the case of failure, <code>nil</code>, and a Lua string which describles the corresponding error will be given.</p> <p>The first parameter <code>method</code>, is the HTTP method that you want to use(same as HTTP's semantic), which takes a Lua string and the value can be:</p> <ul> <li><code>GET</code></li> <li><code>HEAD</code></li> <li><code>POST</code></li> <li><code>PUT</code></li> <li><code>DELETE</code></li> <li><code>OPTIONS</code></li> <li><code>PATCH</code></li> </ul> <p>The second parameter <code>url</code>, just takes the literal meaning(i.e. Uniform Resource Location), for instance, <code>http://foo.com/blah?a=b</code>, you can omit the scheme prefix and as the default scheme, <code>http</code> will be selected.</p> <p>The third param, an optional Lua table, which contains a number of  options:</p> <ul> <li> <p><code>headers</code> holds the custom request headers.</p> </li> <li> <p><code>allow_redirects</code> specifies whether redirecting to the target url(specified by <code>Location</code> header) or not when the status code is <code>301</code>, <code>302</code>, <code>303</code>, <code>307</code> or <code>308</code>.</p> </li> <li> <p><code>redirect_max_times</code> specifies the redirect limits, default is <code>10</code>.</p> </li> <li> <p><code>body</code>, the request body, can be:</p> <ul> <li>a Lua string, or</li> <li>a Lua function, without parameter and returns a piece of data (string) or an empty Lua string to represent EOF, or</li> <li>a Lua table, each key-value pair will be concatenated with the \"&amp;\", and Content-Type header will <code>\"application/x-www-form-urlencoded\"</code></li> </ul> </li> <li> <p><code>error_filter</code>, holds a Lua function which takes two parameters, <code>state</code> and <code>err</code>.  the parameter <code>err</code> describes the error and <code>state</code> is always one of these values(represents the current stage):</p> <ul> <li><code>requests.CONNECT</code></li> <li><code>requests.HANDSHAKE</code></li> <li><code>requests.SEND_HEADER</code></li> <li><code>requests.SEND_BODY</code></li> <li><code>requests.RECV_HEADER</code></li> <li><code>requests.RECV_BODY</code></li> <li><code>requests.CLOSE</code></li> </ul> </li> </ul> <p>You can use the method requests.state to get the textual meaning of these values.</p> <ul> <li> <p><code>timeouts</code>, an array-like table, <code>timeouts[1]</code>, <code>timeouts[2]</code> and <code>timeouts[3]</code> represents <code>connect timeout</code>, <code>send timeout</code> and <code>read timeout</code> respectively (in milliseconds).</p> </li> <li> <p><code>http10</code> specify whether the <code>HTTP/1.0</code> should be used, default verion is <code>HTTP/1.1</code>.</p> </li> <li><code>http20</code> specify whether the <code>HTTP/2</code> should be used, default verion is <code>HTTP/1.1</code>.</li> </ul> <p>Note this is still unstable, caution should be exercised. Also, there are some limitations, see lua-resty-http2 for the details.</p> <ul> <li><code>ssl</code> holds a Lua table, with three fields:</li> <li><code>verify</code>, controls whether to perform SSL verification</li> <li> <p><code>server_name</code>, is used to specify the server name for the new TLS extension Server Name Indication (SNI)</p> </li> <li> <p><code>proxies</code> specify proxy servers, the form is like</p> </li> </ul> <pre><code>{\n    http = { host = \"127.0.0.1\", port = 80 },\n    https = { host = \"192.168.1.3\", port = 443 },\n}\n</code></pre> <p>When using HTTPS proxy, a preceding CONNECT request will be sent to proxy server.</p> <ul> <li><code>hooks</code>, also a Lua table, represents the hook system that you can use to manipulate portions of the request process. Available hooks are:</li> <li><code>response</code>, will be triggered immediately after receiving the response headers</li> </ul> <p>you can assign Lua functions to hooks, these functions accept the response object as the unique param.</p> <pre><code>local hooks = {\n    response = function(r)\n        ngx.log(ngx.WARN, \"during requests process\")\n    end\n}\n</code></pre> <p>Considering the convenience, there are also some \"short path\" options:</p> <ul> <li><code>auth</code>, to do the Basic HTTP Authorization, takes a Lua table contains <code>user</code> and <code>pass</code>, e.g. when <code>auth</code> is:</li> </ul> <pre><code>{\n    user = \"alex\",\n    pass = \"123456\"\n}\n</code></pre> <p>Request header <code>Authorization</code> will be added, and the value is <code>Basic YWxleDoxMjM0NTY=</code>.</p> <ul> <li> <p><code>json</code>, takes a Lua table, it will be serialized by <code>cjson</code>, the serialized data will be sent as the request body, and it takes the priority when both <code>json</code> and <code>body</code> are specified.</p> </li> <li> <p><code>cookie</code>, takes a Lua table, the key-value pairs will be organized according to the <code>Cookie</code> header's rule, e.g. <code>cookie</code> is:</p> </li> </ul> <pre><code>{\n    [\"PHPSESSID\"] = \"298zf09hf012fh2\",\n    [\"csrftoken\"] = \"u32t4o3tb3gg43\"\n}\n</code></pre> <p>The <code>Cookie</code> header will be <code>PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43</code>.</p> <ul> <li><code>stream</code>, takes a boolean value, specifies whether reading the body in the stream mode, and it will be true by default. </li> </ul>"},{"location":"lua/requests/#state","title":"state","text":"<p>syntax: local state_name = requests.state(state)</p> <p>The method is used for getting the textual meaning of these values:</p> <ul> <li><code>requests.CONNECT</code></li> <li><code>requests.HANDSHAKE</code></li> <li><code>requests.SEND_HEADER</code></li> <li><code>requests.SEND_BODY</code></li> <li><code>requests.RECV_HEADER</code></li> <li><code>requests.RECV_BODY</code></li> <li><code>requests.CLOSE</code></li> </ul> <p>a Lua string <code>\"unknown\"</code> will be returned if <code>state</code> isn't one of the above values.</p>"},{"location":"lua/requests/#get","title":"get","text":"<p>syntax: local r, err = requests.get(url, opts?) syntax: local r, err = requests.get { url = url, ... }</p> <p>Sends a HTTP GET request. This is identical with</p> <pre><code>requests.request(\"GET\", url, opts)\n</code></pre>"},{"location":"lua/requests/#head","title":"head","text":"<p>syntax: local r, err = requests.head(url, opts?) syntax: local r, err = requests.head { url = url, ... }</p> <p>Sends a HTTP HEAD request. This is identical with</p> <pre><code>requests.request(\"HEAD\", url, opts)\n</code></pre>"},{"location":"lua/requests/#post","title":"post","text":"<p>syntax: local r, err = requests.post(url, opts?) syntax: local r, err = requests.post { url = url, ... }</p> <p>Sends a HTTP POST request. This is identical with</p> <pre><code>requests.request(\"POST\", url, opts)\n</code></pre>"},{"location":"lua/requests/#put","title":"put","text":"<p>syntax: local r, err = requests.put(url, opts?) syntax: local r, err = requests.put { url = url, ... }</p> <p>Sends a HTTP PUT request. This is identical with</p> <pre><code>requests.request(\"PUT\", url, opts)\n</code></pre>"},{"location":"lua/requests/#delete","title":"delete","text":"<p>syntax: local r, err = requests.delete(url, opts?) syntax: local r, err = requests.delete { url = url, ... }</p> <p>Sends a HTTP DELETE request. This is identical with</p> <pre><code>requests.request(\"DELETE\", url, opts)\n</code></pre>"},{"location":"lua/requests/#options","title":"options","text":"<p>syntax: local r, err = requests.options(url, opts?) syntax: local r, err = requests.options { url = url, ... }</p> <p>Sends a HTTP OPTIONS request. This is identical with</p> <pre><code>requests.request(\"OPTIONS\", url, opts)\n</code></pre>"},{"location":"lua/requests/#patch","title":"patch","text":"<p>syntax: local r, err = requests.patch(url, opts?) syntax: local r, err = requests.patch { url = url, ... }</p> <p>Sends a HTTP PATCH request. This is identical with</p> <pre><code>requests.request(\"PATCH\", url, opts)\n</code></pre>"},{"location":"lua/requests/#response-object","title":"Response Object","text":"<p>Methods like <code>requests.get</code> and others will return a response object <code>r</code>, which can be manipulated by the following methods and variables:</p> <ul> <li><code>url</code>, the url passed from caller</li> <li><code>method</code>, the request method, e.g. <code>POST</code></li> <li><code>status_line</code>, the raw status line(received from the remote)</li> <li><code>status_code</code>, the HTTP status code</li> <li><code>http_version</code>, the HTTP version of response, e.g. <code>HTTP/1.1</code></li> <li><code>headers</code>, a Lua table represents the HTTP response headers(case-insensitive)</li> <li><code>close</code>, holds a Lua function, used to close(keepalive) the underlying TCP connection</li> <li><code>drop</code>, is a Lua function, used for dropping the unread HTTP response body, will be invoked automatically when closing (if any unread data remains)</li> <li><code>iter_content</code>, which is also a Lua function, emits a part of response body(decoded from chunked format) each time called. </li> </ul> <p>This function accepts an optional param <code>size</code> to specify the size of body that the caller wants, when absent, <code>iter_content</code> returns <code>8192</code> bytes when the response body is plain or returns a piece of chunked data if the resposne body is chunked.</p> <p>In case of failure, <code>nil</code> and a Lua string described the error will be returned.</p> <ul> <li><code>body</code>, also holds a Lua function that returns the whole response body.</li> </ul> <p>In case of failure, <code>nil</code> and a Lua string described the error will be returned.</p> <ul> <li> <p><code>json</code>, holds a Lua function, serializes the body to a Lua table, note the <code>Content-Type</code> should be <code>application/json</code>. In case of failure, <code>nil</code> and an error string will be given.</p> </li> <li> <p><code>content</code>, the response body, only valid in the non-stream mode.</p> </li> <li> <p><code>elapsed</code>, a hash-like Lua table which represents the cost time (in seconds) for each stage.</p> </li> <li><code>elapsed.connect</code>, cost time for the TCP 3-Way Handshake;</li> <li><code>elapsed.handshake</code>, cost time for the SSL/TLS handshake (if any);</li> <li><code>elapsed.send_header</code>, cost time for sending the HTTP request headers;</li> <li><code>elapsed.send_body</code>, cost time for sending the HTTP request body (if any);</li> <li><code>elapsed.read_header</code>, cost time for receiving the HTTP response headers;</li> <li><code>elapsed.ttfb</code>, the time to first byte.</li> </ul> <p>Note When HTTP/2 protocol is applied, the <code>elapsed.send_body</code> (if any) will be same as <code>elapsed.send_header</code>.</p>"},{"location":"lua/requests/#session","title":"Session","text":"<p>A session persists some data across multiple requests, like cookies data, authorization data and etc.</p> <p>This mechanism now is still experimental.</p> <p>A simple example:</p> <pre><code>s = requests.session()\nlocal r, err = s:get(\"https://www.example.com\")\nngx.say(r:body())\n</code></pre> <p>A session object has same interfaces with <code>requests</code>, i.e. those http methods.</p>"},{"location":"lua/requests/#see-also","title":"See Also","text":"<ul> <li>upyun-resty: https://github.com/upyun/upyun-resty</li> <li>httpipe: https://github.com/timebug/lua-resty-httpipe</li> </ul>"},{"location":"lua/requests/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-requests.</p>"},{"location":"lua/riak/","title":"riak: Lua riak protocol buffer client driver for nginx-module-lua based on the cosocket API","text":""},{"location":"lua/riak/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/riak/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-riak\n</code></pre>"},{"location":"lua/riak/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-riak\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-riak v2.0.0  released on Dec 05 2013.</p> <p>lua-resty-riak - Lua riak protocol buffer client driver for the ngx_lua based on the cosocket API.</p> <p>Originally based on the lua-resty-memcached library.</p> <p>Influence by riak-client-ruby</p>"},{"location":"lua/riak/#status","title":"Status","text":"<p>This library is currently alpha quality. It passes all its unit tests. A few billion requests per day are handled by it however.</p>"},{"location":"lua/riak/#description","title":"Description","text":"<p>This Lua library is a riak protocol buffer client driver for the ngx_lua nginx module</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.5.0rc29 or ngx_openresty 1.0.15.7 is required.</p> <p>Depends on the following Lua modules:</p> <ul> <li>lua-pb - https://github.com/Neopallium/lua-pb</li> <li>struct - http://www.inf.puc-rio.br/~roberto/struct/</li> <li>lpack - http://www.tecgraf.puc-rio.br/~lhf/ftp/lua/#lpack </li> </ul>"},{"location":"lua/riak/#synopsis","title":"Synopsis","text":"<pre><code>location /t {\n    content_by_lua '\n        require \"luarocks.loader\"\n        local riak = require \"resty.riak\"\n        local client = riak.new()\n        local ok, err = client:connect(\"127.0.0.1\", 8087)\n        if not ok then\n            ngx.log(ngx.ERR, \"connect failed: \" .. err)\n        end\n        local bucket = client:bucket(\"test\")\n        local object = bucket:new(\"1\")\n        object.value = \"test\"\n        object.content_type = \"text/plain\"\n        local rc, err = object:store()\n        ngx.say(rc)\n        local object, err = bucket:get(\"1\")\n        if not object then\n            ngx.say(err)\n        else\n            ngx.say(object.value)\n        end\n        client:close()\n    ';\n}\n</code></pre>"},{"location":"lua/riak/#usage","title":"Usage","text":"<p>See the generated docs  for usage and examples.</p> <p>Note The high level API should be considered stable - ie will   not break between minor versions. The low-level or raw API   should not be considered stable. </p>"},{"location":"lua/riak/#potentially-breaking-change-in-20","title":"Potentially Breaking Change in 2.0","text":"<p>2.0.0 now uses vector clocks for gets,sets, and deletes of objects.  If you are using a bucket that allows multiple values (siblings) then this may break your application.</p>"},{"location":"lua/riak/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like set_by_lua, log_by_lua, and header_filter_by_lua where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.riak</code> object instances  cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see Data Sharing within an Nginx Worker ) and result in bad race conditions when concurrent requests are trying to use the same instances. You should always initiate these objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/riak/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-riak.</p>"},{"location":"lua/router/","title":"router: Lua http router for nginx-module-lua","text":""},{"location":"lua/router/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/router/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-router\n</code></pre>"},{"location":"lua/router/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-router\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-router v0.1.0  released on Jun 26 2017.</p> <p>lua-resty-router - Lua http router for the ngx_lua</p>"},{"location":"lua/router/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/router/#description","title":"Description","text":"<p>This Lua library is a http router for the ngx_lua nginx module:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.5.0rc29 or OpenResty 1.0.15.7 is required.</p>"},{"location":"lua/router/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua '\n                local Router = require \"resty.router\"\n              router = Router:new()\n              router:get(\"/a/:b/:c\", function(params)\n                ngx.print(params[\"b\"]..\"-\"..parmams[\"c\"])\n              end)\n              router:post(\"/b/c/*.html\", function(params)\n                ngx.print(\"echo html\")\n              end)\n              router:any(\"/c/d/\", function(params)\n                ngx.print(\"hello, world\")\n              end)\n            ';\n        }\n    }\n</code></pre>"},{"location":"lua/router/#methods","title":"Methods","text":"<p>The <code>key</code> argument provided in the following methods will be automatically escaped according to the URI escaping rules before sending to the memcached server.</p>"},{"location":"lua/router/#new","title":"new","text":"<p><code>syntax: r, err = router:new()</code></p> <p>Creates a router object, never return an error.</p>"},{"location":"lua/router/#route","title":"route","text":""},{"location":"lua/router/#using-get-post-head-put-patch-delete-any-and-options","title":"Using GET, POST, HEAD, PUT, PATCH, DELETE, ANY and OPTIONS","text":"<pre><code>local R = require(\"resty.router\")\nlocal router = R:new()\nrouter:get(\"/GetRoute\", handler)\nrouter:post(\"/PostRoute\", handler)\nrouter:head(\"/HeadRoute\", handler)\nrouter:put(\"/PutRoute\", handler)\nrouter:delete(\"/DeleteRoute\", handler)\nrouter:patch(\"/PatchRoute\", handler)\nrouter:options(\"/OptionsRoute\", handler)\nrouter:any(\"/AnyRoute\", handler)\nrouter:run()\n</code></pre>"},{"location":"lua/router/#parameters-in-path","title":"Parameters in path","text":"<pre><code>    local R = require(\"resty.router\")\n    local router = R:new()\n\n    -- catch all when on route is match\n    router:get(\"/*\", function(params) -- /* or * is ok\n        ngx.say(\"catch all\") \n        ngx.exit(200)\n    end)\n\n    -- This handler will match /user/john but will not match neither /user/ or /user\n    router:get(\"/user/:name\", function(params)\n        local name = params[\"name\"]\n        ngx.print(\"Hello\", name)\n        ngx.exit(200)\n    end)\n\n    -- However, this one will match /user/john/ and also /user/john/send\n    -- If no other routers match /user/john, it will redirect to /user/john/\n    router.get(\"/user/:name/*\", function(params)\n        local name = params(\"name\")\n        ngx.print(\"Hello\", name)\n        ngx.exit(200)\n    end)\n\n    -- This one will match /user/jhon/send.html, also match any uri start with /user/jhon/ and end with .html\n    router:get(\"/user/jhon/*.html\", function(params)\n        ngx.print(\"Hello\")\n        ngx.exit(200)\n    end)\n\n    router:run()\n</code></pre>"},{"location":"lua/router/#handler","title":"handler","text":"<p>Type of parameter handler should be function or string, when type is:</p> <ul> <li>function, handler would be called when uri is matched</li> <li>string, router would require <code>a.b</code>, when ret type is table, search method <code>handle</code>, if ret type is function, return function would be called.</li> </ul>"},{"location":"lua/router/#tips","title":"Tips","text":"<ul> <li>'*' rule can be used at the end of the route</li> <li>throw http code 500 when route conflicts</li> </ul>"},{"location":"lua/router/#run","title":"run","text":"<p>Method run would find route, and callback the handler. when not handler was found and notfound_handler is set, callback the handler.</p> <pre><code>    local R = require(\"resty.router\")\n    local router = R:new()\n    router:run() -- or router:run(notfound_handler)\n</code></pre>"},{"location":"lua/router/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like <code>set_by_lua*</code>, <code>log_by_lua*</code>, and <code>header_filter_by_lua*</code> where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.memcached</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see http://wiki.nginx.org/HttpLuaModule#Data_Sharing_within_an_Nginx_Worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.memcached</code> instance. You should always initiate <code>resty.memcached</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/router/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-router.</p>"},{"location":"lua/rsa/","title":"rsa: RSA encrypt/decrypt &amp; sign/verify for nginx-module-luaJIT","text":""},{"location":"lua/rsa/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/rsa/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-rsa\n</code></pre>"},{"location":"lua/rsa/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-rsa\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-rsa v1.1.1  released on Nov 09 2024.</p> <p>lua-resty-rsa - RSA functions for OpenResty</p>"},{"location":"lua/rsa/#status","title":"Status","text":"<p>This library is considered production ready.</p> <p>Build status: </p>"},{"location":"lua/rsa/#description","title":"Description","text":"<p>This library requires an nginx build with OpenSSL, the ngx_lua module, and LuaJIT.</p>"},{"location":"lua/rsa/#synopsis","title":"Synopsis","text":"<pre><code>    # nginx.conf:\n\n    server {\n        location = /test {\n            content_by_lua_file conf/test.lua;\n        }\n    }\n\n    -- conf/test.lua:\n\n    local resty_rsa = require \"resty.rsa\"\n    local rsa_public_key, rsa_priv_key, err = resty_rsa:generate_rsa_keys(2048)\n    if not rsa_public_key then\n        ngx.say('generate rsa keys err: ', err)\n    end\n\n    ngx.say(rsa_public_key)\n    --[[\n    -----BEGIN RSA PUBLIC KEY-----\n    MIIBCgKCAQEAuw4T755fepEyXTM66pzf6nv8NtnukQTMGnhmBFIFHp/P2vEpxjXU\n    BBDUpzKkVFR3wuK9O1FNmRDAGNGYC0N/9cZNdhykA1NixJfKQzncN31VJTmNqJNZ\n    W0x7H9ZGoh2aE0zCCZpRlC1Rf5rL0SVlBoQkn/n9LnYFwyLLIK5/d/y/NZVL6Z6L\n    cyvga0zRajamLIjY0Dy/8YIwVV6kaSsHeRv2cOB03eam6gbhLGIz/l8wuJhIn1rO\n    yJLQ36IOJymbbNmcC7+2hEQJP40qLvH7hZ1LaAkgQUHjfi8RvH2T1Jmce7XGPxCo\n    Ed0yfeFz+pL1KeSWNey6cL3N5hJZE8EntQIDAQAB\n    -----END RSA PUBLIC KEY-----\n    ]]--\n\n    ngx.say(rsa_priv_key)\n    --[[\n    -----BEGIN RSA PRIVATE KEY-----\n    MIIEpAIBAAKCAQEAuw4T755fepEyXTM66pzf6nv8NtnukQTMGnhmBFIFHp/P2vEp\n    xjXUBBDUpzKkVFR3wuK9O1FNmRDAGNGYC0N/9cZNdhykA1NixJfKQzncN31VJTmN\n    qJNZW0x7H9ZGoh2aE0zCCZpRlC1Rf5rL0SVlBoQkn/n9LnYFwyLLIK5/d/y/NZVL\n    6Z6Lcyvga0zRajamLIjY0Dy/8YIwVV6kaSsHeRv2cOB03eam6gbhLGIz/l8wuJhI\n    n1rOyJLQ36IOJymbbNmcC7+2hEQJP40qLvH7hZ1LaAkgQUHjfi8RvH2T1Jmce7XG\n    PxCoEd0yfeFz+pL1KeSWNey6cL3N5hJZE8EntQIDAQABAoIBAGim1ayIFK8EMQNH\n    uDyui/Aqcc9WWky0PGTK23irUsXxb1708gQ89WNY70Cj6qBrqZ1VMb3QHPP4FSFN\n    kh0rJJoi2g+ssm5R5r5KlhTKeFRrQInVC1Y3KhUUUwZa4aWtnhgSJ7Urq1yVhjU4\n    K7PVkhH1OHBwcp/d1Bd6jd65AgPkY63P+WpcARJkClmQ1RhgoRwThyJdpKrV4/gO\n    ha0AUGlJNRNvRwiZxP0zaI5C8RdrG96SnVpeYOcD0z/M1HVlkoYMXsXLKttwLfpK\n    88Igtm6ZJwRpfuMF5VA+9hHaYGCBdGz0B/rMp2fc+EtrOavYQGrWIWi2RL1Qk6Rt\n    BUyeTgECgYEA9anj4n/cak1MT+hbNFsL31mJXryl1eVNjEZj/iPMztpdS15CmFgj\n    Kjr9UuintjSiK7Is43nZUWWyP1XQjRhVi2uP7PRIv92QNl/YteWD6tYCInJHKe2J\n    QqYyZrElezsdayXb5DK6bi1UIYYji90g79N7x6pOR0UnQNQUXTv+Y8ECgYEAwuzl\n    6Ez4BSXIIL9NK41jfNMa73Utfl5oO1f6mHM2KbILqaFE76PSgEeXDbOKdcjCbbqC\n    KCGjwyPd+Clehg4vkYXTq1y2SQGHwfz7DilPSOxhPY9ND7lGbeNzDUK4x8xe52hd\n    MWKdgqeqCK83e5D0ihzRiMah8dbxmlfLAOZ3sPUCgYEA0dT9Czg/YqUHq7FCReQG\n    rg3iYgMsexjTNh/hxO97PqwRyBCJPWr7DlU4j5qdteobIsubv+kSEI6Ww7Ze3kWM\n    u/tyAeleQlPTnD4d8rBKD0ogpJ+L3WpBNaaToldpNmr149GAktgpmXYqSEA1GIAW\n    ZAL11UPIfOO6dYswobpevYECgYEApSosSODnCx2PbMgL8IpWMU+DNEF6sef2s8oB\n    aam9zCi0HyCqE9AhLlb61D48ZT8eF/IAFVcjttauX3dWQ4rDna/iwgHF5yhnyuS8\n    KayxJJ4+avYAmwEnfzdJpoPRpGI0TCovRQhFZI8C0Wb+QTJ7Mofmt9lvIUc64sff\n    GD0wT/0CgYASMf708dmc5Bpzcis++EgMJVb0q+ORmWzSai1NB4bf3LsNS6suWNNU\n    zj/JGtMaGvQo5vzGU4exNkhpQo8yUU5YbHlA8RCj7SYkmP78kCewEqxlx7dbcuj2\n    LAPWpiDca8StTfEphoKEVfCPHaUk0MlBHR4lCrnAkEtz23vhZKWhFw==\n    -----END RSA PRIVATE KEY-----\n    ]]--\n\n    local pub, err = resty_rsa:new({ public_key = rsa_public_key })\n    if not pub then\n        ngx.say(\"new rsa err: \", err)\n        return\n    end\n    local encrypted, err = pub:encrypt(\"hello\")\n    if not encrypted then\n        ngx.say(\"failed to encrypt: \", err)\n        return\n    end\n    ngx.say(\"encrypted length: \", #encrypted)\n\n    local priv, err = resty_rsa:new({ private_key = rsa_priv_key })\n    if not priv then\n        ngx.say(\"new rsa err: \", err)\n        return\n    end\n    local decrypted = priv:decrypt(encrypted)\n    ngx.say(decrypted == \"hello\")\n\n    local algorithm = \"SHA256\"\n    local priv, err = resty_rsa:new({ private_key = rsa_priv_key, algorithm = algorithm })\n    if not priv then\n        ngx.say(\"new rsa err: \", err)\n        return\n    end\n\n    local str = \"hello\"\n    local sig, err = priv:sign(str)\n    if not sig then\n        ngx.say(\"failed to sign:\", err)\n        return\n    end\n    ngx.say(\"sig length: \", #sig)\n\n    local pub, err = resty_rsa:new({ public_key = rsa_public_key, algorithm = algorithm })\n    if not pub then\n        ngx.say(\"new rsa err: \", err)\n        return\n    end\n    local verify, err = pub:verify(str, sig)\n    if not verify then\n        ngx.say(\"verify err: \", err)\n        return\n    end\n    ngx.say(verify)\n</code></pre>"},{"location":"lua/rsa/#methods","title":"Methods","text":"<p>To load this library,</p> <ol> <li>you need to specify this library's path in ngx_lua's lua_package_path directive. For example, <code>lua_package_path \"/path/to/lua-resty-rsa/lib/?.lua;;\";</code>.</li> <li>you use <code>require</code> to load the library into a local Lua variable:</li> </ol> <pre><code>    local rsa = require \"resty.rsa\"\n</code></pre>"},{"location":"lua/rsa/#generate_rsa_keys","title":"generate_rsa_keys","text":"<p><code>syntax: public_key, private_key, err = rsa:generate_rsa_keys(bits, in_pkcs8_fmt)</code></p> <p>Generate rsa public key and private key by specifying the number of <code>bits</code>.  The <code>in_pkcs8_fmt</code> is optional. If <code>in_pkcs8_fmt</code> is true, the generated priviate key is in PKCS#8 format and  the public key is in PKIX format, which start with <code>-----BEGIN PUBLIC</code> or <code>-----BEGIN PRIVATE</code>.  Otherwise the generated keys are in PKCS#1 format, which start with <code>-----BEGIN RSA</code>.</p>"},{"location":"lua/rsa/#new","title":"new","text":"<p><code>syntax: obj, err = rsa:new(opts)</code></p> <p>Creates a new rsa object instance by specifying an options table <code>opts</code>.</p> <p>The options table accepts the following options:</p> <ul> <li><code>public_key</code> Specifies the public rsa key.</li> <li><code>private_key</code> Specifies the private rsa key.</li> <li><code>password</code> Specifies the password to read rsa key.</li> <li><code>key_type</code> Specifies the type of given key. By default the type will be detected from the value of the key.</li> </ul> <code>key_type</code> value meaning rsa.KEY_TYPE.PKCS1 The input key is in PKCS#1 format(usually starts with <code>-----BEGIN RSA PUBLIC</code>). rsa.KEY_TYPE.PKIX The input key is in PKIX format(usually starts with <code>-----BEGIN PUBLIC</code>). <pre><code>-- creates a rsa object with PKIX format of public key\nlocal resty_rsa = require \"resty.rsa\"\nlocal pub, err = resty_rsa:new({\n    public_key = RSA_PKCS8_PUB_KEY,\n    key_type = resty_rsa.KEY_TYPE.PKIX,\n})\n\n-- creates a rsa object with pkcs#8 format of private key\nlocal priv, err = resty_rsa:new({\n    private_key = RSA_PKCS8_PASS_PRIV_KEY,\n    key_type = resty_rsa.KEY_TYPE.PKCS8,\n    -- you need to specify the password if the pkey is encrypted\n    -- password = \"foobar\",\n})\n</code></pre> <ul> <li><code>padding</code> Specifies the padding mode when you want to encrypt/decrypt.</li> <li><code>algorithm</code> Specifies the digest algorithm when you want to sign/verify.</li> </ul> <code>algorithm</code> value meaning md4/MD4/RSA-MD4/md4WithRSAEncryption digest with <code>md4</code> md5/MD5/RSA-MD5/md5WithRSAEncryption/ssl3-md5 digest with <code>md5</code> ripemd160/RIPEMD160/RSA-RIPEM160/ripemd160WithRSA/rmd160 digest with <code>ripemd160</code> sha1/SHA1/RSA-SHA1/sha1WithRSAEncryption/ssl3-sha1 digest with <code>sha1</code> sha224/SHA224/RSA-SHA224/sha224WithRSAEncryption digest with <code>sha224</code> sha256/SHA256/RSA-SHA256/sha256WithRSAEncryption digest with <code>sha256</code> sha384/SHA384/RSA-SHA384/sha384WithRSAEncryption digest with <code>sha384</code> sha512/SHA512/RSA-SHA512/sha512WithRSAEncryption digest with <code>sha512</code>"},{"location":"lua/rsa/#encrypt","title":"encrypt","text":"<p><code>syntax: encrypted, err = obj:encrypt(str)</code></p>"},{"location":"lua/rsa/#decrypt","title":"decrypt","text":"<p><code>syntax: decrypted, err = obj:decrypt(encrypted)</code></p>"},{"location":"lua/rsa/#sign","title":"sign","text":"<p><code>syntax: signature, err = obj:sign(str)</code></p>"},{"location":"lua/rsa/#verify","title":"verify","text":"<p><code>syntax: ok, err = obj:verify(str, signature)</code></p>"},{"location":"lua/rsa/#performance","title":"Performance","text":"<p>I got the result: <pre><code>encrypt for 50000 times cost : 2.4110000133514s\ndecrypt for 50000 times cost : 57.196000099182s\nsign for 50000 times cost : 59.169999837875s\nverify for 50000 times cost : 1.8230001926422s\n</code></pre></p> <p>when I run this script. <pre><code>local resty_rsa = require \"resty.rsa\"\nlocal algorithm = \"SHA256\"\n\nlocal rsa_public_key, rsa_priv_key, err = resty_rsa:generate_rsa_keys(2048)\nif not rsa_public_key then\n    ngx.say(\"generate rsa keys err: \", err)\n    return\nend\n\nlocal pub, err = resty_rsa:new({\n    public_key = rsa_public_key,\n    padding = resty_rsa.PADDING.RSA_PKCS1_PADDING,\n    algorithm = algorithm,\n})\nif not pub then\n    ngx.say(\"new rsa err: \", err)\n    return\nend\n\nlocal priv, err = resty_rsa:new({\n    private_key = rsa_priv_key,\n    padding = resty_rsa.PADDING.RSA_PKCS1_PADDING,\n    algorithm = algorithm,\n})\nif not priv then\n    ngx.say(\"new rsa err: \", err)\n    return\nend\n\n\nlocal num = 5 * 10000\n\nlocal str = \"hello test\"\n\nlocal encrypted, decrypted, err, sig, verify\n\nngx.update_time()\nlocal now = ngx.now()\n\nlocal function timer(operation)\n    ngx.update_time()\n    local t = ngx.now()\n\n    ngx.say(operation, \" for \", num, \" times cost : \", t - now, \"s\")\n    now = t\nend\n\nfor _ = 1, num do\n    encrypted, err = pub:encrypt(str)\n    if not encrypted then\n        ngx.say(\"failed to encrypt: \", err)\n        return\n    end\nend\n\ntimer(\"encrypt\")\n\nfor _ = 1, num do\n    decrypted = priv:decrypt(encrypted)\n    if decrypted ~= str then\n        ngx.say(\"decrypted not match\")\n        return\n    end\nend\n\ntimer(\"decrypt\")\n\nfor _ = 1, num do\n    sig, err = priv:sign(str)\n    if not sig then\n        ngx.say(\"failed to sign:\", err)\n        return\n    end\nend\n\ntimer(\"sign\")\n\nfor _ = 1, num do\n    verify, err = pub:verify(str, sig)\n    if not verify then\n        ngx.say(\"verify err: \", err)\n        return\n    end\nend\n\ntimer(\"verify\")\n</code></pre></p>"},{"location":"lua/rsa/#release-steps","title":"Release Steps","text":"<ol> <li>update the <code>_VERSION</code> in <code>lib/resty/rsa.lua</code></li> <li>update the <code>version</code> in <code>dist.ini</code></li> <li>rename current rockspec to the new version and update the reference in it.</li> <li>tag the new version</li> <li>opm upload</li> </ol>"},{"location":"lua/rsa/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> <li>the lua-resty-string: https://github.com/openresty/lua-resty-string</li> </ul>"},{"location":"lua/rsa/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-rsa.</p>"},{"location":"lua/scrypt/","title":"scrypt: LuaJIT FFI-based scrypt library for nginx-module-lua","text":""},{"location":"lua/scrypt/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/scrypt/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-scrypt\n</code></pre>"},{"location":"lua/scrypt/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-scrypt\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-scrypt v1.0  released on Oct 09 2014.</p> <p><code>lua-resty-scrypt</code> is a scrypt (password) hashing library for OpenResty.</p>"},{"location":"lua/scrypt/#hello-world-with-lua-resty-scrypt","title":"Hello World with lua-resty-scrypt","text":"<pre><code>local scrypt = require \"resty.scrypt\"\nlocal hash   = scrypt.crypt \"My Secret\"         -- returns a hash that can be stored in db\nlocal valid  = scrypt.check(\"My Secret\", hash)  -- valid holds true\nlocal valid  = scrypt.check(\"My Guess\",  hash)  -- valid holds false\n\nlocal n,r,p  = scrypt.calibrate()               -- returns n,r,p calibration values\n</code></pre>"},{"location":"lua/scrypt/#lua-api","title":"Lua API","text":""},{"location":"lua/scrypt/#string-scryptcryptopts","title":"string scrypt.crypt(opts)","text":"<p>Uses scrypt algorithm to generate hash from the input. Input parameter <code>opts</code> can either be <code>string</code> (a <code>secret</code>) or a table. If it is a table you may pass in some configuration parameters as well. Available table options (defaults are as follows):</p> <pre><code>local opts = {\n    secret   = \"\",\n    keysize  = 32,\n    n        = 32768\n    r        = 8,\n    p        = 1,\n    salt     = \"random (saltsize) bytes generated with OpenSSL\",\n    saltsize = 8\n}\n</code></pre> <p>If you pass opts anything other than a table, it will be <code>tostring</code>ified and used as a <code>secret</code>. <code>keysize</code> can be between 16 and 512, <code>saltsize</code> can be between 8 and 32.</p> <p>This function returns string that looks like this:</p> <pre><code>n$r$p$salt$hash\n</code></pre> <p>All parts present a <code>hex dump</code> of their values.</p>"},{"location":"lua/scrypt/#example","title":"Example","text":"<pre><code>local h1 = scrypt.crypt \"My Secret\"\nlocal h2 = scrypt.crypt{\n    secret  = \"My Secret\",\n    keysize = 512 \n}\n</code></pre>"},{"location":"lua/scrypt/#boolean-scryptchecksecret-hash","title":"boolean scrypt.check(secret, hash)","text":"<p>With this function you can check if the <code>secret</code> really matches with the <code>hash</code> that was generated with <code>scrypt.crypt</code> from the same <code>secret</code>. The <code>hash</code> contains also the configuration parameters like <code>n</code>, <code>r</code>, <code>p</code> and <code>salt</code>.</p>"},{"location":"lua/scrypt/#example_1","title":"Example","text":"<pre><code>local b1 = scrypt.check(\"My Secret\", scrypt.crypt \"My Secret\") -- returns true\nlocal b2 = scrypt.check(\"My Secret\", scrypt.crypt \"No Secret\") -- returns false\n</code></pre>"},{"location":"lua/scrypt/#n-r-p-scryptcalibratemaxmem-maxmemfrac-maxtime","title":"n, r, p scrypt.calibrate(maxmem, maxmemfrac, maxtime)","text":"<p>This function can be used to count <code>n</code>, <code>r</code>, and <code>p</code> configuration values from <code>maxmem</code>, <code>maxmemfrac</code> and <code>maxtime</code> parameters. These are the defaults for those:</p> <pre><code>maxmem     = 1048576\nmaxmemfrac = 0.5\nmaxtime    = 0.2\n</code></pre> <p>The results may change depending on your computer's processing power.</p>"},{"location":"lua/scrypt/#example_2","title":"Example","text":"<pre><code>local n,r,p = scrypt.calibrate()\nlocal hash  = scrypt.crypt{\n    secret  = \"My Secret\",\n    n = n,\n    r = r,\n    p = p\n}\n</code></pre>"},{"location":"lua/scrypt/#number-scryptmemoryusen-r-p","title":"number scrypt.memoryuse(n, r, p)","text":"<p>Counts the memory use of scrypt-algorigth with the provided <code>n</code>, <code>r</code>, and <code>p</code> arguments.</p>"},{"location":"lua/scrypt/#example_3","title":"Example","text":"<pre><code>local memoryuse = scrypt.memoryuse(scrypt.calibrate())\n</code></pre> <p>Default parameters for <code>n</code>, <code>r</code>, and <code>p</code> are:</p> <pre><code>n = 32768\nr = 8\np = 1\n</code></pre>"},{"location":"lua/scrypt/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-scrypt.</p>"},{"location":"lua/session/","title":"session: Session library for nginx-module-lua \u2013 flexible and secure","text":""},{"location":"lua/session/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/session/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-session\n</code></pre>"},{"location":"lua/session/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-session\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-session v4.1.5  released on Nov 24 2025.</p> <p>lua-resty-session is a secure, and flexible session library for OpenResty.</p>"},{"location":"lua/session/#tldr","title":"TL;DR;","text":"<ul> <li>Sessions are immutable (each save generates a new session), and lockless.</li> <li>Session data is AES-256-GCM encrypted with a key derived using HKDF-SHA256   (on FIPS-mode it uses PBKDF2 with SHA-256 instead.</li> <li>Session has a fixed size header that is protected with HMAC-SHA256 MAC with   a key derived using HKDF-SHA256 (on FIPS-mode it uses PBKDF2 with SHA-256 instead).</li> <li>Session data can be stored in a stateless cookie or in various backend storages.</li> <li>A single session cookie can maintain multiple sessions across different audiences.</li> </ul> <p>Note: Version 4.0.0 was a rewrite of this library with a lot of lessons learned during the years. If you still use older version, please refer old documentation.</p>"},{"location":"lua/session/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/session/#synopsis","title":"Synopsis","text":"<pre><code>worker_processes  1;\n\nevents {\n  worker_connections 1024;\n}\n\nhttp {\n  init_by_lua_block {\n    require \"resty.session\".init({\n      remember = true,\n      audience = \"demo\",\n      secret   = \"RaJKp8UQW1\",\n      storage  = \"cookie\",\n    })\n  }\n\n  server {\n    listen       8080;\n    server_name  localhost;\n    default_type text/html;\n\n    location / {\n      content_by_lua_block {\n        ngx.say([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;a href=/start&gt;Start the test&lt;/a&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]])\n      }\n    }\n\n    location /start {\n      content_by_lua_block {\n        local session = require \"resty.session\".new()\n        session:set_subject(\"OpenResty Fan\")\n        session:set(\"quote\", \"The quick brown fox jumps over the lazy dog\")\n        local ok, err = session:save()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session started (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/started&gt;Check if it really was&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]], err or \"no error\"))\n      }\n    }\n\n    location /started {\n      content_by_lua_block {\n        local session, err = require \"resty.session\".start()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session was started by %s (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;blockquote&gt;%s&lt;/blockquote&gt;&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/modify&gt;Modify the session&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]],\n          session:get_subject() or \"Anonymous\",\n          err or \"no error\",\n          session:get(\"quote\") or \"no quote\"\n        ))\n      }\n    }\n\n    location /modify {\n      content_by_lua_block {\n        local session, err = require \"resty.session\".start()\n        session:set_subject(\"Lua Fan\")\n        session:set(\"quote\", \"Lorem ipsum dolor sit amet\")\n        local _, err_save = session:save()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session was modified (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/modified&gt;Check if it is modified&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]], err or err_save or \"no error\"))\n      }\n    }\n\n    location /modified {\n      content_by_lua_block {\n        local session, err = require \"resty.session\".start()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session was started by %s (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;blockquote&gt;%s&lt;/blockquote&gt;&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/destroy&gt;Destroy the session&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]],\n          session:get_subject() or \"Anonymous\",\n          err or \"no error\",\n          session:get(\"quote\")  or \"no quote\"\n        ))\n      }\n    }\n\n    location /destroy {\n      content_by_lua_block {\n        local ok, err = require \"resty.session\".destroy()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session was destroyed (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/destroyed&gt;Check that it really was?&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]], err or \"no error\"))\n      }\n    }\n\n    location /destroyed {\n      content_by_lua_block {\n        local session, err = require \"resty.session\".open()\n\n        ngx.say(string.format([[\n          &lt;html&gt;\n          &lt;body&gt;\n            &lt;p&gt;Session was really destroyed, you are known as %s (%s)&lt;/p&gt;\n            &lt;p&gt;&lt;a href=/&gt;Start again&lt;/a&gt;&lt;/p&gt;\n          &lt;/body&gt;\n          &lt;/html&gt;\n        ]],\n          session:get_subject() or \"Anonymous\",\n          err or \"no error\"\n        ))\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"lua/session/#configuration","title":"Configuration","text":"<p>The configuration can be divided to generic session configuration and the server side storage configuration.</p> <p>Here is an example:</p> <pre><code>init_by_lua_block {\n  require \"resty.session\".init({\n    remember = true,\n    store_metadata = true,\n    secret = \"RaJKp8UQW1\",\n    secret_fallbacks = {\n      \"X88FuG1AkY\",\n      \"fxWNymIpbb\",\n    },\n    storage = \"postgres\",\n    postgres = {\n      username = \"my-service\",\n      password = \"kVgIXCE5Hg\",\n      database = \"sessions\",\n    },\n  })\n}\n</code></pre>"},{"location":"lua/session/#session-configuration","title":"Session Configuration","text":"<p>Session configuration can be passed to initialization, constructor, and helper functions.</p> <p>Here are the possible session configuration options:</p> Option Default Description <code>secret</code> <code>nil</code> Secret used for the key derivation. The secret is hashed with SHA-256 before using it. E.g. <code>\"RaJKp8UQW1\"</code>. <code>secret_fallbacks</code> <code>nil</code> Array of secrets that can be used as alternative secrets (when doing key rotation), E.g. <code>{ \"6RfrAYYzYq\", \"MkbTkkyF9C\" }</code>. <code>ikm</code> (random) Initial keying material (or ikm) can be specified directly (without using a secret) with exactly 32 bytes of data. E.g. <code>\"5ixIW4QVMk0dPtoIhn41Eh1I9enP2060\"</code> <code>ikm_fallbacks</code> <code>nil</code> Array of initial keying materials that can be used as alternative keys (when doing key rotation), E.g. <code>{ \"QvPtlPKxOKdP5MCu1oI3lOEXIVuDckp7\" }</code>. <code>cookie_prefix</code> <code>nil</code> Cookie prefix, use <code>nil</code>, <code>\"__Host-\"</code> or <code>\"__Secure-\"</code>. <code>cookie_name</code> <code>\"session\"</code> Session cookie name, e.g. <code>\"session\"</code>. <code>cookie_path</code> <code>\"/\"</code> Cookie path, e.g. <code>\"/\"</code>. <code>cookie_domain</code> <code>nil</code> Cookie domain, e.g. <code>\"example.com\"</code> <code>cookie_http_only</code> <code>true</code> Mark cookie HTTP only, use <code>true</code> or <code>false</code>. <code>cookie_secure</code> <code>nil</code> Mark cookie secure, use <code>nil</code>, <code>true</code> or <code>false</code>. <code>cookie_priority</code> <code>nil</code> Cookie priority, use <code>nil</code>, <code>\"Low\"</code>, <code>\"Medium\"</code>, or <code>\"High\"</code>. <code>cookie_same_site</code> <code>\"Lax\"</code> Cookie same-site policy, use <code>nil</code>, <code>\"Lax\"</code>, <code>\"Strict\"</code>, <code>\"None\"</code>, or <code>\"Default\"</code> <code>cookie_same_party</code> <code>nil</code> Mark cookie with same party flag, use <code>nil</code>, <code>true</code>, or <code>false</code>. <code>cookie_partitioned</code> <code>nil</code> Mark cookie with partitioned flag, use <code>nil</code>, <code>true</code>, or <code>false</code>. <code>remember</code> <code>false</code> Enable or disable persistent sessions, use <code>nil</code>, <code>true</code>, or <code>false</code>. <code>remember_safety</code> <code>\"Medium\"</code> Remember cookie key derivation complexity, use <code>nil</code>, <code>\"None\"</code> (fast), <code>\"Low\"</code>, <code>\"Medium\"</code>, <code>\"High\"</code> or <code>\"Very High\"</code> (slow). <code>remember_cookie_name</code> <code>\"remember\"</code> Persistent session cookie name, e.g. <code>\"remember\"</code>. <code>audience</code> <code>\"default\"</code> Session audience, e.g. <code>\"my-application\"</code>. <code>subject</code> <code>nil</code> Session subject, e.g. <code>\"john.doe@example.com\"</code>. <code>enforce_same_subject</code> <code>false</code> When set to <code>true</code>, audiences need to share the same subject. The library removes non-subject matching audience data on save. <code>stale_ttl</code> <code>10</code> When session is saved a new session is created, stale ttl specifies how long the old one can still be used, e.g. <code>10</code> (in seconds). <code>idling_timeout</code> <code>900</code> Idling timeout specifies how long the session can be inactive until it is considered invalid, e.g. <code>900</code> (15 minutes) (in seconds), <code>0</code> disables the checks and touching. <code>rolling_timeout</code> <code>3600</code> Rolling timeout specifies how long the session can be used until it needs to be renewed, e.g. <code>3600</code> (an hour) (in seconds), <code>0</code> disables the checks and rolling. <code>absolute_timeout</code> <code>86400</code> Absolute timeout limits how long the session can be renewed, until re-authentication is required, e.g. <code>86400</code> (a day) (in seconds), <code>0</code> disables the checks. <code>remember_rolling_timeout</code> <code>604800</code> Remember timeout specifies how long the persistent session is considered valid, e.g. <code>604800</code> (a week) (in seconds), <code>0</code> disables the checks and rolling. <code>remember_absolute_timeout</code> <code>2592000</code> Remember absolute timeout limits how long the persistent session can be renewed, until re-authentication is required, e.g. <code>2592000</code> (30 days) (in seconds), <code>0</code> disables the checks. <code>hash_storage_key</code> <code>false</code> Whether to hash or not the storage key. With storage key hashed it is impossible to decrypt data on server side without having a cookie too, use <code>nil</code>, <code>true</code> or <code>false</code>. <code>hash_subject</code> <code>false</code> Whether to hash or not the subject when <code>store_metadata</code> is enabled, e.g. for PII reasons. <code>store_metadata</code> <code>false</code> Whether to also store metadata of sessions, such as collecting data of sessions for a specific audience belonging to a specific subject. <code>touch_threshold</code> <code>60</code> Touch threshold controls how frequently or infrequently the <code>session:refresh</code> touches the cookie, e.g. <code>60</code> (a minute) (in seconds) <code>compression_threshold</code> <code>1024</code> Compression threshold controls when the data is deflated, e.g. <code>1024</code> (a kilobyte) (in bytes), <code>0</code> disables compression. <code>bind</code> <code>nil</code> Bind the session to data acquired from the HTTP request or connection, use <code>ip</code>, <code>scheme</code>, <code>user-agent</code>. E.g. <code>{ \"scheme\", \"user-agent\" }</code> will calculate MAC utilizing also HTTP request <code>Scheme</code> and <code>User-Agent</code> header. <code>request_headers</code> <code>nil</code> Set of headers to send to upstream, use <code>id</code>, <code>audience</code>, <code>subject</code>, <code>timeout</code>, <code>idling-timeout</code>, <code>rolling-timeout</code>, <code>absolute-timeout</code>. E.g. <code>{ \"id\", \"timeout\" }</code> will set <code>Session-Id</code> and <code>Session-Timeout</code> request headers when <code>set_headers</code> is called. <code>response_headers</code> <code>nil</code> Set of headers to send to downstream, use <code>id</code>, <code>audience</code>, <code>subject</code>, <code>timeout</code>, <code>idling-timeout</code>, <code>rolling-timeout</code>, <code>absolute-timeout</code>. E.g. <code>{ \"id\", \"timeout\" }</code> will set <code>Session-Id</code> and <code>Session-Timeout</code> response headers when <code>set_headers</code> is called. <code>storage</code> <code>nil</code> Storage is responsible of storing session data, use <code>nil</code> or <code>\"cookie\"</code> (data is stored in cookie), <code>\"dshm\"</code>, <code>\"file\"</code>, <code>\"memcached\"</code>, <code>\"mysql\"</code>, <code>\"postgres\"</code>, <code>\"redis\"</code>, or <code>\"shm\"</code>, or give a name of custom module (<code>\"custom-storage\"</code>), or a <code>table</code> that implements session storage interface. <code>dshm</code> <code>nil</code> Configuration for dshm storage, e.g. <code>{ prefix = \"sessions\" }</code> (see below) <code>file</code> <code>nil</code> Configuration for file storage, e.g. <code>{ path = \"/tmp\", suffix = \"session\" }</code> (see below) <code>memcached</code> <code>nil</code> Configuration for memcached storage, e.g. <code>{ prefix = \"sessions\" }</code> (see below) <code>mysql</code> <code>nil</code> Configuration for MySQL / MariaDB storage, e.g. <code>{ database = \"sessions\" }</code> (see below) <code>postgres</code> <code>nil</code> Configuration for Postgres storage, e.g. <code>{ database = \"sessions\" }</code> (see below) <code>redis</code> <code>nil</code> Configuration for Redis / Redis Sentinel / Redis Cluster storages, e.g. <code>{ prefix = \"sessions\" }</code> (see below) <code>shm</code> <code>nil</code> Configuration for shared memory storage, e.g. <code>{ zone = \"sessions\" }</code> <code>[\"custom-storage\"]</code> <code>nil</code> custom storage (loaded with <code>require \"custom-storage\"</code>) configuration."},{"location":"lua/session/#cookie-storage-configuration","title":"Cookie Storage Configuration","text":"<p>When storing data to cookie, there is no additional configuration required, just set the <code>storage</code> to <code>nil</code> or <code>\"cookie\"</code>.</p>"},{"location":"lua/session/#dshm-storage-configuration","title":"DSHM Storage Configuration","text":"<p>With DHSM storage you can use the following settings (set the <code>storage</code> to <code>\"dshm\"</code>):</p> Option Default Description <code>prefix</code> <code>nil</code> The Prefix for the keys stored in DSHM. <code>suffix</code> <code>nil</code> The suffix for the keys stored in DSHM. <code>host</code> <code>\"127.0.0.1\"</code> The host to connect. <code>port</code> <code>4321</code> The port to connect. <code>connect_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>connect</code> method. <code>send_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>send</code> method. <code>read_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>receive</code> method. <code>keepalive_timeout</code> <code>nil</code> Controls the default maximal idle time of the connections in the connection pool. <code>pool</code> <code>nil</code> A custom name for the connection pool being used. <code>pool_size</code> <code>nil</code> The size of the connection pool. <code>backlog</code> <code>nil</code> A queue size to use when the connection pool is full (configured with pool_size). <code>ssl</code> <code>nil</code> Enable SSL. <code>ssl_verify</code> <code>nil</code> Verify server certificate. <code>server_name</code> <code>nil</code> The server name for the new TLS extension Server Name Indication (SNI). <p>Please refer to ngx-distributed-shm to get necessary dependencies installed.</p>"},{"location":"lua/session/#file-storage-configuration","title":"File Storage Configuration","text":"<p>With file storage you can use the following settings (set the <code>storage</code> to <code>\"file\"</code>):</p> Option Default Description <code>prefix</code> <code>nil</code> File prefix for session file. <code>suffix</code> <code>nil</code> File suffix (or extension without <code>.</code>) for session file. <code>pool</code> <code>nil</code> Name of the thread pool under which file writing happens (available on Linux only). <code>path</code> (tmp directory) Path (or directory) under which session files are created. <p>The implementation requires <code>LuaFileSystem</code> which you can install with LuaRocks: <pre><code>\u276f luarocks install LuaFileSystem\n</code></pre></p>"},{"location":"lua/session/#memcached-storage-configuration","title":"Memcached Storage Configuration","text":"<p>With file Memcached you can use the following settings (set the <code>storage</code> to <code>\"memcached\"</code>):</p> Option Default Description <code>prefix</code> <code>nil</code> Prefix for the keys stored in memcached. <code>suffix</code> <code>nil</code> Suffix for the keys stored in memcached. <code>host</code> <code>127.0.0.1</code> The host to connect. <code>port</code> <code>11211</code> The port to connect. <code>socket</code> <code>nil</code> The socket file to connect to. <code>connect_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>connect</code> method. <code>send_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>send</code> method. <code>read_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>receive</code> method. <code>keepalive_timeout</code> <code>nil</code> Controls the default maximal idle time of the connections in the connection pool. <code>pool</code> <code>nil</code> A custom name for the connection pool being used. <code>pool_size</code> <code>nil</code> The size of the connection pool. <code>backlog</code> <code>nil</code> A queue size to use when the connection pool is full (configured with pool_size). <code>ssl</code> <code>false</code> Enable SSL <code>ssl_verify</code> <code>nil</code> Verify server certificate <code>server_name</code> <code>nil</code> The server name for the new TLS extension Server Name Indication (SNI)."},{"location":"lua/session/#mysql-mariadb-storage-configuration","title":"MySQL / MariaDB Storage Configuration","text":"<p>With file MySQL / MariaDB you can use the following settings (set the <code>storage</code> to <code>\"mysql\"</code>):</p> Option Default Description <code>host</code> <code>\"127.0.0.1\"</code> The host to connect. <code>port</code> <code>3306</code> The port to connect. <code>socket</code> <code>nil</code> The socket file to connect to. <code>username</code> <code>nil</code> The database username to authenticate. <code>password</code> <code>nil</code> Password for authentication, may be required depending on server configuration. <code>charset</code> <code>\"ascii\"</code> The character set used on the MySQL connection. <code>database</code> <code>nil</code> The database name to connect. <code>table_name</code> <code>\"sessions\"</code> Name of database table to which to store session data. <code>table_name_meta</code> <code>\"sessions_meta\"</code> Name of database meta data table to which to store session meta data. <code>max_packet_size</code> <code>1048576</code> The upper limit for the reply packets sent from the MySQL server (in bytes). <code>connect_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>connect</code> method. <code>send_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>send</code> method. <code>read_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>receive</code> method. <code>keepalive_timeout</code> <code>nil</code> Controls the default maximal idle time of the connections in the connection pool. <code>pool</code> <code>nil</code> A custom name for the connection pool being used. <code>pool_size</code> <code>nil</code> The size of the connection pool. <code>backlog</code> <code>nil</code> A queue size to use when the connection pool is full (configured with pool_size). <code>ssl</code> <code>false</code> Enable SSL. <code>ssl_verify</code> <code>nil</code> Verify server certificate. <p>You also need to create following tables in your database:</p> <pre><code>--\n-- Database table that stores session data.\n--\nCREATE TABLE IF NOT EXISTS sessions (\n  sid  CHAR(43) PRIMARY KEY,\n  name VARCHAR(255),\n  data MEDIUMTEXT,\n  exp  DATETIME,\n  INDEX (exp)\n) CHARACTER SET ascii;\n\n--\n-- Sessions metadata table.\n--\n-- This is only needed if you want to store session metadata.\n--\nCREATE TABLE IF NOT EXISTS sessions_meta (\n  aud VARCHAR(255),\n  sub VARCHAR(255),\n  sid CHAR(43),\n  PRIMARY KEY (aud, sub, sid),\n  CONSTRAINT FOREIGN KEY (sid) REFERENCES sessions(sid) ON DELETE CASCADE ON UPDATE CASCADE\n) CHARACTER SET ascii;\n</code></pre>"},{"location":"lua/session/#postgres-configuration","title":"Postgres Configuration","text":"<p>With file Postgres you can use the following settings (set the <code>storage</code> to <code>\"postgres\"</code>):</p> Option Default Description <code>host</code> <code>\"127.0.0.1\"</code> The host to connect. <code>port</code> <code>5432</code> The port to connect. <code>application</code> <code>5432</code> Set the name of the connection as displayed in pg_stat_activity (defaults to <code>\"pgmoon\"</code>). <code>username</code> <code>\"postgres\"</code> The database username to authenticate. <code>password</code> <code>nil</code> Password for authentication, may be required depending on server configuration. <code>database</code> <code>nil</code> The database name to connect. <code>table_name</code> <code>\"sessions\"</code> Name of database table to which to store session data (can be <code>database schema</code> prefixed). <code>table_name_meta</code> <code>\"sessions_meta\"</code> Name of database meta data table to which to store session meta data (can be <code>database schema</code> prefixed). <code>connect_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>connect</code> method. <code>send_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>send</code> method. <code>read_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>receive</code> method. <code>keepalive_timeout</code> <code>nil</code> Controls the default maximal idle time of the connections in the connection pool. <code>pool</code> <code>nil</code> A custom name for the connection pool being used. <code>pool_size</code> <code>nil</code> The size of the connection pool. <code>backlog</code> <code>nil</code> A queue size to use when the connection pool is full (configured with pool_size). <code>ssl</code> <code>false</code> Enable SSL. <code>ssl_verify</code> <code>nil</code> Verify server certificate. <code>ssl_required</code> <code>nil</code> Abort the connection if the server does not support SSL connections. <p>You also need to create following tables in your database:</p> <pre><code>--\n-- Database table that stores session data.\n--\nCREATE TABLE IF NOT EXISTS sessions (\n  sid  TEXT PRIMARY KEY,\n  name TEXT,\n  data TEXT,\n  exp  TIMESTAMP WITH TIME ZONE\n);\nCREATE INDEX ON sessions (exp);\n\n--\n-- Sessions metadata table.\n--\n-- This is only needed if you want to store session metadata.\n--\nCREATE TABLE IF NOT EXISTS sessions_meta (\n  aud TEXT,\n  sub TEXT,\n  sid TEXT REFERENCES sessions (sid) ON DELETE CASCADE ON UPDATE CASCADE,\n  PRIMARY KEY (aud, sub, sid)\n);\n</code></pre> <p>The implementation requires <code>pgmoon</code> which you can install with LuaRocks: <pre><code>\u276f luarocks install pgmoon\n</code></pre></p>"},{"location":"lua/session/#redis-configuration","title":"Redis Configuration","text":"<p>The session library supports single Redis, Redis Sentinel, and Redis Cluster connections. Common configuration settings among them all:</p> Option Default Description <code>prefix</code> <code>nil</code> Prefix for the keys stored in Redis. <code>suffix</code> <code>nil</code> Suffix for the keys stored in Redis. <code>username</code> <code>nil</code> The database username to authenticate. <code>password</code> <code>nil</code> Password for authentication. <code>connect_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>connect</code> method. <code>send_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>send</code> method. <code>read_timeout</code> <code>nil</code> Controls the default timeout value used in TCP/unix-domain socket object's <code>receive</code> method. <code>keepalive_timeout</code> <code>nil</code> Controls the default maximal idle time of the connections in the connection pool. <code>pool</code> <code>nil</code> A custom name for the connection pool being used. <code>pool_size</code> <code>nil</code> The size of the connection pool. <code>backlog</code> <code>nil</code> A queue size to use when the connection pool is full (configured with pool_size). <code>ssl</code> <code>false</code> Enable SSL <code>ssl_verify</code> <code>nil</code> Verify server certificate <code>server_name</code> <code>nil</code> The server name for the new TLS extension Server Name Indication (SNI). <p>The <code>single redis</code> implementation is selected when you don't pass either <code>sentinels</code> or <code>nodes</code>, which would lead to selecting <code>sentinel</code> or <code>cluster</code> implementation.</p>"},{"location":"lua/session/#single-redis-configuration","title":"Single Redis Configuration","text":"<p>Single Redis has following additional configuration options (set the <code>storage</code> to <code>\"redis\"</code>):</p> Option Default Description <code>host</code> <code>\"127.0.0.1\"</code> The host to connect. <code>port</code> <code>6379</code> The port to connect. <code>socket</code> <code>nil</code> The socket file to connect to. <code>database</code> <code>nil</code> The database to connect."},{"location":"lua/session/#redis-sentinels-configuration","title":"Redis Sentinels Configuration","text":"<p>Redis Sentinel has following additional configuration options (set the <code>storage</code> to <code>\"redis\"</code> and configure the <code>sentinels</code>):</p> Option Default Description <code>master</code> <code>nil</code> Name of master. <code>role</code> <code>nil</code> <code>\"master\"</code> or <code>\"slave\"</code>. <code>socket</code> <code>nil</code> The socket file to connect to. <code>sentinels</code> <code>nil</code> Redis Sentinels. <code>sentinel_username</code> <code>nil</code> Optional sentinel username. <code>sentinel_password</code> <code>nil</code> Optional sentinel password. <code>database</code> <code>nil</code> The database to connect. <p>The <code>sentinels</code> is an array of Sentinel records:</p> Option Default Description <code>host</code> <code>nil</code> The host to connect. <code>port</code> <code>nil</code> The port to connect. <p>The <code>sentinel</code> implementation is selected when you pass <code>sentinels</code> as part of <code>redis</code> configuration (and do not pass <code>nodes</code>, which would select <code>cluster</code> implementation).</p> <p>The implementation requires <code>lua-resty-redis-connector</code> which you can install with LuaRocks: <pre><code>\u276f luarocks install lua-resty-redis-connector\n</code></pre></p>"},{"location":"lua/session/#redis-cluster-configuration","title":"Redis Cluster Configuration","text":"<p>Redis Cluster has following additional configuration options (set the <code>storage</code> to <code>\"redis\"</code> and configure the <code>nodes</code>):</p> Option Default Description <code>name</code> <code>nil</code> Redis cluster name. <code>nodes</code> <code>nil</code> Redis cluster nodes. <code>lock_zone</code> <code>nil</code> Shared dictionary name for locks. <code>lock_prefix</code> <code>nil</code> Shared dictionary name prefix for lock. <code>max_redirections</code> <code>nil</code> Maximum retry attempts for redirection. <code>max_connection_attempts</code> <code>nil</code> Maximum retry attempts for connection. <code>max_connection_timeout</code> <code>nil</code> Maximum connection timeout in total among the retries. <p>The <code>nodes</code> is an array of Cluster node records:</p> Option Default Description <code>ip</code> <code>\"127.0.0.1\"</code> The IP address to connect. <code>port</code> <code>6379</code> The port to connect. <p>The <code>cluster</code> implementation is selected when you pass <code>nodes</code> as part of <code>redis</code> configuration.</p> <p>For <code>cluster</code> to work properly, you need to configure <code>lock_zone</code>, so also add this to your Nginx configuration:</p> <pre><code>lua_shared_dict redis_cluster_locks 100k;\n</code></pre> <p>And set the <code>lock_zone</code> to <code>\"redis_cluster_locks\"</code></p> <p>The implementation requires <code>resty-redis-cluster</code> or <code>kong-redis-cluster</code> which you can install with LuaRocks: <pre><code>\u276f luarocks install resty-redis-cluster\n## or\n\u276f luarocks install kong-redis-cluster\n</code></pre></p>"},{"location":"lua/session/#shm-configuration","title":"SHM Configuration","text":"<p>With SHM storage you can use the following settings (set the <code>storage</code> to <code>\"shm\"</code>):</p> Option Default Description <code>prefix</code> <code>nil</code> Prefix for the keys stored in SHM. <code>suffix</code> <code>nil</code> Suffix for the keys stored in SHM. <code>zone</code> <code>\"sessions\"</code> A name of shared memory zone. <p>You will also need to create a shared dictionary <code>zone</code> in Nginx:</p> <pre><code>lua_shared_dict sessions 10m;\n</code></pre> <p>Note: you may need to adjust the size of shared memory zone according to your needs.</p>"},{"location":"lua/session/#api","title":"API","text":"<p>LDoc generated API docs can also be viewed at bungle.github.io/lua-resty-session.</p>"},{"location":"lua/session/#initialization","title":"Initialization","text":""},{"location":"lua/session/#sessioninit","title":"session.init","text":"<p>syntax: session.init(configuration)</p> <p>Initialize the session library.</p> <p>This function can be called on <code>init</code> or <code>init_worker</code> phases on OpenResty to set global default configuration to all session instances created by this library.</p> <pre><code>require \"resty.session\".init({\n  audience = \"my-application\",\n  storage = \"redis\",\n  redis = {\n    username = \"session\",\n    password = \"storage\",\n  },\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#constructors","title":"Constructors","text":""},{"location":"lua/session/#sessionnew","title":"session.new","text":"<p>syntax: session = session.new(configuration)</p> <p>Creates a new session instance.</p> <pre><code>local session = require \"resty.session\".new()\n-- OR\nlocal session = require \"resty.session\".new({\n  audience = \"my-application\",\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#helpers","title":"Helpers","text":""},{"location":"lua/session/#sessionopen","title":"session.open","text":"<p>syntax: session, err, exists = session.open(configuration)</p> <p>This can be used to open a session, and it will either return an existing session or a new session. The <code>exists</code> (a boolean) return parameters tells whether it was existing or new session that was returned. The <code>err</code> (a string) contains a message of why opening might have failed (the function will still return <code>session</code> too).</p> <pre><code>local session = require \"resty.session\".open()\n-- OR\nlocal session, err, exists = require \"resty.session\".open({\n  audience = \"my-application\",\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#sessionstart","title":"session.start","text":"<p>syntax: session, err, exists, refreshed = session.start(configuration)</p> <p>This can be used to start a session, and it will either return an existing session or a new session. In case there is an existing session, the session will be refreshed as well (as needed). The <code>exists</code> (a boolean) return parameters tells whether it was existing or new session that was returned. The <code>refreshed</code> (a boolean) tells whether the call to <code>refresh</code> was succesful.  The <code>err</code> (a string) contains a message of why opening or refreshing might have failed (the function will still return <code>session</code> too).</p> <pre><code>local session = require \"resty.session\".start()\n-- OR\nlocal session, err, exists, refreshed = require \"resty.session\".start({\n  audience = \"my-application\",\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#sessionlogout","title":"session.logout","text":"<p>syntax: ok, err, exists, logged_out = session.logout(configuration)</p> <p>It logouts from a specific audience.</p> <p>A single session cookie may be shared between multiple audiences (or applications), thus there is a need to be able to logout from just a single audience while keeping the session for the other audiences. The <code>exists</code> (a boolean) return parameters tells whether session existed. The <code>logged_out</code> (a boolean) return parameter signals if the session existed and was also logged out. The <code>err</code> (a string) contains a reason why session didn't exists or why the logout failed. The <code>ok</code> (truthy) will be <code>true</code> when session existed and was successfully logged out.</p> <p>When there is only a single audience, then this can be considered equal to <code>session.destroy</code>.</p> <p>When the last audience is logged out, the cookie will be destroyed as well and invalidated on a client.</p> <pre><code>require \"resty.session\".logout()\n-- OR\nlocal ok, err, exists, logged_out = require \"resty.session\".logout({\n  audience = \"my-application\",\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#sessiondestroy","title":"session.destroy","text":"<p>syntax: ok, err, exists, destroyed = session.destroy(configuration)</p> <p>It destroys the whole session and clears the cookies.</p> <p>A single session cookie may be shared between multiple audiences (or applications), thus there is a need to be able to logout from just a single audience while keeping the session for the other audiences. The <code>exists</code> (a boolean) return parameters tells whether session existed. The <code>destroyed</code> (a boolean) return parameter signals if the session existed and was also destroyed out. The <code>err</code> (a string) contains a reason why session didn't exists or why the logout failed. The <code>ok</code> (truthy) will be <code>true</code> when session existed and was successfully logged out.</p> <pre><code>require \"resty.session\".destroy()\n-- OR\nlocal ok, err, exists, destroyed = require \"resty.session\".destroy({\n  cookie_name = \"auth\",\n})\n</code></pre> <p>See configuration for possible configuration settings.</p>"},{"location":"lua/session/#instance-methods","title":"Instance Methods","text":""},{"location":"lua/session/#sessionopen_1","title":"session:open","text":"<p>syntax: ok, err = session:open()</p> <p>This can be used to open a session. It returns <code>true</code> when session was opened and validated. Otherwise, it returns <code>nil</code> and an error message.</p> <pre><code>local session = require \"resty.session\".new()\nlocal ok, err = session:open()\nif ok then\n  -- session exists\n\nelse\n  -- session did not exists or was invalid\nend\n</code></pre>"},{"location":"lua/session/#sessionsave","title":"session:save","text":"<p>syntax: ok, err = session:save()</p> <p>Saves the session data and issues a new session cookie with a new session id. When <code>remember</code> is enabled, it will also issue a new persistent cookie and possibly save the data in backend store. It returns <code>true</code> when session was saved. Otherwise, it returns <code>nil</code> and an error message.</p> <pre><code>local session = require \"resty.session\".new()\nsession:set_subject(\"john\")\nlocal ok, err = session:save()\nif not ok then\n  -- error when saving session\nend\n</code></pre>"},{"location":"lua/session/#sessiontouch","title":"session:touch","text":"<p>syntax: ok, err = session:touch()</p> <p>Updates idling offset of the session by sending an updated session cookie. It only sends the client cookie and never calls any backend session store APIs. Normally the <code>session:refresh</code> is used to call this indirectly. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  ok, err = session:touch()\nend\n</code></pre>"},{"location":"lua/session/#sessionrefresh","title":"session:refresh","text":"<p>syntax: ok, err = session:refresh()</p> <p>Either saves the session (creating a new session id) or touches the session depending on whether the rolling timeout is getting closer, which means by default when 3/4 of rolling timeout is spent, that is 45 minutes with default rolling timeout of an hour. The touch has a threshold, by default one minute, so it may be skipped in some cases (you can call <code>session:touch()</code> to force it). In error case it returns <code>nil</code> and an error message, otherwise <code>true</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local ok, err = session:refresh()\nend\n</code></pre> <p>The above code looks a bit like <code>session.start()</code> helper.</p>"},{"location":"lua/session/#sessionlogout_1","title":"session:logout","text":"<p>syntax: ok, err = session:logout()</p> <p>Logout either destroys the session or just clears the data for the current audience, and saves it (logging out from the current audience). In error case it returns <code>nil</code> and an error message, otherwise <code>true</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local ok, err = session:logout()\nend\n</code></pre>"},{"location":"lua/session/#sessiondestroy_1","title":"session:destroy","text":"<p>syntax: ok, err = session:destroy()</p> <p>Destroy the session and clear the cookies. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local ok, err = session:destroy()\nend\n</code></pre>"},{"location":"lua/session/#sessionclose","title":"session:close","text":"<p>syntax: session:close()</p> <p>Just closes the session instance so that it cannot be used anymore.</p> <pre><code>local session = require \"resty.session\".new()\nsession:set_subject(\"john\")\nlocal ok, err = session:save()\nif not ok then\n  -- error when saving session\nend\nsession:close()\n</code></pre>"},{"location":"lua/session/#sessionset_data","title":"session:set_data","text":"<p>syntax: session:set_data(data)</p> <p>Set session data. The <code>data</code> needs to be a <code>table</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif not exists then\n   session:set_data({\n     cart = {},\n   })\n  session:save()\nend\n</code></pre>"},{"location":"lua/session/#sessionget_data","title":"session:get_data","text":"<p>syntax: data = session:get_data()</p> <p>Get session data.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local data = session:get_data()\n  ngx.req.set_header(\"Authorization\", \"Bearer \" .. data.access_token)\nend\n</code></pre>"},{"location":"lua/session/#sessionset","title":"session:set","text":"<p>syntax: session:set(key, value)</p> <p>Set a value in session.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif not exists then\n  session:set(\"access-token\", \"eyJ...\")\n  session:save()\nend\n</code></pre>"},{"location":"lua/session/#sessionget","title":"session:get","text":"<p>syntax: value = session:get(key)</p> <p>Get a value from session.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local access_token = session:get(\"access-token\")\n  ngx.req.set_header(\"Authorization\", \"Bearer \" .. access_token)\nend\n</code></pre>"},{"location":"lua/session/#sessionset_audience","title":"session:set_audience","text":"<p>syntax: session:set_audience(audience)</p> <p>Set session audience.</p> <pre><code>local session = require \"resty.session\".new()\nsession.set_audience(\"my-service\")\n</code></pre>"},{"location":"lua/session/#sessionget_audience","title":"session:get_audience","text":"<p>syntax: audience = session:get_audience()</p> <p>Set session subject.</p>"},{"location":"lua/session/#sessionset_subject","title":"session:set_subject","text":"<p>syntax: session:set_subject(subject)</p> <p>Set session audience.</p> <pre><code>local session = require \"resty.session\".new()\nsession.set_subject(\"john@doe.com\")\n</code></pre>"},{"location":"lua/session/#sessionget_subject","title":"session:get_subject","text":"<p>syntax: subject = session:get_subject()</p> <p>Get session subject.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local subject = session.get_subject()\nend\n</code></pre>"},{"location":"lua/session/#sessionget_property","title":"session:get_property","text":"<p>syntax: value = session:get_property(name)</p> <p>Get session property. Possible property names:</p> <ul> <li><code>\"id\"</code>: 43 bytes session id (same as nonce, but base64 url-encoded)</li> <li><code>\"nonce\"</code>: 32 bytes nonce (same as session id but in raw bytes)</li> <li><code>\"audience\"</code>: Current session audience</li> <li><code>\"subject\"</code>: Current session subject</li> <li><code>\"timeout\"</code>: Closest timeout (in seconds) (what's left of it)</li> <li><code>\"idling-timeout</code>\"`: Session idling timeout (in seconds) (what's left of it)</li> <li><code>\"rolling-timeout</code>\"`: Session rolling timeout (in seconds) (what's left of it)</li> <li><code>\"absolute-timeout</code>\"`: Session absolute timeout (in seconds) (what's left of it)</li> </ul> <p>Note: the returned value may be <code>nil</code>.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local timeout = session.get_property(\"timeout\")\nend\n</code></pre>"},{"location":"lua/session/#sessionset_remember","title":"session:set_remember","text":"<p>syntax: session:set_remember(value)</p> <p>Set persistent sessions on/off.</p> <p>In many login forms user is given an option for \"remember me\". You can call this function based on what user selected.</p> <pre><code>local session = require \"resty.session\".new()\nif ngx.var.args.remember then\n  session:set_remember(true)\nend\nsession:set_subject(ngx.var.args.username)\nsession:save()\n</code></pre>"},{"location":"lua/session/#sessionget_remember","title":"session:get_remember","text":"<p>syntax: remember = session:get_remember()</p> <p>Get state of persistent sessions.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local remember = session.get_remember()\nend\n</code></pre>"},{"location":"lua/session/#sessionclear_request_cookie","title":"session:clear_request_cookie","text":"<p>syntax: ok, err = session:clear_request_cookie()</p> <p>Modifies the request headers by removing the session related cookies. This is useful when you use the session library on a proxy server and don't want the session cookies to be forwarded to the upstream service. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code> (which can be ignored).</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  session:clear_request_cookie()\nend\n</code></pre>"},{"location":"lua/session/#sessionset_headers","title":"session:set_headers","text":"<p>syntax: ok, err = session:set_headers(arg1, arg2, ...)</p> <p>Sets request and response headers based on configuration. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code> (that can be ignored).</p> <pre><code>local session, err, exists = require \"resty.session\".open({\n  request_headers = { \"audience\", \"subject\", \"id\" },\n  response_headers = { \"timeout\", \"idling-timeout\", \"rolling-timeout\", \"absolute-timeout\" },\n})\nif exists then\n  session:set_headers()\nend\n</code></pre> <p>When called without arguments it will set request headers configured with <code>request_headers</code> and response headers configured with <code>response_headers</code>.</p> <p>See configuration for possible header names.</p>"},{"location":"lua/session/#sessionset_request_headers","title":"session:set_request_headers","text":"<p>syntax: ok, err = session:set_request_headers(arg1, arg2, ...)</p> <p>Set request headers. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code> (that can be ignored).</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  session:set_request_headers(\"audience\", \"subject\", \"id\")\nend\n</code></pre> <p>When called without arguments it will set request headers configured with <code>request_headers</code>.</p> <p>See configuration for possible header names.</p>"},{"location":"lua/session/#sessionset_response_headers","title":"session:set_response_headers","text":"<p>syntax: ok, err = session:set_response_headers(arg1, arg2, ...)</p> <p>Set request headers. In error case it returns <code>nil</code> and an error message, otherwise <code>true</code> (that can be ignored).</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  session:set_response_headers(\"timeout\", \"idling-timeout\", \"rolling-timeout\", \"absolute-timeout\")\nend\n</code></pre> <p>When called without arguments it will set request headers configured with <code>response_headers</code>.</p> <p>See configuration for possible header names.</p>"},{"location":"lua/session/#sessioninfoset","title":"session.info:set","text":"<p>syntax: session.info:set(key, value)</p> <p>Set a value in session information store. Session information store may be used in scenarios when you want to store data on server side storage, but do not want to create a new session and send a new session cookie. The information store data is not considered when checking authentication tag or message authentication code. Thus if you want to use this for data that needs to be encrypted, you need to encrypt value before passing it to thus function.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  session.info:set(\"last-access\", ngx.now())\n  session.info:save()\nend\n</code></pre> <p>With cookie storage this still works, but it is then almost the same as <code>session:set</code>.</p>"},{"location":"lua/session/#sessioninfoget","title":"session.info:get","text":"<p>syntax: value = session.info:get(key)</p> <p>Get a value from session information store.</p> <pre><code>local session, err, exists = require \"resty.session\".open()\nif exists then\n  local last_access = session.info:get(\"last-access\")\nend\n</code></pre>"},{"location":"lua/session/#sessioninfosave","title":"session.info:save","text":"<p>syntax: ok, err = session.info:save()</p> <p>Save information. Only updates backend storage. Does not send a new cookie (except with cookie storage).</p> <pre><code>local session = require \"resty.session\".new()\nsession.info:set(\"last-access\", ngx.now())\nlocal ok, err = session.info:save()\n</code></pre>"},{"location":"lua/session/#cookie-format","title":"Cookie Format","text":"<pre><code>[ HEADER -------------------------------------------------------------------------------------]\n[ Type || Flags || SID || Created at || Rolling Offset || Size || Tag || Idling Offset || Mac ]\n[ 1B   || 2B    || 32B || 5B         || 4B             || 3B   || 16B || 3B            || 16B ]\n</code></pre> <p>and</p> <pre><code>[ PAYLOAD --]\n[ Data  *B  ]\n</code></pre> <p>Both the <code>HEADER</code> and <code>PAYLOAD</code> are base64 url-encoded before putting in a <code>Set-Cookie</code> header. When using a server side storage, the <code>PAYLOAD</code> is not put in the cookie. With cookie storage the base64 url-encoded header is concatenated with base64 url-encoded payload.</p> <p>The <code>HEADER</code> is fixed size 82 bytes binary or 110 bytes in base64 url-encoded form.</p> <p>Header fields explained:</p> <ul> <li>Type: number <code>1</code> binary packed in a single little endian byte (currently the only supported <code>type</code>).</li> <li>Flags: binary packed flags (short) in a two byte little endian form.</li> <li>SID: <code>32</code> bytes of crypto random data (Session ID).</li> <li>Created at: binary packed secs from epoch in a little endian form, truncated to 5 bytes.</li> <li>Rolling Offset: binary packed secs from creation time in a little endian form (integer).</li> <li>Size: binary packed data size in a three byte little endian form.</li> <li>Tag: <code>16</code> bytes of authentication tag from AES-256-GCM encryption of the data.</li> <li>Idling Offset: binary packed secs from creation time + rolling offset in a little endian form, truncated to 3 bytes.</li> <li>Mac: <code>16</code> bytes message authentication code of the header.</li> </ul>"},{"location":"lua/session/#data-encryption","title":"Data Encryption","text":"<ol> <li>Initial keying material (IKM):</li> <li>derive IKM from <code>secret</code> by hashing <code>secret</code> with SHA-256, or</li> <li>use 32 byte IKM when passed to library with <code>ikm</code></li> <li>Generate 32 bytes of crypto random session id (<code>sid</code>)</li> <li>Derive 32 byte encryption key and 12 byte initialization vector with HKDF using SHA-256 (on FIPS-mode it uses PBKDF2 with SHA-256 instead)</li> <li>Use HKDF extract to derive a new key from <code>ikm</code> to get <code>key</code> (this step can be done just once per <code>ikm</code>):<ul> <li>output length: <code>32</code></li> <li>digest: <code>\"sha256\"</code></li> <li>key: <code>&lt;ikm&gt;</code></li> <li>mode: <code>extract only</code></li> <li>info: <code>\"\"</code></li> <li>salt: <code>\"\"</code></li> </ul> </li> <li>Use HKDF expand to derive <code>44</code> bytes of <code>output</code>:<ul> <li>output length: <code>44</code></li> <li>digest: <code>\"sha256\"</code></li> <li>key: <code>&lt;key&gt;</code></li> <li>mode: <code>expand only</code></li> <li>info: <code>\"encryption:&lt;sid&gt;\"</code></li> <li>salt: <code>\"\"</code></li> </ul> </li> <li>The first 32 bytes of <code>output</code> are the encryption key (<code>aes-key</code>), and the last 12 bytes are the initialization vector (<code>iv</code>)</li> <li>Encrypt <code>plaintext</code> (JSON encoded and optionally deflated) using AES-256-GCM to get <code>ciphertext</code> and <code>tag</code></li> <li>cipher: <code>\"aes-256-gcm\"</code></li> <li>key: <code>&lt;aes-key&gt;</code></li> <li>iv: <code>&lt;iv&gt;</code></li> <li>plaintext: <code>&lt;plaintext&gt;</code></li> <li>aad: use the first 47 bytes of <code>header</code> as <code>aad</code>, that includes:<ol> <li>Type</li> <li>Flags</li> <li>Session ID</li> <li>Creation Time</li> <li>Rolling Offset</li> <li>Data Size</li> </ol> </li> </ol> <p>There is a variation for <code>remember</code> cookies on step 3, where we may use <code>PBKDF2</code> instead of <code>HKDF</code>, depending  on <code>remember_safety</code> setting (we also use it in FIPS-mode). The <code>PBKDF2</code> settings:</p> <ul> <li>output length: <code>44</code></li> <li>digest: <code>\"sha256\"</code></li> <li>password: <code>&lt;key&gt;</code></li> <li>salt: <code>\"encryption:&lt;sid&gt;\"</code></li> <li>iterations: <code>&lt;1000|10000|100000|1000000&gt;</code></li> <li>pkcs5: <code>1</code> (FIPS compliant in our use case, but is needed to disable <code>SP800-132</code> based verifications, such as iteration count, see: https://docs.openssl.org/master/man7/provider-kdf/#kdf-parameters)</li> </ul> <p>Iteration counts are based on <code>remember_safety</code> setting (<code>\"Low\"</code>, <code>\"Medium\"</code>, <code>\"High\"</code>, <code>\"Very High\"</code>), if <code>remember_safety</code> is set to <code>\"None\"</code>, we will use the HDKF as above.</p> <p>Note: For backwards compatibility, we disabled the SP800-132 compliance checks on FIPS-mode. This checks that the salt length is at least 128 bits, the derived key length is at least 112 bits, and that the iteration count is at least 1000. These checks are disabled by default in OpenSSL's default provider, but are enabled by default in the FIPS provider.</p>"},{"location":"lua/session/#cookie-header-authentication","title":"Cookie Header Authentication","text":"<ol> <li>Derive 32 byte authentication key (<code>mac_key</code>) with HKDF using SHA-256  (on FIPS-mode it uses PBKDF2 with SHA-256 instead):<ol> <li>Use HKDF extract to derive a new key from <code>ikm</code> to get <code>key</code> (this step can be done just once per <code>ikm</code> and reused with encryption key generation):<ul> <li>output length: <code>32</code></li> <li>digest: <code>\"sha256\"</code></li> <li>key: <code>&lt;ikm&gt;</code></li> <li>mode: <code>extract only</code></li> <li>info: <code>\"\"</code></li> <li>salt: <code>\"\"</code></li> </ul> </li> <li>Use HKDF expand to derive <code>32</code> bytes of <code>mac-key</code>:<ul> <li>output length: <code>32</code></li> <li>digest: <code>\"sha256\"</code></li> <li>key: <code>&lt;key&gt;</code></li> <li>mode: <code>expand only</code></li> <li>info: <code>\"authentication:&lt;sid&gt;\"</code></li> <li>salt: <code>\"\"</code></li> </ul> </li> </ol> </li> <li>Calculate message authentication code using HMAC-SHA256:</li> <li>digest: <code>\"sha256\"</code></li> <li>key: <code>&lt;mac-key&gt;</code></li> <li>message: use the first 66 bytes of <code>header</code>, that includes:<ol> <li>Type</li> <li>Flags</li> <li>Session ID</li> <li>Creation Time</li> <li>Rolling Offset</li> <li>Data Size</li> <li>Tag</li> <li>Idling Offset</li> </ol> </li> </ol>"},{"location":"lua/session/#custom-storage-interface","title":"Custom Storage Interface","text":"<p>If you want to implement custom storage, you need to implement following interface:</p> <pre><code>---\n-- &lt;custom&gt; backend for session library\n--\n-- @module &lt;custom&gt;\n\n\n---\n-- Storage\n-- @section instance\n\n\nlocal metatable = {}\n\n\nmetatable.__index = metatable\n\n\nfunction metatable.__newindex()\n  error(\"attempt to update a read-only table\", 2)\nend\n\n\n---\n-- Store session data.\n--\n-- @function instance:set\n-- @tparam string name cookie name\n-- @tparam string key session key\n-- @tparam string value session value\n-- @tparam number ttl session ttl\n-- @tparam number current_time current time\n-- @tparam[opt] string old_key old session id\n-- @tparam string stale_ttl stale ttl\n-- @tparam[opt] table metadata table of metadata\n-- @treturn true|nil ok\n-- @treturn string error message\nfunction metatable:set(name, key, value, ttl, current_time, old_key, stale_ttl, metadata)\n  -- NYI\nend\n\n\n---\n-- Retrieve session data.\n--\n-- @function instance:get\n-- @tparam string name cookie name\n-- @tparam string key session key\n-- @treturn string|nil session data\n-- @treturn string error message\nfunction metatable:get(name, key)\n  -- NYI\nend\n\n\n---\n-- Delete session data.\n--\n-- @function instance:delete\n-- @tparam string name cookie name\n-- @tparam string key session key\n-- @tparam[opt] table metadata  session meta data\n-- @treturn boolean|nil session data\n-- @treturn string error message\nfunction metatable:delete(name, key, current_time, metadata)\n  -- NYI\nend\n\n\nlocal storage = {}\n\n\n---\n-- Constructors\n-- @section constructors\n\n\n---\n-- Configuration\n-- @section configuration\n\n\n---\n-- &lt;custom&gt; storage backend configuration\n-- @field &lt;field-name&gt; TBD\n-- @table configuration\n\n\n---\n-- Create a &lt;custom&gt; storage.\n--\n-- This creates a new shared memory storage instance.\n--\n-- @function module.new\n-- @tparam[opt]  table   configuration  &lt;custom&gt; storage @{configuration}\n-- @treturn      table                  &lt;custom&gt; storage instance\nfunction storage.new(configuration)\n  -- NYI\n  -- return setmetatable({}, metatable)\nend\n\n\nreturn storage\n</code></pre> <p>Please check the existing implementations for the defails. And please make a pull-request so that we can integrate it directly to library for other users as well.</p>"},{"location":"lua/session/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-session.</p>"},{"location":"lua/shell/","title":"shell: Lua module for nonblocking system shell command executions","text":""},{"location":"lua/shell/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/shell/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-shell\n</code></pre>"},{"location":"lua/shell/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-shell\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-shell v0.3  released on Jul 01 2020.</p> <p>lua-resty-shell - Lua module for nonblocking system shell command executions</p>"},{"location":"lua/shell/#synopsis","title":"Synopsis","text":"<pre><code>local shell = require \"resty.shell\"\n\nlocal stdin = \"hello\"\nlocal timeout = 1000  -- ms\nlocal max_size = 4096  -- byte\n\nlocal ok, stdout, stderr, reason, status =\n    shell.run([[perl -e 'warn \"he\\n\"; print &lt;&gt;']], stdin, timeout, max_size)\nif not ok then\n    -- ...\nend\n</code></pre>"},{"location":"lua/shell/#functions","title":"Functions","text":""},{"location":"lua/shell/#run","title":"run","text":"<p>syntax: <code>ok, stdout, stderr, reason, status = shell.run(cmd, stdin?, timeout?, max_size?)</code></p> <p>context: <code>all phases supporting yielding</code></p> <p>Runs a shell command, <code>cmd</code>, with an optional stdin.</p> <p>The <code>cmd</code> argument can either be a single string value (e.g. <code>\"echo 'hello, world'\"</code>) or an array-like Lua table (e.g. <code>{\"echo\", \"hello, world\"}</code>). The former is equivalent to <code>{\"/bin/sh\", \"-c\", \"echo 'hello, world'\"}</code>, but simpler and slightly faster.</p> <p>When the <code>stdin</code> argument is <code>nil</code> or <code>\"\"</code>, the stdin device will immediately be closed.</p> <p>The <code>timeout</code> argument specifies the timeout threshold (in ms) for stderr/stdout reading timeout, stdin writing timeout, and process waiting timeout.</p> <p>The <code>max_size</code> argument specifies the maximum size allowed for each output data stream of stdout and stderr. When exceeding the limit, the <code>run()</code> function will immediately stop reading any more data from the stream and return an error string in the <code>reason</code> return value: <code>\"failed to read stdout: too much data\"</code>.</p> <p>Upon terminating successfully (with a zero exit status), <code>ok</code> will be <code>true</code>, <code>reason</code> will be <code>\"exit\"</code>, and <code>status</code> will hold the sub-process exit status.</p> <p>Upon terminating abnormally (non-zero exit status), <code>ok</code> will be <code>false</code>, <code>reason</code> will be <code>\"exit\"</code>, and <code>status</code> will hold the sub-process exit status.</p> <p>Upon exceeding a timeout threshold or any other unexpected error, <code>ok</code> will be <code>nil</code>, and <code>reason</code> will be a string describing the error.</p> <p>When a timeout threshold is exceeded, the sub-process will be terminated as such:</p> <ol> <li>first, by receiving a <code>SIGTERM</code> signal from this library,</li> <li>then, after 1ms, by receiving a <code>SIGKILL</code> signal from this library.</li> </ol> <p>Note that child processes of the sub-process (if any) will not be terminated. You may need to terminate these processes yourself.</p> <p>When the sub-process is terminated by a UNIX signal, the <code>reason</code> return value will be <code>\"signal\"</code> and the <code>status</code> return value will hold the signal number.</p>"},{"location":"lua/shell/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-shell.</p>"},{"location":"lua/signal/","title":"signal: Lua library for killing or sending signals to UNIX processes","text":""},{"location":"lua/signal/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/signal/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-signal\n</code></pre>"},{"location":"lua/signal/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-signal\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-signal v0.4  released on Aug 08 2024.</p> <p>lua-resty-signal - Lua library for killing or sending signals to Linux processes</p>"},{"location":"lua/signal/#synopsis","title":"Synopsis","text":"<pre><code>local resty_signal = require \"resty.signal\"\nlocal pid = 12345\n\nlocal ok, err = resty_signal.kill(pid, \"TERM\")\nif not ok then\n    ngx.log(ngx.ERR, \"failed to kill process of pid \", pid, \": \", err)\n    return\nend\n\n-- send the signal 0 to check the existence of a process\nlocal ok, err = resty_signal.kill(pid, \"NONE\")\n\nlocal ok, err = resty_signal.kill(pid, \"HUP\")\n\nlocal ok, err = resty_signal.kill(pid, \"KILL\")\n</code></pre>"},{"location":"lua/signal/#functions","title":"Functions","text":""},{"location":"lua/signal/#kill","title":"kill","text":"<p>syntax: <code>ok, err = resty_signal.kill(pid, signal_name_or_num)</code></p> <p>Sends a signal with its name string or number value to the process of the specified pid.</p> <p>All signal names accepted by signum are supported, like <code>HUP</code>, <code>KILL</code>, and <code>TERM</code>.</p> <p>Signal numbers are also supported when specifying nonportable system-specific signals is desired.</p>"},{"location":"lua/signal/#signum","title":"signum","text":"<p>syntax: <code>num = resty_signal.signum(sig_name)</code></p> <p>Maps the signal name specified to the system-specific signal number. Returns <code>nil</code> if the signal name is not known.</p> <p>All the POSIX and BSD signal names are supported:</p> <pre><code>HUP\nINT\nQUIT\nILL\nTRAP\nABRT\nBUS\nFPE\nKILL\nUSR1\nSEGV\nUSR2\nPIPE\nALRM\nTERM\nCHLD\nCONT\nSTOP\nTSTP\nTTIN\nTTOU\nURG\nXCPU\nXFSZ\nVTALRM\nPROF\nWINCH\nIO\nPWR\nEMT\nSYS\nINFO\n</code></pre> <p>The special signal name <code>NONE</code> is also supported, which is mapped to zero (0).</p>"},{"location":"lua/signal/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-signal.</p>"},{"location":"lua/smtp/","title":"smtp: Send mail with NGINX","text":""},{"location":"lua/smtp/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/smtp/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-smtp\n</code></pre>"},{"location":"lua/smtp/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-smtp\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-smtp v0.0.3  released on Mar 06 2015.</p> <p>I must be crazy trying to send mail with Nginx. </p>"},{"location":"lua/smtp/#purpose","title":"Purpose","text":"<p>To make Nginx a bridge between HTTP and SMTP.</p> <p>Using <code>lua-resty-smtp</code> in your lua code under Nginx, you just need to issue a  HTTP request with your handy HTTP client (<code>curl</code>, <code>wget</code>, <code>urllib2</code> from Python etc.), in order to send a mail to your SMTP server.</p>"},{"location":"lua/smtp/#features","title":"Features","text":"<ul> <li> <p>Based on module <code>socket.smtp</code> from LuaScoket 2.0.2,  and API-compatible with it also</p> </li> <li> <p>SSL connection supported (lua-nginx-lua &gt;= v0.9.11 needed)</p> </li> </ul>"},{"location":"lua/smtp/#apis","title":"APIs","text":"<p><code>lua-resty-smtp</code> is API-compatible with <code>socket.smtp</code> from LuaSocket 2.0.2, and you can check SMTP for detailed reference of it.</p> <p>And to support SSL connection to SMTP server, optional parameter <code>ssl</code> is added:</p> <ul> <li> <p><code>ssl</code>: should be a table with following fields:</p> <ul> <li> <p><code>enable</code> - boolean - whether or not use SSL connection to SMTP server, default <code>false</code>;</p> </li> <li> <p><code>verify_cert</code> - boolean - whether or not to perform SSL verification, default <code>false</code>. When set to <code>true</code>, the server certificate will be verified according to the CA certificate specified by the <code>lua_ssl_trusted_cerfificate</code> directive.</p> </li> </ul> </li> </ul>"},{"location":"lua/smtp/#extra-filters","title":"Extra filters","text":"<p>In addtion to the low-level filters provided by LuaSocket, two more filters is provided:</p> <ul> <li> <p><code>mime.ew</code>: used to encode non-ASCII string into the  Encoded-Word format (not support Q-encoding yet);</p> </li> <li> <p><code>mime.unew</code>: used to decode string in Encoded-Word format (not implemented);</p> </li> </ul>"},{"location":"lua/smtp/#example","title":"Example","text":"<pre><code>local config = require(\"config\")\nlocal smtp = require(\"resty.smtp\")\nlocal mime = require(\"resty.smtp.mime\")\nlocal ltn12 = require(\"resty.smtp.ltn12\")\n\n-- ...\n-- Suppose your mail data in table `args` and default settings \n-- in table `config.mail`\n-- ...\n\nlocal mesgt = { \n    headers= {\n        subject= mime.ew(args.subject or config.mail.SUBJECT, nil, \n                         { charset= \"utf-8\" }), \n        [\"content-transfer-encoding\"]= \"BASE64\",\n        [\"content-type\"]= \"text/plain; charset='utf-8'\",\n    },\n\n    body= mime.b64(args.body)\n}\n\nlocal ret, err = smtp.send {\n    from= args.from or config.mail.FROM,\n    rcpt= rcpts,\n    user= args.user or config.mail.USER,\n    password= args.password or config.mail.PASSWORD,\n    server= args.server or config.mail.SERVER,\n    domain= args.domain or config.mail.DOMAIN,\n    source= smtp.message(mesgt),\n}\n</code></pre>"},{"location":"lua/smtp/#performance","title":"Performance","text":"<p>Your SMTP server is the bottleneck. :)</p>"},{"location":"lua/smtp/#known-issues","title":"Known Issues","text":"<ul> <li>Only work with LuaJIT 2.x now, because the codebase relies on <code>pcall</code>   massively and lua-nginx-module does not work well with standard Lua 5.1 VM    under this situation. See Known Issues</li> </ul>"},{"location":"lua/smtp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-smtp.</p>"},{"location":"lua/snappy/","title":"snappy: LuaJIT FFI bindings for Snappy, a fast compressor/decompressor (https://code.google.com/p/snappy/)","text":""},{"location":"lua/snappy/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/snappy/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-snappy\n</code></pre>"},{"location":"lua/snappy/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-snappy\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-snappy v1.0  released on Oct 01 2014.</p> <p><code>lua-resty-snappy</code> provides LuaJIT FFI bindings to Snappy, a fast compressor/decompressor (https://code.google.com/p/snappy/).</p>"},{"location":"lua/snappy/#lua-api","title":"Lua API","text":""},{"location":"lua/snappy/#error-codes","title":"Error Codes","text":"<pre><code>  SNAPPY_OK               = 0,\n  SNAPPY_INVALID_INPUT    = 1,\n  SNAPPY_BUFFER_TOO_SMALL = 2\n</code></pre>"},{"location":"lua/snappy/#stringlen-snappycompressinput","title":"string,len snappy.compress(input)","text":"<p>Compresses <code>input</code> with Snappy algorithm, and returns compressed data and its length. On error this will return nil and an error code.</p>"},{"location":"lua/snappy/#example","title":"Example","text":"<pre><code>local snappy    = require \"resty.snappy\"\nlocal comp, err = snappy.compress(\"test\")\nif comp then\n    -- do something with compressed data and length\n    -- (length is stored in err value)...\nelse\n    if err = 1 then\n        print \"Invalid input\"\n    elseif err == 2 then\n        print \"Buffer too small\"\n    end\nend\n</code></pre>"},{"location":"lua/snappy/#stringlen-snappyuncompresscompressed","title":"string,len snappy.uncompress(compressed)","text":"<p>Uncompresses <code>compressed</code> with Snappy algorithm, and returns uncompressed data and its length. On error this will return nil and an error code.</p>"},{"location":"lua/snappy/#example_1","title":"Example","text":"<pre><code>local snappy      = require \"resty.snappy\"\nlocal uncomp, err = snappy.uncompress(snappy.compress(\"test\"))\n</code></pre>"},{"location":"lua/snappy/#number-snappymax_compressed_lengthsource_length","title":"number snappy.max_compressed_length(source_length)","text":"<p>Returns maximum-possible length as a number of bytes of compressed data when uncompressed <code>source_length</code> is given. This is used to create buffer for compressing, but can also be used in quick measurement (and it may have nothing to do with final compressed output length, other than it cannot be larger than what this function returns).</p>"},{"location":"lua/snappy/#example_2","title":"Example","text":"<pre><code>local snappy = require \"resty.snappy\"\nlocal number = snappy.max_compressed_length(1000)\n</code></pre>"},{"location":"lua/snappy/#number-snappyuncompressed_lengthcompressed","title":"number snappy.uncompressed_length(compressed)","text":"<p>This is quicker way (than using <code>snappy.uncompress</code> to determine how many bytes the compressed data will be when it is uncompressed.</p>"},{"location":"lua/snappy/#example_3","title":"Example","text":"<pre><code>local snappy = require \"resty.snappy\"\nlocal number = snappy.uncompressed_length(snappy.compress(\"test\"))\n</code></pre>"},{"location":"lua/snappy/#boolean-snappyvalidate_compressed_buffercompressed","title":"boolean snappy.validate_compressed_buffer(compressed)","text":"<p>This can be used to check if the compressed bytes are actually Snappy compressed bytes or something else. I.e. something that can be uncompressed with Snappy.</p>"},{"location":"lua/snappy/#example_4","title":"Example","text":"<pre><code>local snappy = require \"resty.snappy\"\nlocal bool   = snappy.validate_compressed_buffer(snappy.compress(\"test\"))\n</code></pre>"},{"location":"lua/snappy/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-snappy.</p>"},{"location":"lua/sniproxy/","title":"sniproxy: SNI Proxy based on stream-lua-nginx-module","text":""},{"location":"lua/sniproxy/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/sniproxy/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-sniproxy\n</code></pre>"},{"location":"lua/sniproxy/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-sniproxy\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-sniproxy v0.22  released on Aug 31 2020.</p> <p>lua-resty-sniproxy - SNI Proxy based on the ngx_lua cosocket API</p>"},{"location":"lua/sniproxy/#description","title":"Description","text":"<p>This library is an SNI proxy written in Lua. TLS parsing part is rewritten from dlundquist/sniproxy</p> <p>Note that nginx stream module and ngx_stream_lua_module is required.</p> <p>Tested on Openresty &gt;= 1.9.15.1.</p>"},{"location":"lua/sniproxy/#status","title":"Status","text":"<p>Experimental.</p>"},{"location":"lua/sniproxy/#synopsis","title":"Synopsis","text":"<pre><code>stream {\n    init_by_lua_block {\n        local sni = require(\"resty.sniproxy\")\n        sni.rules = { \n            {\"www.google.com\", \"www.google.com\", 443},\n            {\"www.facebook.com\", \"9.8.7.6\", 443},\n            {\"api.twitter.com\", \"1.2.3.4\"},\n            {\".+.twitter.com\", nil, 443},\n            -- to activate this rule, you must use Lua land proxying\n            -- {\"some.service.svc\", \"unix:/var/run/nginx-proxy-proto.sock\", nil, sni.SNI_PROXY_PROTOCOL_UPSTREAM},\n            -- {\"some2.service.svc\", \"unix:/var/run/nginx-proxy-proto.sock\", nil,\n            --                            sni.SNI_PROXY_PROTOCOL_UPSTREAM + sni.SNI_PROXY_PROTOCOL},\n            {\".\", \"unix:/var/run/nginx-default.sock\"}\n        }   \n    }\n\n    # for OpenResty &gt;= 1.13.6.1, native Nginx proxying\n    lua_add_variable $sniproxy_upstream;\n    server {\n            error_log /var/log/nginx/sniproxy-error.log error;\n            listen 443;\n\n            resolver 8.8.8.8;\n\n            prepread_by_lua_block {\n                    local sni = require(\"resty.sniproxy\")\n                    local sp = sni:new()\n                    sp:preread_by()\n            }\n            proxy_pass $sniproxy_upstream;\n    }\n\n    # for OpenResty &lt; 1.13.6.1 or `flags` are configured, Lua land proxying\n    server {\n            error_log /var/log/nginx/sniproxy-error.log error;\n            listen 443;\n\n            resolver 8.8.8.8;\n\n            content_by_lua_block {\n                    local sni = require(\"resty.sniproxy\")\n                    local sp = sni:new()\n                    sp:content_by()\n            }\n    }\n}\n</code></pre> <p>A Lua array table <code>sni_rules</code> should be defined in the <code>init_worker_by_lua_block</code> directive.</p> <p>The first value can be either whole host name or regular expression. Use <code>.</code> for a default host name. If no entry is matched, connection will be closed.</p> <p>The second and third values are target host name and port. A host can be DNS name, IP address or UNIX domain socket path. If host is not defined or set to <code>nil</code>, server_name in SNI will be used. If the port is not defined or set to <code>nil</code> , 443 will be used.</p> <p>The forth value is the flags to use. Available flags are:</p> <pre><code>    sni.SNI_PROXY_PROTOCOL -- use client address received from proxy protocol to send to upstream\n    sni.SNI_PROXY_PROTOCOL_UPSTREAM -- send proxy protocol v1 handshake to upstream\n</code></pre> <p>To use flags, the server must be configured to do Lua land proxying (see above example).</p> <p>Rules are applied with the priority as its occurrence sequence in the table. In the example above, api.twitter.com will match the third rule api.twitter.com rather than the fourth .+.twitter.com.</p> <p>If the protocol version is less than TLSv1 (eg. SSLv3, SSLv2), connection will be closed, since SNI extension is not supported in these versions.</p>"},{"location":"lua/sniproxy/#see-also","title":"See Also","text":"<ul> <li>the ngx_stream_lua_module: https://github.com/openresty/stream-lua-nginx-module</li> <li>[dlundquist/sniproxy] (https://github.com/dlundquist/sniproxy)</li> <li>[ngx_stream_ssl_preread_module] (https://nginx.org/en/docs/stream/ngx_stream_ssl_preread_module.html) is available since Nginx 1.11.5 as an alternative to this module.</li> </ul>"},{"location":"lua/sniproxy/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-sniproxy.</p>"},{"location":"lua/socket/","title":"socket: Automatic LuaSocket/cosockets compatibility module","text":""},{"location":"lua/socket/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/socket/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-socket\n</code></pre>"},{"location":"lua/socket/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-socket\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-socket v1.0.0  released on Jan 18 2019.</p> <p>cosocket/LuaSocket automatic compatibility module for lua-resty modules wanting to be compatible with plain Lua or OpenResty's <code>init</code> context.</p> <p>The use case for this library is: you are developing a lua-resty module relying on cosockets, but you want it to also be usable in OpenResty's <code>init</code> context or even in plain Lua. This module aims at always providing your library with sockets that will be compatible in the current context, saving you time and effort, and extending LuaSocket's API to match that of cosockets, allowing you to always write your code as if you were in a cosocket-compatible OpenResty context.</p>"},{"location":"lua/socket/#features","title":"Features","text":"<ul> <li>Allows your lua-resty modules to automatically use cosockets/LuaSocket</li> <li>Provides <code>sslhandshake</code> proxy when using LuaSocket, with a dependency on   LuaSec</li> <li>Does not get blocked to using LuaSocket in further contexts if loaded in the   ngx_lua <code>init</code> (easy mistake to make)</li> <li>Memoizes underlying socket methods for performance</li> <li>Outputs a warning log for your users when spawning a socket using LuaSocket   while in OpenResty</li> </ul>"},{"location":"lua/socket/#motivation","title":"Motivation","text":"<p>The aim of this module is to provide an automatic fallback to LuaSocket when [ngx_lua]'s cosockets are not available. That is: - When not used in ngx_lua - In ngx_lua contexts where cosockets are not supported (<code>init</code>, <code>init_worker</code>, etc...)</p> <p>When falling back to LuaSocket, it provides you with shims for cosocket-only functions such as <code>getreusedtimes</code>, <code>setkeepalive</code> etc...</p> <p>It comes handy when one is developing a module/library that aims at being either compatible with both ngx_lua and plain Lua, or in ngx_lua contexts such as <code>init</code>.</p>"},{"location":"lua/socket/#libraries-using-it","title":"Libraries using it","text":"<p>Here are some concrete examples uses of this module. You can see how we only write code as if we were constantly in an cosocket-compatible OpenResty context, which greatly simplifies our work and provides out of the box plain Lua compatibility.</p> <ul> <li>lua-cassandra: see how the   cassandra   module is compatible in both OpenResty and plain Lua with no efforts or   special code paths distinguishing cosockets and LuaSocket.</li> </ul>"},{"location":"lua/socket/#important-note","title":"Important note","text":"<p>The use of LuaSocket inside ngx_lua is very strongly discouraged due to its blocking nature. However, it is fine to use it in the <code>init</code> context where blocking is not considered harmful.</p> <p>In the future, only the <code>init</code> phase will allow falling back to LuaSocket.</p> <p>It currently only support TCP sockets.</p>"},{"location":"lua/socket/#usage","title":"Usage","text":"<p>All of the available functions follow the same prototype as the cosocket API, allowing this example to run in any ngx_lua context or outside ngx_lua altogether: <pre><code>local socket = require 'resty.socket'\nlocal sock = socket.tcp()\n\ngetmetatable(sock) == socket.luasocket_mt ---&gt; true/false depending on underlying socket\n\nsock:settimeout(1000) ---&gt; 1000ms translated to 1s if LuaSocket\n\nsock:getreusedtimes(...) ---&gt; 0 if LuaSocket\n\nsock:setkeepalive(...) ---&gt; calls close() if LuaSocket\n\nsock:sslhandshake(...) ---&gt; LuaSec dependency if LuaSocket\n</code></pre></p> <p>As such, one can write a module relying on TCP sockets such as: <pre><code>local socket = require 'resty.socket'\n\nlocal _M = {}\n\nfunction _M.new()\n  local sock = socket.tcp() -- similar to ngx.socket.tcp()\n\n  return setmetatable({\n    sock = sock\n  }, {__index = _M})\nend\n\nfunction _M:connect(host, port)\n  local ok, err = self.sock:connect(host, port)\n  if not ok then\n    return nil, err\n  end\n\n  local times, err = self.sock:getreusedtimes() -- cosocket API\n  if not times then\n    return nil, err\n  elseif times == 0 then\n    -- handle connection\n  end\nend\n\nreturn _M\n</code></pre></p> <p>The user of such a module could use it in contexts with cosocket support, or in the <code>init</code> phase of ngx_lua, with little effort from the developer.</p>"},{"location":"lua/socket/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-socket.</p>"},{"location":"lua/stats/","title":"stats: Is a statistical module for nginx base on nginx-module-lua, Statistical key and values are configurable, can use the nginx core's variables and this module's variables. The statistical result store in mongodb","text":""},{"location":"lua/stats/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/stats/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-stats\n</code></pre>"},{"location":"lua/stats/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-stats\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-stats v1.0.3  released on Nov 28 2020.</p> <p>lua-resty-stats - is a statistical module for nginx base on ngx_lua, Statistical key and values are configurable, can use the nginx core's variables and this module's variables. The statistical result store in mongodb.</p>"},{"location":"lua/stats/#synopsis","title":"Synopsis","text":"<pre><code>    #set ngx_lua's environment variable:\n    # init the lua-resty-stats\n    init_worker_by_lua '\n        local stats = require(\"resty.stats\")\n        -- add the default stats that named \"stats_host\"\n        stats.add_def_stats()\n        -- the general stats\"s config\n        local update = {[\"$inc\"]= {count=1, [\"hour_cnt.$hour\"]=1, [\"status.$status\"]=1, \n                      [\"req_time.all\"]=\"$request_time\", [\"req_time.$hour\"]=\"$request_time\"}}\n\n        -- stats by uri\n        stats.add_stats_config(\"stats_uri\", \n            {selector={date=\"$date\",key=\"$uri\"}, update=update,\n             indexes={{keys={'date', 'key'}, options={unique=true}},{keys={'key'}, options={}}} })\n\n        -- stats by arg        \n        stats.add_stats_config(\"stats_arg\", \n            {selector={date=\"$date\",key=\"$arg_client_type\"}, update=update,\n             indexes={{keys={'date', 'key'}, options={unique=true}},{keys={'key'}, options={}}} })\n\n        -- stats by uri and args \n        stats.add_stats_config(\"stats_uri_arg\", \n            {selector={date=\"$date\",key=\"$uri?$arg_from\"}, update=update,\n             indexes={{keys={'date', 'key'}, options={unique=true}},{keys={'key'}, options={}}} })\n\n        -- stats by http request header\n        stats.add_stats_config(\"stats_header_in\", \n            {selector={date=\"$date\",key=\"city:$http_city\"}, update=update,\n             indexes={{keys={'date', 'key'}, options={unique=true}},{keys={'key'}, options={}}} })\n\n        -- stats by http response header\n        stats.add_stats_config(\"stats_header_out\", \n            {selector={date=\"$date\",key=\"cache:$sent_http_cache\"}, update=update,\n             indexes={{keys={'date', 'key'}, options={unique=true}},{keys={'key'}, options={}}} })\n\n        local mongo_cfg = {host=\"192.168.1.201\", port=27017, dbname=\"ngx_stats\"}\n        local flush_interval = 2 -- second\n        local retry_interval = 0.2 -- second\n        -- init stats and start flush timer.\n        stats.init(mongo_cfg, flush_interval, retry_interval)\n    ';\n    server {\n        listen       80;\n        server_name  localhost;\n\n        location /byuri {            \n            echo \"byuri: $uri\";\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_uri\")\n                stats.log(\"stats_host\")\n            ';\n        }\n\n        location /byarg {\n            echo_sleep 0.005;    \n            echo \"login $args\";\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_arg\")\n            ';\n        }\n\n        location /byarg/404 {\n            request_stats statby_arg \"clitype:$arg_client_type\";        \n            return 404;\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_arg\")\n            ';\n        }\n\n        location /byuriarg {\n            echo \"$uri?$args\";\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_uri_arg\")\n            ';\n        }\n\n        location /byhttpheaderin {\n            echo \"city: $http_city\";\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_header_in\")\n            ';\n        }\n\n        location /byhttpheaderout/ {\n            proxy_pass http://127.0.0.1:82;\n            log_by_lua '\n                local stats = require(\"resty.stats\")\n                stats.log(\"stats_header_out\")\n            ';\n        }\n    }\n\n    server {\n        listen       82;\n        server_name  localhost;\n            location /byhttpheaderout/hit {\n            add_header cache hit;\n            echo \"cache: hit\";\n        }\n        location /byhttpheaderout/miss {\n            add_header cache miss;\n            echo \"cache: miss\";\n        }\n    }\n\n    server {\n        listen 2000;\n        server_name localhost;\n\n        location /stats {\n            set $template_root /path/to/lua-resty-stats/view;\n            content_by_lua_file '/path/to/lua-resty-stats/view/main.lua';\n        }\n    }\n</code></pre>"},{"location":"lua/stats/#variables","title":"Variables","text":"<ul> <li>nginx_core module supports variable: http://nginx.org/en/docs/http/ngx_http_core_module.html#variables </li> <li>This module variables <ul> <li>date: current date in the format: 1970-09-28 </li> <li>time: current time in the format: 12:00:00 </li> <li>year: current year </li> <li>month: current month </li> <li>day: current date </li> <li>hour: current hour </li> <li>minute: current minute </li> <li>second: current second </li> </ul> </li> </ul>"},{"location":"lua/stats/#methods","title":"Methods","text":"<p>To load this library,</p> <p>you need to specify this library's path in ngx_lua's lua_package_path directive. For example: <pre><code>http {\n}\n</code></pre></p> <p>you use require to load the library into a local Lua variable: <pre><code>local stats = require(\"resty.stats\")\n</code></pre></p>"},{"location":"lua/stats/#add_def_stats","title":"add_def_stats","text":"<p><code>syntax: stats.add_def_stats()</code></p> <p>add the predefined stats configs that contains: <pre><code>stats_name: stats_host\nstats_config:\n{\n    selector={date='$date',key='$host'}, \n    update={['$inc']= {count=1, ['hour_cnt.$hour']=1, ['status.$status']=1, \n            ['req_time.all']=\"$request_time\", ['req_time.$hour']=\"$request_time\"}},\n            indexes={\n                {keys={'date', 'key'}, options={unique=true}},\n                {keys={'key'}, options={}}\n            },\n    }\n}\n</code></pre> After this method is called, when you used stats.log(stats_name) method, you can use these predefined statistics.</p>"},{"location":"lua/stats/#add_stats_config","title":"add_stats_config","text":"<p><code>syntax: stats.add_stats_config(stats_name, stats_config)</code></p> <p>Add a custom statistical configuration item that contains stats_name and stats config. * <code>stats_name</code> is the name of the statistics, and also is the name of the mongodb's table.  The name will be used when calling the <code>stats.log(stats_name)</code> method. * <code>stats_config</code> is used to define the values of statistics.   <code>stats_config</code> is a table that contains some fileds:     * <code>selector</code> a mongodb query statement. like: <code>{date=\"$date\",key=\"$host\"}</code>     * <code>update</code> a mongodb update statement. like: <code>{[\"$inc\"]= {count=1, [\"hour_cnt.$hour\"]=1, [\"status.$status\"]=1,                        [\"req_time.all\"]=\"$request_time\", [\"req_time.$hour\"]=\"$request_time\"}}</code>     * <code>indexes</code> a table that contains all fields of the index.</p> <p>The <code>selector</code> and <code>update</code> configuration can use variables.   Note that \"$inc\" is not a nginx variable, it's a mongodb's operator. </p>"},{"location":"lua/stats/#init","title":"init","text":"<p><code>syntax: stats.init(mongo_cfg, flush_interval, retry_interval)</code></p> <p>Initialization statistical library. * <code>mongo_cfg</code> The mongodb configuration, contains fields:     * <code>host</code> mongodb's host     * <code>port</code> mongodb's port     * <code>dbname</code> mongodb's database name. * <code>flush_interval</code> flush data to the mongodb time interval, the time unit is seconds. * <code>retry_interval</code> the retry time interval on flush error,the time unit is seconds.</p>"},{"location":"lua/stats/#log","title":"log","text":"<p><code>syntax: stats.log(stats_name)</code></p> <p>Collect the specified(by stats_name) statistical information at the log phrase. * <code>stats_name</code>  is one statistical name that add by <code>stats.add_stats_config</code>.  if the <code>stats_name</code> is nil, log method will collect all the statistics that have been configured.</p>"},{"location":"lua/stats/#simple-query-and-api","title":"Simple Query And API","text":"<p>lua-resty-stats with a simple query page and API interface, which can be used in the following steps: * add location configuration to nginx.conf</p> <pre><code>location /stats {\n    set $template_root /path/to/lua-resty-stats/view;\n    content_by_lua_file '/path/to/lua-resty-stats/view/main.lua';\n}\n</code></pre> <ul> <li>Access query page. eg. <code>http://192.168.1.xxx/stats</code>:</li> </ul> <p></p> <ul> <li>Access API:</li> </ul> <pre><code>## by date\ncurl http://127.0.0.1:8020/stats/api?table=stats_uri&amp;date=2020-02-20&amp;limit=100\n## by date, today\ncurl http://127.0.0.1:8020/stats/api?table=stats_uri&amp;date=today&amp;limit=10\n\n## by key(The date parameter is ignored.)\ncurl http://127.0.0.1:8020/stats/api?table=stats_uri&amp;key=/path/to/uri\n</code></pre> <ul> <li>The API response will look something like this:</li> </ul> <pre><code>{\n    \"stats\": [\n        {\n            \"hour_cnt\": {\n                \"19\": 24\n            },\n            \"count\": 24,\n            \"status\": {\n                \"200\": 24\n            },\n            \"total\": 24,\n            \"req_time\": {\n                \"19\": 13.262,\n                \"all\": 13.262\n            },\n            \"percent\": 100,\n            \"key\": \"/path/to/uri\",\n            \"date\": \"2020-09-24\"\n        }\n    ]\n}\n</code></pre> <p>If you've configured some other fields in your update, this will be different</p>"},{"location":"lua/stats/#simple-demo","title":"Simple Demo","text":"<p>Simple Stats demo</p> <p>You can include it in nginx.conf using the include directive. Such as: <code>include /path/to/simple_stats.conf;</code></p>"},{"location":"lua/stats/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-stats.</p>"},{"location":"lua/string/","title":"string: String utilities and common hash functions for nginx-module-lua and LuaJIT","text":""},{"location":"lua/string/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/string/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-string\n</code></pre>"},{"location":"lua/string/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-string\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-string v0.16  released on Aug 08 2024.</p> <p>lua-resty-string - String utilities and common hash functions for ngx_lua and LuaJIT</p>"},{"location":"lua/string/#status","title":"Status","text":"<p>This library is considered experimental and still under active development.</p> <p>The API is still in flux and may change without notice.</p>"},{"location":"lua/string/#description","title":"Description","text":"<p>This library requires an nginx build with OpenSSL, the ngx_lua module, and LuaJIT 2.0.</p>"},{"location":"lua/string/#synopsis","title":"Synopsis","text":"<pre><code>    # nginx.conf:\n\n    server {\n        location = /test {\n            content_by_lua_file conf/test.lua;\n        }\n    }\n\n    -- conf/test.lua:\n\n    local resty_sha1 = require \"resty.sha1\"\n\n    local sha1 = resty_sha1:new()\n    if not sha1 then\n        ngx.say(\"failed to create the sha1 object\")\n        return\n    end\n\n    local ok = sha1:update(\"hello, \")\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n    ok = sha1:update(\"world\")\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n    local digest = sha1:final()  -- binary digest\n\n    local str = require \"resty.string\"\n    ngx.say(\"sha1: \", str.to_hex(digest))\n        -- output: \"sha1: b7e23ec29af22b0b4e41da31e868d57226121c84\"\n\n    local resty_md5 = require \"resty.md5\"\n    local md5 = resty_md5:new()\n    if not md5 then\n        ngx.say(\"failed to create md5 object\")\n        return\n    end\n\n    local ok = md5:update(\"hel\")\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n        -- md5:update() with an optional \"len\" parameter\n    ok = md5:update(\"loxxx\", 2)\n    if not ok then\n        ngx.say(\"failed to add data\")\n        return\n    end\n\n    local digest = md5:final()\n\n    local str = require \"resty.string\"\n    ngx.say(\"md5: \", str.to_hex(digest))\n        -- yield \"md5: 5d41402abc4b2a76b9719d911017c592\"\n\n    local resty_sha224 = require \"resty.sha224\"\n    local str = require \"resty.string\"\n    local sha224 = resty_sha224:new()\n    ngx.say(sha224:update(\"hello\"))\n    local digest = sha224:final()\n    ngx.say(\"sha224: \", str.to_hex(digest))\n\n    local resty_sha256 = require \"resty.sha256\"\n    local str = require \"resty.string\"\n    local sha256 = resty_sha256:new()\n    ngx.say(sha256:update(\"hello\"))\n    local digest = sha256:final()\n    ngx.say(\"sha256: \", str.to_hex(digest))\n\n    local resty_sha512 = require \"resty.sha512\"\n    local str = require \"resty.string\"\n    local sha512 = resty_sha512:new()\n    ngx.say(sha512:update(\"hello\"))\n    local digest = sha512:final()\n    ngx.say(\"sha512: \", str.to_hex(digest))\n\n    local resty_sha384 = require \"resty.sha384\"\n    local str = require \"resty.string\"\n    local sha384 = resty_sha384:new()\n    ngx.say(sha384:update(\"hel\"))\n    ngx.say(sha384:update(\"lo\"))\n    local digest = sha384:final()\n    ngx.say(\"sha384: \", str.to_hex(digest))\n\n    local resty_random = require \"resty.random\"\n    local str = require \"resty.string\"\n    local random = resty_random.bytes(16)\n        -- generate 16 bytes of pseudo-random data\n    ngx.say(\"pseudo-random: \", str.to_hex(random))\n\n    local resty_random = require \"resty.random\"\n    local str = require \"resty.string\"\n    local strong_random = resty_random.bytes(16,true)\n        -- attempt to generate 16 bytes of\n        -- cryptographically strong random data\n    while strong_random == nil do\n        strong_random = resty_random.bytes(16,true)\n    end\n    ngx.say(\"random: \", str.to_hex(strong_random))\n\n    local aes = require \"resty.aes\"\n    local str = require \"resty.string\"\n    local aes_128_cbc_md5 = aes:new(\"AKeyForAES\")\n        -- the default cipher is AES 128 CBC with 1 round of MD5\n        -- for the key and a nil salt\n    local encrypted = aes_128_cbc_md5:encrypt(\"Secret message!\")\n    ngx.say(\"AES 128 CBC (MD5) Encrypted HEX: \", str.to_hex(encrypted))\n    ngx.say(\"AES 128 CBC (MD5) Decrypted: \", aes_128_cbc_md5:decrypt(encrypted))\n\n    local aes = require \"resty.aes\"\n    local str = require \"resty.string\"\n    local aes_256_cbc_sha512x5 = aes:new(\"AKeyForAES-256-CBC\",\n        \"MySalt!!\", aes.cipher(256,\"cbc\"), aes.hash.sha512, 5)\n        -- AES 256 CBC with 5 rounds of SHA-512 for the key\n        -- and a salt of \"MySalt!!\"\n        -- Note: salt can be either nil or exactly 8 characters long\n    local encrypted = aes_256_cbc_sha512x5:encrypt(\"Really secret message!\")\n    ngx.say(\"AES 256 CBC (SHA-512, salted) Encrypted HEX: \", str.to_hex(encrypted))\n    ngx.say(\"AES 256 CBC (SHA-512, salted) Decrypted: \",\n        aes_256_cbc_sha512x5:decrypt(encrypted))\n\n    local aes = require \"resty.aes\"\n    local str = require \"resty.string\"\n    local aes_128_cbc_with_iv = assert(aes:new(\"1234567890123456\",\n        nil, aes.cipher(128,\"cbc\"), {iv=\"1234567890123456\"}))\n        -- AES 128 CBC with IV and no SALT\n    local encrypted = aes_128_cbc_with_iv:encrypt(\"Really secret message!\")\n    ngx.say(\"AES 128 CBC (WITH IV) Encrypted HEX: \", str.to_hex(encrypted))\n    ngx.say(\"AES 128 CBC (WITH IV) Decrypted: \",\n        aes_128_cbc_with_iv:decrypt(encrypted))\n\n    local aes = require \"resty.aes\"\n    local str = require \"resty.string\"\n    local enable_padding = false\n    local aes_256_cbc_with_padding = aes:new(\n        key, nil, aes.cipher(256,\"cbc\"), {iv = string.sub(key, 1, 16)}, nil,\n        nil, enable_padding)\n        -- AES-256 CBC (custom keygen, user padding with block_size=32)\n    local text = \"hello\"\n    local block_size = 32\n    local pad = block_size - #text % 32\n    local text_paded = text .. string.rep(string.char(pad), pad)\n    local encrypted = aes_256_cbc_with_padding:encrypt(text_paded)\n    ngx.say(\"AES-256 CBC (custom keygen, user padding with block_size=32) HEX: \",\n        str.to_hex(encrypted))\n</code></pre>"},{"location":"lua/string/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/string/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-string.</p>"},{"location":"lua/t1k/","title":"t1k: Lua implementation of the T1K protocol for Chaitin/SafeLine WAF","text":""},{"location":"lua/t1k/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/t1k/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-t1k\n</code></pre>"},{"location":"lua/t1k/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-t1k\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-t1k v1.1.6  released on Nov 04 2024.</p> <p> </p>"},{"location":"lua/t1k/#name","title":"Name","text":"<p>Lua implementation of the T1K protocol for Chaitin/SafeLine Web Application Firewall.</p>"},{"location":"lua/t1k/#status","title":"Status","text":"<p>Production ready.</p> <p></p>"},{"location":"lua/t1k/#synopsis","title":"Synopsis","text":"<pre><code>location / {\n    access_by_lua_block {\n        local t1k = require \"resty.t1k\"\n\n        local t = {\n            mode = \"block\",                            -- block or monitor or off, default off\n            host = \"unix:/workdir/snserver.sock\",      -- required, SafeLine WAF detection service host, unix domain socket, IP, or domain is supported, string\n            port = 8000,                               -- required when the host is an IP or domain, SafeLine WAF detection service port, integer\n            connect_timeout = 1000,                    -- connect timeout, in milliseconds, integer, default 1s (1000ms)\n            send_timeout = 1000,                       -- send timeout, in milliseconds, integer, default 1s (1000ms)\n            read_timeout = 1000,                       -- read timeout, in milliseconds, integer, default 1s (1000ms)\n            req_body_size = 1024,                      -- request body size, in KB, integer, default 1MB (1024KB)\n            keepalive_size = 256,                      -- maximum concurrent idle connections to the SafeLine WAF detection service, integer, default 256\n            keepalive_timeout = 60000,                 -- idle connection timeout, in milliseconds, integer, default 60s (60000ms)\n            remote_addr = \"http_x_forwarded_for: 1\",   -- remote address from ngx.var.VARIABLE, string, default from ngx.var.remote_addr\n        }\n\n        local ok, err, _ = t1k.do_access(t, true)\n        if not ok then \n            ngx.log(ngx.ERR, err)\n        end\n    }\n\n    header_filter_by_lua_block {\n        local t1k = require \"resty.t1k\"\n        t1k.do_header_filter()\n    }\n}\n</code></pre>"},{"location":"lua/t1k/#lua-resty-t1k-vs-c-t1k","title":"Lua Resty T1K vs. C T1K","text":"<p>C T1K, as part of SafeLine's enterprise edition, is a deployment mode crafted in C language for enhanced performance. It is compatible with all versions of Nginx and does not require deployment via OpenResty (lua_nginx_module).</p> Lua Resty T1K C T1K Request Detection \u2705 \u2705 Response Detection \u274c \u2705 Health Checks* \u274c \u2705 Cookie Protection \u274c \u2705 Bot Protection \u274c \u2705 Proxy-side Statistics \u274c \u2705 <p>* APISIX implements health check functionality for the <code>chaitin-waf</code> plugin. For more information, please see the chaitin-waf documentation.</p>"},{"location":"lua/t1k/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-t1k.</p>"},{"location":"lua/tags/","title":"tags: A small DSL for building HTML documents","text":""},{"location":"lua/tags/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/tags/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-tags\n</code></pre>"},{"location":"lua/tags/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-tags\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-tags v1.0  released on Jul 06 2016.</p> <p>A small DSL for building HTML documents</p>"},{"location":"lua/tags/#synopsis","title":"Synopsis","text":""},{"location":"lua/tags/#here-we-define-some-local-functions","title":"Here we define some local functions:","text":"<pre><code>local tags = require \"resty.tags\"\nlocal html,   head,   script,   body,   h1,   p,   table,   tr,   th,   img,   br = tags(\n     \"html\", \"head\", \"script\", \"body\", \"h1\", \"p\", \"table\", \"tr\", \"th\", \"img\", \"br\")\n\nprint(\n    html { lang = \"en\" } (\n        head (\n            script { src = \"main.js\" }\n        ),\n        body (\n            h1 { class = 'title \"is\" bigger than you think', \"selected\" } \"Hello\",\n            h1 \"Another Headline\",\n            p (\n                \"&lt;Beautiful&gt; &amp; &lt;Strange&gt;\",\n                br,\n                { Car = \"Was Stolen\" },\n                \"Weather\"\n            ),\n            p \"A Dog\",\n            img { src = \"logo.png\" },\n            table(\n                tr (\n                    th { class = \"selected\" } \"'Headline'\",\n                    th \"Headline 2\",\n                    th \"Headline 3\"\n                )\n            )\n        )\n    )\n)\n</code></pre>"},{"location":"lua/tags/#the-above-will-output-html-similar-to","title":"The above will output HTML similar to:","text":"<pre><code>&lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;script src=\"main.js\"&gt;&lt;/script&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1 class=\"title &amp;quot;is&amp;quot; bigger than you think\" selected&gt;\n            Hello\n        &lt;/h1&gt;\n        &lt;h1&gt;\n            Another Headline\n        &lt;/h1&gt;\n        &lt;p&gt;\n            &amp;lt;Beautiful&amp;gt; &amp;amp; &amp;lt;Strange&amp;gt;\n            &lt;br&gt;\n            table: 0x0004c370Weather\n        &lt;/p&gt;\n        &lt;p&gt;\n            A Dog\n        &lt;/p&gt;\n        &lt;img src=\"logo.png\"&gt;\n        &lt;table&gt;\n            &lt;tr&gt;\n                &lt;th class=\"selected\"&gt;\n                    &amp;#39;Headline&amp;#39;\n                &lt;/th&gt;\n                &lt;th&gt;\n                    Headline 2\n                &lt;/th&gt;\n                &lt;th&gt;\n                    Headline 3\n                &lt;/th&gt;\n            &lt;/tr&gt;\n        &lt;/table&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/tags/#here-we-pass-in-a-function","title":"Here we pass in a function:","text":"<pre><code>local tags = require \"resty.tags\"\nlocal html = tags(function()\n    return html { lang = \"en\"} (\n        head (\n            script { src = \"main.js\" }\n        ),\n        body (\n            h1 { class = 'title \"is\" bigger than you think', \"selected\" } \"Hello\",\n            h1 \"Another Headline\",\n            p (\n                \"&lt;Beautiful&gt; &amp; &lt;Strange&gt;\",\n                br,\n                { Car = \"Was Stolen\" },\n                \"Weather\"\n            ),\n            p \"A Dog\",\n            img { src = \"logo.png\" },\n            table(\n                tr (\n                    th { class = \"selected\" } \"'Headline'\",\n                    th \"Headline 2\",\n                    th \"Headline 3\"\n                )\n            )\n        )\n    )\nend)\nprint(html())\n</code></pre>"},{"location":"lua/tags/#and-the-output-is-similar","title":"And the output is similar:","text":"<pre><code>&lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;script src=\"main.js\"&gt;&lt;/script&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1 class=\"title &amp;quot;is&amp;quot; bigger than you think\" selected&gt;\n            Hello\n        &lt;/h1&gt;\n        &lt;h1&gt;\n            Another Headline\n        &lt;/h1&gt;\n        &lt;p&gt;\n            &amp;lt;Beautiful&amp;gt; &amp;amp; &amp;lt;Strange&amp;gt;\n            &lt;br&gt;\n            table: 0x00054ce0Weather\n        &lt;/p&gt;\n        &lt;p&gt;\n            A Dog\n        &lt;/p&gt;\n        &lt;img src=\"logo.png\"&gt;\n        &lt;table&gt;\n            &lt;tr&gt;\n                &lt;th class=\"selected\"&gt;\n                    &amp;#39;Headline&amp;#39;\n                &lt;/th&gt;\n                &lt;th&gt;\n                    Headline 2\n                &lt;/th&gt;\n                &lt;th&gt;\n                    Headline 3\n                &lt;/th&gt;\n            &lt;/tr&gt;\n        &lt;/table&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/tags/#in-this-example-we-create-a-table-snippet","title":"In this example we create a table snippet:","text":"<pre><code>local tags = require \"resty.tags\"\nlocal table = tags(function(rows)\n    local table = table\n    for _, row in ipairs(rows) do\n        local tr = tr\n        for _, col in ipairs(row) do\n            tr(td(col))\n        end\n        table(tr)\n    end\n    return table\nend)\n\nprint(table{\n    { \"A\", 1, 1 },\n    { \"B\", 2, 2 },\n    { \"C\", 3, 3 }\n})\n</code></pre>"},{"location":"lua/tags/#and-here-is-the-output-of-it","title":"And here is the output of it:","text":"<pre><code>&lt;table&gt;\n    &lt;tr&gt;\n        &lt;td&gt;A&lt;/td&gt;\n        &lt;td&gt;1&lt;/td&gt;\n        &lt;td&gt;1&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;B&lt;/td&gt;\n        &lt;td&gt;2&lt;/td&gt;\n        &lt;td&gt;2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;C&lt;/td&gt;\n        &lt;td&gt;3&lt;/td&gt;\n        &lt;td&gt;3&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre>"},{"location":"lua/tags/#some-special-treatment-is-done-to-script-and-style-tags","title":"Some special treatment is done to <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> tags:","text":"<pre><code>local tags = require \"resty.tags\"\nlocal script = tags(\"script\")\nprint(script[[\n    function hello() {\n        alert(\"&lt;strong&gt;Hello World&lt;/strong&gt;\");\n    }\n    hello();\n]])\n</code></pre>"},{"location":"lua/tags/#as-you-can-see-we-dont-html-encode-the-output","title":"As you can see, we don't HTML encode the output:","text":"<pre><code>&lt;script&gt;\n    function hello() {\n        alert(\"&lt;strong&gt;Hello World&lt;/strong&gt;\");\n    }\n    hello();\n&lt;/script&gt;\n</code></pre>"},{"location":"lua/tags/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-tags.</p>"},{"location":"lua/tarantool/","title":"tarantool: Library for working with tarantool from nginx with the embedded Lua module or with nginx-module-lua","text":""},{"location":"lua/tarantool/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/tarantool/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-tarantool\n</code></pre>"},{"location":"lua/tarantool/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-tarantool\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-tarantool v0.3  released on Oct 21 2015.</p>"},{"location":"lua/tarantool/#introduction","title":"Introduction","text":"<p>This is a library to connect to the tarantool NoSQL database. This database has very interesting features that make it be sort of a bridge between a traditional SQL based database and document oriented storages like CouchDB.</p> <p>It's a fork of another project that I was unhappy with. It's abundantly documented and is update regarding the tarantool API. Notably wtih support for the upsert command. </p> <p>Another thing to bear in minf is that the library tries to be consistent between the way the <code>update</code> and <code>upsert</code> commands are issued in the console using Lua and the way the API works. Notably the field numbers. In the console a field number takes into account the existence of a primary index as the first field. Hence any field that come afterward will have an position that accounts for it. Specifically when specifying the operators to use for the <code>update</code> or <code>upsert</code> operations.</p>"},{"location":"lua/tarantool/#usage","title":"Usage","text":""},{"location":"lua/tarantool/#creating-a-connection","title":"Creating a connection","text":"<p><pre><code>local tar = require 'resty.tarantool'\n\nlocal tar, err = tnt:new({\n    host = '127.0.0.1',\n    port = 3301,\n    user = 'luser',\n    password = 'some password',\n    socket_timeout = 2000,\n})\n</code></pre> The above creates a connection object that connects to a tarantool server instance running on the loopback in port 3301, for user <code>luser</code> with password <code>some password</code>. See the Tarantool manual in authentication for details on how to setup users and assigning privileges to them.</p> <p>The socket timeout (receive and send) is 2 seconds (2000 ms).</p>"},{"location":"lua/tarantool/#set_timeout","title":"set_timeout","text":"<pre><code>settimeout(&lt;connection object&gt;, &lt;timeout in ms&gt;)\n</code></pre> <p>Sets both the send and receive timeouts in miliseconds for a given socket.</p> <pre><code>tnt:set_timeout(5000) -- 5s timeout for send/receive operations\n</code></pre> <p>The function returns true if the setting succeeds, <code>nil</code> if not. Note that for the timeout to take effect this function needs to be invoked before the connection is established, i.e., before invoking the <code>connect</code> function. Alternatively the timeout can be specified when creating the connection object (cosocket).</p>"},{"location":"lua/tarantool/#connect","title":"connect","text":"<pre><code>connect(&lt;connection object&gt;)\n</code></pre> <p>Connects the socket created above to the port and address specified when creating the connection object.</p> <p><pre><code>tar:connect()\n</code></pre> The function returns true if the connection succeeds, <code>nil</code> if not.</p>"},{"location":"lua/tarantool/#set_keepalive","title":"set_keepalive","text":"<pre><code>set_keepalive(&lt;connection object&gt;)\n</code></pre> <p>Makes the connection created get pushed to a connection pool so that the connection is kept alive across multiple requests.</p> <pre><code>tar:set_keepalive()\n</code></pre> <p>The function returns true if the socket is successfully pushed to connection pool (set keepalive). <code>nil</code> if not.</p>"},{"location":"lua/tarantool/#disconnect","title":"disconnect","text":"<pre><code>disconnect(&lt;connection object&gt;)\n</code></pre> <p>Closes a connection to a given tarantool server running on a given address and port.</p> <pre><code>tar:disconnect()\n</code></pre> <p>The function returns true if the connection is successfully closed. <code>nil</code> if not.</p>"},{"location":"lua/tarantool/#ping","title":"ping","text":"<p>The ping command is useful for monitoring the tarantool server to see if it's available. If it's available for queries it returns the string <code>PONG</code>.</p> <pre><code>tar:ping()\n-- returns PONG\n</code></pre>"},{"location":"lua/tarantool/#select","title":"select","text":"<p>The select operation queries a given database (space) for retrieving records.</p> <pre><code>select(&lt;connection object&gt;, &lt;space name&gt;, &lt;index&gt;, &lt;key&gt;, &lt;options&gt;)\n</code></pre> <p>where <code>&lt;options&gt;</code> is an optional argument that can consists of a table that can have the following keys:</p> <ul> <li><code>offset</code>: number of records to skip when doing the query.</li> <li><code>limit</code>: the maximum number of records to return.</li> <li><code>iterator</code>: a number specifiyng the iterator to use. Specified by  the table:</li> </ul> <p><pre><code>local iterator_keys = {\n  EQ = 0, -- equality\n  REQ = 1, -- reverse equality\n  ALL = 2, -- all tuples in an index\n  LT = 3, -- less than\n  LE = 4, -- less than or equal\n  GE = 5, -- greater than or equal\n  GT = 6, -- greater than\n  BITSET_ALL_SET = 7, -- bits in the bitmask all set\n  BITSET_ANY_SET = 8, -- any of the bist in the bitmask are set\n  BITSET_ALL_NOT_SET = 9, -- none on the bits on the bitmask are set\n}\n</code></pre> More details about iterators on the tarantool manual.</p>"},{"location":"lua/tarantool/#select-examples","title":"select examples","text":""},{"location":"lua/tarantool/#query-the-_space-space-db-to-get-the-space-id-of-the-_index-space","title":"Query the <code>_space</code> space (DB) to get the space id of the <code>_index</code> space.","text":"<p><pre><code>local res, err = tar:select('_space', 'name', '_index')\n\n-- response:\n[2881,\"_index\",\"memtx\",0,\"\",\n  [{\"name\":\"id\",\"type\":\"num\"},\n   {\"name\":\"iid\",\"type\":\"num\"},\n   {\"name\":\"name\",\"type\":\"str\"},\n   {\"name\":\"type\",\"type\":\"str\"},\n   {\"name\":\"opts\",\"type\":\"array\"},\n   {\"name\":\"parts\",\"type\":\"array\"}]]]\n</code></pre> The above request is equivalent to the console request:</p> <pre><code>box.space._space.index.name:select{ '_index' }\n</code></pre>"},{"location":"lua/tarantool/#query-the-space-activities-for-the-activities-with-a-price-less-than-300","title":"Query the space 'activities' for the activities with a <code>price</code> less than 300","text":"<p><pre><code>-- N.B. price is an index of the activities space.\nlocal res, err = tar:select('activities', 'price', 300, { iterator = 'LT' })\n</code></pre> The above request is equivalent to the console request:</p> <pre><code>box.space.activities.index.price:select({ 300 }, { iterator = 'LT' }) \n</code></pre>"},{"location":"lua/tarantool/#insert","title":"insert","text":"<pre><code>insert(&lt;connection object&gt;, &lt;space name&gt;, &lt;tuple&gt;)\n</code></pre> <p>where <code>&lt;tuple&gt;</code> is the tuple to insert into <code>&lt;space&gt;</code> while setting the primary index, which is unique, to the value specified in the tuple.</p> <p>The function returns the inserted record if the operation succeeds.</p>"},{"location":"lua/tarantool/#insert-examples","title":"insert examples","text":"<p><pre><code>local res, err = tar:insert('activities', { 16, 120, { activity = 'surf', price = 121 } })\n\n-- response: \n[[16,120,{\"activity\":\"surf\",\"price\":121}]]\n</code></pre> The above request is equivalent to the console request:</p> <p><pre><code>box.space.activities:insert({16, 120, { activity = 'surf', price = 121 }})\n</code></pre> 16 is the value of the primary index here. This means that for an integer type index this will be the record with primary index 16.</p>"},{"location":"lua/tarantool/#replace","title":"replace","text":"<pre><code>replace(&lt;connection object&gt;, &lt;space name&gt;, &lt;tuple&gt;)\n</code></pre> <p>The replace command is similar in the invocation and signature to the insert command. But now we're looking for replacing a record that exists already instead of inserting a new one. We need again the value of a primary unique index. But now the value must exist for the operation to succeed. If the operations succeeds the record with the replaced values is returned.</p>"},{"location":"lua/tarantool/#replace-examples","title":"replace examples","text":"<p><pre><code>local res, err = tar:replace('activities', { 16, 120, { activity = 'surf', price = 120 } })\n-- response:\n[[16,120,{\"activity\":\"surf\",\"price\":120}]]\n</code></pre> Here we replace the former 121 price by 120. The value of the primary index, 16 matches the record we inserted above.</p> <p>The above request is equivalent to the console request:</p> <pre><code>box.space.activities:update({ 16, 120, { activity = 'surf', price = 120 }})\n</code></pre>"},{"location":"lua/tarantool/#update","title":"update","text":"<pre><code>update(&lt;connection object&gt;, &lt;space name&gt;, &lt;index&gt;, &lt;key&gt;, &lt;operator list&gt;)\n</code></pre> <p>where <code>&lt;operator list&gt;</code> is the list of operators as specified n tarantool manual. The pair (, ) uniquely identifies a record, i.e., the <code>&lt;key&gt;</code> is a value of the primary (unique) <code>&lt;index&gt;</code>. <p><code>&lt;operator list&gt;</code> is a table of the form:</p> <p><pre><code>{ &lt;operator&gt;, &lt;field position&gt;, &lt;value&gt; }\n</code></pre> the operators are:</p> <ul> <li><code>+</code> for adding to a numeric field. </li> <li><code>-</code> for subtracting to a numeric field.</li> <li><code>&amp;</code> for bitwise AND operation between two unsigned integers.</li> <li><code>|</code> for bitwise OR operation between two unsigned integers.</li> <li><code>^</code> for bitwise XOR operation between two unsigned integers.</li> <li><code>:</code> for string splicing.</li> <li><code>!</code> for field insertion.</li> <li><code>#</code> for field deletion.</li> <li><code>=</code> for assigning a given value to a field.</li> </ul> <p>it returns the updated record if the operation is successful.</p>"},{"location":"lua/tarantool/#update-examples","title":"update examples","text":"<p><pre><code>local res, err = tar:update('activities', 'primary', 16, { { '=', 2, 341 }, { '=', 3,  { activity = 'kitesurfing', price = 341 }}} )\n-- response:\n[16,341,{\"activity\":\"kitesurfing\",\"price\":341}]]\n</code></pre> The record with <code>primary</code> index 16 that we inserted above was updated.</p> <p>The above request is equivalent to the console request:</p> <pre><code>box.space.activities.index.primary({ 16 }, { { '=', 2, 341 }, { '=', 3,  { activity = 'kitesurfing', price = 341 }}})\n</code></pre>"},{"location":"lua/tarantool/#upsert","title":"upsert","text":"<pre><code>upsert(&lt;connection object&gt;, &lt;space name&gt;, &lt;key&gt;, &lt;operator list&gt;, &lt;new tuple&gt;)\n</code></pre> <p>apart from the <code>&lt;new tuple&gt;</code> argument the function signature is similar to update. In fact upsert is two commands in one. update if the record specified by the pair (, ) exists and insert if not. The key is a value from a primary index, i.e., is unique. The <code>&lt;new tuple&gt;</code> is the tuple to be inserted if the <code>&lt;key&gt;</code> value doesn't exist in the <code>&lt;index&gt;</code>. It returns an empty table <code>{}</code> if the operation is successful. If the operation is unsuccessful it returns <code>nil</code>."},{"location":"lua/tarantool/#upsert-examples","title":"upsert examples","text":"<p>An insert.</p> <p><pre><code>local res, err = tar:upsert('activities', 17, { { '=', 2, 450 }, { '=', 3,  { activity = 'submarine tour 8', price = 450 }}}, { 17, 450, { activity = 'waterski', price = 365 }})\n-- response:\n{}\n</code></pre> We inserted a new record with key 17 for the primary index from the tuple:</p> <p><pre><code>{ 18, 450, { activity = 'waterski', price = 365 }}\n</code></pre> The above request is equivalent to the console request:</p> <p><pre><code>box.space.activities:upsert({ 17 }, { { '=', 2, 450 }, { '=', 3,  { activity = 'submarine tour 8', price = 450 }}}, { 17, 450, { activity = 'waterski', price = 365 }})\n</code></pre> An update.</p> <p><pre><code>local res, err = tar:upsert('activities', 17, { { '=', 2, 450 }, { '=', 3,  { activity = 'submarine tour 8', price = 450 }}}, { 18, 285, { activity = 'kitesurfing', price = 285 }})\n-- response:\n{}\n</code></pre> Now we perform an update of the record identified by the key 17 in de <code>primary</code> index (unique).</p>"},{"location":"lua/tarantool/#delete","title":"delete","text":"<pre><code>delete(&lt;connection object&gt;, &lt;space&gt;, &lt;key&gt;)\n</code></pre> <p>deletes the record uniquely specified by <code>&lt;key&gt;</code> from <code>&lt;space&gt;</code>. Note that <code>&lt;key&gt;</code> must belong to a primary (unique) index. It returns the deleted record if the operation is successful.</p>"},{"location":"lua/tarantool/#delete-examples","title":"delete examples","text":"<p><pre><code>local response, err = tar:delete('activities', 17)\n-- response:\n[17,450,{\"activity\":\"waterski\",\"price\":365}]]\n</code></pre> We deleted the record uniquely identified by the key 17 in the primary index from the activites space.</p> <p>The above request is equivalent to the console request:</p> <pre><code>box.space.activities:delete({ 17 })\n</code></pre>"},{"location":"lua/tarantool/#call","title":"call","text":"<pre><code>call(&lt;connection object&gt;, &lt;proc&gt;, &lt;args&gt;)\n</code></pre> <p>Invokes a stored procedure (Lua function) in the tarantool server we're connected to. It returns the results of the invocation.</p>"},{"location":"lua/tarantool/#call-examples","title":"call examples","text":"<p>Since the tarantool console is a Lua REPL any function can be invoked as long as it is available in the environment.</p> <p><pre><code>local res, err = tar:call('table.concat', { {'hello', ' ', 'world' } })\n-- response:\n[[\"hello world\"]]\n</code></pre> We called the <code>table.concat</code> function from the table library to concatenate the table:</p> <p><pre><code>{'hello', ' ', 'world' }\n</code></pre> The above request is equivalent to the console request:</p> <pre><code>table.concat({'hello', ' ', 'world' })\n</code></pre> <p>For many examples of tarantool stored procedures see the repository; https://github.com/mailru/tarlua</p>"},{"location":"lua/tarantool/#hide_version_header","title":"hide_version_header","text":"<pre><code>hide_version_header(&lt;connection object&gt;)\n</code></pre> <p>By default each response sends a custom HTTP header <code>X-Tarantool-Version</code> with the version of the tarantool server.</p> <pre><code>X-Tarantool-Version: 1.6.6-191-g82d1bc3\n</code></pre> <p>Invoking <code>hide_version_header</code> removes the header.</p> <pre><code>tar:hide_version_header()\n</code></pre> <p>It returns no values.</p>"},{"location":"lua/tarantool/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-tarantool.</p>"},{"location":"lua/template/","title":"template: Templating Engine (HTML) for Lua and nginx-module-lua","text":""},{"location":"lua/template/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/template/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-template\n</code></pre>"},{"location":"lua/template/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-template\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-template v2.0  released on Feb 24 2020.</p> <p>lua-resty-template is a compiling (1) (HTML) templating engine for Lua and OpenResty.</p> <p>(1) with compilation we mean that templates are translated to Lua functions that you may call or <code>string.dump</code> as a binary bytecode blobs to disk that can be later utilized with <code>lua-resty-template</code> or basic <code>load</code> and <code>loadfile</code> standard Lua functions (see also Template Precompilation). Although, generally you don't need to do that as <code>lua-resty-template</code> handles this behind the scenes.</p>"},{"location":"lua/template/#hello-world-with-lua-resty-template","title":"Hello World with lua-resty-template","text":"<pre><code>local template = require \"resty.template\"      -- OR\nlocal template = require \"resty.template.safe\" -- return nil, err on errors\n\n-- Using template.new\nlocal view = template.new \"view.html\"\nview.message = \"Hello, World!\"\nview:render()\n-- Using template.render\ntemplate.render(\"view.html\", { message = \"Hello, World!\" })\n</code></pre>"},{"location":"lua/template/#viewhtml","title":"view.html","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n  &lt;h1&gt;{{message}}&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#output","title":"Output","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n  &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>The same can be done with inline template string:</p> <pre><code>-- Using template string\ntemplate.render([[\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n  &lt;h1&gt;{{message}}&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;]], { message = \"Hello, World!\" })\n</code></pre>"},{"location":"lua/template/#contents","title":"Contents","text":"<ul> <li>Template Syntax</li> <li>Example</li> <li>Reserved Context Keys and Remarks</li> <li>Installation</li> <li>Using OpenResty Package Manager (opm)</li> <li>Using LuaRocks</li> <li>Nginx / OpenResty Configuration</li> <li>Lua API</li> <li>template.root</li> <li>template.location</li> <li>table template.new(view, layout)</li> <li>boolean template.caching(boolean or nil)</li> <li>function, boolean template.compile(view, cache_key, plain)</li> <li>function, boolean template.compile_string(view, cache_key)</li> <li>function, boolean template.compile_file(view, cache_key)</li> <li>template.visit(func)</li> <li>string template.process(view, context, cache_key, plain)</li> <li>string template.process_string(view, context, cache_key)</li> <li>string template.process_file(view, context, cache_key) </li> <li>template.render(view, context, cache_key, plain)</li> <li>template.render_string(view, context, cache_key)</li> <li>template.render_file(view, context, cache_key)</li> <li>string template.parse(view, plain)</li> <li>string template.parse_string(view, plain)</li> <li>string template.parse_file(view, plain)</li> <li>string template.precompile(view, path, strip)</li> <li>string template.precompile_string(view, path, strip)</li> <li>string template.precompile_file(view, path, strip) </li> <li>string template.load(view, plain)</li> <li>string template.load_string(view)</li> <li>string template.load_file(view)</li> <li>template.print</li> <li>Template Precompilation</li> <li>Template Helpers</li> <li>Built-in Helpers<ul> <li>echo(...)</li> <li>include(view, context)</li> </ul> </li> <li>Other Ways to Extend</li> <li>Usage Examples</li> <li>Template Including</li> <li>Views with Layouts</li> <li>Using Blocks</li> <li>Grandfather-Father-Son Inheritance</li> <li>Macros</li> <li>Calling Methods in Templates</li> <li>Embedding Angular or other tags / templating inside the Templates</li> <li>Embedding Markdown inside the Templates</li> <li>Lua Server Pages (LSP) with OpenResty</li> <li>FAQ</li> <li>Alternatives</li> <li>Benchmarks</li> <li>Changes</li> <li>Roadmap</li> <li>See Also</li> <li>License</li> </ul>"},{"location":"lua/template/#template-syntax","title":"Template Syntax","text":"<p>You may use the following tags in templates:</p> <ul> <li><code>{{expression}}</code>, writes result of expression - html escaped</li> <li><code>{*expression*}</code>, writes result of expression </li> <li><code>{% lua code %}</code>, executes Lua code</li> <li><code>{(template)}</code>, includes <code>template</code> file, you may also supply context for include file <code>{(file.html, { message = \"Hello, World\" } )}</code> (NOTE: you cannot use comma (<code>,</code>) in <code>file.html</code>, in that case use <code>{[\"file,with,comma\"]}</code> instead)</li> <li><code>{[expression]}</code>, includes <code>expression</code> file (the result of expression), you may also supply context for include file <code>{[\"file.html\", { message = \"Hello, World\" } ]}</code></li> <li><code>{-block-}...{-block-}</code>, wraps inside of a <code>{-block-}</code> to a value stored in a <code>blocks</code> table with a key <code>block</code> (in this case), see using blocks. Don't use predefined block names <code>verbatim</code> and <code>raw</code>.</li> <li><code>{-verbatim-}...{-verbatim-}</code> and <code>{-raw-}...{-raw-}</code> are predefined blocks whose inside is not processed by the <code>lua-resty-template</code> but the content is outputted as is.</li> <li><code>{# comments #}</code> everything between <code>{#</code> and <code>#}</code> is considered to be commented out (i.e. not outputted or executed)</li> </ul> <p>From templates you may access everything in <code>context</code> table, and everything in <code>template</code> table. In templates you can also access <code>context</code> and <code>template</code> by prefixing keys.</p> <pre><code>&lt;h1&gt;{{message}}&lt;/h1&gt; == &lt;h1&gt;{{context.message}}&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#short-escaping-syntax","title":"Short Escaping Syntax","text":"<p>If you don't want a particular template tag to be processed you may escape the starting tag with backslash <code>\\</code>:</p> <pre><code>&lt;h1&gt;\\{{message}}&lt;/h1&gt;\n</code></pre> <p>This will output (instead of evaluating the message):</p> <pre><code>&lt;h1&gt;{{message}}&lt;/h1&gt;\n</code></pre> <p>If you want to add backslash char just before template tag, you need to escape that as well:</p> <pre><code>&lt;h1&gt;\\\\{{message}}&lt;/h1&gt;\n</code></pre> <p>This will output:</p> <pre><code>&lt;h1&gt;\\[message-variables-content-here]&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#a-word-about-complex-keys-in-context-table","title":"A Word About Complex Keys in Context Table","text":"<p>Say you have this kind of a context table:</p> <pre><code>local ctx = {[\"foo:bar\"] = \"foobar\"}\n</code></pre> <p>And you want to render the <code>ctx[\"foo:bar\"]</code>'s value <code>foobar</code> in your template.  You have to specify it explicitly by referencing the <code>context</code> in your template:</p> <pre><code>{# {*[\"foo:bar\"]*} won't work, you need to use: #}\n{*context[\"foo:bar\"]*}\n</code></pre> <p>Or altogether:</p> <pre><code>template.render([[\n{*context[\"foo:bar\"]*}\n]], {[\"foo:bar\"] = \"foobar\"})\n</code></pre>"},{"location":"lua/template/#a-word-about-html-escaping","title":"A Word About HTML Escaping","text":"<p>Only strings are escaped, functions are called without arguments (recursively) and results are returned as is, other types are <code>tostring</code>ified. <code>nil</code>s and <code>ngx.null</code>s are converted to empty strings <code>\"\"</code>.</p> <p>Escaped HTML characters:</p> <ul> <li><code>&amp;</code> becomes <code>&amp;amp;</code></li> <li><code>&lt;</code> becomes <code>&amp;lt;</code></li> <li><code>&gt;</code> becomes <code>&amp;gt;</code></li> <li><code>\"</code> becomes <code>&amp;quot;</code></li> <li><code>'</code> becomes <code>&amp;#39;</code></li> <li><code>/</code> becomes <code>&amp;#47;</code></li> </ul>"},{"location":"lua/template/#example","title":"Example","text":""},{"location":"lua/template/#lua","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\ntemplate.render(\"view.html\", {\n  title   = \"Testing lua-resty-template\",\n  message = \"Hello, World!\",\n  names   = { \"James\", \"Jack\", \"Anne\" },\n  jquery  = '&lt;script src=\"js/jquery.min.js\"&gt;&lt;/script&gt;' \n})\n</code></pre>"},{"location":"lua/template/#viewhtml_1","title":"view.html","text":"<pre><code>{(header.html)}\n&lt;h1&gt;{{message}}&lt;/h1&gt;\n&lt;ul&gt;\n{% for _, name in ipairs(names) do %}\n    &lt;li&gt;{{name}}&lt;/li&gt;\n{% end %}\n&lt;/ul&gt;\n{(footer.html)}\n</code></pre>"},{"location":"lua/template/#headerhtml","title":"header.html","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;{{title}}&lt;/title&gt;\n  {*jquery*}\n&lt;/head&gt;\n&lt;body&gt;\n</code></pre>"},{"location":"lua/template/#footerhtml","title":"footer.html","text":"<pre><code>&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#reserved-context-keys-and-remarks","title":"Reserved Context Keys and Remarks","text":"<p>It is advised that you do not use these keys in your context tables:</p> <ul> <li><code>___</code>, holds the compiled template, if set you need to use <code>{{context.___}}</code></li> <li><code>context</code>, holds the current context, if set you need to use <code>{{context.context}}</code></li> <li><code>echo</code>, holds the echo helper function, if set you need to use <code>{{context.echo}}</code></li> <li><code>include</code>, holds the include helper function, if set you need to use <code>{{context.include}}</code></li> <li><code>layout</code>, holds the layout by which the view will be decorated, if set you need to use <code>{{context.layout}}</code></li> <li><code>blocks</code>, holds the blocks, if set you need to use <code>{{context.blocks}}</code> (see: using blocks)</li> <li><code>template</code>, holds the template table, if set you need to use <code>{{context.template}}</code></li> </ul> <p>In addition to that with <code>template.new</code> you should not overwrite:</p> <ul> <li><code>render</code>, the function that renders a view, obviously ;-)</li> </ul> <p>You should also not <code>{(view.html)}</code> recursively:</p>"},{"location":"lua/template/#lua_1","title":"Lua","text":"<pre><code>template.render \"view.html\"\n</code></pre>"},{"location":"lua/template/#viewhtml_2","title":"view.html","text":"<pre><code>{(view.html)}\n</code></pre> <p>You can  load templates from \"sub-directories\" as well with <code>{(syntax)}</code>:</p>"},{"location":"lua/template/#viewhtml_3","title":"view.html","text":"<pre><code>{(users/list.html)}\n</code></pre> <p>Also note that you can provide template either as a file path or as a string. If the file exists, it will be used, otherwise the string is used. See also <code>template.load</code>.</p>"},{"location":"lua/template/#nginx-openresty-configuration","title":"Nginx / OpenResty Configuration","text":"<p>When <code>lua-resty-template</code> is used in context of Nginx / OpenResty there are a few configuration directives that you need to be aware:</p> <ul> <li><code>template_root</code> (<code>set $template_root /var/www/site/templates</code>)</li> <li><code>template_location</code> (<code>set $template_location /templates</code>)</li> </ul> <p>If none of these are set in Nginx configuration, <code>ngx.var.document_root</code> (aka root-directive) value is used. If <code>template_location</code> is set, it will be used first, and if the location returns anything but <code>200</code> as a status code, we do fallback to either <code>template_root</code> (if defined) or <code>document_root</code>.</p> <p>With <code>lua-resty-template</code> <code>2.0</code> it is possible to override <code>$template_root</code> and <code>$template_location</code> with <code>Lua</code> code:</p> <pre><code>local template = require \"resty.template\".new({\n  root     = \"/templates\",\n  location = \"/templates\" \n})\n</code></pre>"},{"location":"lua/template/#using-document_root","title":"Using <code>document_root</code>","text":"<p>This one tries to load file content with Lua code from <code>html</code> directory (relative to Nginx prefix).</p> <pre><code>http {\n  server {\n    location / {\n      root html;\n      content_by_lua '\n        local template = require \"resty.template\"\n        template.render(\"view.html\", { message = \"Hello, World!\" })\n      ';      \n    }\n  }\n}\n</code></pre>"},{"location":"lua/template/#using-template_root","title":"Using <code>template_root</code>","text":"<p>This one tries to load file content with Lua code from <code>/usr/local/openresty/nginx/html/templates</code> directory.</p> <pre><code>http {\n  server {\n    set $template_root /usr/local/openresty/nginx/html/templates;\n    location / {\n      root html;\n      content_by_lua '\n        local template = require \"resty.template\"\n        template.render(\"view.html\", { message = \"Hello, World!\" })\n      ';      \n    }\n  }\n}\n</code></pre>"},{"location":"lua/template/#using-template_location","title":"Using <code>template_location</code>","text":"<p>This one tries to load content with <code>ngx.location.capture</code> from <code>/templates</code> location (in this case this is served with <code>ngx_static</code> module).</p> <pre><code>http {\n  server {\n    set $template_location /templates;\n    location / {\n      root html;\n      content_by_lua '\n        local template = require \"resty.template\"\n        template.render(\"view.html\", { message = \"Hello, World!\" })\n      ';      \n    }\n    location /templates {\n      internal;\n      alias html/templates/;\n    }    \n  }\n}\n</code></pre> <p>See also <code>template.load</code>.</p>"},{"location":"lua/template/#lua-api","title":"Lua API","text":""},{"location":"lua/template/#templateroot","title":"template.root","text":"<p>You can setup template root by setting this variable which will be looked for template files:</p> <pre><code>local template = require \"resty.template\".new({\n  root = \"/templates\"\n})\ntemplate.render_file(\"test.html\")\n</code></pre> <p>This property overrides the one set in Nginx configuration (<code>set $template_root /my-templates;</code>)</p>"},{"location":"lua/template/#templatelocation","title":"template.location","text":"<p>This is what you can use with OpenResty as that will use <code>ngx.location.capture</code> to fetch templates files in non-blocking fashion.</p> <pre><code>local template = require \"resty.template\".new({\n  location = \"/templates\"\n})\ntemplate.render_file(\"test.html\")\n</code></pre> <p>This property overrides the one set in Nginx configuration (<code>set $template_location /my-templates;</code>)</p>"},{"location":"lua/template/#table-templatenewview-layout","title":"table template.new(view, layout)","text":"<p>Creates a new template instance that is used as a (default) context when <code>render</code>ed. A table that gets created has only one method <code>render</code>, but the table also has metatable with <code>__tostring</code> defined. See the example below. Both <code>view</code> and <code>layout</code> arguments can either be strings or file paths, but layout can also be a table created previously with <code>template.new</code>.</p> <p>With 2.0 the new can also be used without arguments, which creates a new template instance:</p> <pre><code>local template = require \"resty.template\".new()\n</code></pre> <p>You can also pass a table that is then modified to be a template:</p> <pre><code>local config = {\n  root = \"/templates\"\n}\n\nlocal template = require \"resty.template\".new(config)\n</code></pre> <p>This is handy as the <code>template</code> created by <code>new</code> does not share the cache with the global template returned by <code>require \"resty.template\"</code> (this was reported with issue #25).</p> <p>You can also pass a boolean <code>true</code> or <code>false</code> as a <code>view</code> parameter which means that either <code>safe</code> or <code>un-safe</code> version of template is returned:</p> <pre><code>local unsafe = require \"resty.template\"\nlocal safe   = unsafe.new(true)\n</code></pre> <p>There is also a default <code>safe</code> implementation available:</p> <pre><code>local safe = require \"resty.template.safe\"\n-- you can create instance of safe too:\nlocal safe_instance = safe.new()\n</code></pre> <p><code>safe</code> version uses <code>return nil, err</code> Lua error handling pattern and <code>unsafe</code> just throws the errors, which you can catch with <code>pcall</code>, <code>xpcall</code> or <code>coroutine.wrap</code>.</p> <p>Here are examples of using <code>new</code> with arguments:</p> <pre><code>local view = template.new\"template.html\"              -- or\nlocal view = template.new(\"view.html\", \"layout.html\") -- or\nlocal view = template.new[[&lt;h1&gt;{{message}}&lt;/h1&gt;]]     -- or\nlocal view = template.new([[&lt;h1&gt;{{message}}&lt;/h1&gt;]], [[\n&lt;html&gt;\n&lt;body&gt;\n  {*view*}\n&lt;/body&gt;\n&lt;/html&gt;\n]])\n</code></pre>"},{"location":"lua/template/#example_1","title":"Example","text":"<pre><code>local template = require \"resty.template\"\nlocal view = template.new\"view.html\"\nview.message  = \"Hello, World!\"\nview:render()\n-- You may also replace context on render\nview:render{ title = \"Testing lua-resty-template\" }\n-- If you want to include view context in  replacement context\nview:render(setmetatable({ title = \"Testing lua-resty-template\" }, { __index = view }))\n-- To get rendered template as a string, you can use tostring\nlocal result = tostring(view)\n</code></pre>"},{"location":"lua/template/#boolean-templatecachingboolean-or-nil","title":"boolean template.caching(boolean or nil)","text":"<p>This function enables or disables template caching, or if no parameters are passed, returns current state of template caching. By default template caching is enabled, but you may want to disable it on development or low-memory situations.</p> <pre><code>local template = require \"resty.template\"   \n-- Get current state of template caching\nlocal enabled = template.caching()\n-- Disable template caching\ntemplate.caching(false)\n-- Enable template caching\ntemplate.caching(true)\n</code></pre> <p>Please note that if the template was already cached when compiling a template, the cached version will be returned. You may want to flush cache with <code>template.cache = {}</code> to ensure that your template really gets recompiled.</p>"},{"location":"lua/template/#function-boolean-templatecompileview-cache_key-plain","title":"function, boolean template.compile(view, cache_key, plain)","text":"<p>Parses, compiles and caches (if caching is enabled) a template and returns the compiled template as a function that takes context as a parameter and returns rendered template as a string. Optionally you may pass <code>cache_key</code> that is used as a cache key. If cache key is not provided <code>view</code> wil be used as a cache key. If cache key is <code>no-cache</code> the template cache will not be checked and the resulting function will not be cached. You may also optionally pass <code>plain</code> with a value of <code>true</code> if the <code>view</code> is plain text string (this will skip <code>template.load</code> and binary chunk detection in <code>template.parse</code> phase). If <code>plain</code> is <code>false</code> the template is considered to be a file, and all the issues with file reading are considered as errors. If the <code>plain</code> is set to <code>nil</code> (the default) the template does not consider file reading errors as fatal, and returns back the <code>view</code> (usually the path of the template).</p> <pre><code>local func = template.compile(\"template.html\")          -- or\nlocal func = template.compile([[&lt;h1&gt;{{message}}&lt;/h1&gt;]])\n</code></pre>"},{"location":"lua/template/#example_2","title":"Example","text":"<pre><code>local template = require \"resty.template\"\nlocal func     = template.compile(\"view.html\")\nlocal world    = func{ message = \"Hello, World!\" }\nlocal universe = func{ message = \"Hello, Universe!\" }\nprint(world, universe)\n</code></pre> <p>Also note the second return value which is a boolean. You may discard it, or use it to determine if the returned function was cached.</p>"},{"location":"lua/template/#function-boolean-templatecompile_stringview-cache_key","title":"function, boolean template.compile_string(view, cache_key)","text":"<p>This just calls <code>template.compile(view, cache_key, true)</code></p>"},{"location":"lua/template/#function-boolean-templatecompile_fileview-cache_key","title":"function, boolean template.compile_file(view, cache_key)","text":"<p>This just calls <code>template.compile(view, cache_key, false)</code></p>"},{"location":"lua/template/#templatevisitfunc","title":"template.visit(func)","text":"<p>Allows you to register template parser visitor functions. Visitors are called in the order they are registered. And once registered, cannot be removed from parser. Perhaps it is easier to show how it works:</p> <pre><code>local template = require \"resty.template.safe\".new()\n\nlocal i = 0\n\ntemplate.visit(function(content, type, name)\n  local trimmed = content:gsub(\"^%s+\", \"\"):gsub(\"%s+$\", \"\")\n  if trimmed == \"\" then return content end\n  i = i + 1\n  print(\"  visit: \", i)\n  if type then print(\"   type: \", type) end\n  if name then print(\"   name: \", name) end\n  print(\"content: \", trimmed)\n  print()\n  return content\nend)\n\nlocal func = template.compile([[\nHow are you, {{user.name}}?\n\nHere is a new cooking recipe for you!\n\n{% for i, ingredient in ipairs(ingredients) do %}\n  {*i*}. {{ingredient}}\n{% end %}\n{-ad-}`lua-resty-template` the templating engine for OpenResty!{-ad-}\n]])\n\nlocal content = func{\n  user = {\n    name = \"bungle\"\n  },\n  ingredients = {\n    \"potatoes\",\n    \"sausages\"\n  }\n}\n\nprint(content)\n</code></pre> <p>This will output the following:</p> <pre><code>  visit: 1\ncontent: How are you,\n\n  visit: 2\n   type: {\ncontent: user.name\n\n  visit: 3\ncontent: ?\n\nHere is a new cooking recipe for you!\n\n  visit: 4\n   type: %\ncontent: for i, ingredient in ipairs(ingredients) do\n\n  visit: 5\n   type: *\ncontent: i\n\n  visit: 6\ncontent: .\n\n  visit: 7\n   type: {\ncontent: ingredient\n\n  visit: 8\n   type: %\ncontent: end\n\n  visit: 9\n   type: -\n   name: ad\ncontent: `lua-resty-template` the templating engine for OpenResty!\n\n  visit: 10\ncontent: `lua-resty-template` the templating engine for OpenResty!\n\nHow are you, bungle?\n\nHere is a new cooking recipe for you!\n\n  1. potatoes\n  2. sausages\n</code></pre> <p>The visitor functions should have this signature: <pre><code>string function(content, type, name)\n</code></pre></p> <p>If the function doesn't modify the <code>content</code> it should return the <code>content</code> back, like the visitor above does.</p> <p>Here is a bit more advanced visitor example that handles run-time errors on expressions:</p> <pre><code>local template = require \"resty.template\".new()\n\ntemplate.render \"Calculation: {{i*10}}\"\n</code></pre> <p>This will runtime error with: <pre><code>ERROR: [string \"context=... or {}...\"]:7: attempt to perform arithmetic on global 'i' (a nil value)\nstack traceback:\n    resty/template.lua:652: in function 'render'\n    a.lua:52: in function 'file_gen'\n    init_worker_by_lua:45: in function &lt;init_worker_by_lua:43&gt;\n    [C]: in function 'xpcall'\n    init_worker_by_lua:52: in function &lt;init_worker_by_lua:50&gt;\n</code></pre></p> <p>Now let's add a visitor that handles this error:</p> <pre><code>local template = require \"resty.template\".new()\n\ntemplate.visit(function(content, type)\n  if type == \"*\" or type == \"{\" then\n    return \"select(3, pcall(function() return nil, \" .. content .. \" end)) or ''\"\n  end\n\n  return content\nend)\n\ntemplate.render \"Calculation: {{i*10}}\\n\"\ntemplate.render(\"Calculation: {{i*10}}\\n\", { i = 1 })\n</code></pre> <p>This will output:</p> <pre><code>Calculation: \nCalculation: 10\n</code></pre>"},{"location":"lua/template/#string-templateprocessview-context-cache_key-plain","title":"string template.process(view, context, cache_key, plain)","text":"<p>Parses, compiles, caches (if caching is enabled) and returns output as string. You may optionally also pass <code>cache_key</code> that is used as a cache key. If <code>plain</code> evaluates to <code>true</code>, the <code>view</code> is considered to be plain string template (<code>template.load</code> and binary chunk detection is skipped on <code>template.parse</code>). If <code>plain</code> is <code>false\"</code> the template is considered to be a file, and all the issues with file reading are considered as errors. If the <code>plain</code> is set to <code>nil</code> (the default) the template does not consider file reading errors as fatal, and returns back the <code>view</code>.</p> <pre><code>local output = template.process(\"template.html\", { message = \"Hello, World!\" })          -- or\nlocal output = template.process([[&lt;h1&gt;{{message}}&lt;/h1&gt;]], { message = \"Hello, World!\" })\n</code></pre>"},{"location":"lua/template/#string-templateprocess_stringview-context-cache_key","title":"string template.process_string(view, context, cache_key)","text":"<p>This just calls <code>template.process(view, context, cache_key, true)</code></p>"},{"location":"lua/template/#string-templateprocess_fileview-context-cache_key","title":"string template.process_file(view, context, cache_key)","text":"<p>This just calls <code>template.process(view, context, cache_key, false)</code></p>"},{"location":"lua/template/#templaterenderview-context-cache_key-plain","title":"template.render(view, context, cache_key, plain)","text":"<p>Parses, compiles, caches (if caching is enabled) and outputs template either with <code>ngx.print</code> if available, or <code>print</code>. You may optionally also pass <code>cache_key</code> that is used as a cache key. If <code>plain</code> evaluates to <code>true</code>, the <code>view</code> is considered to be plain string template (<code>template.load</code> and binary chunk detection is skipped on <code>template.parse</code>). If <code>plain</code> is <code>false\"</code> the template is considered to be a file, and all the issues with file reading are considered as errors. If the <code>plain</code> is set to <code>nil</code> (the default) the template does not consider file reading errors as fatal, and returns back the <code>view</code>.</p> <pre><code>template.render(\"template.html\", { message = \"Hello, World!\" })          -- or\ntemplate.render([[&lt;h1&gt;{{message}}&lt;/h1&gt;]], { message = \"Hello, World!\" })\n</code></pre>"},{"location":"lua/template/#templaterender_stringview-context-cache_key","title":"template.render_string(view, context, cache_key)","text":"<p>This just calls <code>template.render(view, context, cache_key, true)</code></p>"},{"location":"lua/template/#templaterender_fileview-context-cache_key","title":"template.render_file(view, context, cache_key)","text":"<p>This just calls <code>template.render(view, context, cache_key, false)</code></p>"},{"location":"lua/template/#string-templateparseview-plain","title":"string template.parse(view, plain)","text":"<p>Parses template file or string, and generates a parsed template string. This may come useful when debugging templates. You should note that if you are trying to parse a binary chunk (e.g. one returned with <code>template.compile</code>), <code>template.parse</code> will return that binary chunk as is. If <code>plain</code> evaluates to <code>true</code>, the <code>view</code> is considered to be plain string template (<code>template.load</code> and binary chunk detection is skipped on <code>template.parse</code>). If <code>plain</code> is <code>false\"</code> the template is considered to be a file, and all the issues with file reading are considered as errors. If the <code>plain</code> is set to <code>nil</code> (the default) the template does not consider file reading errors as fatal, and returns back the <code>view</code>.</p> <pre><code>local t1 = template.parse(\"template.html\")\nlocal t2 = template.parse([[&lt;h1&gt;{{message}}&lt;/h1&gt;]])\n</code></pre>"},{"location":"lua/template/#string-templateparse_stringview-plain","title":"string template.parse_string(view, plain)","text":"<p>This just calls <code>template.parse(view, plain, true)</code></p>"},{"location":"lua/template/#string-templateparse_fileview-plain","title":"string template.parse_file(view, plain)","text":"<p>This just calls <code>template.parse(view, plain, false)</code></p>"},{"location":"lua/template/#string-templateprecompileview-path-strip-plain","title":"string template.precompile(view, path, strip, plain)","text":"<p>Precompiles template as a binary chunk. This binary chunk can be written out as a file (and you may use it directly with Lua's <code>load</code> and <code>loadfile</code>). For convenience you may optionally specify <code>path</code> argument to output binary chunk to file. You may also supply <code>strip</code> parameter with value of <code>false</code> to make precompiled templates to have debug information as well (defaults to <code>true</code>). The last parameter <code>plain</code> means that should complilation treat the <code>view</code> as <code>string</code> (<code>plain = true</code>) or as <code>file path</code> (<code>plain = false</code>) or try first as a file, and fallback to <code>string</code> (<code>plain = nil</code>). In case the <code>plain=false</code> (a file) and there is error with <code>file io</code> the function will also error with an assertion failure. </p> <pre><code>local view = [[\n&lt;h1&gt;{{title}}&lt;/h1&gt;\n&lt;ul&gt;\n{% for _, v in ipairs(context) do %}\n    &lt;li&gt;{{v}}&lt;/li&gt;\n{% end %}\n&lt;/ul&gt;]]\n\nlocal compiled = template.precompile(view)\n\nlocal file = io.open(\"precompiled-bin.html\", \"wb\")\nfile:write(compiled)\nfile:close()\n\n-- Alternatively you could just write (which does the same thing as above)\ntemplate.precompile(view, \"precompiled-bin.html\")\n\ntemplate.render(\"precompiled-bin.html\", {\n    title = \"Names\",\n    \"Emma\", \"James\", \"Nicholas\", \"Mary\"\n})\n</code></pre>"},{"location":"lua/template/#string-templateprecompile_stringview-path-strip","title":"string template.precompile_string(view, path, strip)","text":"<p>This just calls <code>template.precompile(view, path, strip, true)</code>.</p>"},{"location":"lua/template/#string-templateprecompile_fileview-path-strip","title":"string template.precompile_file(view, path, strip)","text":"<p>This just calls <code>template.precompile(view, path, strip, false)</code>.</p>"},{"location":"lua/template/#string-templateloadview-plain","title":"string template.load(view, plain)","text":"<p>This field is used to load templates. <code>template.parse</code> calls this function before it starts parsing the template (assuming that optional <code>plain</code> argument in <code>template.parse</code> evaluates to <code>false</code> or <code>nil</code> (the default). By default there are two loaders in <code>lua-resty-template</code>: one for Lua and the other for Nginx / OpenResty. Users can overwrite this field with their own function. For example you may want to write a template loader function that loads templates from a database.</p> <p>The default <code>template.load</code> for Lua (attached as template.load when used directly with Lua):</p> <pre><code>function(view, plain)\n    if plain == true then return view end\n    local path, root = view, template.root\n    if root and root ~= EMPTY then\n        if byte(root, -1) == SOL then root = sub(root, 1, -2) end\n        if byte(view,  1) == SOL then path = sub(view, 2) end\n        path = root .. \"/\" .. path\n    end\n    return plain == false and assert(read_file(path)) or read_file(path) or view\nend\n</code></pre> <p>The default <code>template.load</code> for Nginx / OpenResty (attached as template.load when used in context of Nginx / OpenResty):</p> <pre><code>function(view, plain)\n    if plain == true then return view end\n    local vars = VAR_PHASES[phase()]\n    local path = view\n    local root = template.location\n    if (not root or root == EMPTY) and vars then\n        root = var.template_location\n    end\n    if root and root ~= EMPTY then\n        if byte(root, -1) == SOL then root = sub(root, 1, -2) end\n        if byte(path,  1) == SOL then path = sub(path, 2) end\n        path = root .. \"/\" .. path\n        local res = capture(path)\n        if res.status == 200 then return res.body end\n    end\n    path = view\n    root = template.root\n    if (not root or root == EMPTY) and vars then\n        root = var.template_root\n        if not root or root == EMPTY then root = var.document_root or prefix end\n    end\n    if root and root ~= EMPTY then\n        if byte(root, -1) == SOL then root = sub(root, 1, -2) end\n        if byte(path,  1) == SOL then path = sub(path, 2) end\n        path = root .. \"/\" .. path\n    end\n    return plain == false and assert(read_file(path)) or read_file(path) or view\nend\n</code></pre> <p>As you can see, <code>lua-resty-template</code> always tries (by default) to load a template from a file (or with <code>ngx.location.capture</code>) even if you provided template as a string. <code>lua-resty-template</code>. But if you know that your templates are always strings, and not file paths, you may use <code>plain</code> argument in <code>template.compile</code>, <code>template.render</code>, and <code>template.parse</code> OR replace <code>template.load</code> with the simplest possible template loader there is (but be aware that if your templates use <code>{(file.html)}</code> includes, those are considered as strings too, in this case <code>file.html</code> will be the template string that is parsed) - you could also setup a loader that finds templates in some database system, e.g. Redis:</p> <pre><code>local template = require \"resty.template\"\ntemplate.load = function(view, plain) return view end\n</code></pre> <p>If the <code>plain</code> parameter is <code>false</code> (<code>nil</code> is not treated as <code>false</code>), all the issues with file io are considered assertion errors.</p>"},{"location":"lua/template/#string-templateload_stringview","title":"string template.load_string(view)","text":"<p>This just calls <code>template.load(view, true)</code></p>"},{"location":"lua/template/#string-templateload_fileview","title":"string template.load_file(view)","text":"<p>This just calls <code>template.load(view, false)</code></p>"},{"location":"lua/template/#templateprint","title":"template.print","text":"<p>This field contains a function that is used on <code>template.render()</code> or <code>template.new(\"example.html\"):render()</code> to output the results. By default this holds either <code>ngx.print</code> (if available) or <code>print</code>. You may want to (and are allowed to) overwrite this field, if you want to use your own output function instead. This is also useful if you are using some other framework, e.g. Turbo.lua (http://turbolua.org/).</p> <pre><code>local template = require \"resty.template\"\n\ntemplate.print = function(s)\n  print(s)\n  print(\"&lt;!-- Output by My Function --&gt;\")\nend\n</code></pre>"},{"location":"lua/template/#template-precompilation","title":"Template Precompilation","text":"<p><code>lua-resty-template</code> supports template precompilation. This can be useful when you want to skip template parsing (and Lua interpretation) in production or if you do not want your templates distributed as plain text files on production servers. Also by precompiling, you can ensure that your templates do not contain something, that cannot be compiled (they are syntactically valid Lua). Although templates are cached (even without precompilation), there are some performance (and memory) gains. You could integrate template precompilation in your build (or deployment) scripts (maybe as Gulp, Grunt or Ant tasks).</p>"},{"location":"lua/template/#precompiling-template-and-output-it-as-a-binary-file","title":"Precompiling template, and output it as a binary file","text":"<pre><code>local template = require \"resty.template\"\nlocal compiled = template.precompile(\"example.html\", \"example-bin.html\")\n</code></pre>"},{"location":"lua/template/#load-precompiled-template-file-and-run-it-with-context-parameters","title":"Load precompiled template file, and run it with context parameters","text":"<pre><code>local template = require \"resty.template\"\ntemplate.render(\"example-bin.html\", { \"Jack\", \"Mary\" })\n</code></pre>"},{"location":"lua/template/#template-helpers","title":"Template Helpers","text":""},{"location":"lua/template/#built-in-helpers","title":"Built-in Helpers","text":""},{"location":"lua/template/#echo","title":"echo(...)","text":"<p>Echoes output. This is useful with <code>{% .. %}</code>:</p> <pre><code>require \"resty.template\".render[[\nbegin\n{%\nfor i=1, 10 do\n  echo(\"\\tline: \", i, \"\\n\")\nend\n%}\nend\n]]\n</code></pre> <p>This will output:</p> <pre><code>begin\n    line: 1\n    line: 2\n    line: 3\n    line: 4\n    line: 5\n    line: 6\n    line: 7\n    line: 8\n    line: 9\n    line: 10\nend\n</code></pre> <p>This can also be written as but <code>echo</code> might come handy in some cases:</p> <pre><code>require \"resty.template\".render[[\nbegin\n{% for i=1, 10 do %}\n  line: {* i *}\n{% end %}\nend\n]]\n</code></pre>"},{"location":"lua/template/#includeview-context","title":"include(view, context)","text":"<p>This is mainly used with internally with <code>{(view.hmtl)}</code>, <code>{[\"view.hmtl\"]}</code> and with blocks <code>{-block-name-}..{-block-name-}</code>. If <code>context</code> is not given the context used to compile parent view is used. This function will compile the <code>view</code> and call the resulting function with <code>context</code> (or the <code>context</code> of parent view if not given).</p>"},{"location":"lua/template/#other-ways-to-extend","title":"Other Ways to Extend","text":"<p>While <code>lua-resty-template</code> does not have much infrastucture or ways to extend it, you still have a few possibilities that you may try.</p> <ul> <li>Adding methods to global <code>string</code>, and <code>table</code> types (not encouraged, though)</li> <li>Wrap your values with something before adding them in context (e.g. proxy-table)</li> <li>Create global functions</li> <li>Add local functions either to <code>template</code> table or <code>context</code> table</li> <li>Use metamethods in your tables</li> </ul> <p>While modifying global types seems convenient, it can have nasty side effects. That's why I suggest you to look at these libraries, and articles first:</p> <ul> <li>Method Chaining Wrapper (http://lua-users.org/wiki/MethodChainingWrapper)</li> <li>Moses (https://github.com/Yonaba/Moses)</li> <li>underscore-lua (https://github.com/jtarchie/underscore-lua)</li> </ul> <p>You could for example add Moses' or Underscore's <code>_</code> to template table or context table.</p>"},{"location":"lua/template/#example_3","title":"Example","text":"<pre><code>local _ = require \"moses\"\nlocal template = require \"resty.template\"\ntemplate._ = _\n</code></pre> <p>Then you can use <code>_</code> inside your templates. I created one example template helper that can be found from here: https://github.com/bungle/lua-resty-template/blob/master/lib/resty/template/html.lua</p>"},{"location":"lua/template/#lua_2","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\nlocal html = require \"resty.template.html\"\n\ntemplate.render([[\n&lt;ul&gt;\n{% for _, person in ipairs(context) do %}\n    {*html.li(person.name)*}\n{% end %}\n&lt;/ul&gt;\n&lt;table&gt;\n{% for _, person in ipairs(context) do %}\n    &lt;tr data-sort=\"{{(person.name or \"\"):lower()}}\"&gt;\n        {*html.td{ id = person.id }(person.name)*}\n    &lt;/tr&gt;\n{% end %}\n&lt;/table&gt;]], {\n    { id = 1, name = \"Emma\"},\n    { id = 2, name = \"James\" },\n    { id = 3, name = \"Nicholas\" },\n    { id = 4 }\n})\n</code></pre>"},{"location":"lua/template/#output_1","title":"Output","text":"<pre><code>&lt;ul&gt;\n    &lt;li&gt;Emma&lt;/li&gt;\n    &lt;li&gt;James&lt;/li&gt;\n    &lt;li&gt;Nicholas&lt;/li&gt;\n    &lt;li /&gt;\n&lt;/ul&gt;\n&lt;table&gt;\n    &lt;tr data-sort=\"emma\"&gt;\n        &lt;td id=\"1\"&gt;Emma&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr data-sort=\"james\"&gt;\n        &lt;td id=\"2\"&gt;James&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr data-sort=\"nicholas\"&gt;\n        &lt;td id=\"3\"&gt;Nicholas&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr data-sort=\"\"&gt;\n        &lt;td id=\"4\" /&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre>"},{"location":"lua/template/#usage-examples","title":"Usage Examples","text":""},{"location":"lua/template/#template-including","title":"Template Including","text":"<p>You may include templates inside templates with <code>{(template)}</code> and <code>{(template, context)}</code> syntax. The first one uses the current context as a context for included template, and the second one replaces it with a new context. Here is example of using includes and passing a different context to include file:</p>"},{"location":"lua/template/#lua_3","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\ntemplate.render(\"include.html\", { users = {\n    { name = \"Jane\", age = 29 },\n    { name = \"John\", age = 25 }\n}})\n</code></pre>"},{"location":"lua/template/#includehtml","title":"include.html","text":"<pre><code>&lt;html&gt;\n&lt;body&gt;\n&lt;ul&gt;\n{% for _, user in ipairs(users) do %}\n    {(user.html, user)}\n{% end %}\n&lt;/ul&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#userhtml","title":"user.html","text":"<pre><code>&lt;li&gt;User {{name}} is of age {{age}}&lt;/li&gt;\n</code></pre>"},{"location":"lua/template/#outut","title":"Outut","text":"<pre><code>&lt;html&gt;\n&lt;body&gt;\n&lt;ul&gt;\n    &lt;li&gt;User Jane is of age 29&lt;/li&gt;\n    &lt;li&gt;User John is of age 25&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#views-with-layouts","title":"Views with Layouts","text":"<p>Layouts (or Master Pages) can be used to wrap a view inside another view (aka layout).</p>"},{"location":"lua/template/#lua_4","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\nlocal layout   = template.new \"layout.html\"\nlayout.title   = \"Testing lua-resty-template\"\nlayout.view    = template.compile \"view.html\" { message = \"Hello, World!\" }\nlayout:render()\n-- Or like this\ntemplate.render(\"layout.html\", {\n  title = \"Testing lua-resty-template\",\n  view  = template.compile \"view.html\" { message = \"Hello, World!\" }\n})\n-- Or maybe you like this style more\n-- (but please remember that context.view is overwritten on rendering the layout.html)\nlocal view     = template.new(\"view.html\", \"layout.html\")\nview.title     = \"Testing lua-resty-template\"\nview.message   = \"Hello, World!\"\nview:render()\n-- Well, maybe like this then?\nlocal layout   = template.new \"layout.html\"\nlayout.title   = \"Testing lua-resty-template\"\nlocal view     = template.new(\"view.html\", layout)\nview.message   = \"Hello, World!\"\nview:render()\n</code></pre>"},{"location":"lua/template/#viewhtml_4","title":"view.html","text":"<pre><code>&lt;h1&gt;{{message}}&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#layouthtml","title":"layout.html","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{title}}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {*view*}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#alternatively-you-can-define-the-layout-in-a-view-as-well","title":"Alternatively you can define the layout in a view as well:","text":""},{"location":"lua/template/#lua_5","title":"Lua","text":"<pre><code>local view     = template.new(\"view.html\", \"layout.html\")\nview.title     = \"Testing lua-resty-template\"\nview.message   = \"Hello, World!\"\nview:render()\n</code></pre>"},{"location":"lua/template/#viewhtml_5","title":"view.html","text":"<pre><code>{% layout=\"section.html\" %}\n&lt;h1&gt;{{message}}&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#sectionhtml","title":"section.html","text":"<pre><code>&lt;div id=\"section\"&gt;\n    {*view*}\n&lt;/div&gt;\n</code></pre>"},{"location":"lua/template/#layouthtml_1","title":"layout.html","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{title}}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {*view*}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#output_2","title":"Output","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Testing lua-resty-template&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id=\"section\"&gt;\n    &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#using-blocks","title":"Using Blocks","text":"<p>Blocks can be used to move different parts of the views to specific places in layouts. Layouts have placeholders for blocks.</p>"},{"location":"lua/template/#lua_6","title":"Lua","text":"<pre><code>local view     = template.new(\"view.html\", \"layout.html\")\nview.title     = \"Testing lua-resty-template blocks\"\nview.message   = \"Hello, World!\"\nview.keywords  = { \"test\", \"lua\", \"template\", \"blocks\" }\nview:render()\n</code></pre>"},{"location":"lua/template/#viewhtml_6","title":"view.html","text":"<pre><code>&lt;h1&gt;{{message}}&lt;/h1&gt;\n{-aside-}\n&lt;ul&gt;\n    {% for _, keyword in ipairs(keywords) do %}\n    &lt;li&gt;{{keyword}}&lt;/li&gt;\n    {% end %}\n&lt;/ul&gt;\n{-aside-}\n</code></pre>"},{"location":"lua/template/#layouthtml_2","title":"layout.html","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;{*title*}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;article&gt;\n    {*view*}\n&lt;/article&gt;\n{% if blocks.aside then %}\n&lt;aside&gt;\n    {*blocks.aside*}\n&lt;/aside&gt;\n{% end %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#output_3","title":"Output","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Testing lua-resty-template blocks&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;article&gt;\n    &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/article&gt;\n&lt;aside&gt;\n    &lt;ul&gt;\n        &lt;li&gt;test&lt;/li&gt;\n        &lt;li&gt;lua&lt;/li&gt;\n        &lt;li&gt;template&lt;/li&gt;\n        &lt;li&gt;blocks&lt;/li&gt;\n    &lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#grandfather-father-son-inheritance","title":"Grandfather-Father-Son Inheritance","text":"<p>Say you have <code>base.html</code>, <code>layout1.html</code>, <code>layout2.html</code> and <code>page.html</code>. You want an inheritance like this: <code>base.html \u27a1 layout1.html \u27a1 page.html</code> or <code>base.html \u27a1 layout2.html \u27a1 page.html</code> (actually this nesting is not limited to three levels).</p>"},{"location":"lua/template/#lua_7","title":"Lua","text":"<pre><code>local res = require\"resty.template\".compile(\"page.html\"){} \n</code></pre>"},{"location":"lua/template/#basehtml","title":"base.html","text":"<pre><code>&lt;html lang='zh'&gt;\n   &lt;head&gt;\n   &lt;link href=\"css/bootstrap.min.css\" rel=\"stylesheet\"&gt;\n   {* blocks.page_css *}\n   &lt;/head&gt;\n   &lt;body&gt;\n   {* blocks.main *}\n   &lt;script src=\"js/jquery.js\"&gt;&lt;/script&gt;\n   &lt;script src=\"js/bootstrap.min.js\"&gt;&lt;/script&gt;\n   {* blocks.page_js *}\n   &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"lua/template/#layout1html","title":"layout1.html","text":"<pre><code>{% layout = \"base.html\" %}\n{-main-}\n    &lt;div class=\"sidebar-1\"&gt;\n      {* blocks.sidebar *}\n    &lt;/div&gt;\n    &lt;div class=\"content-1\"&gt;\n      {* blocks.content *}\n    &lt;/div&gt;\n{-main-}\n</code></pre>"},{"location":"lua/template/#layout2html","title":"layout2.html","text":"<pre><code>{% layout = \"base.html\" %}\n{-main-}\n    &lt;div class=\"sidebar-2\"&gt;\n      {* blocks.sidebar *}\n    &lt;/div&gt;\n    &lt;div class=\"content-2\"&gt;\n      {* blocks.content *}\n    &lt;/div&gt;\n    &lt;div&gt;I am different from layout1 &lt;/div&gt;\n{-main-}\n</code></pre>"},{"location":"lua/template/#pagehtml","title":"page.html","text":"<pre><code>{% layout = \"layout1.html\" %}\n{-sidebar-}\n  this is sidebar\n{-sidebar-}\n\n{-content-}\n  this is content\n{-content-}\n\n{-page_css-}\n  &lt;link href=\"css/page.css\" rel=\"stylesheet\"&gt;\n{-page_css-}\n\n{-page_js-}\n  &lt;script src=\"js/page.js\"&gt;&lt;/script&gt;\n{-page_js-}\n</code></pre> <p>Or:</p>"},{"location":"lua/template/#pagehtml_1","title":"page.html","text":"<pre><code>{% layout = \"layout2.html\" %}\n{-sidebar-}\n  this is sidebar\n{-sidebar-}\n\n{-content-}\n  this is content\n{-content-}\n\n{-page_css-}\n  &lt;link href=\"css/page.css\" rel=\"stylesheet\"&gt;\n{-page_css-}\n\n{-page_js-}\n  &lt;script src=\"js/page.js\"&gt;&lt;/script&gt;\n{-page_js-}\n</code></pre>"},{"location":"lua/template/#macros","title":"Macros","text":"<p>@DDarko mentioned in an issue #5 that he has a use case where he needs to have macros or parameterized views. That is a nice feature that you can use with <code>lua-resty-template</code>.</p> <p>To use macros, let's first define some Lua code:</p> <pre><code>template.render(\"macro.html\", {\n    item = \"original\",\n    items = { a = \"original-a\", b = \"original-b\" } \n})\n</code></pre> <p>And the <code>macro-example.html</code>:</p> <pre><code>{% local string_macro = [[\n&lt;div&gt;{{item}}&lt;/div&gt;\n]] %}\n{* template.compile(string_macro)(context) *}\n{* template.compile(string_macro){ item = \"string-macro-context\" } *}\n</code></pre> <p>This will output:</p> <pre><code>&lt;div&gt;original&lt;/div&gt;\n&lt;div&gt;string-macro-context&lt;/div&gt;\n</code></pre> <p>Now let's add function macro, in <code>macro-example.html</code> (you can omit <code>local</code> if you want):</p> <pre><code>{% local function_macro = function(var, el)\n    el = el or \"div\"\n    return \"&lt;\" .. el .. \"&gt;{{\" .. var .. \"}}&lt;/\" .. el .. \"&gt;\\n\"\nend %}\n\n{* template.compile(function_macro(\"item\"))(context) *}\n{* template.compile(function_macro(\"a\", \"span\"))(items) *}\n</code></pre> <p>This will output:</p> <pre><code>&lt;div&gt;original&lt;/div&gt;\n&lt;span&gt;original-a&lt;/span&gt;\n</code></pre> <p>But this is even more flexible, let's try another function macro:</p> <pre><code>{% local function function_macro2(var)\n    return template.compile(\"&lt;div&gt;{{\" .. var .. \"}}&lt;/div&gt;\\n\")\nend %}\n{* function_macro2 \"item\" (context) *}\n{* function_macro2 \"b\" (items) *}\n</code></pre> <p>This will output:</p> <pre><code>&lt;div&gt;original&lt;/div&gt;\n&lt;div&gt;original-b&lt;/div&gt;\n</code></pre> <p>And here is another one:</p> <pre><code>{% function function_macro3(var, ctx)\n    return template.compile(\"&lt;div&gt;{{\" .. var .. \"}}&lt;/div&gt;\\n\")(ctx or context)\nend %}\n{* function_macro3(\"item\") *}\n{* function_macro3(\"a\", items) *}\n{* function_macro3(\"b\", items) *}\n{* function_macro3(\"b\", { b = \"b-from-new-context\" }) *}\n</code></pre> <p>This will output:</p> <pre><code>&lt;div&gt;original&lt;/div&gt;\n&lt;div&gt;original-a&lt;/div&gt;\n&lt;div&gt;original-b&lt;/div&gt;\n&lt;div&gt;b-from-new-context&lt;/div&gt;\n</code></pre> <p>Macros are really flexible. You may have form-renderers and other helper-macros to have a reusable and parameterized template output. One thing you should know is that inside code blocks (between <code>{%</code> and <code>%}</code>) you cannot have <code>%}</code>, but you can work around this using string concatenation <code>\"%\" .. \"}\"</code>.</p>"},{"location":"lua/template/#calling-methods-in-templates","title":"Calling Methods in Templates","text":"<p>You can call string methods (or other table functions) in templates too.</p>"},{"location":"lua/template/#lua_8","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\ntemplate.render([[\n&lt;h1&gt;{{header:upper()}}&lt;/h1&gt;\n]], { header = \"hello, world!\" })\n</code></pre>"},{"location":"lua/template/#output_4","title":"Output","text":"<pre><code>&lt;h1&gt;HELLO, WORLD!&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#embedding-angular-or-other-tags-templating-inside-the-templates","title":"Embedding Angular or other tags / templating inside the Templates","text":"<p>Sometimes you need to mix and match other templates (say client side Javascript templates like Angular) with server side lua-resty-templates. Say you have this kind of Angular template:</p> <pre><code>&lt;html ng-app&gt;\n &lt;body ng-controller=\"MyController\"&gt;\n   &lt;input ng-model=\"foo\" value=\"bar\"&gt;\n   &lt;button ng-click=\"changeFoo()\"&gt;{{buttonText}}&lt;/button&gt;\n   &lt;script src=\"angular.js\"&gt;\n &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Now you can see that there is <code>{{buttonText}}</code> that is really for Angular templating, and not for lua-resty-template. You can fix this by wrapping either the whole code with <code>{-verbatim-}</code> or <code>{-raw-}</code> or only the parts that you want:</p> <pre><code>{-raw-}\n&lt;html ng-app&gt;\n &lt;body ng-controller=\"MyController\"&gt;\n   &lt;input ng-model=\"foo\" value=\"bar\"&gt;\n   &lt;button ng-click=\"changeFoo()\"&gt;{{buttonText}}&lt;/button&gt;\n   &lt;script src=\"angular.js\"&gt;\n &lt;/body&gt;\n&lt;/html&gt;\n{-raw-}\n</code></pre> <p>or (see the <code>{(head.html)}</code> is processed by lua-resty-template):</p> <pre><code>&lt;html ng-app&gt;\n {(head.html)}\n &lt;body ng-controller=\"MyController\"&gt;\n   &lt;input ng-model=\"foo\" value=\"bar\"&gt;\n   &lt;button ng-click=\"changeFoo()\"&gt;{-raw-}{{buttonText}}{-raw-}&lt;/button&gt;\n   &lt;script src=\"angular.js\"&gt;\n &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>You may also use short escaping syntax:</p> <pre><code>...\n&lt;button ng-click=\"changeFoo()\"&gt;\\{{buttonText}}&lt;/button&gt;\n...\n</code></pre>"},{"location":"lua/template/#embedding-markdown-inside-the-templates","title":"Embedding Markdown inside the Templates","text":"<p>If you want to embed Markdown (and SmartyPants) syntax inside your templates you can do it by using for example <code>lua-resty-hoedown</code> (it depends on LuaJIT). Here is an example of using that:</p>"},{"location":"lua/template/#lua_9","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\ntemplate.markdown = require \"resty.hoedown\"\n\ntemplate.render[=[\n&lt;html&gt;\n&lt;body&gt;\n{*markdown[[\n#Hello, World\n\nTesting Markdown.\n]]*}\n&lt;/body&gt;\n&lt;/html&gt;\n]=]\n</code></pre>"},{"location":"lua/template/#output_5","title":"Output","text":"<pre><code>&lt;html&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello, World&lt;/h1&gt;\n\n&lt;p&gt;Testing Markdown.&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>You may also add config parameters that are documented in <code>lua-resty-hoedown</code> project. Say you want also to use SmartyPants:</p>"},{"location":"lua/template/#lua_10","title":"Lua","text":"<pre><code>local template = require \"resty.template\"\ntemplate.markdown = require \"resty.hoedown\"\n\ntemplate.render[=[\n&lt;html&gt;\n&lt;body&gt;\n{*markdown([[\n#Hello, World\n\nTesting Markdown with \"SmartyPants\"...\n]], { smartypants = true })*}\n&lt;/body&gt;\n&lt;/html&gt;\n]=]\n</code></pre>"},{"location":"lua/template/#output_6","title":"Output","text":"<pre><code>&lt;html&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello, World&lt;/h1&gt;\n\n&lt;p&gt;Testing Markdown with &amp;ldquo;SmartyPants&amp;rdquo;&amp;hellip;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>You may also want to add caching layer for your Markdowns, or a helper functions instead of placing Hoedown library directly  as a template helper function in <code>template</code>.   </p>"},{"location":"lua/template/#lua-server-pages-lsp-with-openresty","title":"Lua Server Pages (LSP) with OpenResty","text":"<p>Lua Server Pages or LSPs is similar to traditional PHP or Microsoft Active Server Pages (ASP) where you can just place source code files in your document root (of your web server) and have them processed by compilers of the respective languages (PHP, VBScript, JScript, etc.). You can emulate quite closely this, sometimes called spaghetti-style of develoment, easily with <code>lua-resty-template</code>. Those that have been doing ASP.NET Web Forms development, know a concept of Code Behind files. There is something similar, but this time we call it Layout in Front here (you may include Lua modules with normal <code>require</code> calls if you wish in LSPs). To help you understand the concepts, let's have a small example:</p>"},{"location":"lua/template/#nginxconf","title":"nginx.conf:","text":"<pre><code>http {\n  init_by_lua '\n    require \"resty.core\"\n    template = require \"resty.template\"\n    template.caching(false); -- you may remove this on production\n  ';\n  server {\n    location ~ \\.lsp$ {\n      default_type text/html;\n      content_by_lua 'template.render(ngx.var.uri)';\n    }\n  }\n}\n</code></pre> <p>The above configuration creates a global <code>template</code> variable in Lua environment (you may not want that). We also created location to match all <code>.lsp</code> files (or locations), and then we just render the template.</p> <p>Let's imagine that the request is for <code>index.lsp</code>.</p>"},{"location":"lua/template/#indexlsp","title":"index.lsp","text":"<pre><code>{%\nlayout = \"layouts/default.lsp\"\nlocal title = \"Hello, World!\"\n%}\n&lt;h1&gt;{{title}}&lt;/h1&gt;\n</code></pre> <p>Here you can see that this file includes a little bit of a view (<code>&lt;h1&gt;{{title}}&lt;/h1&gt;</code>) in addition to some Lua code that we want to run. If you want to have a pure code file with Layout in Front, then just don't write any view code in this file. The <code>layout</code> variable is already defined in views as documented else where in this documentation. Now let's see the other files too.</p>"},{"location":"lua/template/#layoutsdefaultlsp","title":"layouts/default.lsp","text":"<pre><code>&lt;html&gt;\n{(include/header.lsp)}\n&lt;body&gt;\n{*view*}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Here we have a layout to decorate the <code>index.lsp</code>, but we also have include here, so let's look at it.</p>"},{"location":"lua/template/#includeheaderlsp","title":"include/header.lsp","text":"<pre><code>&lt;head&gt;\n  &lt;title&gt;Testing Lua Server Pages&lt;/title&gt;\n&lt;/head&gt;\n</code></pre> <p>Static stuff here only.</p>"},{"location":"lua/template/#output_7","title":"Output","text":"<p>The final output will look like this:</p> <pre><code>&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Testing Lua Server Pages&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>As you can see, <code>lua-resty-template</code> can be quite flexibile and easy to start with. Just place files under your document root and use the normal save-and-refresh style of development. The server will automatically pick the new files and reload the templates (if the caching is turned of) on save.</p> <p>If you want to pass variables to layouts or includes you can add stuff to context table (in the example below see <code>context.title</code>):</p> <pre><code>{%\nlayout = \"layouts/default.lsp\"\nlocal title = \"Hello, World!\"\ncontext.title = 'My Application - ' .. title\n%}\n&lt;h1&gt;{{title}}&lt;/h1&gt;\n</code></pre>"},{"location":"lua/template/#faq","title":"FAQ","text":""},{"location":"lua/template/#how-do-i-clear-the-template-cache","title":"How Do I Clear the Template Cache","text":"<p><code>lua-resty-template</code> automatically caches (if caching is enabled) the resulting template functions in <code>template.cache</code> table. You can clear the cache by issuing <code>template.cache = {}</code>.</p>"},{"location":"lua/template/#where-is-lua-resty-template-used","title":"Where is <code>lua-resty-template</code> Used","text":"<ul> <li>jd.com \u2013 Jingdong Mall (Chinese: \u4eac\u4e1c\u5546\u57ce; pinyin: J\u012bngd\u014dng Sh\u0101ngch\u00e9ng), formerly 360Buy, is a Chinese electronic commerce company</li> </ul> <p>Please let me know if there are errors or old information in this list. </p>"},{"location":"lua/template/#alternatives","title":"Alternatives","text":"<p>You may also look at these (as alternatives, or to mix them with <code>lua-resty-template</code>):</p> <ul> <li>lemplate (https://github.com/openresty/lemplate)</li> <li>lua-resty-tags (https://github.com/bungle/lua-resty-tags)</li> <li>lua-resty-hoedown (https://github.com/bungle/lua-resty-hoedown)</li> <li>etlua (https://github.com/leafo/etlua)</li> <li>lua-template (https://github.com/dannote/lua-template)</li> <li>lua-resty-tmpl (https://github.com/lloydzhou/lua-resty-tmpl) (a fork of the lua-template)</li> <li>htmlua (https://github.com/benglard/htmlua)</li> <li>cgilua (http://keplerproject.github.io/cgilua/manual.html#templates)</li> <li>orbit (http://keplerproject.github.io/orbit/pages.html)</li> <li>turbolua mustache (http://turbolua.org/doc/web.html#mustache-templating)</li> <li>pl.template (http://stevedonovan.github.io/Penlight/api/modules/pl.template.html)</li> <li>lustache (https://github.com/Olivine-Labs/lustache)</li> <li>luvstache (https://github.com/james2doyle/luvstache)</li> <li>luaghetti (https://github.com/AterCattus/luaghetti)</li> <li>lub.Template (http://doc.lubyk.org/lub.Template.html)</li> <li>lust (https://github.com/weshoke/Lust)</li> <li>templet (http://colberg.org/lua-templet/)</li> <li>luahtml (https://github.com/TheLinx/LuaHTML)</li> <li>mixlua (https://github.com/LuaDist/mixlua)</li> <li>lutem (https://github.com/daly88/lutem)</li> <li>tirtemplate (https://github.com/torhve/LuaWeb/blob/master/tirtemplate.lua)</li> <li>cosmo (http://cosmo.luaforge.net/)</li> <li>lua-codegen (http://fperrad.github.io/lua-CodeGen/)</li> <li>groucho (https://github.com/hanjos/groucho)</li> <li>simple lua preprocessor (http://lua-users.org/wiki/SimpleLuaPreprocessor)</li> <li>slightly less simple lua preprocessor (http://lua-users.org/wiki/SlightlyLessSimpleLuaPreprocessor)</li> <li>ltp (http://www.savarese.com/software/ltp/)</li> <li>slt (https://code.google.com/p/slt/)</li> <li>slt2 (https://github.com/henix/slt2)</li> <li>luasp (http://luasp.org/)</li> <li>view0 (https://bitbucket.org/jimstudt/view0)</li> <li>leslie (https://code.google.com/p/leslie/)</li> <li>fraudster (https://bitbucket.org/sphen_lee/fraudster)</li> <li>lua-haml (https://github.com/norman/lua-haml)</li> <li>lua-template (https://github.com/tgn14/Lua-template)</li> <li>hige (https://github.com/nrk/hige)</li> <li>mod_pLua (https://sourceforge.net/p/modplua/wiki/Home/)</li> <li>lapis html generation (http://leafo.net/lapis/reference.html#html-generation)</li> </ul> <p><code>lua-resty-template</code> was originally forked from Tor Hveem's <code>tirtemplate.lua</code> that he had extracted from Zed Shaw's Tir web framework (http://tir.mongrel2.org/). Thank you Tor, and Zed for your earlier contributions.</p>"},{"location":"lua/template/#benchmarks","title":"Benchmarks","text":"<p>There is a small microbenchmark located here: https://github.com/bungle/lua-resty-template/blob/master/lib/resty/template/microbenchmark.lua</p> <p>There is also a regression in LuaJIT that affects the results. If you want your LuaJIT patched against this, you need to merge this pull request: https://github.com/LuaJIT/LuaJIT/pull/174.</p> <p>Others have reported that in simple benchmarks running this template engine actually beats Nginx serving static files by a factor of three. So I guess this engine is quite fast. </p>"},{"location":"lua/template/#lua_11","title":"Lua","text":"<pre><code>local benchmark = require \"resty.template.microbenchmark\"\nbenchmark.run()\n-- You may also pass iteration count (by default it is 1,000)\nbenchmark.run(100)\n</code></pre> <p>Here are some results from my desktop (old 2010 Mac Pro): <pre><code>&lt;lua|luajit|resty&gt; -e 'require \"resty.template.microbenchmark\".run()'\n</code></pre> `</p>"},{"location":"lua/template/#lua-515-copyright-c-1994-2012-luaorg-puc-rio","title":"Lua 5.1.5  Copyright (C) 1994-2012 Lua.org, PUC-Rio","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.010759\nCompilation Time: 0.054640 (template)\nCompilation Time: 0.000213 (template, cached)\n  Execution Time: 0.061851 (same template)\n  Execution Time: 0.006722 (same template, cached)\n  Execution Time: 0.092698 (different template)\n  Execution Time: 0.009537 (different template, cached)\n  Execution Time: 0.092452 (different template, different context)\n  Execution Time: 0.010106 (different template, different context, cached)\n      Total Time: 0.338978\n</code></pre>"},{"location":"lua/template/#lua-524-copyright-c-1994-2015-luaorg-puc-rio","title":"Lua 5.2.4  Copyright (C) 1994-2015 Lua.org, PUC-Rio","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.011633\nCompilation Time: 0.060598 (template)\nCompilation Time: 0.000243 (template, cached)\n  Execution Time: 0.068009 (same template)\n  Execution Time: 0.007307 (same template, cached)\n  Execution Time: 0.071339 (different template)\n  Execution Time: 0.007150 (different template, cached)\n  Execution Time: 0.066766 (different template, different context)\n  Execution Time: 0.006940 (different template, different context, cached)\n      Total Time: 0.299985\n</code></pre>"},{"location":"lua/template/#lua-535-copyright-c-1994-2018-luaorg-puc-rio","title":"Lua 5.3.5  Copyright (C) 1994-2018 Lua.org, PUC-Rio","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.012458\nCompilation Time: 0.050013 (template)\nCompilation Time: 0.000249 (template, cached)\n  Execution Time: 0.057579 (same template)\n  Execution Time: 0.006959 (same template, cached)\n  Execution Time: 0.065352 (different template)\n  Execution Time: 0.007133 (different template, cached)\n  Execution Time: 0.060965 (different template, different context)\n  Execution Time: 0.007726 (different template, different context, cached)\n      Total Time: 0.268434\n</code></pre>"},{"location":"lua/template/#lua-540-copyright-c-1994-2019-luaorg-puc-rio","title":"Lua 5.4.0  Copyright (C) 1994-2019 Lua.org, PUC-Rio","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.009466\nCompilation Time: 0.053116 (template)\nCompilation Time: 0.000209 (template, cached)\n  Execution Time: 0.059017 (same template)\n  Execution Time: 0.006129 (same template, cached)\n  Execution Time: 0.061882 (different template)\n  Execution Time: 0.006613 (different template, cached)\n  Execution Time: 0.059104 (different template, different context)\n  Execution Time: 0.005761 (different template, different context, cached)\n      Total Time: 0.261297\n</code></pre>"},{"location":"lua/template/#luajit-205-copyright-c-2005-2017-mike-pall-httpluajitorg","title":"LuaJIT 2.0.5 -- Copyright (C) 2005-2017 Mike Pall. http://luajit.org/","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.005198\nCompilation Time: 0.029687 (template)\nCompilation Time: 0.000082 (template, cached)\n  Execution Time: 0.033824 (same template)\n  Execution Time: 0.003130 (same template, cached)\n  Execution Time: 0.075899 (different template)\n  Execution Time: 0.007027 (different template, cached)\n  Execution Time: 0.070269 (different template, different context)\n  Execution Time: 0.007456 (different template, different context, cached)\n      Total Time: 0.232572\n</code></pre>"},{"location":"lua/template/#luajit-210-beta3-copyright-c-2005-2017-mike-pall-httpluajitorg","title":"LuaJIT 2.1.0-beta3 -- Copyright (C) 2005-2017 Mike Pall. http://luajit.org/","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.003647\nCompilation Time: 0.027145 (template)\nCompilation Time: 0.000083 (template, cached)\n  Execution Time: 0.034685 (same template)\n  Execution Time: 0.002801 (same template, cached)\n  Execution Time: 0.073466 (different template)\n  Execution Time: 0.010836 (different template, cached)\n  Execution Time: 0.068790 (different template, different context)\n  Execution Time: 0.009818 (different template, different context, cached)\n      Total Time: 0.231271\n</code></pre>"},{"location":"lua/template/#resty-resty-023-nginx-version-openresty11582","title":"resty (resty 0.23, nginx version: openresty/1.15.8.2)","text":"<pre><code>Running 1000 iterations in each test\n    Parsing Time: 0.003980\nCompilation Time: 0.025983 (template)\nCompilation Time: 0.000066 (template, cached)\n  Execution Time: 0.032752 (same template)\n  Execution Time: 0.002740 (same template, cached)\n  Execution Time: 0.036111 (different template)\n  Execution Time: 0.005559 (different template, cached)\n  Execution Time: 0.032453 (different template, different context)\n  Execution Time: 0.006057 (different template, different context, cached)\n      Total Time: 0.145701\n</code></pre> <p>I have not yet compared the results against the alternatives.</p>"},{"location":"lua/template/#changes","title":"Changes","text":"<p>The changes of every release of this module is recorded in Changes.md file.</p>"},{"location":"lua/template/#see-also","title":"See Also","text":"<ul> <li>lua-resty-route \u2014 Routing library</li> <li>lua-resty-reqargs \u2014 Request arguments parser</li> <li>lua-resty-session \u2014 Session library</li> <li>lua-resty-validation \u2014 Validation and filtering library</li> </ul>"},{"location":"lua/template/#roadmap","title":"Roadmap","text":"<p>Some things I and the community wishes to be added:</p> <ul> <li>Better debugging capabilities and better error messages</li> <li>Proper sandboxing</li> </ul>"},{"location":"lua/template/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-template.</p>"},{"location":"lua/test/","title":"test: Lua test frame for nginx-module-lua based on nginx-module-lua","text":""},{"location":"lua/test/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/test/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-test\n</code></pre>"},{"location":"lua/test/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-test\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-test v0.1  released on Sep 03 2019.</p> <p>lua-resty-test is Ngx_lua test frame based on Openresty</p>"},{"location":"lua/test/#description","title":"Description","text":"<p>This Lua library is a test frame for test your ngx_lua source or other server(tcp or udp):</p> <p>http://wiki.nginx.org/HttpLuaModule</p>"},{"location":"lua/test/#synopsis","title":"Synopsis","text":"<pre><code>-- test.lua\nlocal iresty_test    = require \"resty.iresty_test\"\nlocal tb = iresty_test.new({unit_name=\"example\"})\n\nfunction tb:init(  )\n    self:log(\"init complete\")\nend\n\nfunction tb:test_00001(  )\n    error(\"invalid input\")\nend\n\nfunction tb:atest_00002()\n    self:log(\"never be called\")\nend\n\nfunction tb:test_00003(  )\n    self:log(\"ok\")\nend\n\n-- units test\ntb:run()\n</code></pre> <p>Run test case:</p> <p></p>"},{"location":"lua/test/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> </ul>"},{"location":"lua/test/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-test.</p>"},{"location":"lua/timer/","title":"timer: Extended timers for nginx-module-lua","text":""},{"location":"lua/timer/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/timer/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-timer\n</code></pre>"},{"location":"lua/timer/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-timer\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-timer v1.1.0  released on Nov 06 2020.</p> <p>Extended timers for OpenResty. Provided recurring, cancellable, node-wide timers, beyond what the basic OpenResty timers do.</p>"},{"location":"lua/timer/#status","title":"Status","text":"<p>This library is production ready.</p>"},{"location":"lua/timer/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    lua_shared_dict timer_shm 1m;\n    init_worker_by_lua_block {\n        local timer = require(\"resty.timer\")\n\n        local options = {\n            interval = 0.1,           -- expiry interval in seconds\n            recurring = true,         -- recurring or single timer\n            immediate = true,         -- initial interval will be 0\n            detached = false,         -- run detached, or be garbagecollectible\n            jitter = 0.1,             -- add a random interval\n            expire = object.handler,  -- callback on timer expiry\n            cancel = function(reason, self, param1)\n                -- will be called when the timer gets cancelled\n            end,\n            shm_name = \"timer_shm\",   -- shm to use for node-wide timers\n            key_name = \"my_key\",      -- key-name to use for node-wide timers\n            sub_interval = 0.1,       -- max cross worker extra delay\n        }\n\n        local object\n        object = {                            -- create some object with a timer\n            count = 0,\n            handler = function(self, param1)  -- the timer callback as a method\n                -- do something here\n                print(param1)                 --&gt; \"Param 1\"\n            end,\n\n            -- create and add to object, but also pass it as 'self' to the handler\n            timer = timer(options, object, \"Param 1\"),\n        }\n\n        -- anchor the object and timer\n        _M.global_object = object     -- will be collected if not anchored\n\n        -- cancel the timer\n        object.timer:cancel()\n    }\n}\n</code></pre>"},{"location":"lua/timer/#description","title":"Description","text":"<p>The OpenResty timer is fairly limited, this timer adds a number of common options as parameters without having to recode (and retest) them in each project.</p> <ul> <li> <p>recurring timers (supported by OR as well through <code>ngx.timer.every</code>)</p> </li> <li> <p>immediate first run for recurring timers</p> </li> <li> <p>cancellable timers</p> </li> <li> <p>cancel callback, called when the timer is cancelled</p> </li> <li> <p>garbage collectible timers, enabling timers to (optionally) be attached to   objects and automatically stop when garbage collected.</p> </li> <li> <p>node-wide timers: the same timer started in each worker will still only   run once across the system. If the worker running it is removed the   timer will automatically be executed on another worker.</p> </li> </ul> <p>See the online LDoc documentation for the complete API.</p>"},{"location":"lua/timer/#history","title":"History","text":"<p>Versioning is strictly based on Semantic Versioning</p>"},{"location":"lua/timer/#releasing-new-versions","title":"Releasing new versions:","text":"<ul> <li>update changelog below (PR's should be merged including a changelog entry)</li> <li>based on changelog determine new SemVer version</li> <li>create a new rockspec</li> <li>render the docs using <code>ldoc</code> (don't do this within PR's)</li> <li>commit as \"release x.x.x\" (do not include rockspec revision)</li> <li>tag the commit with \"x.x.x\" (do not include rockspec revision)</li> <li>push commit and tag</li> <li>upload rock to luarocks: <code>luarocks upload rockspecs/[name] --api-key=abc</code></li> </ul>"},{"location":"lua/timer/#110-6-nov-2020","title":"1.1.0 (6-Nov-2020)","text":"<ul> <li>Feat: add a <code>jitter</code> option. This adds a random interval to distribute the   timers (in case of scheduling many timers at once).</li> </ul>"},{"location":"lua/timer/#100-21-sep-2020","title":"1.0.0 (21-Sep-2020)","text":"<ul> <li>Change [BREAKING]: the recurring timers are now implemented as a sleeping   thread which is more efficient. Side effect is that the timer only gets   rescheduled AFTER executing the handler. So if the handler is long running,   then individual runs will be further apart.</li> </ul>"},{"location":"lua/timer/#03-28-may-2018","title":"0.3 (28-May-2018)","text":"<ul> <li>Feat: added cancellation callback invocation on timer being GC'ed. This   changes the first argument of the <code>cancel</code> callback, and hence is   breaking.</li> </ul>"},{"location":"lua/timer/#02-12-feb-2018-bug-fix","title":"0.2 (12-Feb-2018) Bug fix","text":"<ul> <li>Fix: bugfix in <code>unpack</code> function not honoring table length parameter</li> <li>Docs: small fixes and typo's</li> </ul>"},{"location":"lua/timer/#01-22-nov-2017-initial-release","title":"0.1 (22-Nov-2017) Initial release","text":"<ul> <li>Added <code>sub_interval</code> option to reduce delays</li> <li>Initial upload</li> </ul>"},{"location":"lua/timer/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-timer.</p>"},{"location":"lua/tlc/","title":"tlc: General two level cache (lrucache + shared dict)","text":""},{"location":"lua/tlc/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/tlc/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-tlc\n</code></pre>"},{"location":"lua/tlc/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-tlc\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-tlc v0.2  released on Oct 03 2016.</p> <p>Two Layer Cache implementation using lua-resty-lrucache and shared dictionaries.</p> <p>Cache entries are written to lru-cache in the current worker and to a shared dictionary.</p> <p>Cache reads that miss in the worker's lru-cache instance are re-populated from the shared dictionary if available.</p> <p>Values in shared dictionaries are automatically serialised and unserialised to JSON (custom serialisation functions are supported)</p> <p>Also provides a manager module to maintain global set of TLC cache instances</p>"},{"location":"lua/tlc/#overview","title":"Overview","text":"<pre><code>lua_shared_dict tlc_cache 10m;\nlua_shared_dict tlc_cache2 1m;\n\ninit_by_lua_block {\n    local manager = require(\"resty.tlc.manager\")\n    manager.new(\"my_cache\", {size = 500, dict = \"tlc_cache\"})\n\n    manager.new(\"my_cache2\", {size = 500, dict = \"tlc_cache2\"})\n}\n\n\nlocation = /get {\n    content_by_lua_block {\n        local manager = require(\"resty.tlc.manager\")\n        local cache = manager.get(\"my_cache\")\n\n        local args = ngx.req.get_uri_args()\n        local key = args[\"key\"]\n\n        local data, err = cache:get(key)\n        if err then\n            ngx.log(ngx.ERR, err)\n        elseif data == nil then\n            ngx.status = ngx.HTTP_NOT_FOUND\n            ngx.say(\"Not Found\")\n        else\n            ngx.say(tostring(data))\n        end\n    }\n}\n\nlocation = /set {\n    content_by_lua_block {\n        local manager = require(\"resty.tlc.manager\")\n        local cache = manager.get(\"my_cache\")\n\n        local args = ngx.req.get_uri_args()\n        local key = args[\"key\"]\n        local val = args[\"val\"] or { foo = bar }\n        local ttl = args[\"ttl\"]\n\n        local ok, err = cache:set(key, val, ttl)\n        if not ok then\n            ngx.log(ngx.ERR, err)\n        end\n    }\n}\n\nlocation = /flush {\n    content_by_lua_block {\n        local manager = require(\"resty.tlc.manager\")\n        local cache = manager.get(\"my_cache\")\n        cache:flush()\n    }\n}\n\nlocation = /list {\n    content_by_lua_block {\n        local manager = require(\"resty.tlc.manager\")\n        local instances = manager.list()\n\n        ngx.say(require(\"cjson\").encode(instances))\n    }\n}\n</code></pre>"},{"location":"lua/tlc/#methods","title":"Methods","text":"<ul> <li>manager</li> <li>new</li> <li>get</li> <li>set</li> <li>delete</li> <li>list</li> <li>cache</li> <li>new</li> <li>set</li> <li>get</li> <li>delete</li> <li>flush</li> </ul>"},{"location":"lua/tlc/#manager","title":"manager","text":""},{"location":"lua/tlc/#new","title":"new","text":"<p><code>syntax: ok, err = manager.new(name, opts)</code></p> <p>Create a new <code>resty.tlc.cache</code> instance with given name/id and options.</p> <p>Will not check if instance already exists, existing instances will be overwritten</p>"},{"location":"lua/tlc/#get","title":"get","text":"<p><code>syntax: cache = manager.get(name)</code></p> <p>Returns the specified TLC cache instance or nil</p>"},{"location":"lua/tlc/#delete","title":"delete","text":"<p><code>syntax: manager.delete(name)</code></p> <p>Removes the specified cache instance.</p>"},{"location":"lua/tlc/#list","title":"list","text":"<p><code>syntax: instances = manager.list()</code></p> <p>Returns an array table of available cache instances</p>"},{"location":"lua/tlc/#cache","title":"cache","text":""},{"location":"lua/tlc/#new_1","title":"new","text":"<p><code>syntax: instance = cache:new(opts)</code></p> <p>Creates a new instance of <code>resty.tlc.cache</code>, <code>opts</code> is a table of options for this instance.</p> <pre><code>opts = {\n    dict         = dict,         -- Shared dictionary name, required\n    size         = size,         -- max_items parameter for LRU cache, optional, default 200\n    pureffi      = pureffi,      -- Use the pureffi LRU cache variant, optional, default false\n    loadfactor   = loadfactor,   -- Load factor for pureffi LRU cache, optional\n    serialiser   = serialiser,   -- Function to serialise values when saving to shared dictionary, optional, defaults to pcall'd cjson encode\n    unserialiser = unserialiser, -- Function to unserialise values when saving to shared dictionary, optional, defaults to pcall'd cjson decode\n}\n</code></pre> <p>Functions to serialise and unserialise should <code>return nil, err</code> on failure.</p>"},{"location":"lua/tlc/#set","title":"set","text":"<p><code>syntax: ok, err = cache:set(key, value, ttl?)</code></p> <p>Set or update an entry in the cache.</p> <p><code>ttl</code> is optional and in seconds</p>"},{"location":"lua/tlc/#get_1","title":"get","text":"<p><code>syntax: data = cache:get(key)</code></p> <p>Returns data from cache or <code>nil</code> if not set</p>"},{"location":"lua/tlc/#delete_1","title":"delete","text":"<p><code>syntax: cache:delete(key)</code></p> <p>Deletes entry from both LRU cache and shared dictionary</p> <p>TODO: Delete from LRU cache in all workers</p>"},{"location":"lua/tlc/#flush","title":"flush","text":"<p><code>syntax: cache:flush(hard?)</code></p> <p>Re-initialises LRU cache in current worker and flushes shared dictionary.</p> <p><code>hard</code> argument will also call <code>flush_expired()</code> on dictionary.</p> <p>TODO: Re-initialise LRU cache in all workers</p>"},{"location":"lua/tlc/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-tlc.</p>"},{"location":"lua/tsort/","title":"tsort: Performs a topological sort on input data","text":""},{"location":"lua/tsort/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/tsort/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-tsort\n</code></pre>"},{"location":"lua/tsort/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-tsort\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-tsort v1.0  released on Apr 06 2016.</p> <p>Performs a topological sort on input data.</p>"},{"location":"lua/tsort/#synopsis","title":"Synopsis","text":"<pre><code>local dump  = require \"pl.pretty\".dump\nlocal tsort = require \"resty.tsort\"\n\nlocal graph = tsort.new()\n\ngraph:add('a', 'b')\ngraph:add('b', 'c')\ngraph:add('0', 'a')\n\ndump(graph:sort())\n\n-- Output:\n-- {\n--   \"0\",\n--   \"a\",\n--   \"b\",\n--   \"c\"\n-- }\n\ngraph:add('1', '2', '3', 'a');\n\ndump(graph:sort())\n\n-- Output:\n-- {\n--   \"0\",\n--   \"1\",\n--   \"2\",\n--   \"3\",\n--   \"a\",\n--   \"b\",\n--   \"c\"\n-- }\n\ngraph:add{'1', '1.5'};\ngraph:add{'1.5', 'a'};\n\ndump(graph:sort())\n\n-- Output:\n-- {\n--   \"0\",\n--   \"1\",\n--   \"2\",\n--   \"3\",\n--   \"1.5\",\n--   \"a\",\n--   \"b\",\n--   \"c\"\n-- }\n\ngraph:add('first', 'second');\ngraph:add('second', 'third', 'first');\n\nlocal sorted, err = graph:sort()\n\n-- Returns:\n-- sorted = nil\n-- err = \"There is a circular dependency in the graph. It is not possible to derive a topological sort.\"\n</code></pre>"},{"location":"lua/tsort/#alternatives","title":"Alternatives","text":"<p>Before developing this library, I asked on #lua channel on Freenode if anyone knows a library that does topological sort. I also tried to search for a library. Unfortunately I didn't find anything. But, there was already a library from the great @starius called toposort. <code>toposort</code> looks really nice and it has a lot more features compared to <code>lua-resty-tsort</code>. So you may want to take a look to that as well especially if you are looking for a more full featured library. I have not benchmarked these libs or compared them to C-implementation of tsort or other alternatives. If your graph is not too big, say you use these to sort Javascript / CSS files or something similar, I think the performance is not an issue.</p>"},{"location":"lua/tsort/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-tsort.</p>"},{"location":"lua/txid/","title":"txid: Generate sortable, unique transaction or request IDs for nginx-module-lua/nginx","text":""},{"location":"lua/txid/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/txid/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-txid\n</code></pre>"},{"location":"lua/txid/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-txid\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-txid v1.0.0  released on Apr 01 2018.</p> <p></p> <p>lua-resty-txid provides a function that can be used to generate unique transaction/request IDs for OpenResty/nginx. The IDs can be used to correlate logs or upstream requests and have the following characteristics:</p> <ul> <li>20 characters</li> <li>base32hex encoded</li> <li>Temporally and lexically sortable</li> <li>Case insensitive</li> <li>96 bit identifier</li> </ul> <p>lua-resty-txid is a LuaJIT port of ngx_txid for OpenResty (or nginx with ngx_lua). The IDs generated by lua-resty-txid follow the exact same pattern and are compatible with ngx_txid.</p>"},{"location":"lua/txid/#usage","title":"Usage","text":"<p>A single <code>txid()</code> Lua function is exposed by this module to generate IDs:</p> <pre><code>local txid = require \"resty.txid\"\nlocal id = txid() -- b2g6q94qdn6h84an7vfg\n</code></pre> <p>Each time <code>txid()</code> is called, a new, unique ID will be returned, so you will need to cache the result if you wish to reuse the same ID in multiple places for a single request. Depending on your usage, <code>ngx.ctx</code> or <code>set_by_lua</code> offer some simple options for caching the value on a per-request basis.</p> <pre><code>txid() -- b2g83t2oshrg092mjggg\ntxid() -- b2g83t2oodncokuges00\n\nngx.ctx.txid = txid() -- b2g83t2od939mdvb2l0g\nngx.ctx.txid          -- b2g83t2od939mdvb2l0g\n</code></pre> <p>Finally, <code>txid()</code> accepts an optional argument for what timestamp (in milliseconds) to use when generating the ID. By default, the current timestamp is used. Since the resulting IDs are temporally and lexically sortable, this can be used to generate IDs that will be sorted based on a previous date or time.</p> <pre><code>local timestamp_ms = 655829050000 -- 1990-10-13 14:44:10\ntxid(timestamp_ms) -- 4om9qi54la8ffr4bd9sg\n\nlocal timestamp_ms = 655929050000 -- 1990-10-14 12:30:50\ntxid(timestamp_ms) -- 4on1lg74nt0ud2ssllu0\n</code></pre>"},{"location":"lua/txid/#example","title":"Example","text":"<p>A more complete example, with caching, setting request/response headers, and integration with nginx's logging:</p> <pre><code>http {\n  log_format agent \"$lua_txid $http_user_agent\";\n  log_format addr \"$lua_txid $remote_addr\";\n\n  init_by_lua_block {\n    # Pre-load the module.\n    require \"resty.txid\"\n  }\n\n  server {\n    listen 8080;\n    access_log logs/agents.log agent;\n    access_log logs/addrs.log addr;\n\n    # Set an nginx variable that is cached per request and can be used in the\n    # nginx log_format.\n    set_by_lua_block $lua_txid {\n      local txid = require \"resty.txid\"\n      return txid()\n    }\n\n    location / {\n      # Set a header on the response providing the ID.\n      more_set_headers \"X-Request-Id: $lua_txid\";\n\n      # Set a header on the request providing the ID (which will be sent to the\n      # proxied upstream).\n      more_set_input_headers \"X-Request-Id: $lua_txid\";\n\n      proxy_pass http://localhost:8081;\n    }\n  }\n}\n</code></pre>"},{"location":"lua/txid/#performance","title":"Performance","text":"<p>Benchmarks indicate that performance is equivalent to the ngx_txid C extension.</p>"},{"location":"lua/txid/#design","title":"Design","text":"<p>The transaction ID design is a direct port of ngx_txid, so here's all the original information about the design from ngx_txid:</p>"},{"location":"lua/txid/#background","title":"Background","text":"<p>The design of this transaction ID should meet the following requirements:</p> <ul> <li>Be roughly numerically temporally sortable with ~second granularity.</li> <li>Have a representation that is roughly lexically sortable with ~second granularity.</li> <li>Have a probability of less than 1e-9 for collision at 1 million transactions per second.</li> <li>Be efficient and easy to decode into fixed size C types</li> <li>Always be available at the risk of higher collision probability</li> <li>Use as few bytes as possible</li> <li>Work with IPv4 and IPv6 networks</li> </ul>"},{"location":"lua/txid/#technique","title":"Technique","text":"<p>Use a monotonic millisecond resolution clock in the high 42 bits and system entropy for the low 54 bits. Use enough entropy bits to satisfy a collision probability at a desired global request rate.</p> <pre><code>+------------- 64 bits------------+--- 32 bits ----+\n+------ 42 bits ------+--22 bits--|----------------+\n| msec since 1970-1-1 | random    | random         |\n+---------------------+-----------+----------------+\n</code></pre> <p>A request rate of 1 million per second across all servers means 1000 random values per millisecond.  Estimating the collision probability using the birthday paradox can be done with this formula: <code>1 - e^(-((m^2)/(2*n)))</code> where <code>m</code> is the number of ids and <code>n</code> is the number of random values possible.</p> <p>When using 54 bits of entropy:</p> <pre><code>1mil req/s  = 1 - exp(-((1000^2) /(2*2^54))) = 2.775558e-11\n10mil req/s = 1 - exp(-((10000^2)/(2*2^54))) = 2.775558e-09\n</code></pre> <p>The odds of collision are small even at 10 million requests per second.</p> <p>Nginx keeps track of the current clock in increments of the configuration directive <code>timer_resolution</code>.  The clock resolution for <code>$txid</code> is 1ms, so a timer resolution greater than 1ms means that the probability of collision will increase.  If you have a <code>timer_resolution</code> of 10ms, 1 million requests per second would require 10,000 random values per second in the worst case.</p>"},{"location":"lua/txid/#encoding","title":"Encoding","text":"<p>base32hex is used with a lower case alphabet and without padding characters is chosen for the following reasons:</p> <ul> <li>Lexically sort order equivalent to numeric sort order</li> <li>Case insensitive equality</li> <li>Lower case is easer for visual compares</li> <li>Denser than hex encoding by 4 bytes</li> </ul>"},{"location":"lua/txid/#other-techniques","title":"Other techniques","text":"<ul> <li>snowflake: Uses time(41) + unique id(10) + sequence(12).</li> <li>Pro: Guaranteed unique sequences</li> <li>Pro: Fits in 63 bits</li> <li>Cons: Requires unique id coordination for each server - 16 workers processes per host means a limit of 64 instances of nginx</li> <li>Cons: Only 11 bits available for unique id, needs monitoring</li> <li>Cons: Total ordering only possible in the same process</li> <li> <p>Cons: Service interruption possible when clocks lose synchronization</p> </li> <li> <p>flake: Uses time + mac id + sequence.</p> </li> <li>Pro: Guaranteed unique sequences</li> <li>Cons: Uses 128 bits</li> <li>Cons: Wastes 22 bits of timestamp data</li> <li>Cons: Only a single process per host can generate ids - needs to synchronize access to the sequence from each worker process</li> <li>Cons: Service interruption possible when clocks lose synchronization</li> <li> <p>Cons: Seeds cross platform MAC Address lookup.</p> </li> <li> <p>UUIDv4: 122 bits of entropy</p> </li> <li>Pro: Very low probability of collision</li> <li> <p>Cons: Unsortable</p> </li> <li> <p>UUID with timestamp: 48 bits of time + 74 bits entropy</p> </li> <li>Pro: Very low probability of collision</li> <li> <p>Cons: String representation is not temporally local</p> </li> <li> <p>httpd mod_unique_id: Host ip(32) + pid(32) + time(32) + sequence (16) + thread id (32)</p> </li> <li>Pro: Deterministic</li> <li>Cons: Uses 144 bits</li> <li>Cons: Assumes unique IPv4 for the hostnamme's interface</li> <li>Cons: Unsortable case-sensitive custom representation - base64 with a custom alphabet</li> <li>Cons: Hard limit of 65535 ids per second per pid - small tolerance for clock steps</li> </ul>"},{"location":"lua/txid/#development","title":"Development","text":"<p>After checking out the repo, Docker can be used to run the test suite:</p> <pre><code>docker-compose run --rm app make test\n</code></pre>"},{"location":"lua/txid/#release-process","title":"Release Process","text":"<p>To publish releases to OPM and LuaRocks:</p> <pre><code>VERSION=x.x.x make release\n</code></pre>"},{"location":"lua/txid/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-txid.</p>"},{"location":"lua/upload/","title":"upload: Streaming reader and parser for http file uploading based on nginx-module-lua cosocket","text":""},{"location":"lua/upload/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/upload/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-upload\n</code></pre>"},{"location":"lua/upload/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-upload\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-upload v0.11  released on Jan 19 2023.</p> <p>lua-resty-upload - Streaming reader and parser for HTTP file uploading based on ngx_lua cosocket</p>"},{"location":"lua/upload/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/upload/#description","title":"Description","text":"<p>This Lua library is a streaming file uploading API for the ngx_lua nginx module:</p> <p>http://wiki.nginx.org/HttpLuaModule</p> <p>The multipart/form-data MIME type is supported.</p> <p>The API of this library just returns tokens one by one. The user just needs to call the <code>read</code> method repeatedly until a nil token type is returned. For each token returned from the <code>read</code> method, just check the first return value for the current token type. The token type can be <code>header</code>, <code>body</code>, and <code>part end</code>. Each <code>multipart/form-data</code> form field parsed consists of several <code>header</code> tokens holding each field header, several <code>body</code> tokens holding each body data chunk, and a <code>part end</code> flag indicating the field end.</p> <p>This is how streaming reading works. Even for giga bytes of file data input, the memory used in the lua land can be small and constant, as long as the user does not accumulate the input data chunks herself.</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that at least ngx_lua 0.7.9 or OpenResty 1.2.4.14 is required.</p>"},{"location":"lua/upload/#synopsis","title":"Synopsis","text":"<pre><code>    server {\n        location /test {\n            content_by_lua '\n                local upload = require \"resty.upload\"\n                local cjson = require \"cjson\"\n\n                local chunk_size = 5 -- should be set to 4096 or 8192\n                                     -- for real-world settings\n\n                local form, err = upload:new(chunk_size)\n                if not form then\n                    ngx.log(ngx.ERR, \"failed to new upload: \", err)\n                    ngx.exit(500)\n                end\n\n                form:set_timeout(1000) -- 1 sec\n\n                while true do\n                    local typ, res, err = form:read()\n                    if not typ then\n                        ngx.say(\"failed to read: \", err)\n                        return\n                    end\n\n                    ngx.say(\"read: \", cjson.encode({typ, res}))\n\n                    if typ == \"eof\" then\n                        break\n                    end\n                end\n\n                local typ, res, err = form:read()\n                ngx.say(\"read: \", cjson.encode({typ, res}))\n            ';\n        }\n    }\n</code></pre> <p>A typical output of the /test location defined above is:</p> <pre><code>read: [\"header\",[\"Content-Disposition\",\"form-data; name=\\\"file1\\\"; filename=\\\"a.txt\\\"\",\"Content-Disposition: form-data; name=\\\"file1\\\"; filename=\\\"a.txt\\\"\"]]\nread: [\"header\",[\"Content-Type\",\"text\\/plain\",\"Content-Type: text\\/plain\"]]\nread: [\"body\",\"Hello\"]\nread: [\"body\",\", wor\"]\nread: [\"body\",\"ld\"]\nread: [\"part_end\"]\nread: [\"header\",[\"Content-Disposition\",\"form-data; name=\\\"test\\\"\",\"Content-Disposition: form-data; name=\\\"test\\\"\"]]\nread: [\"body\",\"value\"]\nread: [\"body\",\"\\r\\n\"]\nread: [\"part_end\"]\nread: [\"eof\"]\nread: [\"eof\"]\n</code></pre> <p>You can use the lua-resty-string library to compute SHA-1 and MD5 digest of the file data incrementally. Here is such an example:</p> <pre><code>    local resty_sha1 = require \"resty.sha1\"\n    local upload = require \"resty.upload\"\n\n    local chunk_size = 4096\n    local form = upload:new(chunk_size)\n    local sha1 = resty_sha1:new()\n    local file\n    while true do\n        local typ, res, err = form:read()\n\n        if not typ then\n             ngx.say(\"failed to read: \", err)\n             return\n        end\n\n        if typ == \"header\" then\n            local file_name = my_get_file_name(res)\n            if file_name then\n                file = io.open(file_name, \"w+\")\n                if not file then\n                    ngx.say(\"failed to open file \", file_name)\n                    return\n                end\n            end\n\n         elseif typ == \"body\" then\n            if file then\n                file:write(res)\n                sha1:update(res)\n            end\n\n        elseif typ == \"part_end\" then\n            file:close()\n            file = nil\n            local sha1_sum = sha1:final()\n            sha1:reset()\n            my_save_sha1_sum(sha1_sum)\n\n        elseif typ == \"eof\" then\n            break\n\n        else\n            -- do nothing\n        end\n    end\n</code></pre> <p>If you want to compute MD5 sums for the uploaded files, just use the resty.md5 module shipped by the lua-resty-string library. It has a similar API as resty.sha1.</p> <p>For big file uploading, it is important not to buffer all the data in memory. That is, you should never accumulate data chunks either in a huge Lua string or in a huge Lua table. You must write the data chunk into files as soon as possible and throw away the data chunk immediately (to let the Lua GC free it up).</p> <p>Instead of writing the data chunk into files (as shown in the example above), you can also write the data chunks to upstream cosocket connections if you do not want to save the data on local file systems.</p>"},{"location":"lua/upload/#usage","title":"Usage","text":"<p><pre><code>local upload = require \"resty.upload\"\nlocal form, err = upload:new(self, chunk_size, max_line_size, preserve_body)\n</code></pre> <code>chunk_size</code> defaults to 4096. It is the size used to read data from the socket.</p> <p><code>max_line_size</code> defaults to 512. It is the size limit to read the chunked body header.</p> <p>By Default, <code>lua-resty-upload</code> will consume the request body. For proxy mode this means upstream will not see the body. When <code>preserve_body</code> is set to true, the request body will be preserved. Note that this option is not free. When enabled, it will double the memory usage of <code>resty.upload</code>.</p>"},{"location":"lua/upload/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module</li> <li>the lua-resty-string library</li> <li>the lua-resty-memcached library</li> <li>the lua-resty-redis library</li> <li>the lua-resty-mysql library</li> </ul>"},{"location":"lua/upload/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-upload.</p>"},{"location":"lua/upstream-healthcheck/","title":"upstream-healthcheck: Health Checker for NGINX Upstream Servers in Pure Lua","text":""},{"location":"lua/upstream-healthcheck/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/upstream-healthcheck/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-upstream-healthcheck\n</code></pre>"},{"location":"lua/upstream-healthcheck/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-upstream-healthcheck\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-upstream-healthcheck v0.8  released on Mar 07 2023.</p> <p>lua-resty-upstream-healthcheck - Health-checker for Nginx upstream servers</p>"},{"location":"lua/upstream-healthcheck/#status","title":"Status","text":"<p>This library is still under early development but is already production ready.</p>"},{"location":"lua/upstream-healthcheck/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    # sample upstream block:\n    upstream foo.com {\n        server 127.0.0.1:12354;\n        server 127.0.0.1:12355;\n        server 127.0.0.1:12356 backup;\n    }\n\n    # the size depends on the number of servers in upstream {}:\n    lua_shared_dict healthcheck 1m;\n\n    lua_socket_log_errors off;\n\n    init_worker_by_lua_block {\n        local hc = require \"resty.upstream.healthcheck\"\n\n        local ok, err = hc.spawn_checker{\n            shm = \"healthcheck\",  -- defined by \"lua_shared_dict\"\n            upstream = \"foo.com\", -- defined by \"upstream\"\n            type = \"http\", -- support \"http\" and \"https\"\n\n            http_req = \"GET /status HTTP/1.0\\r\\nHost: foo.com\\r\\n\\r\\n\",\n                    -- raw HTTP request for checking\n\n            port = nil,  -- the check port, it can be different than the original backend server port, default means the same as the original backend server\n            interval = 2000,  -- run the check cycle every 2 sec\n            timeout = 1000,   -- 1 sec is the timeout for network operations\n            fall = 3,  -- # of successive failures before turning a peer down\n            rise = 2,  -- # of successive successes before turning a peer up\n            valid_statuses = {200, 302},  -- a list valid HTTP status code\n            concurrency = 10,  -- concurrency level for test requests\n            -- ssl_verify = true, -- https type only, verify ssl certificate or not, default true\n            -- host = foo.com, -- https type only, host name in ssl handshake, default nil\n        }\n        if not ok then\n            ngx.log(ngx.ERR, \"failed to spawn health checker: \", err)\n            return\n        end\n\n        -- Just call hc.spawn_checker() for more times here if you have\n        -- more upstream groups to monitor. One call for one upstream group.\n        -- They can all share the same shm zone without conflicts but they\n        -- need a bigger shm zone for obvious reasons.\n    }\n\n    server {\n        ...\n\n        # status page for all the peers:\n        location = /status {\n            access_log off;\n            allow 127.0.0.1;\n            deny all;\n\n            default_type text/plain;\n            content_by_lua_block {\n                local hc = require \"resty.upstream.healthcheck\"\n                ngx.say(\"Nginx Worker PID: \", ngx.worker.pid())\n                ngx.print(hc.status_page())\n            }\n        }\n\n    # status page for all the peers (prometheus format):\n        location = /metrics {\n            access_log off;\n            default_type text/plain;\n            content_by_lua_block {\n                local hc = require \"resty.upstream.healthcheck\"\n                st , err = hc.prometheus_status_page()\n                if not st then\n                    ngx.say(err)\n                    return\n                end\n                ngx.print(st)\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/upstream-healthcheck/#description","title":"Description","text":"<p>This library performs healthcheck for server peers defined in NGINX <code>upstream</code> groups specified by names.</p>"},{"location":"lua/upstream-healthcheck/#methods","title":"Methods","text":""},{"location":"lua/upstream-healthcheck/#spawn_checker","title":"spawn_checker","text":"<p>syntax: <code>ok, err = healthcheck.spawn_checker(options)</code></p> <p>context: init_worker_by_lua*</p> <p>Spawns background timer-based \"light threads\" to perform periodic healthchecks on the specified NGINX upstream group with the specified shm storage.</p> <p>The healthchecker does not need any client traffic to function. The checks are performed actively and periodically.</p> <p>This method call is asynchronous and returns immediately.</p> <p>Returns true on success, or <code>nil</code> and a string describing an error otherwise.</p>"},{"location":"lua/upstream-healthcheck/#status_page","title":"status_page","text":"<p>syntax: <code>str, err = healthcheck.status_page()</code></p> <p>context: any</p> <p>Generates a detailed status report for all the upstreams defined in the current NGINX server.</p> <p>One typical output is</p> <pre><code>Upstream foo.com\n    Primary Peers\n        127.0.0.1:12354 UP\n        127.0.0.1:12355 DOWN\n    Backup Peers\n        127.0.0.1:12356 UP\n\nUpstream bar.com\n    Primary Peers\n        127.0.0.1:12354 UP\n        127.0.0.1:12355 DOWN\n        127.0.0.1:12357 DOWN\n    Backup Peers\n        127.0.0.1:12356 UP\n</code></pre> <p>If an upstream has no health checkers, then it will be marked by <code>(NO checkers)</code>, as in</p> <pre><code>Upstream foo.com (NO checkers)\n    Primary Peers\n        127.0.0.1:12354 UP\n        127.0.0.1:12355 UP\n    Backup Peers\n        127.0.0.1:12356 UP\n</code></pre> <p>If you indeed have spawned a healthchecker in <code>init_worker_by_lua*</code>, then you should really check out the NGINX error log file to see if there is any fatal errors aborting the healthchecker threads.</p>"},{"location":"lua/upstream-healthcheck/#multiple-upstreams","title":"Multiple Upstreams","text":"<p>One can perform healthchecks on multiple <code>upstream</code> groups by calling the spawn_checker method multiple times in the <code>init_worker_by_lua*</code> handler. For example,</p> <pre><code>upstream foo {\n    ...\n}\n\nupstream bar {\n    ...\n}\n\nlua_shared_dict healthcheck 1m;\n\nlua_socket_log_errors off;\n\ninit_worker_by_lua_block {\n    local hc = require \"resty.upstream.healthcheck\"\n\n    local ok, err = hc.spawn_checker{\n        shm = \"healthcheck\",\n        upstream = \"foo\",\n        ...\n    }\n\n    ...\n\n    ok, err = hc.spawn_checker{\n        shm = \"healthcheck\",\n        upstream = \"bar\",\n        ...\n    }\n}\n</code></pre> <p>Different upstreams' healthcheckers use different keys (by always prefixing the keys with the upstream name), so sharing a single <code>lua_shared_dict</code> among multiple checkers should not have any issues at all. But you need to compensate the size of the shared dict for multiple users (i.e., multiple checkers). If you have many upstreams (thousands or even more), then it is more optimal to use separate shm zones for each (group) of the upstreams.</p>"},{"location":"lua/upstream-healthcheck/#nginxconf","title":"nginx.conf","text":"<p>http {     ... } ```</p>"},{"location":"lua/upstream-healthcheck/#see-also","title":"See Also","text":"<ul> <li>the ngx_lua module: https://github.com/openresty/lua-nginx-module</li> <li>the ngx_lua_upstream module: https://github.com/openresty/lua-upstream-nginx-module</li> <li>OpenResty: http://openresty.org</li> </ul>"},{"location":"lua/upstream-healthcheck/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-upstream-healthcheck.</p>"},{"location":"lua/upstream/","title":"upstream: Upstream connection load balancing and failover module for nginx-module-lua","text":""},{"location":"lua/upstream/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/upstream/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-upstream\n</code></pre>"},{"location":"lua/upstream/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-upstream\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-upstream v0.10  released on Dec 19 2019.</p> <p>Upstream connection load balancing and failover module</p>"},{"location":"lua/upstream/#status","title":"Status","text":"<p>Experimental, API may change without warning.</p> <p>Requires ngx_lua &gt; 0.9.5</p>"},{"location":"lua/upstream/#overview","title":"Overview","text":"<p>Create a lua shared dictionary. Define your upstream pools and hosts in init_by_lua, this will be saved into the shared dictionary.</p> <p>Use the <code>connect</code> method to return a connected tcp socket.</p> <p>Alternatively pass in a resty module (e.g lua-resty-redis or lua-resty-http) that implements <code>connect()</code> and <code>set_timeout()</code>.</p> <p>Call <code>process_failed_hosts</code> to handle failed hosts without blocking current request.</p> <p>Use <code>resty.upstream.api</code> to modify upstream configuration during init or runtime, this is recommended!</p> <p><code>resty.upstream.http</code>  wraps the lua-resty-http from @pintsized.</p> <p>It allows for failover based on HTTP status codes as well as socket connection status.</p> <pre><code>lua_shared_dict my_upstream_dict 1m;\ninit_by_lua '\n    upstream_socket  = require(\"resty.upstream.socket\")\n    upstream_api = require(\"resty.upstream.api\")\n\n    upstream, configured = upstream_socket:new(\"my_upstream_dict\")\n    if not upstream then\n        error(configured)\n    end\n    api = upstream_api:new(upstream)\n\n    if not configured then -- Only reconfigure on start, shared mem persists across a HUP\n        api:create_pool({id = \"primary\", timeout = 100})\n        api:set_priority(\"primary\", 0)\n        api:set_method(\"primary\", \"round_robin\")\n        api:add_host(\"primary\", { id=\"a\", host = \"127.0.0.1\", port = \"80\", weight = 10 })\n        api:add_host(\"primary\", { id=\"b\", host = \"127.0.0.1\", port = \"81\",  weight = 10 })\n\n        api:create_pool({id = \"dr\"})\n        api:set_priority(\"dr\", 10)\n        api:add_host(\"dr\", { host = \"127.0.0.1\", port = \"82\", weight = 5 })\n        api:add_host(\"dr\", { host = \"127.0.0.1\", port = \"83\", weight = 10 })\n\n        api:create_pool({id = \"test\", priority = 5})\n        api:add_host(\"primary\", { id=\"c\", host = \"127.0.0.1\", port = \"82\", weight = 10 })\n        api:add_host(\"primary\", { id=\"d\", host = \"127.0.0.1\", port = \"83\", weight = 10 })\n    end\n';\n\ninit_worker_by_lua 'upstream:init_background_thread()';\n\nserver {\n\n    location / {\n        content_by_lua '\n            local sock, err = upstream:connect()\n            upstream:process_failed_hosts()\n        ';\n    }\n\n}\n</code></pre>"},{"location":"lua/upstream/#upstreamsocket","title":"upstream.socket","text":""},{"location":"lua/upstream/#new","title":"new","text":"<p><code>syntax: upstream, configured = upstream_socket:new(dictionary, id?)</code></p> <p>Returns a new upstream object using the provided dictionary name. When called in init_by_lua returns an additional variable if the dictionary already contains configuration. Takes an optional id parameter, this must be unique if multiple instances of upstream.socket are using the same dictionary.</p>"},{"location":"lua/upstream/#init_background_thread","title":"init_background_thread","text":"<p><code>syntax: ok, err = upstream:init_background_thread()</code></p> <p>Initialises the background thread, should be called in <code>init_worker_by_lua</code></p>"},{"location":"lua/upstream/#connect","title":"connect","text":"<p><code>syntax: ok, err = upstream:connect(client?, key?)</code></p> <p>Attempts to connect to a host in the defined pools in priority order using the selected load balancing method. Returns a connected socket and a table containing the connected <code>host</code>, <code>poolid</code> and <code>pool</code> or nil and an error message.</p> <p>When passed a socket or resty module it will return the same object after successful connection or nil.</p> <p>Additionally, hash methods may take an optional <code>key</code> to define how to hash the connection to determine the host. By default <code>ngx.var.remote_addr</code> is used. This value is ignored when the pool's method is round robin.</p> <pre><code>resty_redis = require('resty.redis')\nlocal redis = resty_redis.new()\n\nlocal key = ngx.req.get_headers()[\"X-Forwarded-For\"]\n\nlocal redis, err = upstream:connect(redis, key)\n\nif not redis then\n    ngx.log(ngx.ERR, err)\n    ngx.status = 500\n    return ngx.exit(ngx.status)\nend\n\nngx.log(ngx.info, 'Connected to ' .. err.host.host .. ':' .. err.host.port)\nlocal ok, err = redis:get('key')\n</code></pre>"},{"location":"lua/upstream/#process_failed_hosts","title":"process_failed_hosts","text":"<p><code>syntax: ok, err = upstream:process_failed_hosts()</code></p> <p>Processes any failed or recovered hosts from the current request. Spawns an immediate callback via ngx.timer.at, does not block current request.</p>"},{"location":"lua/upstream/#get_pools","title":"get_pools","text":"<p><code>syntax: pools = usptream:get_pools()</code></p> <p>Returns a table containing the current pool and host configuration. e.g.</p> <pre><code>{\n    primary = {\n        up = true,\n        method = 'round_robin',\n        timeout = 100,\n        priority = 0,\n        hosts = {\n            web01 = {\n                host = \"127.0.0.1\",\n                weight = 10,\n                port = \"80\",\n                lastfail = 0,\n                failcount = 0,\n                up = true,\n                healthcheck = true\n            }\n            web02 = {\n                host = \"127.0.0.1\",\n                weight = 10,\n                port = \"80\",\n                lastfail = 0,\n                failcount = 0,\n                up = true,\n                healthcheck = { interval = 30, path = '/check' }\n            }\n        }\n    },\n    secondary = {\n        up = true,\n        method = 'round_robin',\n        timeout = 2000,\n        priority = 10,\n        hosts = {\n            dr01 = {\n                host = \"10.10.10.1\",\n                weight = 10,\n                port = \"80\",\n                lastfail = 0,\n                failcount = 0,\n                up = true\n            }\n\n        }\n    },\n}\n</code></pre>"},{"location":"lua/upstream/#save_pools","title":"save_pools","text":"<p><code>syntax: ok, err = upstream:save_pools(pools)</code></p> <p>Saves a table of pools to the shared dictionary, <code>pools</code> must be in the same format as returned from <code>get_pools</code></p>"},{"location":"lua/upstream/#sort_pools","title":"sort_pools","text":"<p><code>syntax: ok, err = upstream:sort_pools(pools)</code></p> <p>Generates a priority order in the shared dictionary based on the table of pools provided</p>"},{"location":"lua/upstream/#bind","title":"bind","text":"<p><code>syntax: ok, err = upstream:bind(event, func)</code></p> <p>Bind a function to be called when events occur. <code>func</code> should expect 1 argument containing event data.</p> <p>Returns <code>true</code> on a successful bind or <code>nil</code> and an error message on failure.</p> <pre><code>local function host_down_handler(event)\n    ngx.log(ngx.ERR, \"Host: \", event.host.host, \":\", event.host.port, \" in pool '\", event.pool.id,'\" is down!')\nend\nlocal ok, err = upstream:bind('host_down', host_down_handler)\n</code></pre>"},{"location":"lua/upstream/#event-host_up","title":"Event: host_up","text":"<p>Fired when a host changes status from down to up. Event data is a table containing the affected host and pool.</p>"},{"location":"lua/upstream/#event-host_down","title":"Event: host_down","text":"<p>Fired when a host changes status from up to down. Event data is a table containing the affected host and pool.</p>"},{"location":"lua/upstream/#upstreamapi","title":"upstream.api","text":"<p>These functions allow you to dynamically reconfigure upstream pools and hosts</p>"},{"location":"lua/upstream/#new_1","title":"new","text":"<p><code>syntax: api, err = upstream_api:new(upstream)</code></p> <p>Returns a new api object using the provided upstream object.</p>"},{"location":"lua/upstream/#set_method","title":"set_method","text":"<p><code>syntax: ok, err = api:set_method(poolid, method)</code></p> <p>Sets the load balancing method for the specified pool. Currently randomised round robin and hashing methods are supported.</p>"},{"location":"lua/upstream/#create_pool","title":"create_pool","text":"<p><code>syntax: ok, err = api:create_pool(pool)</code></p> <p>Creates a new pool from a table of options, <code>pool</code> must contain at least 1 key <code>id</code> which must be unique within the current upstream object.</p> <p>Other valid options are </p> <ul> <li><code>method</code> Balancing method</li> <li><code>timeout</code> Connection timeout in ms</li> <li><code>priority</code> Higher priority pools are used later</li> <li><code>read_timeout</code></li> <li><code>keepalive_timeout</code></li> <li><code>keepalive_pool</code></li> <li><code>status_codes</code> See status_codes</li> </ul> <p>Hosts cannot be defined at this point.</p> <p>Note: IDs are converted to a string by this function</p> <p>Default pool values <pre><code>{ method = 'round_robin', timeout = 2000, priority = 0 }\n</code></pre></p>"},{"location":"lua/upstream/#set_priority","title":"set_priority","text":"<p><code>syntax: ok, err = api:set_priority(poolid, priority)</code></p> <p>Priority must be a number, returns nil on error.</p>"},{"location":"lua/upstream/#add_host","title":"add_host","text":"<p><code>syntax: ok, err = api:add_host(poolid, host)</code></p> <p>Takes a pool ID and a table of options, <code>host</code> must contain at least <code>host</code>. If the host ID is not specified it will be a numeric index based on the number of hosts in the pool.</p> <p>Note: IDs are converted to a string by this function</p> <p>Defaults: <pre><code>{ host = '', port = 80, weight = 0}\n</code></pre></p>"},{"location":"lua/upstream/#remove_host","title":"remove_host","text":"<p><code>syntax: ok, err = api:remove_host(poolid, host)</code></p> <p>Takes a poolid and a hostid to remove from the pool</p>"},{"location":"lua/upstream/#down_host","title":"down_host","text":"<p><code>syntax: ok,err = api:down_host(poolid, host)</code></p> <p>Manually marks a host as down, this host will not be revived automatically.</p>"},{"location":"lua/upstream/#up_host","title":"up_host","text":"<p><code>syntax: ok,err = api:up_host(poolid, host)</code></p> <p>Manually restores a dead host to the pool</p>"},{"location":"lua/upstream/#upstreamhttp","title":"upstream.http","text":"<p>Functions for making http requests to upstream hosts.</p>"},{"location":"lua/upstream/#status_codes","title":"status_codes","text":"<p>This pool option is an array of status codes that indicate a failed request. Defaults to none.</p> <p>The <code>x</code> character masks a digit</p> <pre><code>{\n    ['5xx'] = true, -- Matches 500, 503, 524\n    ['400'] = true  -- Matches only 400\n}\n</code></pre>"},{"location":"lua/upstream/#new_2","title":"new","text":"<p><code>syntax: httpc, err = upstream_http:new(upstream, ssl_opts?)</code></p> <p>Returns a new http upstream object using the provided upstream object.</p> <p><code>ssl_opts</code> is an optional table for configuring SSL support.  * <code>ssl</code> set to <code>true</code> to enable SSL Handshaking, default <code>false</code>  * <code>ssl_verify</code> set to <code>false</code> to disable SSL certificate verification, default <code>true</code>  * <code>sni_host</code> a string to use as the sni hostname, default is the request's Host header</p> <p><code>lua https_upstream = Upstream_HTTP:new(upstream_ssl, {         ssl = true,         ssl_verify = true,         sni_host = \"foo.example.com\"     })</code></p>"},{"location":"lua/upstream/#init_background_thread_1","title":"init_background_thread","text":"<p><code>syntax: ok, err = upstream_http:init_background_thread()</code></p> <p>Initialises the background thread, should be called in <code>init_worker_by_lua</code>.</p> <p>Do not call the <code>init_background_thread</code> method in <code>upstream.socket</code> if using the <code>upstream.http</code> background thread</p>"},{"location":"lua/upstream/#request","title":"request","text":"<p><code>syntax: res, err_or_conn_info, status? = upstream_api:request(params)</code></p> <p>Takes the same parameters as lua-resty-http's request method.</p> <p>On a successful request returns the lua-resty-http object and a table containing the connected host and pool.</p> <p>If the request failed returns nil, the error and a suggested http status code</p> <pre><code>local ok, err, status = upstream_http:request({\n        path = \"/helloworld\",\n        headers = {\n            [\"Host\"] = \"example.com\",\n        }\n    })\nif not ok then\n    ngx.status = status\n    ngx.say(err)\n    ngx.exit(status)\nelse\n    local host = err.host\n    local pool = err.pool\nend\n</code></pre>"},{"location":"lua/upstream/#set_keepalive","title":"set_keepalive","text":"<p><code>syntax: ok, err = upstream_http:set_keepalive()</code></p> <p>Passes the keepalive timeout / pool from the pool configuration through to the lua-resty-http <code>set_keepalive</code> method.</p>"},{"location":"lua/upstream/#get_reused_times","title":"get_reused_times","text":"<p><code>syntax: ok, err = upstream_http:get_reused_times()</code></p> <p>Passes through to the lua-resty-http <code>get_reused_times</code> method.</p>"},{"location":"lua/upstream/#close","title":"close","text":"<p><code>syntax: ok, err = upstream_http:close()</code></p> <p>Passes through to the lua-resty-http <code>close</code> method.</p>"},{"location":"lua/upstream/#http-healthchecks","title":"HTTP Healthchecks","text":"<p>Active background healthchecks can be enabled by adding the <code>healthcheck</code> parameter to a host.</p> <p>A value of <code>true</code> will enable the default check, a <code>GET</code> request for <code>/</code>.</p> <p>The <code>healthcheck</code> parameter can also be a table of parameters valid for lua-resty-http's request method.</p> <p>With a few additional parameters</p> <ul> <li><code>interval</code> to set the time between healthchecks, in seconds. Must be &gt;= 10s. Defaults to 60s</li> <li><code>timeout</code> sets the connect timeout for healthchecks. Defaults to pool setting.</li> <li><code>read_timeout</code> sets the read timeout for healthchecks. Defaults to pool setting.</li> <li><code>status_codes</code> a table of invalid response status codes. Defaults to pool setting.</li> </ul> <p>Failure for the background check is according to the same parameters as for a frontend request, unless overriden explicitly.</p> <pre><code>-- Custom check parameters\napi:add_host(\"primary\", {\n     host = 123.123.123.123,\n     port = 80,\n     healthcheck = {\n        interval = 30, -- check every 30s\n        timeout      = (5*1000), -- 5s connect timeout\n        read_timeout = (15*1000), -- 15s connect timeout\n        status_codes = {[\"5xx\"] = true, [\"403\"] = true}, -- 5xx and 403 responses are a fail\n        -- resty-http params\n        path = \"/check\",\n        headers = {\n            [\"Host\"] = \"domain.com\",\n            [\"Accept-Encoding\"] = \"gzip\"\n        }\n     }\n})\n\n-- Default check parameters\napi:add_host(\"primary\", {host = 123.123.123.123, port = 80, healthcheck = true})\n</code></pre>"},{"location":"lua/upstream/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-upstream.</p>"},{"location":"lua/uuid/","title":"uuid: LuaJIT FFI bindings for libuuid, a DCE compatible Universally Unique Identifier library","text":""},{"location":"lua/uuid/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/uuid/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-uuid\n</code></pre>"},{"location":"lua/uuid/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-uuid\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-uuid v1.1  released on Apr 13 2016.</p> <p>LuaJIT FFI bindings for libuuid, a DCE compatible Universally Unique Identifier library.</p>"},{"location":"lua/uuid/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-uuid.</p>"},{"location":"lua/validation/","title":"validation: Validation Library (Input Validation and Filtering) for Lua and nginx-module-lua","text":""},{"location":"lua/validation/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/validation/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-validation\n</code></pre>"},{"location":"lua/validation/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-validation\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-validation v2.7  released on Aug 25 2017.</p> <p>lua-resty-validation is an extendable chaining validation and filtering library for Lua and OpenResty.</p>"},{"location":"lua/validation/#hello-world-with-lua-resty-validation","title":"Hello World with lua-resty-validation","text":"<pre><code>local validation = require \"resty.validation\"\n\nlocal valid, e = validation.number:between(0, 9)(5)  -- valid = true,  e = 5\nlocal valid, e = validation.number:between(0, 9)(50) -- valid = false, e = \"between\"\n\n-- Validators can be reused\nlocal smallnumber = validation.number:between(0, 9)\nlocal valid, e = smallnumber(5)  -- valid = true,  e = 5\nlocal valid, e = smallnumber(50) -- valid = false, e = \"between\"\n\n-- Validators can do filtering (i.e. modify the value being validated)\n-- valid = true, s = \"HELLO WORLD!\"\nlocal valid, s = validation.string.upper \"hello world!\"\n\n-- You may extend the validation library with your own validators and filters...\nvalidation.validators.capitalize = function(value) \n    return true, value:gsub(\"^%l\", string.upper)\nend\n\n-- ... and then use it\nlocal valid, e = validation.capitalize \"abc\" -- valid = true,  e = \"Abc\"\n\n-- You can also group validate many values\nlocal group = validation.new{\n    artist = validation.string:minlen(5),\n    number = validation.tonumber:equal(10)\n}\n\nlocal valid, fields, errors = group{ artist = \"Eddie Vedder\", number = \"10\" }\n\nif valid then\n  print(\"all the group fields are valid\")\nelse\n  print(fields.artist.name,      fields.artist.error,\n        fields.artist.valid,     fields.artist.invalid,\n        fields.artist.input,     fields.artist.value, ,\n        fields.artist.validated, fields.artist.unvalidated)\nend\n\n-- You can even call fields to get simple name, value table\n-- (in that case all the `nil`s are removed as well)\n\n-- By default this returns only the valid fields' names and values:\nlocal data = fields()\nlocal data = fields \"valid\"\n\n-- To get only the invalid fields' names and values call:\nlocal data = fields \"invalid\"\n\n-- To get only the validated fields' names and values call (whether or not they are valid):\nlocal data = fields \"validated\"\n\n-- To get only the unvalidated fields' names and values call (whether or not they are valid):\nlocal data = fields \"unvalidated\"\n\n-- To get all, call:\nlocal data = fields \"all\"\n\n-- Or combine:\nlocal data = fields(\"valid\", \"invalid\")\n\n-- This doesn't stop here. You may also want to get only some fields by their name.\n-- You can do that by calling (returns a table):\nlocal data = data{ \"artist\" }\n</code></pre>"},{"location":"lua/validation/#built-in-validators-and-filters","title":"Built-in Validators and Filters","text":"<p><code>lua-resty-validation</code> comes with several built-in validators, and the project is open for contributions of more validators.</p>"},{"location":"lua/validation/#validators-and-filters-without-arguments","title":"Validators and Filters without Arguments","text":"<p>Type validators can be used to validate the type of the validated value. These validators are argument-less validators (call them with dot <code>.</code>):</p> <ul> <li><code>null</code> or <code>[\"nil\"]</code> (as the nil is a reserved keyword in Lua)</li> <li><code>boolean</code></li> <li><code>number</code></li> <li><code>string</code></li> <li><code>table</code></li> <li><code>userdata</code></li> <li><code>func</code> or <code>[\"function\"]</code> (as the function is a reserved keyword in Lua)</li> <li><code>callable</code> (either a function or a table with metamethod <code>__call</code>)</li> <li><code>thread</code></li> <li><code>integer</code></li> <li><code>float</code></li> <li><code>file</code> (<code>io.type(value) == 'file'</code>)</li> </ul> <p>Type conversion filters:</p> <ul> <li><code>tostring</code></li> <li><code>tonumber</code></li> <li><code>tointeger</code></li> <li><code>toboolean</code></li> </ul> <p>Other filters:</p> <ul> <li><code>tonil</code> or <code>tonull</code></li> <li><code>abs</code></li> <li><code>inf</code></li> <li><code>nan</code></li> <li><code>finite</code></li> <li><code>positive</code></li> <li><code>negative</code></li> <li><code>lower</code></li> <li><code>upper</code></li> <li><code>trim</code></li> <li><code>ltrim</code></li> <li><code>rtrim</code></li> <li><code>reverse</code></li> <li><code>email</code></li> <li><code>optional</code></li> </ul>"},{"location":"lua/validation/#example","title":"Example","text":"<pre><code>local validation = require \"resty.validation\"\nlocal ok, e = validation.null(nil)\nlocal ok, e = validation.boolean(true)\nlocal ok, e = validation.number(5.2)\nlocal ok, e = validation.string('Hello, World!')\nlocal ok, e = validation.integer(10)\nlocal ok, e = validation.float(math.pi)\nlocal f = assert(io.open('filename.txt', \"r\"))\nlocal ok, e = validation.file(f)\n</code></pre>"},{"location":"lua/validation/#validation-factory-validators-and-filters","title":"Validation Factory Validators and Filters","text":"<p>Validation factory consist of different validators and filters used to validate or filter the value (call them with colon <code>:</code>):</p> <ul> <li><code>type(t)</code>, validates that the value is of type <code>t</code> (see Type Validators)</li> <li><code>nil()</code> or <code>[\"null\"]()</code>, check that value type is <code>nil</code></li> <li><code>boolean()</code>, check that value type is <code>boolean</code></li> <li><code>number()</code>, check that value type is <code>number</code></li> <li><code>string()</code>, check that value type is <code>string</code></li> <li><code>table()</code>, check that value type is <code>table</code></li> <li><code>userdata()</code>, check that value type is <code>userdata</code></li> <li><code>func()</code> or <code>[\"function\"]()</code>, check that value type is <code>function</code></li> <li><code>callable()</code>, check that value is callable (aka a function or a table with metamethod <code>__call</code>)</li> <li><code>thread()</code>, check that value type is <code>thread</code></li> <li><code>integer()</code>, check that value type is <code>integer</code></li> <li><code>float()</code>, check that value type is <code>float</code></li> <li><code>file()</code>, check that value type is <code>file</code> (<code>io.type(value) == 'file'</code>)</li> <li><code>abs()</code>, filters value and returns absolute value (<code>math.abs</code>)</li> <li><code>inf()</code>, checks that the value is <code>inf</code> or <code>-inf</code></li> <li><code>nan()</code>, checks that the value is <code>nan</code></li> <li><code>finite()</code>, checks that the value is not <code>nan</code>, <code>inf</code> or <code>-inf</code></li> <li><code>positive()</code>, validates that the value is positive (<code>&gt; 0</code>)</li> <li><code>negative()</code>, validates that the value is negative (<code>&lt; 0</code>)</li> <li><code>min(min)</code>, validates that the value is at least <code>min</code> (<code>&gt;=</code>)</li> <li><code>max(max)</code>, validates that the value is at most <code>max</code> (<code>&lt;=</code>)</li> <li><code>between(min[, max = min])</code>, validates that the value is between <code>min</code> and <code>max</code></li> <li><code>outside(min[, max = min])</code>, validates that the value is not between <code>min</code> and <code>max</code></li> <li><code>divisible(number)</code>, validates that the value is divisible with <code>number</code></li> <li><code>indivisible(number)</code>, validates that the value is not divisible with <code>number</code></li> <li><code>len(min[, max = min])</code>, validates that the length of the value is exactly <code>min</code> or between <code>min</code> and <code>max</code>  (UTF-8)</li> <li><code>minlen(min)</code>, validates that the length of the value is at least <code>min</code> (UTF-8)</li> <li><code>maxlen(max)</code>, validates that the length of the value is at most <code>max</code>  (UTF-8)</li> <li><code>equals(equal)</code> or <code>equal(equal)</code>, validates that the value is exactly something</li> <li><code>unequals(equal)</code> or <code>unequal(equal)</code>, validates that the value is not exactly something</li> <li><code>oneof(...)</code>, validates that the value is equal to one of the supplied arguments</li> <li><code>noneof(...)</code>, validates that the value is not equal to any of the supplied arguments</li> <li><code>match(pattern[, init])</code>, validates that the value matches (<code>string.match</code>) the pattern</li> <li><code>unmatch(pattern[, init])</code>, validates that the value does not match (<code>string.match</code>) the pattern</li> <li><code>tostring()</code>, converts value to string</li> <li><code>tonumber([base])</code>, converts value to number</li> <li><code>tointeger()</code>, converts value to integer</li> <li><code>toboolean()</code>, converts value to boolean (using <code>not not value</code>)</li> <li><code>tonil()</code> or <code>tonull()</code>, converts value to nil</li> <li><code>lower()</code>, converts value to lower case (UTF-8 support is not yet implemented)</li> <li><code>upper()</code>, converts value to upper case (UTF-8 support is not yet implemented)</li> <li><code>trim([pattern])</code>, trims whitespace (you may use pattern as well) from the left and the right</li> <li><code>ltrim([pattern])</code>, trims whitespace (you may use pattern as well) from the left</li> <li><code>rtrim([pattern])</code>, trims whitespace (you may use pattern as well) from the right</li> <li><code>starts(starts)</code>, checks if string starts with <code>starts</code></li> <li><code>ends(ends)</code>, checks if string ends with <code>ends</code></li> <li><code>reverse</code>, reverses the value (string or number) (UTF-8)</li> <li><code>coalesce(...)</code>, if the value is nil, returns first non-nil value passed as arguments</li> <li><code>email()</code>, validates that the value is email address</li> <li><code>call(function)</code>, validates / filters the value against custom inline validator / filter</li> <li><code>optional([default])</code>, stops validation if the value is empty string <code>\"\"</code> or <code>nil</code> and returns <code>true</code>, and either, <code>default</code> or <code>value</code></li> </ul>"},{"location":"lua/validation/#conditional-validation-factory-validators","title":"Conditional Validation Factory Validators","text":"<p>For all the Validation Factory Validators there is a conditional version that always validates to true, but where you can replace the actual value depending whether the original validator validated. Hey, this is easier to show than say:</p> <pre><code>local validation = require \"resty.validation\"\n\n-- ok == true, value == \"Yes, the value is nil\"\nlocal ok, value = validation:ifnil(\n    \"Yes, the value is nil\",\n    \"No, you did not supply a nil value\")(nil)\n\n-- ok == true, value == \"No, you did not supply a nil value\"\nlocal ok, value = validation:ifnil(\n    \"Yes, the value is nil\",\n    \"No, you did not supply a nil value\")(\"non nil\")\n\n-- ok == true, value == \"Yes, the number is betweeb 1 and 10\"    \nlocal ok, value = validation:ifbetween(1, 10,\n    \"Yes, the number is between 1 and 10\",\n    \"No, the number is not between 1 and 10\")(5)\n\n-- ok == true, value == \"No, the number is not between 1 and 10\"\nlocal ok, value = validation:ifbetween(1, 10,\n    \"Yes, the number is between 1 and 10\",\n    \"No, the number is not between 1 and 10\")(100)\n</code></pre> <p>The last 2 arguments to conditional validation factory validators are the <code>truthy</code> and <code>falsy</code> values. Every other argument is passed to the actual validation factory validator.</p>"},{"location":"lua/validation/#group-validators","title":"Group Validators","text":"<p><code>lua-resty-validation</code> currently supports a few predefined validators:</p> <ul> <li><code>compare(comparison)</code>, compares two fields and sets fields invalid or valid according to comparison</li> <li><code>requisite{ fields }</code>, at least of of the requisite fields is required, even if they by themselves are optional</li> <li><code>requisites({ fields }, number)</code>, at least <code>number</code> of requisites fields are required (by default all of them)</li> <li><code>call(function)</code>, calls a custom (or inline) group validation function</li> </ul> <pre><code>local ispassword = validation.trim:minlen(8)\nlocal group = validation.new{\n    password1 = ispassword,\n    password2 = ispassword\n}\ngroup:compare \"password1 == password2\"\nlocal valid, fields, errors = group{ password1 = \"qwerty123\", password2 = \"qwerty123\" }\n\nlocal optional = validation:optional\"\".trim\nlocal group = validation.new{\n    text = optional,\n    html = optional\n}\ngroup:requisite{ \"text\", \"html\" }\nlocal valid, fields, errors = group{ text = \"\", html = \"\" }\n\n\nlocal optional = validation:optional \"\"\nlocal group = validation.new{\n    text = optional,\n    html = optional\n}\ngroup:requisites({ \"text\", \"html\" }, 2)\n-- or group:requisites{ \"text\", \"html\" }\nlocal valid, fields, errors = group{ text = \"\", html = \"\" }\n\n\ngroup:call(function(fields)\n    if fields.text.value == \"hello\" then\n        fields.text:reject \"text cannot be 'hello'\"\n        fields.html:reject \"because text was 'hello', this field is also invalidated\"\n    end\nend)\n</code></pre> <p>You can use normal Lua relational operators in <code>compare</code> group validator:</p> <ul> <li><code>&lt;</code></li> <li><code>&gt;</code></li> <li><code>&lt;=</code></li> <li><code>&gt;=</code></li> <li><code>==</code></li> <li><code>~=</code></li> </ul> <p><code>requisite</code> and <code>requisites</code> check if the field value is <code>nil</code> or <code>\"\"</code>(empty string). With <code>requisite</code>, if all the specified fields are <code>nil</code> or <code>\"\"</code> then all the fields are invalid (provided they were not by themselves invalid), and if at least one of the fields is valid then all the fields are valid. <code>requisites</code> works the same, but there you can define the number of how many fields you want to have a value that is not <code>nil</code> and not an empty string <code>\"\"</code>. These provide conditional validation in sense of:</p> <ol> <li>I have (two or more) fields</li> <li>All of them are optional</li> <li>At least one / defined number of fields should be filled but I don't care which one as long as there is at least one / defined number of fields filled</li> </ol>"},{"location":"lua/validation/#stop-validators","title":"Stop Validators","text":"<p>Stop validators, like <code>optional</code>, are just like a normal validators, but instead of returning <code>true</code> or <code>false</code> as a validation result OR as a filtered value, you can return <code>validation.stop</code>. This value can also be used inside conditional validators and in validators that support default values. Here is how the <code>optional</code> validator is implemented:</p> <pre><code>function factory.optional(default)\n    return function(value)\n        if value == nil or value == \"\" then\n            return validation.stop, default ~= nil and default or value\n        end\n        return true, value\n    end\nend\n</code></pre> <p>These are roughly equivalent:</p> <pre><code>-- Both return: true, \"default\" (they stop prosessing :minlen(10) on nil and \"\" inputs\nlocal input = \"\"\nlocal ok, val = validation.optional:minlen(10)(input)\nlocal ok, val = validation:optional(input):minlen(10)(input)\nlocal ok, val = validation:ifoneof(\"\", nil, validation.stop(input), input):minlen(10)(input)\n</code></pre>"},{"location":"lua/validation/#filtering-value-and-setting-the-value-to-nil","title":"Filtering Value and Setting the Value to <code>nil</code>","text":"<p>Most of the validators, that are not filtering the value, only return <code>true</code> or <code>false</code> as a result. That means that there is now no way to signal <code>resty.validation</code> to actually set the value to <code>nil</code>. So there is a work-around, you can return <code>validation.nothing</code> as a value, and that will change the value to <code>nil</code>, e.g. the built-in <code>tonil</code> validator is actually implemented like this (pseudo):</p> <pre><code>function()\n    return true, validation.nothing\nend\n</code></pre>"},{"location":"lua/validation/#custom-inline-validators-and-filters","title":"Custom (Inline) Validators and Filters","text":"<p>Sometimes you may just have one-off validators / filters that you are not using elsewhere, or that you just want to supply quickly an additional validator / filter for a specific case. To make that easy and straight forward, we introduced <code>call</code> factory method with <code>lua-resty-validation</code> 2.4. Here is an example:</p> <pre><code>validation:call(function(value)\n    -- now validate / filter the value, and return the results\n    -- here we just return false (aka making validation to fail) \n    return false\nend)(\"Check this value\"))\n</code></pre> <p>(of course it doesn't need to be inline function as in Lua all functions are first class citizens and they can  be passed around as parameters)</p>"},{"location":"lua/validation/#built-in-validator-extensions","title":"Built-in Validator Extensions","text":"<p>Currently <code>lua-resty-validation</code> has support for two extensions or plugins that you can enable:</p> <ul> <li><code>resty.validation.ngx</code></li> <li><code>resty.validation.tz</code></li> <li><code>resty.validation.utf8</code></li> </ul> <p>These are something you can look at if you want to build your own validator extension. If you do so, and think that it would be usable for others as well, mind you to send your extension as a pull-request for inclusion in this project, thank you very much, ;-).</p>"},{"location":"lua/validation/#restyvalidationngx-extension","title":"resty.validation.ngx extension","text":"<p>As the name tells, this set of validator extensions requires OpenResty (or Lua Nginx module at least). To use this extension all you need to do is:</p> <pre><code>require \"resty.validation.ngx\"\n</code></pre> <p>It will monkey patch the adapters that it will provide in <code>resty.validation</code>, and those are currently:</p> <ul> <li><code>escapeuri</code></li> <li><code>unescapeuri</code></li> <li><code>base64enc</code></li> <li><code>base64dec</code></li> <li><code>crc32short</code></li> <li><code>crc32long</code></li> <li><code>crc32</code></li> <li><code>md5</code></li> </ul> <p>(there is both factory and argument-less version of these)</p> <p>There is also regex matcher in ngx extension that uses <code>ngx.re.match</code>, and parameterized <code>md5</code>:</p> <ul> <li><code>regex(regex[, options])</code></li> <li><code>md5([bin])</code></li> </ul>"},{"location":"lua/validation/#example_1","title":"Example","text":"<pre><code>require \"resty.validation.ngx\"\nlocal validation = require \"resty.validation\"\nlocal valid, value = validation.unescapeuri.crc32(\"https://github.com/\")\nlocal valid, value = validation:unescapeuri():crc32()(\"https://github.com/\")\n</code></pre>"},{"location":"lua/validation/#restyvalidationtz-extension","title":"resty.validation.tz extension","text":"<p>This set of validators and filters is based on the great <code>luatz</code> library by @daurnimator, that is a library for time and date manipulation. To use this extension, all you need to do is:</p> <pre><code>require \"resty.validation.tz\"\n</code></pre> <p>It will monkey patch the adapters that it will provide in <code>resty.validation</code>, and those are currently:</p> <ul> <li><code>totimetable</code></li> <li><code>totimestamp</code></li> </ul> <p>(there is both factory and argument-less version of these)</p> <p><code>totimestamp</code> and <code>totimetable</code> filters work great with HTML5 date and datetime input fields. As the name tells, <code>totimetable</code> returns luatz <code>timetable</code> and <code>totimestamp</code> returns seconds since unix epoch (<code>1970-01-01</code>) as a Lua number.</p>"},{"location":"lua/validation/#example_2","title":"Example","text":"<pre><code>require \"resty.validation.tz\"\nlocal validation = require \"resty.validation\"\nlocal valid, ts = validation.totimestamp(\"1990-12-31T23:59:60Z\")\nlocal valid, ts = validation.totimestamp(\"1996-12-19\")\n</code></pre>"},{"location":"lua/validation/#restyvalidationutf8-extension","title":"resty.validation.utf8 extension","text":"<p>This set of validators and filters is based on the great <code>utf8rewind</code> library by Quinten Lansu - a system library written in C designed to extend the default string handling functions with support for UTF-8 encoded text. It needs my LuaJIT FFI wrapper <code>lua-resty-utf8rewind</code> to work. When the mentioned requirements are installed, the rest is easy. To use this extension, all you need to do is:</p> <pre><code>require \"resty.validation.utf8\"\n</code></pre> <p>It will monkey patch the adapters that it will provide in <code>resty.validation</code>, and those are currently:</p> <ul> <li><code>utf8upper</code></li> <li><code>utf8lower</code></li> <li><code>utf8title</code></li> </ul> <p>(there is both factory and argument-less version of these)</p> <p>There is also a few factory validators / filters:</p> <ul> <li><code>utf8normalize(form)</code></li> <li><code>utf8category(category)</code></li> </ul> <p>The <code>utf8normalize</code> normalizes the UTF-8 input to one of these normalization formats:</p> <ul> <li><code>C</code> (or <code>NFC</code>)</li> <li><code>D</code> (or <code>NFD</code>)</li> <li><code>KC</code> (or <code>NFKC</code>)</li> <li><code>KD</code> (or <code>NFKD</code>)</li> </ul> <p>The <code>utf8category</code> checks that the input string is in one of the following categories (so, you may think it has multiple validators built-in to work with UTF-8 string validation):</p> <ul> <li><code>LETTER_UPPERCASE</code></li> <li><code>LETTER_LOWERCASE</code></li> <li><code>LETTER_TITLECASE</code></li> <li><code>LETTER_MODIFIER</code></li> <li><code>CASE_MAPPED</code></li> <li><code>LETTER_OTHER</code></li> <li><code>LETTER</code></li> <li><code>MARK_NON_SPACING</code></li> <li><code>MARK_SPACING</code></li> <li><code>MARK_ENCLOSING</code></li> <li><code>MARK</code></li> <li><code>NUMBER_DECIMAL</code></li> <li><code>NUMBER_LETTER</code></li> <li><code>NUMBER_OTHER</code></li> <li><code>NUMBER</code></li> <li><code>PUNCTUATION_CONNECTOR</code></li> <li><code>PUNCTUATION_DASH</code></li> <li><code>PUNCTUATION_OPEN</code></li> <li><code>PUNCTUATION_CLOSE</code></li> <li><code>PUNCTUATION_INITIAL</code></li> <li><code>PUNCTUATION_FINAL</code></li> <li><code>PUNCTUATION_OTHER</code></li> <li><code>PUNCTUATION</code></li> <li><code>SYMBOL_MATH</code></li> <li><code>SYMBOL_CURRENCY</code></li> <li><code>SYMBOL_MODIFIER</code></li> <li><code>SYMBOL_OTHER</code></li> <li><code>SYMBOL</code></li> <li><code>SEPARATOR_SPACE</code></li> <li><code>SEPARATOR_LINE</code></li> <li><code>SEPARATOR_PARAGRAPH</code></li> <li><code>SEPARATOR</code></li> <li><code>CONTROL</code></li> <li><code>FORMAT</code></li> <li><code>SURROGATE</code></li> <li><code>PRIVATE_USE</code></li> <li><code>UNASSIGNED</code></li> <li><code>COMPATIBILITY</code></li> <li><code>ISUPPER</code></li> <li><code>ISLOWER</code></li> <li><code>ISALPHA</code></li> <li><code>ISDIGIT</code></li> <li><code>ISALNUM</code></li> <li><code>ISPUNCT</code></li> <li><code>ISGRAPH</code></li> <li><code>ISSPACE</code></li> <li><code>ISPRINT</code></li> <li><code>ISCNTRL</code></li> <li><code>ISXDIGIT</code></li> <li><code>ISBLANK</code></li> <li><code>IGNORE_GRAPHEME_CLUSTER</code></li> </ul>"},{"location":"lua/validation/#example_3","title":"Example","text":"<pre><code>require \"resty.validation.utf8\"\nlocal validation = require \"resty.validation\"\nlocal valid, ts = validation:utf8category(\"LETTER_UPPERCASE\")(\"TEST\")\n</code></pre>"},{"location":"lua/validation/#restyvalidationinjection-extension","title":"resty.validation.injection extension","text":"<p>This set of validators and filters is based on the great <code>libinjection</code> library by Nick Galbreath - a SQL / SQLI / XSS tokenizer parser analyzer. It needs my LuaJIT FFI wrapper <code>lua-resty-injection</code> to work. When the mentioned requirements are installed, the rest is easy. To use this extension, all you need to do is:</p> <pre><code>require \"resty.validation.injection\"\n</code></pre> <p>It will monkey patch the adapters that it will provide in <code>resty.validation</code>, and those are currently:</p> <ul> <li><code>sqli</code>, returns <code>false</code> if SQL injection was detected, otherwise returns <code>true</code></li> <li><code>xss</code>, returns <code>false</code> if Cross-Site Scripting injection was detected, otherwise returns <code>true</code></li> </ul>"},{"location":"lua/validation/#example_4","title":"Example","text":"<pre><code>require \"resty.validation.injection\"\nlocal validation = require \"resty.validation\"\nlocal valid, ts = validation.sqli(\"test'; DELETE FROM users;\")\nlocal valid, ts = validation.xss(\"test &lt;script&gt;alert('XSS');&lt;/script&gt;\")\n</code></pre>"},{"location":"lua/validation/#api","title":"API","text":"<p>I'm not going here for details for all the different validators and filters there is because they all follow the same logic, but I will show some general ways how this works.</p>"},{"location":"lua/validation/#validation_version","title":"validation._VERSION","text":"<p>This field contains a version of the validation library, e.g. it's value can be <code>\"2.5\"</code> for the version 2.5 of this library.</p>"},{"location":"lua/validation/#boolean-valueerror-validation","title":"boolean, value/error validation...","text":"<p>That <code>...</code> means the validation chain. This is used to define a single validator chain. There is no limit to chain length. It will always return boolean (if the validation is valid or not). The second return value will be either the name of the filter that didn't return <code>true</code> as a validation result, or the filtered value.</p> <pre><code>local v = require \"resty.validation\"\n\n-- The below means, create validator that checks that the input is:\n-- 1. string\n-- If, it is, then trim whitespaces from begin and end of the string:\n-- 2. trim\n-- Then check that the trimmed string's length is at least 5 characters (UTF-8):\n-- 3. minlen(5)\n-- And if everything is still okay, convert that string to upper case\n-- (UTF-8 is not yet supported in upper):\n-- 4. upper\nlocal myvalidator = v.string.trim:minlen(5).upper\n\n-- This example will return false and \"minlen\"\nlocal valid, value = myvalidator(\" \\n\\t a \\t\\n \")\n\n-- This example will return true and \"ABCDE\"\nlocal valid, value = myvalidator(\" \\n\\t abcde \\t\\n \")\n</code></pre> <p>Whenever the validator fails and returns <code>false</code>, you should not use the returned value for other purposes than error reporting. So, the chain works like that. The <code>lua-resty-validation</code> will not try to do anything if you specify chains that will never get used, such as:</p> <pre><code>local v = require \"resty.validation\"\n-- The input value can never be both string and number at the same time:\nlocal myvalidator = v.string.number:max(3)\n-- But you could write this like this\n-- (take input as a string, try to convert it to number, and check it is at most 3):\nlocal myvalidator = v.string.tonumber:max(3)\n</code></pre> <p>As you see, this is a way to define single reusable validators. You can for example predefine your set of basic single validator chains and store it in your own module from which you can reuse the same validation logic in different parts of your application. It is good idea to start defining single reusable validators, and then reuse them in group validators.</p> <p>E.g. say you have module called <code>validators</code>:</p> <pre><code>local v = require \"resty.validation\"\nreturn {\n    nick     = v.string.trim:minlen(2),\n    email    = v.string.trim.email,\n    password = v.string.trim:minlen(8)\n}\n</code></pre> <p>And now you have <code>register</code> function somewhere in your application:</p> <pre><code>local validate = require \"validators\"\nlocal function register(nick, email, password)\n    local vn, nick     = validate.nick(nick)\n    local ve, email    = validate.email(email)\n    local vp, password = validate.password(password)\n    if vn and ve and vp then\n        -- input is valid, do something with nick, email, and password\n    else\n        -- input is invalid, nick, email, and password contain the error reasons\n    end\nend\n</code></pre> <p>This quickly gets a little bit dirty, and that's why we have Group validators.</p>"},{"location":"lua/validation/#table-validationnewtable-of-validators","title":"table validation.new([table of validators])","text":"<p>This function is where the group validation kicks in. Say that you have a registration form that asks you nick, email (same twice), and password (same twice).</p> <p>We will reuse the single validators, defined in <code>validators</code> module:</p> <pre><code>local v = require \"resty.validation\"\nreturn {\n    nick     = v.string.trim:minlen(2),\n    email    = v.string.trim.email,\n    password = v.string.trim:minlen(8)\n}\n</code></pre> <p>Now, lets create the reusable group validator in <code>forms</code> module:</p> <pre><code>local v        = require \"resty.validation\"\nlocal validate = require \"validators\"\n\n-- First we create single validators for each form field\nlocal register = v.new{\n    nick      = validate.nick,\n    email     = validate.email,\n    email2    = validate.email,\n    password  = validate.password,\n    password2 = validate.password\n}\n\n-- Next we create group validators for email and password:\nregister:compare \"email    == email2\"\nregister:compare \"password == password2\"\n\n-- And finally we return from this forms module\n\nreturn {\n    register = register\n}\n</code></pre> <p>Now, somewhere in your application you have this <code>register</code> function:</p> <pre><code>local forms = require \"forms\"\nlocal function register(data)\n    local valid, fields, errors = forms.register(data)\n    if valid then\n        -- input is valid, do something with fields\n    else\n        -- input is invalid, do something with fields and errors\n    end\nend\n\n-- And you might call it like:\n\nregister{\n    nick      = \"test\",\n    email     = \"test@test.org\",\n    email2    = \"test@test.org\",\n    password  = \"qwerty123\",\n    password2 = \"qwerty123\"\n}\n</code></pre> <p>The great thing about group validators is that you can JSON encode the fields and errors table and return it to client. This might come handy when building a single page application and you need to report server side errors on client. In the above example, the <code>fields</code> variable will look like this (<code>valid</code> would be true:, and <code>errors</code> would be <code>nil</code>):</p> <pre><code>{\n    nick = {\n        unvalidated = false,\n        value = \"test\",\n        input = \"test\",\n        name = \"nick\",\n        valid = true,\n        invalid = false,\n        validated = true\n    },\n    email = {\n        unvalidated = false,\n        value = \"test@test.org\",\n        input = \"test@test.org\",\n        name = \"email\",\n        valid = true,\n        invalid = false,\n        validated = true\n    },\n    email2 = {\n        unvalidated = false,\n        value = \"test@test.org\",\n        input = \"test@test.org\",\n        name = \"email2\",\n        valid = true,\n        invalid = false,\n        validated = true\n    },\n    password = {\n        unvalidated = false,\n        value = \"qwerty123\",\n        input = \"qwerty123\",\n        name = \"password\",\n        valid = true,\n        invalid = false,\n        validated = true\n    },\n    password2 = {\n        unvalidated = false,\n        value = \"qwerty123\",\n        input = \"qwerty123\",\n        name = \"password2\",\n        valid = true,\n        invalid = false,\n        validated = true\n    }\n}\n</code></pre> <p>This is great for further processing and sending the fields as JSON encoded back to the client-side Javascript application, but usually this is too heavy construct to be send to the backend layer. To get a simple key value table, we can call this fields table:</p> <pre><code>local data = fields()\n</code></pre> <p>The <code>data</code> variable will now contain:</p> <pre><code>{\n    nick = \"test\",\n    email = \"test@test.org\",\n    email2 = \"test@test.org\",\n    password = \"qwerty123\",\n    password2 = \"qwerty123\"\n}\n</code></pre> <p>Now this is something you can send for example in Redis or whatever database (abstraction) layer you have. But, well, this doesn't stop here, if say your database layer is only interested in <code>nick</code>, <code>email</code> and <code>password</code> (e.g. strip those duplicates), you can even call the <code>data</code> table:</p> <pre><code>local realdata = data(\"nick\", \"email\", \"password\")\n</code></pre> <p>The <code>realdata</code> will now contain:</p> <pre><code>{\n    nick = \"test\",\n    email = \"test@test.org\",\n    password = \"qwerty123\"\n}\n</code></pre>"},{"location":"lua/validation/#fieldacceptvalue","title":"field:accept(value)","text":"<p>For field you can call <code>accept</code> that does this:</p> <pre><code>self.error = nil\nself.value = value\nself.valid = true\nself.invalid = false\nself.validated = true\nself.unvalidated = false\n</code></pre>"},{"location":"lua/validation/#fieldrejecterror","title":"field:reject(error)","text":"<p>For field you can call <code>reject</code> that does this:</p> <pre><code>self.error = error\nself.valid = false\nself.invalid = true\nself.validated = true\nself.unvalidated = false\n</code></pre>"},{"location":"lua/validation/#string-fieldstateinvalid-valid-unvalidated","title":"string field:state(invalid, valid, unvalidated)","text":"<p>Calling <code>state</code> on field is great when embedding validation results inside say HTML template, such as <code>lua-resty-template</code>. Here is an example using <code>lua-resty-template</code>:</p> <pre><code>&lt;form method=\"post\"&gt;\n    &lt;input class=\"{{ form.email:state('invalid', 'valid') }}\"\n            name=\"email\"\n            type=\"text\"\n            placeholder=\"Email\"\n            value=\"{{ form.email.input }}\"&gt;\n    &lt;button type=\"submit\"&gt;Join&lt;/button&gt;\n&lt;/form&gt;\n</code></pre> <p>So depending on email field's state this will add a class to input element (e.g. making input's border red or green for example). We don't care about unvalidated (e.g. when the user first loaded the page and form) state here.</p>"},{"location":"lua/validation/#changes","title":"Changes","text":"<p>The changes of every release of this module is recorded in Changes.md file.</p>"},{"location":"lua/validation/#see-also","title":"See Also","text":"<ul> <li>lua-resty-route \u2014 Routing library</li> <li>lua-resty-reqargs \u2014 Request arguments parser</li> <li>lua-resty-session \u2014 Session library</li> <li>lua-resty-template \u2014 Templating Engine</li> </ul>"},{"location":"lua/validation/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-validation.</p>"},{"location":"lua/vhost/","title":"vhost: Hostname matching library for nginx-module-lua","text":""},{"location":"lua/vhost/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/vhost/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-vhost\n</code></pre>"},{"location":"lua/vhost/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-vhost\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-vhost v0.1  released on Oct 14 2016.</p> <p>Library for matching hostnames to values. Supports wildcard and <code>.hostname.tld</code> syntax in the same way as Nginx's server_name directive.</p> <p>Keys beginning with <code>.</code> or <code>*.</code> will match apex and all sub-domains, longest match wins. Non-wildcard matches always win.</p> <p>Regex matches and prefix wildcards are not supported.</p>"},{"location":"lua/vhost/#overview","title":"Overview","text":"<pre><code>init_by_lua_block {\n    local vhost = require(\"resty.vhost\")\n    my_vhost = vhost:new()\n    local ok, err = my_vhost:insert(\"example.com\",      { key = \"example.com.key\",          cert = \"example.com.crt\" })\n    local ok, err = my_vhost:insert(\"www.example.com\",  { key = \"example.com.key\",          cert = \"example.com.crt\" })\n    local ok, err = my_vhost:insert(\".sub.example.com\", { key = \"star.sub.example.com.key\", cert = \"star.sub.example.com.crt\" })\n    local ok, err = my_vhost:insert(\"www.example2.com\", { key = \"www.example2.com.key\",     cert = \"www.example2.com.crt\" })\n}\n\nserver {\n    listen 80 default_server;\n    listen 443 ssl default_server;\n    server_name vhost;\n\n    ssl_certificate         /path/to/default/cert.crt;\n    ssl_certificate_key     /path/to/default/key.crt;\n\n    ssl_certificate_by_lua_block {\n        local val, err = my_vhost:lookup(require(\"ngx.ssl\").server_name())\n        if not val then\n            ngx.log(ngx.ERR, err)\n        else\n            ngx.log(ngx.DEBUG, \"Match, setting certs: \", val.cert, \" \", val.key)\n            -- set_certs_somehow(val)\n        end\n    }\n\n    location / {\n        content_by_lua_block {\n            local val, err = my_vhost:lookup(ngx.var.host)\n            if val then\n                -- do something based on val\n                ngx.say(\"Matched: \", val.cert)\n            else\n                if err then\n                    ngx.log(ngx.ERR, err)\n                end\n                ngx.exit(404)\n            end\n        }\n    }\n}\n</code></pre>"},{"location":"lua/vhost/#methods","title":"Methods","text":""},{"location":"lua/vhost/#new","title":"new","text":"<p><code>syntax: my_vhost, err = vhost:new(size?)</code></p> <p>Creates a new instance of resty-vhost with an optional initial size</p>"},{"location":"lua/vhost/#insert","title":"insert","text":"<p><code>syntax: ok, err = my_vhost:insert(key, value)</code></p> <p>Adds a new hostname key with associated value.</p> <p>Keys must be strings.</p> <p>Returns false and an error message on failure.</p>"},{"location":"lua/vhost/#lookup","title":"lookup","text":"<p><code>syntax: val, err = my_vhost:lookup(hostname)</code></p> <p>Retrieves value for best matching hostname entry.</p> <p>Returns nil and an error message on failure</p>"},{"location":"lua/vhost/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-vhost.</p>"},{"location":"lua/waf/","title":"waf: High-performance WAF built on nginx-module-lua stack","text":""},{"location":"lua/waf/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/waf/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-waf\n</code></pre>"},{"location":"lua/waf/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-waf\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-waf v0.11.1  released on May 09 2017.</p> <p>lua-resty-waf - High-performance WAF built on the OpenResty stack</p>"},{"location":"lua/waf/#status","title":"Status","text":"<p>lua-resty-waf is currently in active development. New bugs and questions opened in the issue tracker will be answered within a day or two, and performance impacting / security related issues will be patched with high priority. Larger feature sets and enhancements will be added when development resources are available (see the Roadmap section for an outline of planned features).</p> <p>lua-resty-waf is compatible with the master branch of <code>lua-resty-core</code>. The bundled version of <code>lua-resty-core</code> available in recent releases of OpenResty (&gt;= 1.9.7.4) is compatible with lua-resty-waf; versions bundled with older OpenResty bundles are not, so users wanting to leverage <code>resty.core</code> will either need to replace the local version with the one available from the GitHub project, or patch the module based off this commit.</p>"},{"location":"lua/waf/#description","title":"Description","text":"<p>lua-resty-waf is a reverse proxy WAF built using the OpenResty stack. It uses the Nginx Lua API to analyze HTTP request information and process against a flexible rule structure. lua-resty-waf is distributed with a ruleset that mimics the ModSecurity CRS, as well as a few custom rules built during initial development and testing, and a small virtual patchset for emerging threats. Additionally, lua-resty-waf is distributed with tooling to automatically translate existing ModSecurity rules, allowing users to extend lua-resty-waf implementation without the need to learn a new rule syntax.</p> <p>lua-resty-waf was initially developed by Robert Paprocki for his Master's thesis at Western Governor's University.</p>"},{"location":"lua/waf/#configure-with-pcrepathtopcresource-with-pcre-jit","title":"./configure --with-pcre=/path/to/pcre/source --with-pcre-jit","text":"<pre><code>You can download the PCRE source from the [PCRE website](http://www.pcre.org/). See also this [blog post](https://www.cryptobells.com/building-openresty-with-pcre-jit/) for a step-by-step walkthrough on building OpenResty with a JIT-enabled PCRE library.\n\n## Performance\n\nlua-resty-waf was designed with efficiency and scalability in mind. It leverages Nginx's asynchronous processing model and an efficient design to process each transaction as quickly as possible. Load testing has show that deployments implementing all provided rulesets, which are designed to mimic the logic behind the ModSecurity CRS, process transactions in roughly 300-500 microseconds per request; this equals the performance advertised by [Cloudflare's WAF](https://www.cloudflare.com/waf). Tests were run on a reasonable hardware stack (E3-1230 CPU, 32 GB RAM, 2 x 840 EVO in RAID 0), maxing at roughly 15,000 requests per second. See [this blog post](http://www.cryptobells.com/freewaf-a-high-performance-scalable-open-web-firewall) for more information.\n\nlua-resty-waf workload is almost exclusively CPU bound. Memory footprint in the Lua VM (excluding persistent storage backed by `lua-shared-dict`) is roughly 2MB.\n\n## make &amp;&amp; sudo make install\n</code></pre> <p>Alternatively, install via Luarocks:</p> <p>```</p>"},{"location":"lua/waf/#pull-requests","title":"Pull Requests","text":"<p>Please target all pull requests towards the development branch, or a feature branch if the PR is a significant change. Commits to master should only come in the form of documentation updates or other changes that have no impact of the module itself (and can be cleanly merged into development).</p>"},{"location":"lua/waf/#roadmap","title":"Roadmap","text":"<ul> <li>Expanded virtual patch ruleset: Increase coverage of emerging threats.</li> <li>Expanded integration/acceptance testing: Increase coverage of common threats and usage scenarios.</li> <li>Expanded ModSecurity syntax translations: Support more operators, variables, and actions.</li> <li>Common application profiles: Tuned rulesets for common CMS/applications.</li> <li>Support multiple socket/file logger targets: Likely requires forking the lua-resty-logger-socket project.</li> </ul>"},{"location":"lua/waf/#limitations","title":"Limitations","text":"<p>lua-resty-waf is undergoing continual development and improvement, and as such, may be limited in its functionality and performance. Currently known limitations can be found within the GitHub issue tracker for this repo.</p>"},{"location":"lua/waf/#see-also","title":"See Also","text":"<ul> <li>The OpenResty project: http://openresty.org/</li> <li>My personal blog for updates and notes on lua-resty-waf development: http://www.cryptobells.com/tag/lua-resty-waf/</li> </ul>"},{"location":"lua/waf/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-waf.</p>"},{"location":"lua/weauth/","title":"weauth: \u9002\u7528\u4e8e nginx-module-lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1","text":""},{"location":"lua/weauth/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/weauth/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-weauth\n</code></pre>"},{"location":"lua/weauth/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-weauth\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-weauth v0.0.3  released on Aug 11 2021.</p> <p>\u9002\u7528\u4e8e OpenResty/ngx_lua \u7684\u57fa\u4e8e\u4f01\u4e1a\u5fae\u4fe1\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1</p>"},{"location":"lua/weauth/#_1","title":"\u4f7f\u7528","text":""},{"location":"lua/weauth/#_2","title":"\u4e0b\u8f7d","text":"<pre><code>cd /path/to\ngit clone git@github.com:ledgetech/lua-resty-http.git\ngit clone git@github.com:SkyLothar/lua-resty-jwt.git\ngit clone git@github.com:k8scat/lua-resty-weauth.git\n</code></pre>"},{"location":"lua/weauth/#_3","title":"\u914d\u7f6e","text":"<pre><code>server {\n    access_by_lua_block {\n        local weauth = require \"resty.weauth\"\n        weauth.corp_id = \"\"\n        weauth.app_agent_id = \"\"\n        weauth.app_secret = \"\"\n        weauth.callback_uri = \"/weauth_callback\"\n        weauth.logout_uri = \"/weauth_logout\"\n        weauth.app_domain = \"weauth.example.com\"\n\n        weauth.jwt_secret = \"thisisjwtsecret\"\n\n        weauth.ip_blacklist = {\"47.1.2.3\"}\n        weauth.uri_whitelist = {\"/\"}\n        weauth.department_whitelist = {1, 2}\n\n        weauth:auth()\n    }\n}\n</code></pre> <p>\u914d\u7f6e\u8bf4\u660e\uff1a</p> <ul> <li><code>corp_id</code> \u7528\u4e8e\u8bbe\u7f6e\u4f01\u4e1a ID</li> <li><code>app_agent_id</code> \u7528\u4e8e\u8bbe\u7f6e\u4f01\u4e1a\u5fae\u4fe1\u81ea\u5efa\u5e94\u7528\u7684 <code>AgentId</code></li> <li><code>app_secret</code> \u7528\u4e8e\u8bbe\u7f6e\u4f01\u4e1a\u5fae\u4fe1\u81ea\u5efa\u5e94\u7528\u7684 <code>Secret</code></li> <li><code>callback_uri</code> \u7528\u4e8e\u8bbe\u7f6e\u4f01\u4e1a\u5fae\u4fe1\u626b\u7801\u767b\u5f55\u540e\u7684\u56de\u8c03\u5730\u5740\uff08\u9700\u8bbe\u7f6e\u4f01\u4e1a\u5fae\u4fe1\u6388\u6743\u767b\u5f55\u4e2d\u7684\u6388\u6743\u56de\u8c03\u57df\uff09</li> <li><code>logout_uri</code> \u7528\u4e8e\u8bbe\u7f6e\u767b\u51fa\u5730\u5740</li> <li><code>app_domain</code> \u7528\u4e8e\u8bbe\u7f6e\u8bbf\u95ee\u57df\u540d\uff08\u9700\u548c\u4e1a\u52a1\u670d\u52a1\u7684\u8bbf\u95ee\u57df\u540d\u4e00\u81f4\uff09</li> <li><code>jwt_secret</code> \u7528\u4e8e\u8bbe\u7f6e JWT secret</li> <li><code>ip_blacklist</code> \u7528\u4e8e\u8bbe\u7f6e IP \u9ed1\u540d\u5355</li> <li><code>uri_whitelist</code> \u7528\u4e8e\u8bbe\u7f6e\u5730\u5740\u767d\u540d\u5355\uff0c\u4f8b\u5982\u9996\u9875\u4e0d\u9700\u8981\u767b\u5f55\u8ba4\u8bc1</li> <li><code>department_whitelist</code> \u7528\u4e8e\u8bbe\u7f6e\u90e8\u95e8\u767d\u540d\u5355\uff08\u6570\u5b57\uff09</li> </ul>"},{"location":"lua/weauth/#_4","title":"\u4f9d\u8d56\u6a21\u5757","text":"<ul> <li>lua-resty-http</li> <li>lua-resty-jwt</li> </ul>"},{"location":"lua/weauth/#_5","title":"\u76f8\u5173\u9879\u76ee","text":"<ul> <li>lua-resty-feishu-auth \u9002\u7528\u4e8e OpenResty / ngx_lua \u7684\u57fa\u4e8e\u98de\u4e66\u7ec4\u7ec7\u67b6\u6784\u7684\u767b\u5f55\u8ba4\u8bc1</li> </ul>"},{"location":"lua/weauth/#_6","title":"\u4f5c\u8005","text":"<p>K8sCat k8scat@gmail.com</p>"},{"location":"lua/weauth/#_7","title":"\u5f00\u6e90\u534f\u8bae","text":"<p>MIT</p>"},{"location":"lua/weauth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-weauth.</p>"},{"location":"lua/websocket-proxy/","title":"websocket-proxy: Reverse-proxying of websocket frames","text":""},{"location":"lua/websocket-proxy/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/websocket-proxy/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-websocket-proxy\n</code></pre>"},{"location":"lua/websocket-proxy/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-websocket-proxy\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-websocket-proxy v0.0.1  released on Apr 04 2022.</p> <p>Reverse-proxying of websocket frames with in-flight inspection/update/drop and frame aggregation support.</p> <p>Resources:</p> <ul> <li>RFC-6455</li> <li>lua-resty-websocket</li> </ul>"},{"location":"lua/websocket-proxy/#status","title":"Status","text":"<p>This library is usable although still under active development.</p> <p>The Lua API may change without notice.</p>"},{"location":"lua/websocket-proxy/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    server {\n        listen 9000;\n\n        location / {\n            content_by_lua_block {\n                local ws_proxy = require \"resty.websocket.proxy\"\n\n                local proxy, err = ws_proxy.new({\n                    aggregate_fragments = true,\n                    on_frame = function(origin, typ, payload, last, code)\n                        --  origin: [string]      \"client\" or \"upstream\"\n                        --     typ: [string]      \"text\", \"binary\", \"ping\", \"pong\", \"close\"\n                        -- payload: [string|nil]  payload if any\n                        --    last: [boolean]     fin flag for fragmented frames; true if aggregate_fragments is on\n                        --    code: [number|nil]  code for \"close\" frames\n\n                        if update_payload then\n                            -- change payload + code before forwarding\n                            return \"new payload\", 1001\n                        end\n\n                        -- forward as-is\n                        return payload\n                    end\n                })\n                if not proxy then\n                    ngx.log(ngx.ERR, \"failed to create proxy: \", err)\n                    return ngx.exit(444)\n                end\n\n                local ok, err = proxy:connect(\"ws://127.0.0.1:9001\")\n                if not ok then\n                    ngx.log(ngx.ERR, err)\n                    return ngx.exit(444)\n                end\n\n                -- Start a bi-directional websocket proxy between\n                -- this client and the upstream\n                local done, err = proxy:execute()\n                if not done then\n                    ngx.log(ngx.ERR, \"failed proxying: \", err)\n                    return ngx.exit(444)\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/websocket-proxy/#limitations","title":"Limitations","text":"<ul> <li>Built with lua-resty-websocket   which only supports <code>Sec-Websocket-Version: 13</code> (no extensions) and denotes   its client component a   work-in-progress.</li> </ul>"},{"location":"lua/websocket-proxy/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-websocket-proxy.</p>"},{"location":"lua/websocket/","title":"websocket: WebSocket support for nginx-module-lua module","text":""},{"location":"lua/websocket/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/websocket/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-websocket\n</code></pre>"},{"location":"lua/websocket/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-websocket\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-websocket v0.13  released on Feb 11 2025.</p> <p>lua-resty-websocket - Lua WebSocket implementation for the ngx_lua module</p>"},{"location":"lua/websocket/#status","title":"Status","text":"<p>This library is considered production ready.</p>"},{"location":"lua/websocket/#description","title":"Description","text":"<p>This Lua library implements a WebSocket server and client libraries based on the ngx_lua module.</p> <p>This Lua library takes advantage of ngx_lua's cosocket API, which ensures 100% nonblocking behavior.</p> <p>Note that only RFC 6455 is supported. Earlier protocol revisions like \"hybi-10\", \"hybi-07\", and \"hybi-00\" are not and will not be considered.</p>"},{"location":"lua/websocket/#synopsis","title":"Synopsis","text":"<pre><code>    local server = require \"resty.websocket.server\"\n\n    local wb, err = server:new{\n        timeout = 5000,  -- in milliseconds\n        max_payload_len = 65535,\n    }\n    if not wb then\n        ngx.log(ngx.ERR, \"failed to new websocket: \", err)\n        return ngx.exit(444)\n    end\n\n    local data, typ, err = wb:recv_frame()\n\n    if not data then\n        if not string.find(err, \"timeout\", 1, true) then\n            ngx.log(ngx.ERR, \"failed to receive a frame: \", err)\n            return ngx.exit(444)\n        end\n    end\n\n    if typ == \"close\" then\n        -- for typ \"close\", err contains the status code\n        local code = err\n\n        -- send a close frame back:\n\n        local bytes, err = wb:send_close(1000, \"enough, enough!\")\n        if not bytes then\n            ngx.log(ngx.ERR, \"failed to send the close frame: \", err)\n            return\n        end\n        ngx.log(ngx.INFO, \"closing with status code \", code, \" and message \", data)\n        return\n    end\n\n    if typ == \"ping\" then\n        -- send a pong frame back:\n\n        local bytes, err = wb:send_pong(data)\n        if not bytes then\n            ngx.log(ngx.ERR, \"failed to send frame: \", err)\n            return\n        end\n    elseif typ == \"pong\" then\n        -- just discard the incoming pong frame\n\n    else\n        ngx.log(ngx.INFO, \"received a frame of type \", typ, \" and payload \", data)\n    end\n\n    wb:set_timeout(1000)  -- change the network timeout to 1 second\n\n    bytes, err = wb:send_text(\"Hello world\")\n    if not bytes then\n        ngx.log(ngx.ERR, \"failed to send a text frame: \", err)\n        return ngx.exit(444)\n    end\n\n    bytes, err = wb:send_binary(\"blah blah blah...\")\n    if not bytes then\n        ngx.log(ngx.ERR, \"failed to send a binary frame: \", err)\n        return ngx.exit(444)\n    end\n\n    local bytes, err = wb:send_close(1000, \"enough, enough!\")\n    if not bytes then\n        ngx.log(ngx.ERR, \"failed to send the close frame: \", err)\n        return\n    end\n</code></pre>"},{"location":"lua/websocket/#modules","title":"Modules","text":""},{"location":"lua/websocket/#restywebsocketserver","title":"resty.websocket.server","text":"<p>To load this module, just do this</p> <pre><code>    local server = require \"resty.websocket.server\"\n</code></pre>"},{"location":"lua/websocket/#methods","title":"Methods","text":""},{"location":"lua/websocket/#new","title":"new","text":"<p><code>syntax: wb, err = server:new()</code></p> <p><code>syntax: wb, err = server:new(opts)</code></p> <p>Performs the websocket handshake process on the server side and returns a WebSocket server object.</p> <p>In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>An optional options table can be specified. The following options are as follows:</p> <ul> <li> <p><code>max_payload_len</code></p> <p>Specifies the maximal length of payload allowed when sending and receiving WebSocket frames. Defaults to <code>65535</code>. * <code>max_recv_len</code></p> <p>Specifies the maximal length of payload allowed when receiving WebSocket frames. Defaults to the value of <code>max_payload_len</code>. * <code>max_send_len</code></p> <p>Specifies the maximal length of payload allowed when sending WebSocket frames. Defaults to the value of <code>max_payload_len</code>. * <code>send_masked</code></p> <p>Specifies whether to send out masked WebSocket frames. When it is <code>true</code>, masked frames are always sent. Default to <code>false</code>. * <code>timeout</code></p> <p>Specifies the network timeout threshold in milliseconds. You can change this setting later via the <code>set_timeout</code> method call. Note that this timeout setting does not affect the HTTP response header sending process for the websocket handshake; you need to configure the send_timeout directive at the same time.</p> </li> </ul>"},{"location":"lua/websocket/#set_timeout","title":"set_timeout","text":"<p><code>syntax: wb:set_timeout(ms)</code></p> <p>Sets the timeout delay (in milliseconds) for the network-related operations.</p>"},{"location":"lua/websocket/#send_text","title":"send_text","text":"<p><code>syntax: bytes, err = wb:send_text(text)</code></p> <p>Sends the <code>text</code> argument out as an unfragmented data frame of the <code>text</code> type. Returns the number of bytes that have actually been sent on the TCP level.</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/websocket/#send_binary","title":"send_binary","text":"<p><code>syntax: bytes, err = wb:send_binary(data)</code></p> <p>Sends the <code>data</code> argument out as an unfragmented data frame of the <code>binary</code> type. Returns the number of bytes that have actually been sent on the TCP level.</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/websocket/#send_ping","title":"send_ping","text":"<p><code>syntax: bytes, err = wb:send_ping()</code></p> <p><code>syntax: bytes, err = wb:send_ping(msg)</code></p> <p>Sends out a <code>ping</code> frame with an optional message specified by the <code>msg</code> argument. Returns the number of bytes that have actually been sent on the TCP level.</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p> <p>Note that this method does not wait for a pong frame from the remote end.</p>"},{"location":"lua/websocket/#send_pong","title":"send_pong","text":"<p><code>syntax: bytes, err = wb:send_pong()</code></p> <p><code>syntax: bytes, err = wb:send_pong(msg)</code></p> <p>Sends out a <code>pong</code> frame with an optional message specified by the <code>msg</code> argument. Returns the number of bytes that have actually been sent on the TCP level.</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p>"},{"location":"lua/websocket/#send_close","title":"send_close","text":"<p><code>syntax: bytes, err = wb:send_close()</code></p> <p><code>syntax: bytes, err = wb:send_close(code, msg)</code></p> <p>Sends out a <code>close</code> frame with an optional status code and a message.</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p> <p>For a list of valid status code, see the following document:</p> <p>http://tools.ietf.org/html/rfc6455#section-7.4.1</p> <p>Note that this method does not wait for a <code>close</code> frame from the remote end.</p>"},{"location":"lua/websocket/#send_frame","title":"send_frame","text":"<p><code>syntax: bytes, err = wb:send_frame(fin, opcode, payload)</code></p> <p>Sends out a raw websocket frame by specifying the <code>fin</code> field (boolean value), the opcode, and the payload.</p> <p>For a list of valid opcode, see</p> <p>http://tools.ietf.org/html/rfc6455#section-5.2</p> <p>In case of errors, returns <code>nil</code> and a string describing the error.</p> <p>To control the maximal payload length allowed, you can pass the <code>max_payload_len</code> option to the <code>new</code> constructor.</p> <p>To control whether to send masked frames, you can pass <code>true</code> to the <code>send_masked</code> option in the <code>new</code> constructor method. By default, unmasked frames are sent.</p>"},{"location":"lua/websocket/#recv_frame","title":"recv_frame","text":"<p><code>syntax: data, typ, err = wb:recv_frame()</code></p> <p>Receives a WebSocket frame from the wire.</p> <p>In case of an error, returns two <code>nil</code> values and a string describing the error.</p> <p>The second return value is always the frame type, which could be one of <code>continuation</code>, <code>text</code>, <code>binary</code>, <code>close</code>, <code>ping</code>, <code>pong</code>, or <code>nil</code> (for unknown types).</p> <p>For <code>close</code> frames, returns 3 values: the extra status message (which could be an empty string), the string \"close\", and a Lua number for the status code (if any). For possible closing status codes, see</p> <p>http://tools.ietf.org/html/rfc6455#section-7.4.1</p> <p>For other types of frames, just returns the payload and the type.</p> <p>For fragmented frames, the <code>err</code> return value is the Lua string \"again\".</p>"},{"location":"lua/websocket/#restywebsocketclient","title":"resty.websocket.client","text":"<p>To load this module, just do this</p> <pre><code>    local client = require \"resty.websocket.client\"\n</code></pre> <p>A simple example to demonstrate the usage:</p> <pre><code>    local client = require \"resty.websocket.client\"\n    local wb, err = client:new()\n    local uri = \"ws://127.0.0.1:\" .. ngx.var.server_port .. \"/s\"\n    local ok, err, res = wb:connect(uri)\n    if not ok then\n        ngx.say(\"failed to connect: \" .. err)\n        return\n    end\n\n    local data, typ, err = wb:recv_frame()\n    if not data then\n        ngx.say(\"failed to receive the frame: \", err)\n        return\n    end\n\n    ngx.say(\"received: \", data, \" (\", typ, \"): \", err)\n\n    local bytes, err = wb:send_text(\"copy: \" .. data)\n    if not bytes then\n        ngx.say(\"failed to send frame: \", err)\n        return\n    end\n\n    local bytes, err = wb:send_close()\n    if not bytes then\n        ngx.say(\"failed to send frame: \", err)\n        return\n    end\n</code></pre>"},{"location":"lua/websocket/#methods_1","title":"Methods","text":""},{"location":"lua/websocket/#clientnew","title":"client:new","text":"<p><code>syntax: wb, err = client:new()</code></p> <p><code>syntax: wb, err = client:new(opts)</code></p> <p>Instantiates a WebSocket client object.</p> <p>In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>An optional options table can be specified. The following options are as follows:</p> <ul> <li> <p><code>max_payload_len</code></p> <p>Specifies the maximal length of payload allowed when sending and receiving WebSocket frames. Defaults to <code>65536</code>. * <code>max_recv_len</code></p> <p>Specifies the maximal length of payload allowed when receiving WebSocket frames. Defaults to the value of <code>max_payload_len</code>. * <code>max_send_len</code></p> <p>Specifies the maximal length of payload allowed when sending WebSocket frames. Defaults to the value of <code>max_payload_len</code>. * <code>send_unmasked</code></p> <p>Specifies whether to send out an unmasked WebSocket frames. When it is <code>true</code>, unmasked frames are always sent. Default to <code>false</code>. RFC 6455 requires, however, that the client MUST send masked frames to the server, so never set this option to <code>true</code> unless you know what you are doing. * <code>timeout</code></p> <p>Specifies the default network timeout threshold in milliseconds. You can change this setting later via the <code>set_timeout</code> method call.</p> </li> </ul>"},{"location":"lua/websocket/#clientconnect","title":"client:connect","text":"<p><code>syntax: ok, err, res = wb:connect(\"ws://&lt;host&gt;:&lt;port&gt;/&lt;path&gt;\")</code></p> <p><code>syntax: ok, err, res = wb:connect(\"wss://&lt;host&gt;:&lt;port&gt;/&lt;path&gt;\")</code></p> <p><code>syntax: ok, err, res = wb:connect(\"ws://&lt;host&gt;:&lt;port&gt;/&lt;path&gt;\", options)</code></p> <p><code>syntax: ok, err, res = wb:connect(\"wss://&lt;host&gt;:&lt;port&gt;/&lt;path&gt;\", options)</code></p> <p>Connects to the remote WebSocket service port and performs the websocket handshake process on the client side.</p> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p> <p>The third return value of this method contains the raw, plain-text response (status line and headers) to the handshake request. This allows the caller to perform additional validation and/or extract the response headers. When the connection is reused and no handshake request is sent, the string <code>\"connection reused\"</code> is returned in lieu of the response.</p> <p>An optional Lua table can be specified as the last argument to this method to specify various connect options:</p> <ul> <li> <p><code>protocols</code></p> <p>Specifies all the subprotocols used for the current WebSocket session. It could be a Lua table holding all the subprotocol names or just a single Lua string. * <code>origin</code></p> <p>Specifies the value of the <code>Origin</code> request header. * <code>pool</code></p> <p>Specifies a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template <code>&lt;host&gt;:&lt;port&gt;</code>. * <code>pool_size</code></p> </li> </ul> <p>specify the size of the connection pool. If omitted and no   <code>backlog</code> option was provided, no pool will be created. If omitted   but <code>backlog</code> was provided, the pool will be created with a default   size equal to the value of the lua_socket_pool_size   directive.   The connection pool holds up to <code>pool_size</code> alive connections   ready to be reused by subsequent calls to connect, but   note that there is no upper limit to the total number of opened connections   outside of the pool. If you need to restrict the total number of opened   connections, specify the <code>backlog</code> option.   When the connection pool would exceed its size limit, the least recently used   (kept-alive) connection already in the pool will be closed to make room for   the current connection.   Note that the cosocket connection pool is per Nginx worker process rather   than per Nginx server instance, so the size limit specified here also applies   to every single Nginx worker process. Also note that the size of the connection   pool cannot be changed once it has been created.   This option was first introduced in the <code>v0.10.14</code> release.</p> <ul> <li><code>backlog</code></li> </ul> <p>if specified, this module will limit the total number of opened connections   for this pool. No more connections than <code>pool_size</code> can be opened   for this pool at any time. If the connection pool is full, subsequent   connect operations will be queued into a queue equal to this option's   value (the \"backlog\" queue).   If the number of queued connect operations is equal to <code>backlog</code>,   subsequent connect operations will fail and return <code>nil</code> plus the   error string <code>\"too many waiting connect operations\"</code>.   The queued connect operations will be resumed once the number of connections   in the pool is less than <code>pool_size</code>.   The queued connect operation will abort once they have been queued for more   than <code>connect_timeout</code>, controlled by   settimeouts, and will return <code>nil</code> plus   the error string <code>\"timeout\"</code>.   This option was first introduced in the <code>v0.10.14</code> release. * <code>ssl_verify</code></p> <pre><code>Specifies whether to perform SSL certificate verification during the\n</code></pre> <p>SSL handshake if the <code>wss://</code> scheme is used.</p> <ul> <li> <p><code>headers</code></p> <p>Specifies custom headers to be sent in the handshake request. The table is expected to contain strings in the format <code>{\"a-header: a header value\", \"another-header: another header value\"}</code>.</p> </li> <li> <p><code>client_cert</code></p> <p>Specifies a client certificate chain cdata object that will be used while TLS handshaking with remote server.  These objects can be created using  ngx.ssl.parse_pem_cert  function provided by lua-resty-core.  Note that specifying the <code>client_cert</code> option requires corresponding <code>client_priv_key</code> be provided too. See below.</p> </li> <li> <p><code>client_priv_key</code></p> <p>Specifies a private key corresponds to the <code>client_cert</code> option above.  These objects can be created using  ngx.ssl.parse_pem_priv_key  function provided by lua-resty-core.</p> </li> <li> <p><code>host</code></p> <p>Specifies the value of the <code>Host</code> header sent in the handshake request. If not provided, the <code>Host</code> header will be derived from the hostname/address and port in the connection URI.</p> </li> <li> <p><code>server_name</code></p> <p>Specifies the server name (SNI) to use when performing the TLS handshake with the server. If not provided, the <code>host</code> value or the <code>&lt;host/addr&gt;:&lt;port&gt;</code> from the connection URI will be used.</p> </li> <li> <p><code>key</code></p> <p>Specifies the value of the <code>Sec-WebSocket-Key</code> header in the handshake request. The value should be a base64-encoded, 16 byte string conforming to the client handshake requirements of the WebSocket RFC. If not provided, a key is randomly generated.</p> </li> </ul> <p>The SSL connection mode (<code>wss://</code>) requires at least <code>ngx_lua</code> 0.9.11 or OpenResty 1.7.4.1.</p>"},{"location":"lua/websocket/#clientclose","title":"client:close","text":"<p><code>syntax: ok, err = wb:close()</code></p> <p>Closes the current WebSocket connection. If no <code>close</code> frame is sent yet, then the <code>close</code> frame will be automatically sent.</p>"},{"location":"lua/websocket/#clientset_keepalive","title":"client:set_keepalive","text":"<p><code>syntax: ok, err = wb:set_keepalive(max_idle_timeout, pool_size)</code></p> <p>Puts the current WebSocket connection immediately into the <code>ngx_lua</code> cosocket connection pool.</p> <p>You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.</p> <p>In case of success, returns <code>1</code>. In case of errors, returns <code>nil</code> with a string describing the error.</p> <p>Only call this method in the place you would have called the <code>close</code> method instead. Calling this method will immediately turn the current WebSocket object into the <code>closed</code> state. Any subsequent operations other than <code>connect()</code> on the current objet will return the <code>closed</code> error.</p>"},{"location":"lua/websocket/#clientset_timeout","title":"client:set_timeout","text":"<p><code>syntax: wb:set_timeout(ms)</code></p> <p>Identical to the <code>set_timeout</code> method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_text","title":"client:send_text","text":"<p><code>syntax: bytes, err = wb:send_text(text)</code></p> <p>Identical to the send_text method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_binary","title":"client:send_binary","text":"<p><code>syntax: bytes, err = wb:send_binary(data)</code></p> <p>Identical to the send_binary method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_ping","title":"client:send_ping","text":"<p><code>syntax: bytes, err = wb:send_ping()</code></p> <p><code>syntax: bytes, err = wb:send_ping(msg)</code></p> <p>Identical to the send_ping method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_pong","title":"client:send_pong","text":"<p><code>syntax: bytes, err = wb:send_pong()</code></p> <p><code>syntax: bytes, err = wb:send_pong(msg)</code></p> <p>Identical to the send_pong method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_close","title":"client:send_close","text":"<p><code>syntax: bytes, err = wb:send_close()</code></p> <p><code>syntax: bytes, err = wb:send_close(code, msg)</code></p> <p>Identical to the send_close method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#clientsend_frame","title":"client:send_frame","text":"<p><code>syntax: bytes, err = wb:send_frame(fin, opcode, payload)</code></p> <p>Identical to the send_frame method of the <code>resty.websocket.server</code> objects.</p> <p>To control whether to send unmasked frames, you can pass <code>true</code> to the <code>send_unmasked</code> option in the <code>new</code> constructor method. By default, masked frames are sent.</p>"},{"location":"lua/websocket/#clientrecv_frame","title":"client:recv_frame","text":"<p><code>syntax: data, typ, err = wb:recv_frame()</code></p> <p>Identical to the recv_frame method of the <code>resty.websocket.server</code> objects.</p>"},{"location":"lua/websocket/#restywebsocketprotocol","title":"resty.websocket.protocol","text":"<p>To load this module, just do this</p> <pre><code>    local protocol = require \"resty.websocket.protocol\"\n</code></pre>"},{"location":"lua/websocket/#methods_2","title":"Methods","text":""},{"location":"lua/websocket/#protocolrecv_frame","title":"protocol.recv_frame","text":"<p><code>syntax: data, typ, err = protocol.recv_frame(socket, max_payload_len, force_masking)</code></p> <p>Receives a WebSocket frame from the wire.</p>"},{"location":"lua/websocket/#protocolbuild_frame","title":"protocol.build_frame","text":"<p><code>syntax: frame = protocol.build_frame(fin, opcode, payload_len, payload, masking)</code></p> <p>Builds a raw WebSocket frame.</p>"},{"location":"lua/websocket/#protocolsend_frame","title":"protocol.send_frame","text":"<p><code>syntax: bytes, err = protocol.send_frame(socket, fin, opcode, payload, max_payload_len, masking)</code></p> <p>Sends a raw WebSocket frame.</p>"},{"location":"lua/websocket/#automatic-error-logging","title":"Automatic Error Logging","text":"<p>By default the underlying ngx_lua module does error logging when socket errors happen. If you are already doing proper error handling in your own Lua code, then you are recommended to disable this automatic error logging by turning off ngx_lua's lua_socket_log_errors directive, that is,</p> <pre><code>    lua_socket_log_errors off;\n</code></pre>"},{"location":"lua/websocket/#limitations","title":"Limitations","text":"<ul> <li>This library cannot be used in code contexts like init_by_lua, set_by_lua, log_by_lua, and header_filter_by_lua where the ngx_lua cosocket API is not available.</li> <li>The <code>resty.websocket</code> object instance cannot be stored in a Lua variable at the Lua module level, because it will then be shared by all the concurrent requests handled by the same nginx  worker process (see http://wiki.nginx.org/HttpLuaModule#Data_Sharing_within_an_Nginx_Worker ) and result in bad race conditions when concurrent requests are trying to use the same <code>resty.websocket</code> instance. You should always initiate <code>resty.websocket</code> objects in function local variables or in the <code>ngx.ctx</code> table. These places all have their own data copies for each request.</li> </ul>"},{"location":"lua/websocket/#see-also","title":"See Also","text":"<ul> <li>Blog post WebSockets with OpenResty by Aapo Talvensaari.</li> <li>the ngx_lua module: http://wiki.nginx.org/HttpLuaModule</li> <li>the websocket protocol: http://tools.ietf.org/html/rfc6455</li> <li>the lua-resty-upload library</li> <li>the lua-resty-redis library</li> <li>the lua-resty-memcached library</li> <li>the lua-resty-mysql library</li> </ul>"},{"location":"lua/websocket/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-websocket.</p>"},{"location":"lua/woothee/","title":"woothee: Woothee Lua-nginx-module-lua implementation","text":""},{"location":"lua/woothee/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/woothee/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-woothee\n</code></pre>"},{"location":"lua/woothee/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-woothee\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-woothee v1.12.0  released on Oct 13 2021.</p> <p></p>"},{"location":"lua/woothee/#woothee-lua-resty","title":"Woothee lua resty","text":"<p>The Lua-Openresty implementation of Project Woothee, which is multi-language user-agent strings parsers.</p> <p>https://github.com/woothee/woothee</p>"},{"location":"lua/woothee/#synopsis","title":"Synopsis","text":""},{"location":"lua/woothee/#basic-usage","title":"Basic Usage","text":"<pre><code>server {\n    location /test {\n        content_by_lua_block {\n            local woothee = require \"resty.woothee\"\n\n            -- parse\n            local r = woothee.parse(ngx.var.http_user_agent)\n            --  =&gt; {\"name\": \"xxx\", \"category\": \"xxx\", \"os\": \"xxx\", \"version\": \"xxx\", \"vendor\": \"xxx\"}\n\n            -- crawler?\n            local crawler = woothee.is_crawler(ngx.var.http_user_agent)\n            --  =&gt; true\n\n            ngx.header.content_type = \"text/plain\"\n            ngx.say(r.name)\n        }\n    }\n}\n</code></pre>"},{"location":"lua/woothee/#include-nginx-log","title":"Include Nginx Log","text":"<pre><code>log_format woothee_format\n                  '$remote_addr - $remote_user [$time_local] '\n                  '\"$request\" $status $body_bytes_sent '\n                  '\"$http_referer\" \"$http_user_agent\" '\n                  '\"$x_wt_name\" \"$x_wt_category\" \"$x_wt_os\" \"$x_wt_version\" \"$x_wt_vendor\" \"$x_wt_os_version\"'\n                  ;\n\nserver {\n\n    access_log /var/log/nginx/nginx-access-woothee.log woothee_format;\n\n    # set nginx valiables\n    set $x_wt_name       '-';\n    set $x_wt_category   '-';\n    set $x_wt_os         '-';\n    set $x_wt_version    '-';\n    set $x_wt_vendor     '-';\n    set $x_wt_os_version '-';\n\n    location /test {\n        content_by_lua_block {\n            local woothee = require \"resty.woothee\"\n            local r = woothee.parse(ngx.var.http_user_agent)\n            -- set nginx valiables\n            ngx.var.x_wt_name       = r.name\n            ngx.var.x_wt_category   = r.category\n            ngx.var.x_wt_os         = r.os\n            ngx.var.x_wt_version    = r.version\n            ngx.var.x_wt_vendor     = r.vendor\n            ngx.var.x_wt_os_version = r.os_version\n\n            ngx.header.content_type = \"text/plain\"\n            ngx.say(r.name)\n        }\n    }\n}\n</code></pre>"},{"location":"lua/woothee/#forward-backend-server","title":"Forward Backend Server","text":"<pre><code>server {\n\n    # set nginx valiables\n    set $x_wt_name       '-';\n    set $x_wt_category   '-';\n    set $x_wt_os         '-';\n    set $x_wt_version    '-';\n    set $x_wt_vendor     '-';\n    set $x_wt_os_version '-';\n\n    location /test {\n        rewrite_by_lua_block {\n            local woothee = require \"resty.woothee\"\n            local r = woothee.parse(ngx.var.http_user_agent)\n            -- set nginx valiables\n            ngx.var.x_wt_name       = r.name\n            ngx.var.x_wt_category   = r.category\n            ngx.var.x_wt_os         = r.os\n            ngx.var.x_wt_version    = r.version\n            ngx.var.x_wt_vendor     = r.vendor\n            ngx.var.x_wt_os_version = r.os_version\n        }\n\n        proxy_pass http://backend-server/;\n        # proxy set header\n        proxy_set_header X-WT-NAME       $x_wt_name;\n        proxy_set_header X-WT-CATEGORY   $x_wt_category;\n        proxy_set_header X-WT-OS         $x_wt_os;\n        proxy_set_header X-WT-VERSION    $x_wt_version;\n        proxy_set_header X-WT-VENDOR     $x_wt_vendor;\n        proxy_set_header X-WT-OS-VERSION $x_wt_os_version;\n    }\n}\n</code></pre>"},{"location":"lua/woothee/#for-developer-on-docker","title":"For Developer (on Docker)","text":""},{"location":"lua/woothee/#docker-run-run-test","title":"docker run &amp; run test","text":"<pre><code>make local-all\n</code></pre>"},{"location":"lua/woothee/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-woothee.</p>"},{"location":"lua/worker-events/","title":"worker-events: Cross Worker Events for NGINX in Pure Lua","text":""},{"location":"lua/worker-events/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/worker-events/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-worker-events\n</code></pre>"},{"location":"lua/worker-events/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-worker-events\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-worker-events v2.0.1  released on Jun 28 2021.</p>"},{"location":"lua/worker-events/#lua-resty-worker-events","title":"lua-resty-worker-events","text":"<p>Inter process events for Nginx worker processes</p>"},{"location":"lua/worker-events/#status","title":"Status","text":"<p>This library is production ready.</p>"},{"location":"lua/worker-events/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    # the size depends on the number of event to handle:\n    lua_shared_dict process_events 1m;\n\n    init_worker_by_lua_block {\n        local ev = require \"resty.worker.events\"\n\n        local handler = function(data, event, source, pid)\n            print(\"received event; source=\",source,\n                  \", event=\",event,\n                  \", data=\", tostring(data),\n                  \", from process \",pid)\n        end\n\n        ev.register(handler)\n\n        local ok, err = ev.configure {\n            shm = \"process_events\", -- defined by \"lua_shared_dict\"\n            timeout = 2,            -- life time of unique event data in shm\n            interval = 1,           -- poll interval (seconds)\n\n            wait_interval = 0.010,  -- wait before retry fetching event data\n            wait_max = 0.5,         -- max wait time before discarding event\n            shm_retries = 999,      -- retries for shm fragmentation (no memory)\n        }\n        if not ok then\n            ngx.log(ngx.ERR, \"failed to start event system: \", err)\n            return\n        end\n    }\n\n    server {\n        ...\n\n        # example for polling:\n        location = /some/path {\n\n            default_type text/plain;\n            content_by_lua_block {\n                -- manually call `poll` to stay up to date, can be used instead,\n                -- or together with the timer interval. Polling is efficient,\n                -- so if staying up-to-date is important, this is preferred.\n                require(\"resty.worker.events\").poll()\n\n                -- do regular stuff here\n\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lua/worker-events/#description","title":"Description","text":"<p>This module provides a way to send events to the other worker processes in an Nginx server. Communication is through a shared memory zone where event data will be stored.</p> <p>The order of events in all workers is guaranteed to be the same.</p> <p>The worker process will setup a timer to check for events in the background. The module follows a singleton pattern and hence runs once per worker. If staying up-to-date is important though, the interval can be set to a lesser frequency and a call to poll upon each request received makes sure everything is handled as soon as possible.</p> <p>The design allows for 3 usecases;</p> <ol> <li>broadcast an event to all workers processes, see post. In this case the order of the events is guaranteed to be the same in all worker processes. Example; a healthcheck running in one worker, but informing all workers of a failed upstream node.</li> <li>broadcast an event to the local worker only, see post_local.</li> <li>coalesce external events to a single action. Example; all workers watch external events indicating an in-memory cache needs to be refreshed. When receiving it they all post it with a unique event hash (all workers generate the same hash), see <code>unique</code> parameter of post. Now only 1 worker will receive the event only once, so only one worker will hit the upstream database to refresh the in-memory data.</li> </ol> <p>This module itself will fire two events with <code>source=\"resty-worker-events\"</code>;  * <code>event=\"started\"</code> when the module is first configured (note: the event handler must be    registered before calling configure to be able to catch the event)  * <code>event=\"stopping\"</code> when the worker process exits (based on a timer <code>premature</code> setting)</p> <p>See event_list for using events without hardcoded magic values/strings.</p>"},{"location":"lua/worker-events/#troubleshooting","title":"Troubleshooting","text":"<p>To properly size the shm, it is important to understand how it is being used. Event data is stored in the shm to pass it to the other workers. As such there are 2 types of entries in the shm:</p> <ol> <li>events that are to be executed by only a single worker (see the    <code>unique</code> parameter of the <code>post</code> method). These entries get a <code>ttl</code> in the    shm and will hence expire.</li> <li>all other events (except local events which do not use the SHM). In these    cases there is no <code>ttl</code> set.</li> </ol> <p>The result of the above is that the SHM will always be full! so that is not a metric to investigate at.</p> <p>How to prevent problems:</p> <ul> <li>the SHM size must at least be a multiple of the maximum payload expected. It   must be able to cater for all the events that might be send within one   <code>interval</code> (see <code>configure</code>).</li> <li><code>no memory</code> errors cannot be resolved by making the SHM bigger. The only way   to resolve those is by increasing the <code>shm_retries</code> option passed to   <code>configure</code> (which already has a high default).   This is because the error is due to fragmentation and not a lack of memory.</li> <li> <p>the <code>waiting for event data timed out</code> error happens if event data gets   evicted before all the workers got to deal with it. This can happen if   there is a burst of (large-payload) events. To resolve these:</p> <ul> <li>try to avoid big event payloads</li> <li>use a smaller <code>interval</code>, so workers check for (and deal with) events   more frequently (see <code>interval</code> option as passed to <code>configure</code>)</li> <li>increase the SHM size, such that it can hold all the event data that   might be send within 1 interval.</li> </ul> </li> </ul>"},{"location":"lua/worker-events/#methods","title":"Methods","text":""},{"location":"lua/worker-events/#configure","title":"configure","text":"<p><code>syntax: success, err = events.configure(opts)</code></p> <p>Will initialize the event listener. This should typically be called from the <code>init_by_lua</code> handler, because it will make sure all workers start with the first event. In case of a reload of the system (starting new and stopping old workers) past events will not be replayed. And because the order in which workers reload cannot be guaranteed, also the event start cannot be guaranteed. So if some sort of state is derived from the events you have to manage that state separately.</p> <p>The <code>opts</code> parameter is a Lua table with named options:</p> <ul> <li><code>shm</code>: (required) name of the shared memory to use. Event data will not expire, so   the module relies on the shm lru mechanism to evict old events from the shm. As such   the shm should probably not be used for other purposes.</li> <li><code>shm_retries</code>: (optional) number of retries when the shm returns \"no memory\" on posting   an event, default 999. Each time there is an insertion attempt and no memory is available   (either no space is available or the memory is available but fragmented), \"up to tens\"   of old entries are evicted. After that, if there's still no memory available, the   \"no memory\" error is returned. Retrying the insertion triggers the eviction phase   several times, increasing the memory available as well as the probability of finding a   large enough contiguous memory block available for the new event data.</li> <li><code>interval</code>: (optional) interval to poll for events (in seconds), default 1. Set to 0 to   disable polling.</li> <li><code>wait_interval</code>: (optional) interval between two tries when a new eventid is found, but the   data is not available yet (due to asynchronous behaviour of the worker processes)</li> <li><code>wait_max</code>: (optional) max time to wait for data when event id is found, before discarding   the event. This is a fail-safe setting in case something went wrong.</li> <li><code>timeout</code>: (optional) timeout of unique event data stored in shm (in seconds), default 2.   See the <code>unique</code> parameter of the post method.</li> </ul> <p>The return value will be <code>true</code>, or <code>nil</code> and an error message.</p> <p>This method can be called repeatedly to update the settings, except for the <code>shm</code> value which cannot be changed after the initial configuration.</p> <p>NOTE: the <code>wait_interval</code> is executed using the <code>ngx.sleep</code> function. In contexts where this function is not available (eg. <code>init_worker</code>) it will execute a busy-wait to execute the delay.</p>"},{"location":"lua/worker-events/#configured","title":"configured","text":"<p><code>syntax: is_already_configured = events.configured()</code></p> <p>The events module runs as a singelton per workerprocess. The <code>configured</code> function allows to check whether it is already up and running. A check before starting any dependencies is recommended; <pre><code>local events = require \"resty.worker.events\"\n\nlocal initialization_of_my_module = function()\n    assert(events.configured(), \"Please configure the 'lua-resty-worker-events' \"..\n           \"module before using my_module\")\n\n    -- do initialization here\nend\n</code></pre></p>"},{"location":"lua/worker-events/#event_list","title":"event_list","text":"<p><code>syntax: _M.events = events.event_list(sourcename, event1, event2, ...)</code></p> <p>Utility function to generate event lists and prevent typos in magic strings. Accessing a non-existing event on the returned table will result in an 'unknown event error'. The first parameter <code>sourcename</code> is a unique name that identifies the event source, which will be available as field <code>_source</code>. All following parameters are the named events generated by the event source.</p> <p>Example usage; <pre><code>local ev = require \"resty.worker.events\"\n\n-- Event source example\n\nlocal events = ev.event_list(\n        \"my-module-event-source\", -- available as _M.events._source\n        \"started\",                -- available as _M.events.started\n        \"event2\"                  -- available as _M.events.event2\n    )\n\nlocal raise_event = function(event, data)\n    return ev.post(events._source, event, data)\nend\n\n-- Post my own 'started' event\nraise_event(events.started, nil) -- nil for clarity, no eventdata is passed\n\n-- define my module table\nlocal _M = {\n  events = events   -- export events table\n\n  -- implementation goes here\n}\nreturn _M\n\n\n\n-- Event client example;\nlocal mymod = require(\"some_module\")  -- module with an `events` table\n\n-- define a callback and use source modules events table\nlocal my_callback = function(data, event, source, pid)\n    if event == mymod.events.started then  -- 'started' is the event name\n\n        -- started event from the resty-worker-events module\n\n    elseif event == mymod.events.stoppping then  -- 'stopping' is the event name\n\n        -- the above will throw an error because of the typo in `stoppping`\n\n    end\nend\n\nev.register(my_callback, mymod.events._source)\n</code></pre></p>"},{"location":"lua/worker-events/#poll","title":"poll","text":"<p><code>syntax: success, err = events.poll()</code></p> <p>Will poll for new events and handle them all (call the registered callbacks). The implementation is efficient, it will only check a single shared memory value and return immediately if no new events are available.</p> <p>The return value will be <code>\"done\"</code> when it handled all events, <code>\"recursive\"</code> if it was already in a polling-loop, or <code>nil + error</code> if something went wrong. The <code>\"recursive\"</code> result simply means that the event was successfully posted, but not handled yet, due to other events ahead of it that need to be handled first.</p>"},{"location":"lua/worker-events/#post","title":"post","text":"<p><code>syntax: success, err = events.post(source, event, data, unique)</code></p> <p>Will post a new event. <code>source</code> and <code>event</code> are both strings. <code>data</code> can be anything (including <code>nil</code>) as long as it is (de)serializable by the cjson module.</p> <p>If the <code>unique</code> parameter is provided then only one worker will execute the event, the other workers will ignore it. Also any follow up events with the same <code>unique</code> value will be ignored (for the <code>timeout</code> period specified to configure). The process executing the event will not necessarily be the process posting the event.</p> <p>The return value will be <code>true</code> when the event was successfully posted or <code>nil + error</code> in case of failure.</p> <p>Note: the worker process sending the event, will also receive the event! So if the eventsource will also act upon the event, it should not do so from the event posting code, but only when receiving it.</p>"},{"location":"lua/worker-events/#post_local","title":"post_local","text":"<p><code>syntax: success, err = events.post_local(source, event, data)</code></p> <p>The same as post except that the event will be local to the worker process, it will not be broadcasted to other workers. With this method, the <code>data</code> element will not be jsonified.</p> <p>The return value will be <code>true</code> when the event was successfully posted or <code>nil + error</code> in case of failure.</p>"},{"location":"lua/worker-events/#register","title":"register","text":"<p><code>syntax: events.register(callback, source, event1, event2, ...)</code></p> <p>Will register a callback function to receive events. If <code>source</code> and <code>event</code> are omitted, then the callback will be executed on every event, if <code>source</code> is provided, then only events with a matching source will be passed. If (one or more) event name is given, then only when both <code>source</code> and <code>event</code> match the callback is invoked.</p> <p>The callback should have the following signature;</p> <p><code>syntax: callback = function(data, event, source, pid)</code></p> <p>The parameters will be the same as the ones provided to post, except for the extra value <code>pid</code> which will be the pid of the originating worker process, or <code>nil</code> if it was a local event only. Any return value from <code>callback</code> will be discarded. Note: <code>data</code> may be a reference type of data (eg. a Lua <code>table</code>  type). The same value is passed to all callbacks, so do not change the value in your handler, unless you know what you are doing!</p> <p>The return value of <code>register</code> will be <code>true</code>, or it will throw an error if <code>callback</code> is not a function value.</p> <p>WARNING: event handlers must return quickly. If a handler takes more time than the configured <code>timeout</code> value, events will be dropped!</p> <p>Note: to receive the process own <code>started</code> event, the handler must be registered before calling configure</p>"},{"location":"lua/worker-events/#register_weak","title":"register_weak","text":"<p><code>syntax: events.register_weak(callback, source, event1, event2, ...)</code></p> <p>This function is identical to <code>register</code>, with the exception that the module will only hold weak references to the <code>callback</code> function.</p>"},{"location":"lua/worker-events/#unregister","title":"unregister","text":"<p><code>syntax: events.unregister(callback, source, event1, event2, ...)</code></p> <p>Will unregister the callback function and prevent it from receiving further events. The parameters work exactly the same as with register.</p> <p>The return value will be <code>true</code> if it was removed, <code>false</code> if it was not in the handlers list, or it will throw an error if <code>callback</code> is not a function value.</p>"},{"location":"lua/worker-events/#history","title":"History","text":""},{"location":"lua/worker-events/#releasing-new-versions","title":"Releasing new versions","text":"<ul> <li>make sure changelog below is up-to-date</li> <li>update version number in the code</li> <li>create a new rockspec in <code>./rockspecs</code></li> <li>commit with message <code>release x.x.x</code></li> <li>tag the commit as <code>x.x.x</code></li> <li>push commit and tags</li> <li>upload to luarocks</li> </ul>"},{"location":"lua/worker-events/#201-28-june-2021","title":"2.0.1, 28-June-2021","text":"<ul> <li>fix: possible deadlock in the 'init phase</li> </ul>"},{"location":"lua/worker-events/#200-16-september-2020","title":"2.0.0, 16-September-2020","text":"<ul> <li>BREAKING: the <code>post</code> function does not call <code>poll</code> anymore, making all events   asynchronous. When an immediate treatment to an event is needed an explicit   call to <code>poll</code> must be done.</li> <li>BREAKING: the <code>post_local</code> function does not immediately execute the   event anymore, making all local events asynchronous. When an immediate   treatment to an event is needed an explicit call to <code>poll</code> must be done.</li> <li>fix: prevent spinning at 100% CPU when during a reload the event-shm is   cleared</li> <li>fix: improved logging in case of failure to write to shm (add payload size   for troubleshooting purposes)</li> <li>fix: do not log the payload anymore, since it might expose sensitive data   through the logs</li> <li>change: updated <code>shm_retries</code> default to 999</li> <li>change: changed timer loop to a sleep-loop (performance)</li> <li>fix: when re-configuring make sure callbacks table is initialized</li> </ul>"},{"location":"lua/worker-events/#110-23-dec-2020-maintenance-release","title":"1.1.0, 23-Dec-2020 (maintenance release)","text":"<ul> <li>feature: the polling loop now runs forever, sleeping for 0.5 seconds between   runs, avoiding to create new timers on every step.</li> </ul>"},{"location":"lua/worker-events/#100-18-july-2019","title":"1.0.0, 18-July-2019","text":"<ul> <li>BREAKING: the return values from <code>poll</code> (and hence also <code>post</code> and <code>post_local</code>)   changed to be more lua-ish, to be truthy when all is well.</li> <li>feature: new option <code>shm_retries</code> to fix \"no memory\" errors caused by memory   fragmentation in the shm when posting events.</li> <li>fix: fixed two typos in variable names (edge cases)</li> </ul>"},{"location":"lua/worker-events/#033-8-may-2018","title":"0.3.3, 8-May-2018","text":"<ul> <li>fix: timeouts in init phases, by removing timeout setting, see issue #9</li> </ul>"},{"location":"lua/worker-events/#032-11-apr-2018","title":"0.3.2, 11-Apr-2018","text":"<ul> <li>change: add a stacktrace to handler errors</li> <li>fix: failing error handler if value was non-serializable, see issue #5</li> <li>fix: fix a test for the weak handlers</li> </ul>"},{"location":"lua/worker-events/#see-also","title":"See Also","text":"<ul> <li>OpenResty: http://openresty.org</li> </ul>"},{"location":"lua/worker-events/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-worker-events.</p>"},{"location":"lua/xxhash/","title":"xxhash: LuaJIT FFI-bindings to xxHash, an Extremely fast non-cryptographic hash algorithm","text":""},{"location":"lua/xxhash/#installation","title":"Installation","text":"<p>If you haven't set up RPM repository subscription, sign up. Then you can proceed with the following  steps.</p>"},{"location":"lua/xxhash/#centosrhel-7-or-amazon-linux-2","title":"CentOS/RHEL 7 or Amazon Linux 2","text":"<pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install lua-resty-xxhash\n</code></pre>"},{"location":"lua/xxhash/#centosrhel-8-fedora-linux-amazon-linux-2023","title":"CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install lua5.1-resty-xxhash\n</code></pre> <p>To use this Lua library with NGINX, ensure that nginx-module-lua is installed.</p> <p>This document describes lua-resty-xxhash v1.0  released on Dec 03 2015.</p> <p><code>lua-resty-xxhash</code> contains a LuaJIT FFI-bindings to xxHash, an Extremely fast non-cryptographic hash algorithm.</p>"},{"location":"lua/xxhash/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub repository for  nginx-module-xxhash.</p>"},{"location":"modules/accept-language/","title":"accept-language: NGINX Accept-Language module","text":""},{"location":"modules/accept-language/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-accept-language\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-accept-language\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_accept_language_module.so;\n</code></pre> <p>This document describes nginx-module-accept-language v1.0.0  released on Oct 30 2018.</p> <p>This module parses the <code>Accept-Language</code> header and gives the most suitable locale for the user from a list of supported locales from your website.</p>"},{"location":"modules/accept-language/#syntax","title":"Syntax","text":"<pre><code>set_from_accept_language $lang en ja pl;\n</code></pre> <ul> <li><code>$lang</code> is the variable in which to store the locale</li> <li><code>en ja pl</code> are the locales supported by your website</li> </ul> <p>If none of the locales from <code>Accept-Language</code> is available on your website, it sets the variable to the first locale of your website's supported locales (in this case, <code>en</code>).</p>"},{"location":"modules/accept-language/#caveat","title":"Caveat","text":"<p>It currently assumes that the <code>Accept-Language</code> is sorted by quality values (from my tests it's the case for safari, firefox, opera and ie) and discards q (see http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html).  In the situation where I'm using the module, this assumption works... but buyer beware :-)</p>"},{"location":"modules/accept-language/#example-configuration","title":"Example configuration","text":"<p>If you have different subdomains for each languages</p> <pre><code>server {\n    listen 80;\n    server_name your_domain.com;\n    set_from_accept_language $lang en ja zh;\n    rewrite ^/(.*) http://$lang.your_domain.com redirect;\n}\n</code></pre> <p>Or you could do something like this, redirecting people coming to '/' to /en (or /pt):</p> <pre><code>location / {\n    set_from_accept_language $lang pt en;\n     if ( $request_uri ~ ^/$ ) {\n       rewrite ^/$ /$lang redirect;\n       break;\n     }\n}\n</code></pre>"},{"location":"modules/accept-language/#why-did-i-create-it","title":"Why did I create it?","text":"<p>I'm using page caching with merb on a multi-lingual website and I needed a way to serve the correct language page from the cache I'll soon put an example on http://gom-jabbar.org</p>"},{"location":"modules/accept-language/#acknowledgement","title":"Acknowledgement","text":"<p>Thanks to Evan Miller for his guide on writing nginx modules.</p>"},{"location":"modules/accept-language/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-accept-language.</p>"},{"location":"modules/acme/","title":"acme: Automatic certificate management (ACMEv2) module for NGINX","text":""},{"location":"modules/acme/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-acme\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-acme\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_acme_module.so;\n</code></pre> <p>This document describes nginx-module-acme v0.3.1  released on Dec 08 2025.</p> <p> </p>"},{"location":"modules/acme/#nginx-acme","title":"nginx-acme","text":"<p>nginx-acme is an NGINX module with the implementation of the automatic certificate management (ACMEv2) protocol.</p> <p>The module implements following specifications:</p> <ul> <li>RFC8555 (Automatic Certificate Management Environment) with limitations:<ul> <li>Only HTTP-01 challenge type is supported</li> </ul> </li> <li>RFC8737 (ACME TLS Application-Layer Protocol Negotiation (ALPN) Challenge   Extension)</li> <li>RFC8738 (ACME IP Identifier Validation Extension)</li> <li>draft-ietf-acme-profiles (ACME Profiles Extension, version 00)</li> </ul>"},{"location":"modules/acme/#getting-started","title":"Getting Started","text":""},{"location":"modules/acme/#checkout-configure-and-build-nginx-at-nginx","title":"checkout, configure and build NGINX at ../nginx","text":"<p>cd nginx-acme export NGINX_BUILD_DIR=$(realpath ../nginx/objs) cargo build --release <pre><code>The result will be located at `target/release/libnginx_acme.so`.\n\nAnother way is to use the provided config script:\n\n```sh\n## in the NGINX source directory\nauto/configure \\\n    --with-compat \\\n    --with-http_ssl_module \\\n    --add-[dynamic-]module=/path/to/nginx-acme\n</code></pre></p> <p>The result will be located at <code>objs/ngx_http_acme_module.so</code>.</p> <p>Currently this method produces a slightly larger library, as we don't instruct the linker to perform LTO and remove unused code.</p>"},{"location":"modules/acme/#testing","title":"Testing","text":"<p>The repository contains an integration test suite based on the nginx-tests. The following command will build the module and run the tests:</p> <pre><code>## Path to the nginx source checkout, defaults to ../nginx if not specified.\nexport NGINX_SOURCE_DIR=$(realpath ../nginx)\n## Path to the nginx-tests checkout; defaults to ../nginx/tests if not specified.\nexport NGINX_TESTS_DIR=$(realpath ../nginx-tests)\n\nmake test\n</code></pre> <p>Most of the tests require pebble test server binary in the path, or in a location specified via <code>TEST_NGINX_PEBBLE_BINARY</code> environment variable.</p>"},{"location":"modules/acme/#how-to-use","title":"How to Use","text":"<p>Add the module to the NGINX configuration and configure as described below. Note that this module requires a resolver configuration in the <code>http</code> block.</p>"},{"location":"modules/acme/#example-configuration","title":"Example Configuration","text":"<pre><code>resolver 127.0.0.1:53;\n\nacme_issuer example {\n    uri         https://acme.example.com/directory;\n    # contact     admin@example.test;\n    state_path  /var/cache/nginx/acme-example;\n    accept_terms_of_service;\n}\n\nacme_shared_zone zone=ngx_acme_shared:1M;\n\nserver {\n    listen 443 ssl;\n    server_name  .example.test\n                 192.0.2.1      # not supported by some ACME servers\n                 2001:db8::1    # not supported by some ACME servers\n                 ;\n\n    acme_certificate example;\n\n    ssl_certificate       $acme_certificate;\n    ssl_certificate_key   $acme_certificate_key;\n\n    # do not parse the certificate on each request\n    ssl_certificate_cache max=2;\n}\n\nserver {\n    # listener on port 80 is required to process ACME HTTP-01 challenges\n    listen 80;\n\n    location / {\n        return 404;\n    }\n}\n</code></pre>"},{"location":"modules/acme/#directives","title":"Directives","text":"<p>[!IMPORTANT] The reference below reflects the current development version. See ngx_http_acme_module documentation on nginx.org for the latest released version.</p>"},{"location":"modules/acme/#acme_issuer","title":"acme_issuer","text":"<p>Syntax: <code>acme_issuer</code> <code>name</code> { ... }</p> <p>Default: -</p> <p>Context: http</p> <p>Defines an ACME certificate issuer object.</p>"},{"location":"modules/acme/#uri","title":"uri","text":"<p>Syntax: <code>uri</code> <code>uri</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>The directory URL of the ACME server. This directive is mandatory.</p>"},{"location":"modules/acme/#account_key","title":"account_key","text":"<p>Syntax: <code>account_key</code> <code>alg</code>[:<code>size</code>] | <code>file</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>The account's private key used for request authentication.</p> <p>Accepted values:</p> <ul> <li><code>ecdsa</code>:<code>256</code>/<code>384</code>/<code>521</code> for <code>ES256</code>, <code>ES384</code> or <code>ES512</code> JSON Web Signature   algorithms</li> <li><code>rsa</code>:<code>2048</code>/<code>3072</code>/<code>4096</code> for <code>RS256</code>.</li> <li>File path for an existing key, using one of the algorithms above.</li> </ul> <p>The generated account keys are preserved across reloads, but will be lost on restart unless state_path is configured.</p>"},{"location":"modules/acme/#challenge","title":"challenge","text":"<p>Syntax: <code>challenge</code> <code>type</code></p> <p>Default: http-01</p> <p>Context: acme_issuer</p> <p>This directive appeared in version 0.2.0.</p> <p>Specifies the ACME challenge type to be used for the issuer.</p> <p>Accepted values:</p> <ul> <li><code>http-01</code> (<code>http</code>)</li> <li><code>tls-alpn-01</code> (<code>tls-alpn</code>)</li> </ul> <p>ACME challenges are versioned. If an unversioned name is specified, the module automatically selects the latest implemented version.</p>"},{"location":"modules/acme/#contact","title":"contact","text":"<p>Syntax: <code>contact</code> <code>URL</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>Sets an array of URLs that the ACME server can use to contact the client regarding account issues. The <code>mailto:</code> scheme will be used unless specified explicitly.</p>"},{"location":"modules/acme/#external_account_key","title":"external_account_key","text":"<p>Syntax: <code>external_account_key</code> <code>kid</code> <code>file</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>This directive appeared in version 0.2.0.</p> <p>Specifies a key identifier <code>kid</code> and a <code>file</code> with the MAC key for external account authorization.</p> <p>The value <code>data</code>:<code>key</code> can be specified instead of the <code>file</code>, which loads a key directly from the configuration without using intermediate files.</p> <p>In both cases, the key is expected to be encoded in base64url.</p>"},{"location":"modules/acme/#preferred_chain","title":"preferred_chain","text":"<p>Syntax: <code>preferred_chain</code> <code>name</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>This directive appeared in version 0.3.0.</p> <p>Specifies the preferred certificate chain.</p> <p>If the ACME server offers multiple certificate chains, prefer the chain with the topmost certificate issued from the Subject Common Name <code>name</code>. If there are no matches, the default chain will be used.</p>"},{"location":"modules/acme/#profile","title":"profile","text":"<p>Syntax: <code>profile</code> <code>name</code> [<code>require</code>]</p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>This directive appeared in version 0.3.0.</p> <p>Requests the certificate profile <code>name</code> from the ACME server.</p> <p>The <code>require</code> parameter will cause certificate renewals to fail if the server does not support the specified profile.</p>"},{"location":"modules/acme/#ssl_trusted_certificate","title":"ssl_trusted_certificate","text":"<p>Syntax: <code>ssl_trusted_certificate</code> <code>file</code></p> <p>Default: system CA bundle</p> <p>Context: acme_issuer</p> <p>Specifies a <code>file</code> with trusted CA certificates in the PEM format used to verify the certificate of the ACME server.</p>"},{"location":"modules/acme/#ssl_verify","title":"ssl_verify","text":"<p>Syntax: <code>ssl_verify</code> <code>on</code> | <code>off</code></p> <p>Default: on</p> <p>Context: acme_issuer</p> <p>Enables or disables verification of the ACME server certificate.</p>"},{"location":"modules/acme/#state_path","title":"state_path","text":"<p>Syntax: <code>state_path</code> <code>path</code> | <code>off</code></p> <p>Default: acme_&lt;name&gt;</p> <p>Context: acme_issuer</p> <p>Defines a directory for storing the module data that can be persisted across restarts. This can improve the load time by skipping some requests on startup, and avoid hitting request rate limits on the ACME server.</p> <p>The directory contains sensitive content, such as the account key, issued certificates, and private keys.</p> <p>The <code>off</code> parameter (0.2.0) disables storing the account information and issued certificates on disk.</p> <p>Prior to version 0.2.0, the state directory was not created by default.</p>"},{"location":"modules/acme/#accept_terms_of_service","title":"accept_terms_of_service","text":"<p>Syntax: <code>accept_terms_of_service</code></p> <p>Default: -</p> <p>Context: acme_issuer</p> <p>Agrees to the terms of service under which the ACME server will be used. Some servers require accepting the terms of service before account registration. The terms are usually available on the ACME server's website, and the URL will be printed to the error log if necessary.</p>"},{"location":"modules/acme/#acme_shared_zone","title":"acme_shared_zone","text":"<p>Syntax: <code>acme_shared_zone</code> <code>zone</code>=<code>name</code>:<code>size</code></p> <p>Default: zone=ngx_acme_shared:256k</p> <p>Context: http</p> <p>Allows increasing the size of in-memory storage of the module. The shared memory zone will be used to store the issued certificates, keys and challenge data for all the configured certificate issuers.</p> <p>The default zone size is sufficient to hold approximately 50 ECDSA prime256v1 keys or 35 RSA 2048 keys.</p>"},{"location":"modules/acme/#acme_certificate","title":"acme_certificate","text":"<p>Syntax: <code>acme_certificate</code> <code>issuer</code> [<code>identifier</code> ...] [<code>key</code>=<code>alg</code>[:<code>size</code>]]</p> <p>Default: -</p> <p>Context: server</p> <p>Defines a certificate with the list of <code>identifiers</code> requested from issuer <code>issuer</code>.</p> <p>The explicit list of identifiers can be omitted. In this case, the identifiers will be taken from the server_name directive in the same server block. Not all values accepted in the server_name are valid certificate identifiers: regular expressions and wildcards are not supported.</p> <p>The <code>key</code> parameter sets the type of a generated private key. Supported key algorithms and sizes: <code>ecdsa:256</code> (default), <code>ecdsa:384</code>, <code>ecdsa:521</code>, <code>rsa:2048</code>, <code>rsa:3072</code>, <code>rsa:4096</code>.</p>"},{"location":"modules/acme/#embedded-variables","title":"Embedded Variables","text":"<p>The <code>ngx_http_acme_module</code> module supports embedded variables, valid in the server block with the acme_certificate directive:</p>"},{"location":"modules/acme/#acme_certificate_1","title":"<code>$acme_certificate</code>","text":"<p>SSL certificate that can be passed to the ssl_certificate.</p>"},{"location":"modules/acme/#acme_certificate_key","title":"<code>$acme_certificate_key</code>","text":"<p>SSL certificate private key that can be passed to the ssl_certificate_key.</p>"},{"location":"modules/acme/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-acme.</p>"},{"location":"modules/ajp/","title":"ajp: Support AJP protocol proxy with NGINX","text":""},{"location":"modules/ajp/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ajp\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ajp\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_ajp_module.so;\n</code></pre> <p>This document describes nginx-module-ajp v0.3.3  released on Dec 19 2023.</p> <p>nginx_ajp_module - support AJP protocol proxy with Nginx</p>"},{"location":"modules/ajp/#synopsis","title":"Synopsis","text":"<pre><code>    http {\n            upstream tomcats {\n                    server 127.0.0.1:8009;\n                    keepalive 10;\n            }\n\n            server {\n\n                    listen 80;\n\n                    location / {\n                            ajp_keep_conn on;\n                            ajp_pass tomcats;\n                    }\n            }\n    }\n</code></pre>"},{"location":"modules/ajp/#description","title":"Description","text":"<p>With this module, Nginx can connect to AJP port directly. The motivation of writing these modules is Nginx's high performance and robustness.</p>"},{"location":"modules/ajp/#directives","title":"Directives","text":""},{"location":"modules/ajp/#ajp_buffers","title":"ajp_buffers","text":"<p>syntax: ajp_buffers the_number is_size;</p> <p>default: ajp_buffers 8 4k/8k;</p> <p>context: http, server, location</p> <p>This directive specifies the number and the size of buffers, into which will be read the response, obtained from the AJP server. By default, the size of one buffer is equal to the size of a page. Depending on platform this is either 4K, 8K or 16K.</p>"},{"location":"modules/ajp/#ajp_buffer_size","title":"ajp_buffer_size","text":"<p>syntax: ajp_buffer_size the_size;</p> <p>default: ajp_buffer_size 4k/8k;</p> <p>context: http, server, location</p> <p>This directive sets the buffer size, into which will be read the first part of the response, obtained from the AJP server.</p> <p>In this part of response the small response-header is located, as a rule.</p> <p>By default, the buffersize is equal to the size of one buffer in directive <code>ajp_buffers</code>; however, it is possible to set it to less.</p>"},{"location":"modules/ajp/#ajp_cache","title":"ajp_cache","text":"<p>syntax: ajp_cache zone;</p> <p>default: off</p> <p>context: http, server, location</p> <p>The directive specifies the area which actually is the share memory's name for caching. The same area can be used in several places. You must set the <code>ajp_cache_path</code> first.</p>"},{"location":"modules/ajp/#ajp_cache_key","title":"ajp_cache_key","text":"<p>syntax: ajp_cache_key line;</p> <p>default: none</p> <p>context: http, server, location</p> <p>The directive specifies what information is included in the key for caching, for example</p> <pre><code>    ajp_cache_key \"$host$request_uri$cookie_user\";\n</code></pre> <p>Note that by default, the hostname of the server is not included in the cache key. If you are using subdomains for different locations on your website, you need to include it, e.g. by changing the cache key to something like</p> <pre><code>    ajp_cache_key \"$scheme$host$request_uri\";\n</code></pre>"},{"location":"modules/ajp/#ajp_cache_methods","title":"ajp_cache_methods","text":"<p>syntax: ajp_cache_methods [GET HEAD POST];</p> <p>default: ajp_cache_methods GET HEAD;</p> <p>context: main,http,location</p> <p>GET/HEAD is syntax sugar, i.e. you can not disable GET/HEAD even if you set just</p> <pre><code>    ajp_cache_methods  POST;\n</code></pre>"},{"location":"modules/ajp/#ajp_cache_min_uses","title":"ajp_cache_min_uses","text":"<p>syntax: ajp_cache_min_uses n;</p> <p>default: ajp_cache_min_uses 1;</p> <p>context: http, server, location</p> <p>Sets the number of requests after which the response will be cached.</p>"},{"location":"modules/ajp/#ajp_cache_path","title":"ajp_cache_path","text":"<p>syntax: ajp_cache_path /path/to/cache [levels=m:n keys_zone=name:time inactive=time clean_time=time];</p> <p>default: none</p> <p>context: http, server, location</p> <p>This directive sets the cache path and other cache parameters. Cached data stored in files. Key and filename in cache is md5 of proxied URL. Levels parameter set number of subdirectories in cache, for example for:</p> <pre><code>    ajp_cache_path  /data/nginx/cache  levels=1:2   keys_zone=one:10m;\n</code></pre> <p>file names will be like:</p> <p>/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c</p>"},{"location":"modules/ajp/#ajp_cache_use_stale","title":"ajp_cache_use_stale","text":"<p>syntax: ajp_cache_use_stale [updating|error|timeout|invalid_header|http_500];</p> <p>default: ajp_cache_use_stale off;</p> <p>context: http, server, location</p> <p>If an error occurs while working with the AJP server it is possible to use a stale cached response. This directives determines in which cases it is permitted. The directive\u2019s parameters match those of the <code>ajp_next_upstream</code> directive.</p> <p>Additionally, the updating parameter permits to use a stale cached response if it is currently being updated. This allows to minimize the number of accesses to AJP servers when updating cached data.</p>"},{"location":"modules/ajp/#ajp_cache_valid","title":"ajp_cache_valid","text":"<p>syntax: ajp_cache_valid [http_error_code|time];</p> <p>default: none</p> <p>context: http, server, location</p> <p>Sets caching time for different response codes. For example, the following directives</p> <pre><code>    ajp_cache_valid 200 302 10m;\n    ajp_cache_valid 404      1m;\n</code></pre> <p>set 10 minutes of caching for responses with codes 200 and 302, and 1 minute for responses with code 404.</p> <p>If only caching time is specified</p> <pre><code>    ajp_cache_valid 5m;\n</code></pre> <p>then only 200, 301, and 302 responses are cached.</p> <p>In addition, it can be specified to cache any responses using the any parameter:</p> <pre><code>    ajp_cache_valid 200 302 10m;\n    ajp_cache_valid 301      1h;\n    ajp_cache_valid any      1m;\n</code></pre> <p>Parameters of caching can also be set directly in the response header. This has a higher precedence than setting of caching time using the directive. The \u201cX-Accel-Expires\u201d header field sets caching time of a response in seconds. The value 0 disables to cache a response. If a value starts with the prefix @, it sets an absolute time in seconds since Epoch, up to which the response may be cached. If header does not include the \u201cX-Accel-Expires\u201d field, parameters of caching may be set in the header fields \u201cExpires\u201d or \u201cCache-Control\u201d. If a header includes the \u201cSet-Cookie\u201d field, such a response will not be cached. Processing of one or more of these response header fields can be disabled using the <code>ajp_ignore_headers</code> directive.</p>"},{"location":"modules/ajp/#ajp_connect_timeout","title":"ajp_connect_timeout","text":"<p>syntax: ajp_connect_timeout time;</p> <p>default: ajp_connect_timeout 60s;</p> <p>context: http, server, location</p> <p>This directive assigns a timeout for the connection to the upstream server. It is necessary to keep in mind that this time out cannot be more than 75 seconds.</p> <p>This is not the time until the server returns the pages, this is the  ajp_read_timeout  statement. If your upstream server is up, but hanging (e.g. it does not have enough threads to process your request so it puts you in the pool of connections to deal with later), then this statement will not help as the connection to the server has been made.</p>"},{"location":"modules/ajp/#ajp_header_packet_buffer_size","title":"ajp_header_packet_buffer_size","text":"<p>syntax: ajp_header packet_buffer_size;</p> <p>default: ajp_header_packet_buffer_size 8k;</p> <p>context: http, server, location</p> <p>Set the buffer size of Forward Request packet. The range is (0, 2^16).</p>"},{"location":"modules/ajp/#ajp_hide_header","title":"ajp_hide_header","text":"<p>syntax: ajp_hide_header name;</p> <p>context: http, server, location</p> <p>By default, Nginx does not pass headers \"Status\" and \"X-Accel-...\" from the AJP process back to the client.  This directive can be used to hide other headers as well.</p> <p>If the headers \"Status\" and \"X-Accel-...\" must be provided, then it is necessary to use directive ajp_pass_header to force them to be returned to the client.</p>"},{"location":"modules/ajp/#ajp_ignore_headers","title":"ajp_ignore_headers","text":"<p>syntax: ajp_ignore_headers name [name ...];</p> <p>default: none</p> <p>context: http, server, location</p> <p>This directive(0.7.54+) prohibits the processing of the header lines from the proxy server's response.</p> <p>It can specify the string as \"X-Accel-Redirect\", \"X-Accel-Expires\", \"Expires\" or \"Cache-Control\".</p>"},{"location":"modules/ajp/#ajp_ignore_client_abort","title":"ajp_ignore_client_abort","text":"<p>syntax: ajp_ignore_client_abort on|off;</p> <p>default: ajp_ignore_client_abort off;</p> <p>context: http, server, location</p> <p>This directive determines if current request to the AJP-server must be aborted in case the client aborts the request to the server.</p>"},{"location":"modules/ajp/#ajp_intercept_errors","title":"ajp_intercept_errors","text":"<p>syntax: ajp_intercept_errors on|off;</p> <p>default: ajp_intercept_errors off;</p> <p>context: http, server, location</p> <p>This directive determines whether or not to transfer 4xx and 5xx errors back to the client or to allow Nginx to answer with directive error_page.</p> <p>Note: You need to explicitly define the error_page handler for this for it to be useful. As Igor says, \"nginx does not intercept an error if there is no custom handler for it it does not show its default pages. This allows to intercept some errors, while passing others as are.\"</p>"},{"location":"modules/ajp/#ajp_keep_conn","title":"ajp_keep_conn","text":"<p>syntax: ajp_keep_conn on|off;</p> <p>default: ajp_keep_conn off;</p> <p>context: http, server, location</p> <p>This directive determines whether or not to keep the connection alive with backend server.</p>"},{"location":"modules/ajp/#ajp_next_upstream","title":"ajp_next_upstream","text":"<p>syntax: ajp_next_upstream [error|timeout|invalid_header|http_500|http_502|http_503|http_504|http_404|off];</p> <p>default: ajp_next_upstream error timeout;</p> <p>context: http, server, location</p> <p>Directive determines, in what cases the request will be transmitted to the next server:</p> <ul> <li>error \u2014 an error has occurred while connecting to the server, sending a request to it, or reading its response;</li> <li>timeout \u2014 occurred timeout during the connection with the server, transfer the request or while reading response from the server;</li> <li>invalid_header \u2014 server returned a empty or incorrect answer;</li> <li>http_500 \u2014 server returned answer with code 500;</li> <li>http_502 \u2014 server returned answer with code 502;</li> <li>http_503 \u2014 server returned answer with code 503;</li> <li>http_504 \u2014 server returned answer with code 504;</li> <li>http_404 \u2014 server returned answer with code 404;</li> <li>off \u2014 it forbids the request transfer to the next server Transferring the request to the next server is only possible when nothing has been transferred to the client -- that is, if an error or timeout arises in the middle of the transfer of the request, then it is not possible to retry the current request on a different server.</li> </ul>"},{"location":"modules/ajp/#ajp_max_data_packet_size","title":"ajp_max_data_packet_size","text":"<p>syntax: ajp_max_data_packet_size size;</p> <p>default: ajp_max_data_packet_size 8k;</p> <p>context: http, server, location</p> <p>Set the maximum size of AJP's Data packet. The range is [8k, 2^16];</p>"},{"location":"modules/ajp/#ajp_max_temp_file_size","title":"ajp_max_temp_file_size","text":"<p>syntax: ajp_max_temp_file_size size;</p> <p>default: ajp_max_temp_file_size 1G;</p> <p>context: http, server, location, if</p> <p>The maximum size of a temporary file when the content is larger than the proxy buffer.  If file is larger than this size, it will be served synchronously from upstream server rather than buffered to disk.</p> <p>If ajp_max_temp_file_size is equal to zero, temporary files usage will be disabled.</p>"},{"location":"modules/ajp/#ajp_pass","title":"ajp_pass","text":"<p>syntax: ajp_pass ajp-server</p> <p>default: none</p> <p>context: location, if in location</p> <p>Directive assigns the port or socket on which the AJP-server is listening. Port can be indicated by itself or as an address and port, for example:</p> <pre><code>    ajp_pass   localhost:9000;\n</code></pre> <p>using a Unix domain socket:</p> <pre><code>    ajp_pass   unix:/tmp/ajp.socket;\n</code></pre> <p>You may also use an upstream block.</p> <pre><code>    upstream backend  {\n            server   localhost:1234;\n    }\n\n    ajp_pass   backend;\n</code></pre>"},{"location":"modules/ajp/#ajp_secret","title":"ajp_secret","text":"<p>syntax: _ajp_secret ajpsecret</p> <p>default: none</p> <p>Directive assigns the secret of the AJP-server.</p>"},{"location":"modules/ajp/#ajp_pass_header","title":"ajp_pass_header","text":"<p>syntax: ajp_pass_header name;</p> <p>context: http, server, location</p> <p>Permits to pass specific header fields from the AJP server to a client.</p>"},{"location":"modules/ajp/#ajp_pass_request_headers","title":"ajp_pass_request_headers","text":"<p>syntax: ajp_pass_request_headers [ on | off ];</p> <p>default: ajp_pass_request_headers on;</p> <p>context: http, server, location</p> <p>Permits to pass request header fields from the client to server.</p>"},{"location":"modules/ajp/#ajp_pass_request_body","title":"ajp_pass_request_body","text":"<p>syntax: ajp_pass_request_body [ on | off ] ;</p> <p>default: ajp_pass_request_body on;</p> <p>context: http, server, location</p> <p>Permits to pass request body from the client to server.</p>"},{"location":"modules/ajp/#ajp_read_timeout","title":"ajp_read_timeout","text":"<p>syntax: ajp_read_timeout time;</p> <p>default: ajp_read_timeout_time 60</p> <p>context: http, server, location</p> <p>Directive sets the amount of time for upstream to wait for a AJP process to send data.  Change this directive if you have long running AJP processes that do not produce output until they have finished processing.  If you are seeing an upstream timed out error in the error log, then increase this parameter to something more appropriate.</p>"},{"location":"modules/ajp/#ajp_send_lowat","title":"ajp_send_lowat","text":"<p>syntax: ajp_send_lowat [ on | off ];</p> <p>default: ajp_send_lowat off;</p> <p>context: http, server, location, if</p> <p>This directive set SO_SNDLOWAT. This directive is only available on FreeBSD</p>"},{"location":"modules/ajp/#ajp_send_timeout","title":"ajp_send_timeout","text":"<p>syntax: ajp_send_timeout time;</p> <p>default: ajp_send_timeout 60;</p> <p>context: http, server, location</p> <p>This directive assigns timeout with the transfer of request to the upstream server. Timeout is established not on entire transfer of request, but only between two write operations. If after this time the upstream server will not take new data, then nginx is shutdown the connection.</p>"},{"location":"modules/ajp/#ajp_store","title":"ajp_store","text":"<p>syntax: ajp_store [on | off | path] ;</p> <p>default: ajp_store off;</p> <p>context: http, server, location</p> <p>This directive sets the path in which upstream files are stored. The parameter \"on\" preserves files in accordance with path specified in directives alias or root. The parameter \"off\" forbids storing. Furthermore, the name of the path can be clearly assigned with the aid of the line with the variables:</p> <pre><code>    ajp_store   /data/www$original_uri;\n</code></pre> <p>The time of modification for the file will be set to the date of \"Last-Modified\" header in the response. To be able to safe files in this directory it is necessary that the path is under the directory with temporary files, given by directive <code>ajp_temp_path</code> for the data location.</p> <p>This directive can be used for creating the local copies for dynamic output of the backend which is not very often changed, for example:</p> <pre><code>    location /images/ {\n            root                 /data/www;\n            error_page           404 = @fetch;\n    }\n\n    location @fetch {\n            internal;\n            ajp_pass           backend;\n            ajp_store          on;\n            ajp_store_access   user:rw  group:rw  all:r;\n            ajp_temp_path      /data/temp;\n\n            root               /data/www;\n    }\n</code></pre> <p>To be clear ajp_store is not a cache, it's rather mirror on demand.</p>"},{"location":"modules/ajp/#ajp_store_access","title":"ajp_store_access","text":"<p>syntax: ajp_store_access users:permissions [users:permission ...];</p> <p>default: ajp_store_access user:rw;</p> <p>context: http, server, location</p> <p>This directive assigns the permissions for the created files and directories, for example:</p> <pre><code>    ajp_store_access  user:rw  group:rw  all:r;\n</code></pre> <p>If any rights for groups or all are assigned, then it is not necessary to assign rights for user:</p> <pre><code>    ajp_store_access  group:rw  all:r;\n</code></pre>"},{"location":"modules/ajp/#ajp_temp_path","title":"ajp_temp_path","text":"<p>syntax: ajp_temp_path dir-path [ level1 [ level2 [ level3 ] ] ] ;</p> <p>default: $NGX_PREFIX/ajp_temp</p> <p>context: http, server, location</p> <p>This directive works like client_body_temp_path  to specify a location to buffer large proxied requests to the filesystem.</p>"},{"location":"modules/ajp/#ajp_temp_file_write_size","title":"ajp_temp_file_write_size","text":"<p>syntax: ajp_temp_file_write_size size;</p> <p>default: ajp_temp_file_write_size [\"#ajp buffer size\"]  * 2;</p> <p>context: http, server, location, if</p> <p>Sets the amount of data that will be flushed to the ajp_temp_path when writing. It may be used to prevent a worker process blocking for too long while spooling data.</p>"},{"location":"modules/ajp/#known-issues","title":"Known Issues","text":"<p>*</p>"},{"location":"modules/ajp/#pod-errors","title":"POD ERRORS","text":"<p>Hey! The above document had some coding errors, which are explained below:</p> <ul> <li> <p>Around line 212:</p> <p>L&lt;&gt; starts or ends with whitespace</p> </li> </ul>"},{"location":"modules/ajp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ajp.</p>"},{"location":"modules/array-var/","title":"array-var: Array-typed variables for NGINX","text":""},{"location":"modules/array-var/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-array-var\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-array-var\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_array_var_module.so;\n</code></pre> <p>This document describes nginx-module-array-var v0.6  released on May 23 2022.</p> <p>array-var-nginx-module - Add support for array-typed variables to nginx config files</p> <p>installation instructions.</p>"},{"location":"modules/array-var/#status","title":"Status","text":"<p>This module is production ready.</p>"},{"location":"modules/array-var/#synopsis","title":"Synopsis","text":"<pre><code>location /foo {\n    array_split ',' $arg_files to=$array;\n\n    # use the set_quote_sql_str directive in the ngx_set_misc\n    # module to map to each element in the array $array:\n    array_map_op set_quote_sql_str $array;\n\n    array_map \"name = $array_it\" $array;\n\n    array_join ' or ' $array to=$sql_condition;\n\n    # well, we could feed it to ngx_drizzle to talk to MySQL, for example ;)\n    echo \"select * from files where $sql_condition\";\n}\n</code></pre>"},{"location":"modules/array-var/#description","title":"Description","text":"<p>This module provides array typed nginx variables to <code>nginx.conf</code>.</p> <p>Under the hood, this module just \"abuses\" the nginx string values to hold binary pointers to C data structures (NGINX core's <code>ngx_array_t</code> struct on the C land).</p> <p>The array type gives <code>nginx.onf</code> wonderful capabilities of handling value lists. Nowadays, however, you are highly recommended to use the ngx_lua module so as to have the full scripting power provided by the Lua language in nginx.</p>"},{"location":"modules/array-var/#directives","title":"Directives","text":""},{"location":"modules/array-var/#array_split","title":"array_split","text":"<p>syntax: array_split &lt;separator&gt; &lt;subject&gt; to=$target_variable</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Splits the string value in the <code>subject</code> argument with the separator string specified by the <code>separator</code> argument. The result is an array-typed value saved to the nginx variable specified by the <code>to=VAR</code> option.</p> <p>For example,</p> <pre><code>array_split \",\" $arg_names to=$names;\n</code></pre> <p>will split the string values in the URI query argument <code>names</code> into an array-typed value saved to the custom nginx variable <code>$names</code>.</p> <p>This directive creates an array-typed variable. Array-typed variables cannot be used outside the directives offered by this module. If you want to use the values in an array-typed variable in other contexts, you must use the array_join directive to produce a normal string value.</p>"},{"location":"modules/array-var/#array_join","title":"array_join","text":"<p>syntax: array_split &lt;separator&gt; $array_var</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Joins the elements in the array-typed nginx variable (<code>$array_var</code>) into a single string value with the separator specified by the first argument.</p> <p>For example,</p> <pre><code>location /foo {\n    array_split ',' $arg_names to=$names;\n    array_join '+' $names;\n    echo $names;\n}\n</code></pre> <p>Then request <code>GET /foo?names=Bob,Marry,John</code> will yield the response body</p> <pre><code>Bob+Marry+John\n</code></pre> <p>In the example above, we use the ngx_echo module's echo directive to output the final result.</p>"},{"location":"modules/array-var/#array_map","title":"array_map","text":"<p>syntax: array_map &lt;template&gt; $array_var</p> <p>syntax: array_map &lt;template&gt; $array_var to=$new_array_var</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Maps the string template to each element in the array-typed nginx variable specified. Within the string template, you can use the special iterator variable <code>$array_it</code> to reference the current array element in the array being mapped.</p> <p>For example,</p> <pre><code>array_map \"[$array_it]\" $names;\n</code></pre> <p>will change each element in the array variable <code>$names</code> by putting the square brackets around each element's string value. The modification is in-place in this case.</p> <p>If you do not want in-place modifications, you can use the <code>to=$var</code> option to specify a new nginx variable to hold the results. For instance,</p> <pre><code>array_map \"[$array_it]\" $names to=$new_names;\n</code></pre> <p>where the results are saved into another (array-typed) nginx variable named <code>$new_names</code> while the <code>$names</code> variable keeps intact.</p> <p>Below is a complete example for this:</p> <pre><code>location /foo {\n    array_split ',' $arg_names to=$names;\n    array_map '[$array_it]' $names;\n    array_join '+' $names;\n    echo \"$names\";\n}\n</code></pre> <p>Then request <code>GET /foo?names=bob,marry,nomas</code> will yield the response body</p> <pre><code>[bob]+[marry]+[nomas]\n</code></pre>"},{"location":"modules/array-var/#array_map_op","title":"array_map_op","text":"<p>syntax: array_map_op &lt;directive&gt; $array_var</p> <p>syntax: array_map_op &lt;directive&gt; $array_var to=$new_array_var</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Similar to the array_map directive but maps the specified nginx configuration directive instead of a string template to each element in the array-typed nginx variable specified. The result of applying the specified configuration directive becomes the result of the mapping.</p> <p>The nginx configuration directive being used as the iterator must be implemented by Nginx Devel Kit (NDK)'s set_var submodule's <code>ndk_set_var_value</code>. For example, the following set-misc-nginx-module directives can be invoked this way:</p> <ul> <li>set_quote_sql_str</li> <li>set_quote_pgsql_str</li> <li>set_quote_json_str</li> <li>set_unescape_uri</li> <li>set_escape_uri</li> <li>set_encode_base32</li> <li>set_decode_base32</li> <li>set_encode_base64</li> <li>set_decode_base64</li> <li>set_encode_hex</li> <li>set_decode_hex</li> <li>set_sha1</li> <li>set_md5</li> </ul> <p>This is a higher-order operation where other nginx configuration directives can be used as arguments for this <code>map_array_op</code> directive.</p> <p>Consider the following example,</p> <pre><code>array_map_op set_quote_sql_str $names;\n</code></pre> <p>This line changes each element in the array-typed nginx variable <code>$names</code> by applying the set_quote_sql_str directive provided by the ngx_set_misc module one by one. The result is that each element in the array <code>$names</code> has been escaped as SQL string literal values.</p> <p>You can also specify the <code>to=$var</code> option if you do not want in-place modifications of the input arrays. For instance,</p> <pre><code>array_map_op set_quote_sql_str $names to=$quoted_names;\n</code></pre> <p>will save the escaped elements into a new (array-typed) nginx variable named <code>$quoted_names</code> with <code>$names</code> intact.</p> <p>The following is a relatively complete example:</p> <pre><code>location /foo {\n    array_split ',' $arg_names to=$names;\n    array_map_op set_quote_sql_str $names;\n    array_join '+' $names to=$res;\n    echo $res;\n}\n</code></pre> <p>Then request <code>GET /foo?names=bob,marry,nomas</code> will yield the response body</p> <pre><code>'bob'+'marry'+'nomas'\n</code></pre> <p>Pretty cool, huh?</p>"},{"location":"modules/array-var/#here-we-assume-you-would-install-you-nginx-under-optnginx","title":"Here we assume you would install you nginx under /opt/nginx/.","text":"<p>./configure --prefix=/opt/nginx \\   --add-module=/path/to/ngx_devel_kit \\   --add-module=/path/to/array-var-nginx-module</p> <p>make -j2 make install ```</p> <p>Download the latest version of the release tarball of this module from array-var-nginx-module file list, and the latest tarball for ngx_devel_kit from its file list.</p> <p>Also, this module is included and enabled by default in the OpenResty bundle.</p>"},{"location":"modules/array-var/#see-also","title":"See Also","text":"<ul> <li>NDK</li> <li>ngx_lua</li> <li>ngx_set_misc</li> </ul>"},{"location":"modules/array-var/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-array-var.</p>"},{"location":"modules/auth-digest/","title":"auth-digest: Digest Authentication for NGINX","text":""},{"location":"modules/auth-digest/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-auth-digest\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-auth-digest\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_digest_module.so;\n</code></pre> <p>This document describes nginx-module-auth-digest v1.0.0  released on Mar 23 2018.</p>"},{"location":"modules/auth-digest/#nginx-digest-authentication-module","title":"Nginx Digest Authentication module","text":""},{"location":"modules/auth-digest/#changes-from-other-forks","title":"Changes from other forks","text":"<p>Bug fixes 1, 2, 3</p> <p>Added log message for invalid login attempts</p>"},{"location":"modules/auth-digest/#description","title":"Description","text":"<p>The <code>ngx_http_auth_digest</code> module supplements Nginx's built-in Basic Authentication module by providing support for RFC 2617 Digest Authentication. The module is currently functional but has only been tested and reviewed by its author. And given that this is security code, one set of eyes is almost certainly insufficient to guarantee that it's 100% correct. Until a few bug reports come in and some of the \u2018unknown unknowns\u2019 in the code are flushed out, consider this module an \u2018alpha\u2019 and treat it with the appropriate amount of skepticism.</p> <p>A listing of known issues with the module can be found in the <code>bugs.txt</code> file as well as in the Issue Tracker. Please do consider contributing a patch if you have the time and inclination. Any help fixing the bugs or changing the implementation to a more idiomatically nginx-y one would be greatly appreciated.</p>"},{"location":"modules/auth-digest/#dependencies","title":"Dependencies","text":"<ul> <li>Sources for Nginx 1.0.x, and its dependencies.</li> </ul>"},{"location":"modules/auth-digest/#building","title":"Building","text":"<ol> <li> <p>Unpack the Nginx sources:</p> <pre><code>$ tar zxvf nginx-1.0.x.tar.gz\n</code></pre> </li> <li> <p>Unpack the sources for the digest module:</p> <pre><code>$ tar xzvf samizdatco-nginx-http-auth-digest-xxxxxxx.tar.gz\n</code></pre> </li> <li> <p>Change to the directory which contains the Nginx sources, run the configuration script with the desired options and be sure to put an <code>--add-module</code> flag pointing to the directory which contains the source of the digest module:</p> <pre><code>$ cd nginx-1.0.x\n$ ./configure --add-module=../samizdatco-nginx-http-auth-digest-xxxxxxx  [other configure options]\n</code></pre> </li> <li> <p>Build and install the software:</p> <pre><code>$ make &amp;&amp; sudo make install\n</code></pre> </li> <li> <p>Configure Nginx using the module's configuration directives_.</p> </li> </ol>"},{"location":"modules/auth-digest/#example","title":"Example","text":"<p>You can password-protect a directory tree by adding the following lines into a <code>server</code> section in your Nginx configuration file:</p> <pre><code>auth_digest_user_file /opt/httpd/conf/passwd.digest; # a file created with htdigest\nlocation /private{\n  auth_digest 'this is not for you'; # set the realm for this location block\n}\n</code></pre> <p>The other directives control the lifespan defaults for the authentication session. The following is equivalent to the previous example but demonstrates all the directives:</p> <pre><code>auth_digest_user_file /opt/httpd/conf/passwd.digest;\nauth_digest_shm_size 4m;   # the storage space allocated for tracking active sessions\n\nlocation /private {\n  auth_digest 'this is not for you';\n  auth_digest_timeout 60s; # allow users to wait 1 minute between receiving the\n                           # challenge and hitting send in the browser dialog box\n  auth_digest_expires 10s; # after a successful challenge/response, let the client\n                           # continue to use the same nonce for additional requests\n                           # for 10 seconds before generating a new challenge\n  auth_digest_replays 20;  # also generate a new challenge if the client uses the\n                           # same nonce more than 20 times before the expire time limit\n}\n</code></pre> <p>Adding digest authentication to a location will affect any uris that match that block. To disable authentication for specific sub-branches off a uri, set <code>auth_digest</code> to <code>off</code>:</p> <pre><code>location / {\n  auth_digest 'this is not for you';\n  location /pub {\n    auth_digest off; # this sub-tree will be accessible without authentication\n  }\n}\n</code></pre>"},{"location":"modules/auth-digest/#directives","title":"Directives","text":""},{"location":"modules/auth-digest/#auth_digest","title":"auth_digest","text":"<p>Syntax <code>auth_digest</code> [realm-name | <code>off</code>]</p> <p>Default <code>off</code></p> <p>Context server, location</p> <p>Description Enable or disable digest authentication for a server or location block. The realm name should correspond to a realm used in the user file. Any user within that realm will be able to access files after authenticating.</p> <p>To selectively disable authentication within a protected uri hierarchy, set <code>auth_digest</code> to \u201c<code>off</code>\u201d within a more-specific location block (see example).</p>"},{"location":"modules/auth-digest/#auth_digest_user_file","title":"auth_digest_user_file","text":"<p>Syntax <code>auth_digest_user_file</code> /path/to/passwd/file</p> <p>Default unset</p> <p>Context server, location</p> <p>Description The password file should be of the form created by the apache <code>htdigest</code> command (or the included htdigest.py script). Each line of the file is a colon-separated list composed of a username, realm, and md5 hash combining name, realm, and password. For example: <code>joi:enfield:ef25e85b34208c246cfd09ab76b01db7</code></p>"},{"location":"modules/auth-digest/#auth_digest_timeout","title":"auth_digest_timeout","text":"<p>Syntax <code>auth_digest_timeout</code> delay-time</p> <p>Default <code>60s</code></p> <p>Context server, location</p> <p>Description When a client first requests a protected page, the server returns a 401 status code along with a challenge in the <code>www-authenticate</code> header.</p> <p>At this point most browsers will present a dialog box to the user prompting them to log in. This directive defines how long challenges will remain valid. If the user waits longer than this time before submitting their name and password, the challenge will be considered \u2018stale\u2019 and they will be prompted to log in again.</p>"},{"location":"modules/auth-digest/#auth_digest_expires","title":"auth_digest_expires","text":"<p>Syntax <code>auth_digest_expires</code> lifetime-in-seconds</p> <p>Default <code>10s</code></p> <p>Context server, location</p> <p>Description Once a digest challenge has been successfully answered by the client, subsequent requests will attempt to re-use the \u2018nonce\u2019 value from the original challenge. To complicate MitM attacks, it's best to limit the number of times a cached nonce will be accepted. This directive sets the duration for this re-use period after the first successful authentication.</p>"},{"location":"modules/auth-digest/#auth_digest_replays","title":"auth_digest_replays","text":"<p>Syntax <code>auth_digest_replays</code> number-of-uses</p> <p>Default <code>20</code></p> <p>Context server, location</p> <p>Description Nonce re-use should also be limited to a fixed number of requests. Note that increasing this value will cause a proportional increase in memory usage and the shm_size may have to be adjusted to keep up with heavy traffic within the digest-protected location blocks.</p>"},{"location":"modules/auth-digest/#auth_digest_evasion_time","title":"auth_digest_evasion_time","text":"<p>Syntax <code>auth_digest_evasion_time</code> time-in-seconds</p> <p>Default <code>300s</code></p> <p>Context server, location</p> <p>Description The amount of time for which the server will ignore authentication requests from a client address once the number of failed authentications from that client reaches <code>auth_digest_maxtries</code>.</p>"},{"location":"modules/auth-digest/#auth_digest_maxtries","title":"auth_digest_maxtries","text":"<p>Syntax <code>auth_digest_maxtries</code> number-of-attempts</p> <p>Default <code>5</code></p> <p>Context server, location</p> <p>Description The number of failed authentication attempts from a client address before the module enters evasive tactics. For evasion purposes, only network clients are tracked, and only by address (not including port number). A successful authentication clears the counters.</p>"},{"location":"modules/auth-digest/#auth_digest_shm_size","title":"auth_digest_shm_size","text":"<p>Syntax <code>auth_digest_shm_size</code> size-in-bytes</p> <p>Default <code>4096k</code></p> <p>Context server</p> <p>Description The module maintains a fixed-size cache of active digest sessions to save state between authenticated requests. Once this cache is full, no further authentication will be possible until active sessions expire.</p> <p>As a result, choosing the proper size is a little tricky since it depends upon the values set in the expiration-related directives. Each stored challenge takes up <code>48 + ceil(replays/8)</code> bytes and will live for up to <code>auth_digest_timeout + auth_digest_expires</code> seconds. When using the default module settings this translates into allowing around 82k non-replay requests every 70 seconds.</p>"},{"location":"modules/auth-digest/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-auth-digest.</p>"},{"location":"modules/auth-ldap/","title":"auth-ldap: LDAP Authentication module for NGINX","text":""},{"location":"modules/auth-ldap/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-auth-ldap\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-auth-ldap\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_ldap_module.so;\n</code></pre> <p>This document describes nginx-module-auth-ldap v0.3  released on May 28 2020.</p> <p>LDAP module for nginx which supports authentication against multiple LDAP servers.</p>"},{"location":"modules/auth-ldap/#example-configuration","title":"Example configuration","text":"<p>Define list of your LDAP servers with required user/group requirements:</p> <pre><code>    http {\n      ldap_server test1 {\n        url ldap://192.168.0.1:3268/DC=test,DC=local?sAMAccountName?sub?(objectClass=person);\n        binddn \"TEST\\\\LDAPUSER\";\n        binddn_passwd LDAPPASSWORD;\n        group_attribute uniquemember;\n        group_attribute_is_dn on;\n        require valid_user;\n      }\n\n      ldap_server test2 {\n        url ldap://192.168.0.2:3268/DC=test,DC=local?sAMAccountName?sub?(objectClass=person);\n        binddn \"TEST\\\\LDAPUSER\";\n        binddn_passwd LDAPPASSWORD;\n        group_attribute uniquemember;\n        group_attribute_is_dn on;\n        require valid_user;\n      }\n    }\n</code></pre> <p>And add required servers in correct order into your location/server directive: <pre><code>    server {\n        listen       8000;\n        server_name  localhost;\n\n        auth_ldap \"Forbidden\";\n        auth_ldap_servers test1;\n        auth_ldap_servers test2;\n\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n\n    }\n</code></pre></p>"},{"location":"modules/auth-ldap/#available-config-parameters","title":"Available config parameters","text":""},{"location":"modules/auth-ldap/#url","title":"url","text":"<p>expected value: string</p> <p>Available URL schemes: ldap://, ldaps://</p>"},{"location":"modules/auth-ldap/#binddn","title":"binddn","text":"<p>expected value: string</p>"},{"location":"modules/auth-ldap/#binddn_passwd","title":"binddn_passwd","text":"<p>expected value: string</p>"},{"location":"modules/auth-ldap/#group_attribute","title":"group_attribute","text":"<p>expected value: string</p>"},{"location":"modules/auth-ldap/#group_attribute_is_dn","title":"group_attribute_is_dn","text":"<p>expected value: on or off, default off</p>"},{"location":"modules/auth-ldap/#require","title":"require","text":"<p>expected value: valid_user, user, group</p>"},{"location":"modules/auth-ldap/#satisfy","title":"satisfy","text":"<p>expected value: all, any</p>"},{"location":"modules/auth-ldap/#max_down_retries","title":"max_down_retries","text":"<p>expected value: a number, default 0</p> <p>Retry count for attempting to reconnect to an LDAP server if it is considered \"DOWN\".  This may happen if a KEEP-ALIVE connection to an LDAP server times  out or is terminated by the server end after some amount of time.  </p> <p>This can usually help with the following error:</p> <pre><code>http_auth_ldap: ldap_result() failed (-1: Can't contact LDAP server)\n</code></pre>"},{"location":"modules/auth-ldap/#connections","title":"connections","text":"<p>expected value: a number greater than 0</p>"},{"location":"modules/auth-ldap/#ssl_check_cert","title":"ssl_check_cert","text":"<p>expected value: on or off, default off</p> <p>Verify the remote certificate for LDAPs connections. If disabled, any remote certificate will be accepted which exposes you to possible man-in-the-middle attacks. Note that the server's certificate will need to be signed by a proper CA trusted by your system if this is enabled. See below how to trust CAs without installing them system-wide.</p> <p>This options needs OpenSSL &gt;= 1.0.2; it is unavailable if compiled with older versions.</p>"},{"location":"modules/auth-ldap/#ssl_ca_file","title":"ssl_ca_file","text":"<p>expected value: file path</p> <p>Trust the CA certificate in this file (see ssl_check_cert above).</p>"},{"location":"modules/auth-ldap/#ssl_ca_dir","title":"ssl_ca_dir","text":"<p>expected value: directory path</p> <p>Trust all CA certificates in this directory (see ssl_check_cert above).</p> <p>Note that you need to provide hash-based symlinks in the directory for this to work; you'll basically need to run OpenSSL's c_rehash command in this directory.</p>"},{"location":"modules/auth-ldap/#referral","title":"referral","text":"<p>expected value: on, off</p> <p>LDAP library default is on. This option disables usage of referral messages from LDAP server. Usefull for authenticating against read only AD server without access to read write.</p>"},{"location":"modules/auth-ldap/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-auth-ldap.</p>"},{"location":"modules/auth-pam/","title":"auth-pam: PAM authentication dynamic module for NGINX","text":""},{"location":"modules/auth-pam/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-auth-pam\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-auth-pam\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_pam_module.so;\n</code></pre> <p>This document describes nginx-module-auth-pam v1.5.5  released on Jun 20 2023.</p>"},{"location":"modules/auth-pam/#nginx-module-to-use-pam-for-simple-http-authentication","title":"Nginx module to use PAM for simple http authentication","text":""},{"location":"modules/auth-pam/#configuration","title":"Configuration","text":"<p>The module only has two directives:</p> <ul> <li> <p><code>auth_pam</code>: This is the http authentication realm. If given the value   <code>off</code> the module is disabled (needed when we want to override the value   set on a lower-level directive).</p> </li> <li> <p><code>auth_pam_service_name</code>: this is the PAM service name and by default it is   set to <code>nginx</code>.</p> </li> </ul>"},{"location":"modules/auth-pam/#examples","title":"Examples","text":"<p>To protect everything under <code>/secure</code> you will add the following to the <code>nginx.conf</code> file:</p> <pre><code>location /secure {\n    auth_pam              \"Secure Zone\";\n    auth_pam_service_name \"nginx\";\n}\n</code></pre> <p>Note that the module runs as the web server user, so the PAM modules used must be able to authenticate the users without being root; that means that if you want to use the <code>pam_unix.so</code> module to autenticate users you need to let the web server user to read the <code>/etc/shadow</code> file if that does not scare you (on Debian like systems you can add the <code>www-data</code> user to the <code>shadow</code> group).</p> <p>As an example, to authenticate users against an LDAP server (using the <code>pam_ldap.so</code> module) you will use an <code>/etc/pam.d/nginx</code> like the following:</p> <pre><code>auth    required     /lib/security/pam_ldap.so\naccount required     /lib/security/pam_ldap.so\n</code></pre> <p>If you also want to limit the users from LDAP that can authenticate you can use the <code>pam_listfile.so</code> module; to limit who can access resources under <code>/restricted</code> add the following to the <code>nginx.conf</code> file:</p> <pre><code>location /restricted {\n    auth_pam              \"Restricted Zone\";\n    auth_pam_service_name \"nginx_restricted\";\n}\n</code></pre> <p>Use the following <code>/etc/pam.d/nginx_restricted</code> file:</p> <pre><code>auth    required     /lib/security/pam_listfile.so onerr=fail item=user \\\n                     sense=allow file=/etc/nginx/restricted_users\nauth    required     /lib/security/pam_ldap.so\naccount required     /lib/security/pam_ldap.so\n</code></pre> <p>And add the users allowed to authenticate to the <code>/etc/nginx/restricted_users</code> (remember that the web server user has to be able to read this file).</p>"},{"location":"modules/auth-pam/#pam-environment","title":"PAM Environment","text":"<p>If you want use the <code>pam_exec.so</code> plugin for request based authentication the module can add to the PAM environment the <code>HOST</code> and <code>REQUEST</code> variables if you set the <code>auth_pam_set_pam_env</code> flag::</p> <pre><code>location /pam_exec_protected {\n  auth_pam              \"Exec Zone\";\n  auth_pam_service_name \"nginx_exec\";\n  auth_pam_set_pam_env  on;\n}\n</code></pre> <p>With this configuration if you access an URL like:</p> <pre><code>http://localhost:8000/pam_exec_protected/page?foo=yes&amp;bar=too\n</code></pre> <p>the PAM environment will include the following variables:</p> <pre><code>HOST=localhost:8000\nREQUEST=GET /pam_exec_protected/page?foo=yes&amp;bar=too HTTP/1.1\n</code></pre> <p>You may use this information for request based authentication. You need a recent pam release (&gt;= version 1.0.90) to expose environment variables to pam_exec.</p>"},{"location":"modules/auth-pam/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-auth-pam.</p>"},{"location":"modules/auth-totp/","title":"auth-totp: Time-based one-time password (TOTP) authentication for NGINX","text":""},{"location":"modules/auth-totp/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-auth-totp\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-auth-totp\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_totp_module.so;\n</code></pre> <p>This document describes nginx-module-auth-totp v1.1.0  released on Dec 18 2024.</p> <p>Time-based one-time password (TOTP) authentication for Nginx</p> <p>The Time-based One-Time Password (TOTP) algorithm, provides a secure mechanism for short-lived one-time password values, which are desirable for enhanced security. This algorithm can be used across a wide range of network applications ranging from remote Virtual Private Network (VPN) access, Wi-Fi network logon to transaction-orientated Web applications.</p> <p>The nginx-http-auth-totp module provides TOTP authentication for a Nginx server.</p>"},{"location":"modules/auth-totp/#features","title":"Features","text":"<ul> <li>HTTP basic authentication using time-based one-time password (TOTP)</li> <li>Cookie-based tracking of authenticated clients beyond TOTP validity window</li> <li>Configurable secret, time reference, time step and truncation length for TOTP generation</li> <li>Configurable time-skew for TOTP validation</li> </ul>"},{"location":"modules/auth-totp/#packages","title":"Packages","text":"<p>For users who prefer pre-built and optimized packages, the nginx-http-auth-totp module can be installed from the GetPageSpeed repository:</p> <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-auth-totp\n</code></pre>"},{"location":"modules/auth-totp/#configuration","title":"Configuration","text":"<pre><code>server {\n    listen 80;\n\n    location /protected {\n        auth_totp_realm \"Protected\";\n        auth_totp_file /etc/nginx/totp.conf;\n        auth_totp_length 8;\n        auth_totp_skew 1;\n        auth_totp_step 1m;\n        auth_totp_cookie \"totp-session\";\n        auth_totp_expiry 1d;\n    }\n}\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_totp_module.so;\n</code></pre>"},{"location":"modules/auth-totp/#directives","title":"Directives","text":""},{"location":"modules/auth-totp/#auth_totp_cookie","title":"auth_totp_cookie","text":"<ul> <li>syntax: <code>auth_totp_cookie &lt;name&gt;</code></li> <li>default: <code>totp</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the name of the HTTP cookie to be used for tracking authenticated clients.</p> <p>As the validity of the Time-based One-Time Password (TOTP) used for authentication expires (by design), a HTTP cookie is set following successful authentication in order to persist client authentication beyond the TOTP validity window. This configuration directives specifies the name to be used when setting this cookie while the expiry period for this cookie may be set using the <code>auth_totp_expiry</code> directive. </p>"},{"location":"modules/auth-totp/#auth_totp_expiry","title":"auth_totp_expiry","text":"<ul> <li>syntax: <code>auth_totp_expiry &lt;interval&gt;</code></li> <li>default: <code>0s</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the expiry time for the HTTP cookie to be used for tracking authenticated clients.</p> <p>If this expiry value is not specified (or set to zero), the HTTP cookie used for tracking authenticated clients will be set as a session cookie which will be deleted when the current HTTP client session ends. It is important to note that the browser defines when the \"current session\" ends, and some browsers use session restoration when restarting, which can cause session cookies to last indefinitely.</p>"},{"location":"modules/auth-totp/#auth_totp_file","title":"auth_totp_file","text":"<ul> <li>syntax: <code>auth_totp_file &lt;filename&gt;</code></li> <li>default: -</li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the file that contains usernames and shared secrets for Time-based One-Time Password (TOTP) authentication. </p> <p>This configuration file has the format:</p> <pre><code># comment\nuser1:secret1\nuser2:secret2\nuser3:secret3\n</code></pre>"},{"location":"modules/auth-totp/#auth_totp_length","title":"auth_totp_length","text":"<ul> <li>syntax: <code>auth_totp_length &lt;number&gt;</code></li> <li>default: <code>6</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the truncation length of the Time-based One-Time Password (TOTP) code. This truncation length may be between 1 and 8 digits inclusively.</p> <p>If the supplied TOTP is of a different length to this value, the authentication request will fail.</p>"},{"location":"modules/auth-totp/#auth_totp_realm","title":"auth_totp_realm","text":"<ul> <li>syntax: <code>auth_totp_realm &lt;string&gt;|off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Enables validation of user name and Time-based One-Time Password (TOTP) using the \"HTTP Basic Authentication\" protocol. The specified parameter is used as the <code>realm</code> for this authentication. This parameter value can contain variables. The special value of <code>off</code> cancels the application of any <code>auth_totp_realm</code> directive inherited from a higher configuration level.</p>"},{"location":"modules/auth-totp/#auth_totp_reuse","title":"auth_totp_reuse","text":"<ul> <li>syntax: <code>auth_totp_reuse &lt;on&gt;|&lt;off&gt;</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Enables the reuse of a Time-based One-Time Password (TOTP) within a validity window. While this is non-standard behaviour per RFC 6238, it provides a convenient manner to ensure a minimum window of validity for generated TOTP codes, even if the TOTP has already been presented to the validating system.</p>"},{"location":"modules/auth-totp/#auth_totp_skew","title":"auth_totp_skew","text":"<ul> <li>syntax: <code>auth_totp_skew &lt;number&gt;</code></li> <li>default: <code>1</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the number of time steps by which the time base between the issuing and validating TOTP systems.</p> <p>Due to network latency, the gap between the time that a OTP was generated and the time that the OTP is received at the validating system may be large. Indeed, it is possible that the receiving time at the validating system and that when the OTP was generated by the issuing system may not fall within the same time-step window. Accordingly, the validating system should typically set a policy for an acceptable OTP transmission window for validation. In line with this, the validating system should compare OTPs not only with the receiving timestamp, but also the past timestamps that are within the transmission delay.</p> <p>It is important to note that larger acceptable delay windows represent a larger window for attacks and a balance must be struck between the security and usability of OTPs.</p>"},{"location":"modules/auth-totp/#auth_totp_start","title":"auth_totp_start","text":"<ul> <li>syntax: <code>auth_totp_start &lt;time&gt;</code></li> <li>default: <code>0</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the UNIX time from which to start counting time steps as part of Time-based One-Time Password (TOTP) algorithm operations.</p> <p>The default value is 0, the UNIX epoch at 1970/01/01. </p>"},{"location":"modules/auth-totp/#auth_totp_step","title":"auth_totp_step","text":"<ul> <li>syntax: <code>auth_totp_step &lt;interval&gt;</code></li> <li>default: <code>30s</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code></li> </ul> <p>Specifies the time step as part of Time-based One-Time Password (TOTP) algorithm operations.</p>"},{"location":"modules/auth-totp/#references","title":"References","text":"<ul> <li>RFC 4226 HOTP: An HMAC-Based One-Time Password Algorithm</li> <li>RFC 6238 TOTP: Time-Based One-Time Password Algorithm</li> <li>RFC 7235 Hypertext Transfer Protocol (HTTP/1.1): Authentication</li> </ul>"},{"location":"modules/auth-totp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-auth-totp.</p>"},{"location":"modules/aws-auth/","title":"aws-auth: NGINX module to proxy to authenticated AWS services","text":""},{"location":"modules/aws-auth/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-aws-auth\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-aws-auth\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_aws_auth_module.so;\n</code></pre> <p>This document describes nginx-module-aws-auth v2.1.1  released on Mar 06 2017.</p> <p></p> <p>This nginx module can proxy requests to authenticated S3 backends using Amazon's V4 authentication API. The first version of this module was written for the V2 authentication protocol and can be found in the AuthV2 branch.</p>"},{"location":"modules/aws-auth/#usage-example","title":"Usage example","text":"<p>Implements proxying of authenticated requests to S3.</p> <pre><code>  server {\n    listen     8000;\n\n    aws_access_key your_aws_access_key; # Example AKIDEXAMPLE\n    aws_key_scope scope_of_generated_signing_key; #Example 20150830/us-east-1/service/aws4_request\n    aws_signing_key signing_key_generated_using_script; #Example L4vRLWAO92X5L3Sqk5QydUSdB0nC9+1wfqLMOKLbRp4=\n    aws_s3_bucket your_s3_bucket;\n\n    location / {\n      aws_sign;\n      proxy_pass http://your_s3_bucket.s3.amazonaws.com;\n    }\n\n    # This is an example that does not use the server root for the proxy root\n    location /myfiles {\n\n      rewrite /myfiles/(.*) /$1 break;\n      proxy_pass http://your_s3_bucket.s3.amazonaws.com/$1;\n\n\n      aws_access_key your_aws_access_key;\n      aws_key_scope scope_of_generated_signing_key;\n      aws_signing_key signing_key_generated_using_script;\n    }\n\n    # This is an example that use specific s3 endpoint, default endpoint is s3.amazonaws.com\n    location /s3_beijing {\n\n      rewrite /s3_beijing/(.*) /$1 break;\n      proxy_pass http://your_s3_bucket.s3.cn-north-1.amazonaws.com.cn/$1;\n\n      aws_sign;\n      aws_endpoint \"s3.cn-north-1.amazonaws.com.cn\";\n      aws_access_key your_aws_access_key;\n      aws_key_scope scope_of_generated_signing_key;\n      aws_signing_key signing_key_generated_using_script;\n    }\n  }\n</code></pre>"},{"location":"modules/aws-auth/#security-considerations","title":"Security considerations","text":"<p>The V4 protocol does not need access to the actual secret keys that one obtains  from the IAM service. The correct way to use the IAM key is to actually generate a scoped signing key and use this signing key to access S3. This nginx module requires the signing key and not the actual secret key. It is an insecure practise to let the secret key reside on your nginx server.</p> <p>Note that signing keys have a validity of just one week. Hence, they need to be refreshed constantly. Please useyour favourite configuration management system such as saltstack, puppet, chef, etc. etc. to distribute the signing keys to your nginx clusters. Do not forget to HUP the server after placing the new signing key as nginx reads the configuration only at startup time.</p> <p>A standalone python script has been provided to generate the signing key <pre><code>./generate_signing_key -h\nusage: generate_signing_key [-h] -k ACCESS_KEY -r REGION [-s SERVICE]\n                            [-d DATE] [--no-base64] [-v]\n\nGenerate AWS S3 signing key in it's base64 encoded form\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -k SECRET_KEY, --secret-key SECRET_KEY\n                        The secret key generated using AWS IAM. Do not confuse\n                        this with the access key id\n  -r REGION, --region REGION\n                        The AWS region where this key would be used. Example:\n                        us-east-1\n  -s SERVICE, --service SERVICE\n                        The AWS service for which this key would be used.\n                        Example: s3\n  -d DATE, --date DATE  The date on which this key is generated in yyyymmdd\n                        format\n  --no-base64           Disable output as a base64 encoded string. This NOT\n                        recommended\n  -v, --verbose         Produce verbose output on stderr\n\n\n./generate_signing_key -k wJalrXUtnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY -r us-east-1\nL4vRLWAO92X5L3Sqk5QydUSdB0nC9+1wfqLMOKLbRp4=\n20160902/us-east-1/s3/aws4_request\n</code></pre></p>"},{"location":"modules/aws-auth/#known-limitations","title":"Known limitations","text":"<p>The 2.x version of the module currently only has support for GET and HEAD calls. This is because signing request body is complex and has not yet been implemented.</p>"},{"location":"modules/aws-auth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-aws-auth.</p>"},{"location":"modules/bot-verifier/","title":"bot-verifier: A search index bot verification module for NGINX","text":""},{"location":"modules/bot-verifier/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-bot-verifier\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-bot-verifier\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_bot_verifier_module.so;\n</code></pre> <p>This document describes nginx-module-bot-verifier v0.0.11  released on Jun 26 2022.</p>"},{"location":"modules/bot-verifier/#status","title":"Status","text":"<p>[BETA] This module has been tested on a handful of production websites. It has not yet been evaluated at scale. If you would like to consider testing this at scale I would be happy to assist and allocate time to correct any issues.</p>"},{"location":"modules/bot-verifier/#synopsis","title":"Synopsis","text":"<pre><code>location / {\n    bot_verifier on;\n    bot_verifier_redis_host localhost;\n    bot_verifier_redis_port 6379;\n    bot_verifier_redis_connection_timeout 10;\n    bot_verifier_redis_read_timeout 10;\n    bot_verifier_redis_expiry 3600;\n    bot_verifier_repsheet_enabled on;\n}\n</code></pre>"},{"location":"modules/bot-verifier/#description","title":"Description","text":"<p>This is an NGINX module designed to validate actors claiming to be search engine indexers. It is right to disable security mechanisms for valid search engine bots to ensure your controls do not interfere with page rankings on any of the search providers. The issue is that the User Agent header cannot be trusted. In order to ensure you are allowing only valid search engine indexers, you must validate according to their published standards. This module performs that validation and caches the results to ensure you do not pay validation penalties on every request.</p>"},{"location":"modules/bot-verifier/#directives","title":"Directives","text":"<p>The following directives are used only for module configuration.</p>"},{"location":"modules/bot-verifier/#bot_verifier","title":"bot_verifier","text":"<p>syntax: bot_verifier [on|off]</p> <p>default: off</p> <p>context: location</p> <p>phase: access</p> <p>Enables or disables the module. The module will not act unless it is set to on.</p>"},{"location":"modules/bot-verifier/#bot_verifier_redis_host","title":"bot_verifier_redis_host","text":"<p>syntax: bot_verifier_redis_host &lt;string&gt;</p> <p>default: localhost</p> <p>context: location</p> <p>phase: access</p> <p>Sets the Redis host. This setting is used to connect to the Redis database used for caching lookup results.</p>"},{"location":"modules/bot-verifier/#bot_verifier_redis_port","title":"bot_verifier_redis_port","text":"<p>syntax: bot_verifier_redis_port &lt;int&gt;</p> <p>default: 6379</p> <p>context: location</p> <p>phase: access</p> <p>Sets the Redis port. This setting is used to connect to the Redis database used for caching lookup results.</p>"},{"location":"modules/bot-verifier/#bot_verifier_redis_connection_timeout","title":"bot_verifier_redis_connection_timeout","text":"<p>syntax: bot_verifier_redis_connection_timeout &lt;int&gt;</p> <p>default: 10</p> <p>context: location</p> <p>phase: access</p> <p>Sets the timeout when connecting to Redis. This setting is used to connect to the Redis database used for caching lookup results.</p>"},{"location":"modules/bot-verifier/#bot_verifier_redis_read_timeout","title":"bot_verifier_redis_read_timeout","text":"<p>syntax: bot_verifier_redis_read_timeout &lt;int&gt;</p> <p>default: 10</p> <p>context: location</p> <p>phase: access</p> <p>Sets the timeout when querying Redis. This setting is used to connect to the Redis database used for caching lookup results.</p>"},{"location":"modules/bot-verifier/#bot_verifier_redis_expiry","title":"bot_verifier_redis_expiry","text":"<p>syntax: bot_verifier_redis_expiry &lt;seconds&gt;</p> <p>default: 3600</p> <p>context: location</p> <p>phase: access</p> <p>Sets the timeout when querying Redis. This setting is used to connect to the Redis database used for caching lookup results.</p>"},{"location":"modules/bot-verifier/#bot_verifier_repsheet_enabled","title":"bot_verifier_repsheet_enabled","text":"<p>syntax: bot_verifier_repsheet_enabled [on|off]</p> <p>default: off</p> <p>context: location</p> <p>phase: access</p> <p>Enables blacklisting of failed actors in Repsheet. Assumes Repsheet cache lives on already configured redis server.</p>"},{"location":"modules/bot-verifier/#verifying-functionality","title":"Verifying Functionality","text":"<p>In order to ensure the module is working properly you will need to issue a query that will trigger failure and success cases. To trigger a failure case issue the following request:</p> <pre><code>curl -A \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html\" localhost:8888\n</code></pre> <p>This will issue a query that identifies itself as a Google bot. The reverse and forward lookup routine will fail and you will get a <code>403</code> response. To ensure the verification works when a bot is identified issue the following request:</p> <pre><code>curl -H \"X-Forwarded-For: 66.249.66.1\" -A \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html\" localhost:8888\n</code></pre> <p>This will spoof the <code>X-Forwarded-For</code> header and pretend to be from a valid google address. The request should succeed and return a normal response.</p>"},{"location":"modules/bot-verifier/#developer-setup","title":"Developer Setup","text":"<p>This module contains a full self-contained development environment. This is done to ensure work on the module does not interfere with any other NGINX installations. To setup the environment run the <code>script/bootstrap</code> command. This will create the following directories:</p> <pre><code>vendor - The NGINX installation will live here  \nbuild - The NGINX install will live here  \n</code></pre> <p>The <code>nginx.conf</code> file in the root of this repository will be symlinked to <code>build/nginx/conf/nginx.conf</code> to make configuration changes easier. You can start NGINX using the following command:</p> <pre><code>build/nginx/sbin/nginx\n</code></pre> <p>Log files are available at <code>build/nginx/logs</code>. You can stop the server by running</p> <pre><code>build/nginx/sbin/nginx -s stop\n</code></pre> <p>If you are making changes to the module, you can recompile them by running <code>make compile</code>. Remember to restart the NGINX after this completes successfully.</p>"},{"location":"modules/bot-verifier/#running-the-test-suite","title":"Running the Test Suite","text":"<p>This repository comes with a test suite that uses the <code>Test::Nginx</code> library. To run the test you will need to install the following libraries:</p> <pre><code>cpanm -S install Test::Nginx Test::Nginx::Socket\n</code></pre> <p>Once the libraries are installed just run <code>make</code> and the suite will run. If you are submitting a change to this module please make sure to run the test suite before you do. Any changes that break the test suite will not be accepted.</p>"},{"location":"modules/bot-verifier/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-bot-verifier.</p>"},{"location":"modules/brotli/","title":"brotli: NGINX Brotli dynamic modules","text":""},{"location":"modules/brotli/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-brotli\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-brotli\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <p><pre><code>load_module modules/ngx_http_brotli_filter_module.so;\n</code></pre> <pre><code>load_module modules/ngx_http_brotli_static_module.so;\n</code></pre></p> <p>This document describes nginx-module-brotli v0.1.4  released on Jul 01 2021.</p> <p>Brotli is a generic-purpose lossless compression algorithm that compresses data using a combination of a modern variant of the LZ77 algorithm, Huffman coding and 2nd order context modeling, with a compression ratio comparable to the best currently available general-purpose compression methods. It is similar in speed with deflate but offers more dense compression.</p> <p>ngx_brotli is a set of two nginx modules:</p> <ul> <li>ngx_brotli filter module - used to compress responses on-the-fly,</li> <li>ngx_brotli static module - used to serve pre-compressed files.</li> </ul>"},{"location":"modules/brotli/#status","title":"Status","text":"<p>Both Brotli library and nginx module are under active development.</p>"},{"location":"modules/brotli/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/brotli/#brotli_static","title":"<code>brotli_static</code>","text":"<ul> <li>syntax: <code>brotli_static on|off|always</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables or disables checking of the existence of pre-compressed files with<code>.br</code> extension. With the <code>always</code> value, pre-compressed file is used in all cases, without checking if the client supports it.</p>"},{"location":"modules/brotli/#brotli","title":"<code>brotli</code>","text":"<ul> <li>syntax: <code>brotli on|off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>if</code></li> </ul> <p>Enables or disables on-the-fly compression of responses.</p>"},{"location":"modules/brotli/#brotli_types","title":"<code>brotli_types</code>","text":"<ul> <li>syntax: <code>brotli_types &lt;mime_type&gt; [..]</code></li> <li>default: <code>text/html</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables on-the-fly compression of responses for the specified MIME types in addition to <code>text/html</code>. The special value <code>*</code> matches any MIME type. Responses with the <code>text/html</code> MIME type are always compressed.</p>"},{"location":"modules/brotli/#brotli_buffers","title":"<code>brotli_buffers</code>","text":"<ul> <li>syntax: <code>brotli_buffers &lt;number&gt; &lt;size&gt;</code></li> <li>default: <code>32 4k|16 8k</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Deprecated, ignored.</p>"},{"location":"modules/brotli/#brotli_comp_level","title":"<code>brotli_comp_level</code>","text":"<ul> <li>syntax: <code>brotli_comp_level &lt;level&gt;</code></li> <li>default: <code>6</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets on-the-fly compression Brotli quality (compression) <code>level</code>. Acceptable values are in the range from <code>0</code> to <code>11</code>.</p>"},{"location":"modules/brotli/#brotli_window","title":"<code>brotli_window</code>","text":"<ul> <li>syntax: <code>brotli_window &lt;size&gt;</code></li> <li>default: <code>512k</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets Brotli window <code>size</code>. Acceptable values are <code>1k</code>, <code>2k</code>, <code>4k</code>, <code>8k</code>, <code>16k</code>, <code>32k</code>, <code>64k</code>, <code>128k</code>, <code>256k</code>, <code>512k</code>, <code>1m</code>, <code>2m</code>, <code>4m</code>, <code>8m</code> and <code>16m</code>.</p>"},{"location":"modules/brotli/#brotli_min_length","title":"<code>brotli_min_length</code>","text":"<ul> <li>syntax: <code>brotli_min_length &lt;length&gt;</code></li> <li>default: <code>20</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the minimum <code>length</code> of a response that will be compressed. The length is determined only from the <code>Content-Length</code> response header field.</p>"},{"location":"modules/brotli/#variables","title":"Variables","text":""},{"location":"modules/brotli/#brotli_ratio","title":"<code>$brotli_ratio</code>","text":"<p>Achieved compression ratio, computed as the ratio between the original and compressed response sizes.</p>"},{"location":"modules/brotli/#sample-configuration","title":"Sample configuration","text":"<pre><code>brotli on;\nbrotli_comp_level 6;\nbrotli_static on;\nbrotli_types application/atom+xml application/javascript application/json application/rss+xml\n             application/vnd.ms-fontobject application/x-font-opentype application/x-font-truetype\n             application/x-font-ttf application/x-javascript application/xhtml+xml application/xml\n             font/eot font/opentype font/otf font/truetype image/svg+xml image/vnd.microsoft.icon\n             image/x-icon image/x-win-bitmap text/css text/javascript text/plain text/xml;\n</code></pre>"},{"location":"modules/brotli/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-brotli.</p>"},{"location":"modules/cache-purge/","title":"cache-purge: NGINX Cache Purge module","text":""},{"location":"modules/cache-purge/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-cache-purge\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-cache-purge\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_cache_purge_module.so;\n</code></pre> <p>This document describes nginx-module-cache-purge v2.5.4  released on Oct 14 2025.</p> <p><code>ngx_cache_purge</code> is <code>nginx</code> module which adds ability to purge content from <code>FastCGI</code>, <code>proxy</code>, <code>SCGI</code> and <code>uWSGI</code> caches. A purge operation removes the  content with the same cache key as the purge request has.</p>"},{"location":"modules/cache-purge/#sponsors","title":"Sponsors","text":"<p>Work on the original patch was fully funded by yo.se.</p>"},{"location":"modules/cache-purge/#status","title":"Status","text":"<p>This module is production-ready.</p>"},{"location":"modules/cache-purge/#configuration-directives-same-location-syntax","title":"Configuration directives (same location syntax)","text":""},{"location":"modules/cache-purge/#fastcgi_cache_purge","title":"fastcgi_cache_purge","text":"<ul> <li>syntax: <code>fastcgi_cache_purge on|off|&lt;method&gt; [purge_all] [from all|&lt;ip&gt; [.. &lt;ip&gt;]]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Allow purging of selected pages from <code>FastCGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#proxy_cache_purge","title":"proxy_cache_purge","text":"<ul> <li>syntax: <code>proxy_cache_purge on|off|&lt;method&gt; [purge_all] [from all|&lt;ip&gt; [.. &lt;ip&gt;]]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Allow purging of selected pages from <code>proxy</code>'s cache.</p>"},{"location":"modules/cache-purge/#scgi_cache_purge","title":"scgi_cache_purge","text":"<ul> <li>syntax: <code>scgi_cache_purge on|off|&lt;method&gt; [purge_all] [from all|&lt;ip&gt; [.. &lt;ip&gt;]]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Allow purging of selected pages from <code>SCGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#uwsgi_cache_purge","title":"uwsgi_cache_purge","text":"<ul> <li>syntax: <code>uwsgi_cache_purge on|off|&lt;method&gt; [purge_all] [from all|&lt;ip&gt; [.. &lt;ip&gt;]]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Allow purging of selected pages from <code>uWSGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#configuration-directives-separate-location-syntax","title":"Configuration directives (separate location syntax)","text":""},{"location":"modules/cache-purge/#fastcgi_cache_purge_1","title":"fastcgi_cache_purge","text":"<ul> <li>syntax: <code>fastcgi_cache_purge zone_name key</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code></li> </ul> <p>Sets area and key used for purging selected pages from <code>FastCGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#proxy_cache_purge_1","title":"proxy_cache_purge","text":"<ul> <li>syntax: <code>proxy_cache_purge zone_name key</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code></li> </ul> <p>Sets area and key used for purging selected pages from <code>proxy</code>'s cache.</p>"},{"location":"modules/cache-purge/#scgi_cache_purge_1","title":"scgi_cache_purge","text":"<ul> <li>syntax: <code>scgi_cache_purge zone_name key</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code></li> </ul> <p>Sets area and key used for purging selected pages from <code>SCGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#uwsgi_cache_purge_1","title":"uwsgi_cache_purge","text":"<ul> <li>syntax: <code>uwsgi_cache_purge zone_name key</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code></li> </ul> <p>Sets area and key used for purging selected pages from <code>uWSGI</code>'s cache.</p>"},{"location":"modules/cache-purge/#configuration-directives-optional","title":"Configuration directives (Optional)","text":""},{"location":"modules/cache-purge/#cache_purge_response_type","title":"cache_purge_response_type","text":"<ul> <li>syntax: <code>cache_purge_response_type html|json|xml|text</code></li> <li>default: <code>html</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets a response type of purging result.</p>"},{"location":"modules/cache-purge/#partial-keys","title":"Partial Keys","text":"<p>Sometimes it's not possible to pass the exact key cache to purge a page. For example; when the content of a cookie or the params are part of the key. You can specify a partial key adding an asterisk at the end of the URL.</p> <pre><code>curl -X PURGE /page*\n</code></pre> <p>The asterisk must be the last character of the key, so you must put the $uri variable at the end.</p>"},{"location":"modules/cache-purge/#sample-configuration-same-location-syntax","title":"Sample configuration (same location syntax)","text":"<pre><code>http {\n    proxy_cache_path  /tmp/cache  keys_zone=tmpcache:10m;\n\n    server {\n        location / {\n            proxy_pass         http://127.0.0.1:8000;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$uri$is_args$args\";\n            proxy_cache_purge  PURGE from 127.0.0.1;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/cache-purge/#sample-configuration-same-location-syntax-purge-all-cached-files","title":"Sample configuration (same location syntax - purge all cached files)","text":"<pre><code>http {\n    proxy_cache_path  /tmp/cache  keys_zone=tmpcache:10m;\n\n    server {\n        location / {\n            proxy_pass         http://127.0.0.1:8000;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$uri$is_args$args\";\n            proxy_cache_purge  PURGE purge_all from 127.0.0.1 192.168.0.0/8;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/cache-purge/#sample-configuration-separate-location-syntax","title":"Sample configuration (separate location syntax)","text":"<pre><code>http {\n    proxy_cache_path  /tmp/cache  keys_zone=tmpcache:10m;\n\n    server {\n        location / {\n            proxy_pass         http://127.0.0.1:8000;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$uri$is_args$args\";\n        }\n\n        location ~ /purge(/.*) {\n            allow              127.0.0.1;\n            deny               all;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$1$is_args$args\";\n        }\n    }\n}\n</code></pre>"},{"location":"modules/cache-purge/#sample-configuration-optional","title":"Sample configuration (Optional)","text":"<pre><code>http {\n    proxy_cache_path  /tmp/cache  keys_zone=tmpcache:10m;\n\n    cache_purge_response_type text;\n\n    server {\n\n        cache_purge_response_type json;\n\n        location / { #json\n            proxy_pass         http://127.0.0.1:8000;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$uri$is_args$args\";\n        }\n\n        location ~ /purge(/.*) { #xml\n            allow              127.0.0.1;\n            deny               all;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$1$is_args$args\";\n            cache_purge_response_type xml;\n        }\n\n        location ~ /purge2(/.*) { # json\n            allow              127.0.0.1;\n            deny               all;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$1$is_args$args\";\n        }\n    }\n\n    server {\n\n        location / { #text\n            proxy_pass         http://127.0.0.1:8000;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$uri$is_args$args\";\n        }\n\n        location ~ /purge(/.*) { #text\n            allow              127.0.0.1;\n            deny               all;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$1$is_args$args\";\n        }\n\n        location ~ /purge2(/.*) { #html\n            allow              127.0.0.1;\n            deny               all;\n            proxy_cache        tmpcache;\n            proxy_cache_key    \"$1$is_args$args\";\n            cache_purge_response_type html;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/cache-purge/#solve-problems","title":"Solve problems","text":"<ul> <li>Enabling <code>gzip_vary</code> can lead to different results when clearing, when enabling it, you may have problems clearing the cache. For reliable operation, you can disable <code>gzip_vary</code> inside the location #20.</li> </ul>"},{"location":"modules/cache-purge/#testing","title":"Testing","text":"<p><code>ngx_cache_purge</code> comes with complete test suite based on Test::Nginx.</p> <p>You can test it by running:</p> <p><code>$ prove</code></p>"},{"location":"modules/cache-purge/#see-also","title":"See also","text":"<ul> <li>ngx_slowfs_cache.</li> <li>http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#purger</li> <li>http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache_purge</li> <li>https://github.com/wandenberg/nginx-selective-cache-purge-module</li> <li>https://github.com/wandenberg/nginx-sorted-querystring-module</li> <li>https://github.com/ledgetech/ledge</li> <li>Faking Surrogate Cache-Keys for Nginx Plus (gist)</li> <li>Delete NGINX cached md5 items with a PURGE with wildcard support</li> </ul>"},{"location":"modules/cache-purge/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-cache-purge.</p>"},{"location":"modules/captcha/","title":"captcha: NGINX Captcha Module","text":""},{"location":"modules/captcha/#installation","title":"Installation","text":"<p>CentOS/RHEL/RockyLinux/etc. and Amazon Linux are supported and require a subscription.</p> <p>Fedora Linux is supported free of charge and doesn't require a subscription.</p>"},{"location":"modules/captcha/#os-specific-complete-installation-and-configuration-guides-available","title":"OS-specific complete installation and configuration guides available:","text":"<ul> <li>CentOS/RHEL 7</li> <li>CentOS/RHEL 8</li> <li>Amazon Linux 2</li> </ul>"},{"location":"modules/captcha/#other-supported-operating-systems","title":"Other supported operating systems","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install nginx-module-captcha\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_captcha_module.so;\n</code></pre> <p>This document describes nginx-module-captcha v0.0.1  released on Apr 14 2023.</p>"},{"location":"modules/captcha/#example-configuration","title":"Example Configuration:","text":"<pre><code>location =/captcha {\n    captcha;\n}\nlocation =/login {\n    set_form_input $csrf_form csrf;\n    set_unescape_uri $csrf_unescape $csrf_form;\n    set_form_input $captcha_form captcha;\n    set_unescape_uri $captcha_unescape $captcha_form;\n    set_md5 $captcha_md5 \"secret${captcha_unescape}${csrf_unescape}\";\n    if ($captcha_md5 != $cookie_captcha) {\n        # captcha invalid code\n    }\n}\n</code></pre>"},{"location":"modules/captcha/#directives","title":"Directives:","text":"<pre><code>Syntax:  captcha;\nDefault: \u2014\u2014\nContext: location\n</code></pre> <p>Enables generation of captcha image.</p> <pre><code>Syntax:  captcha_case on | off;\nDefault: off\nContext: http, server, location\n</code></pre> <p>Enables/disables ignoring captcha case.</p> <pre><code>Syntax:  captcha_expire seconds;\nDefault: 3600\nContext: http, server, location\n</code></pre> <p>Sets seconds before expiring captcha.</p> <pre><code>Syntax:  captcha_height pixels;\nDefault: 30\nContext: http, server, location\n</code></pre> <p>Sets height of captcha image.</p> <pre><code>Syntax:  captcha_length characters;\nDefault: 4\nContext: http, server, location\n</code></pre> <p>Sets length of captcha text.</p> <pre><code>Syntax:  captcha_size pixels;\nDefault: 20\nContext: http, server, location\n</code></pre> <p>Sets size of captcha font.</p> <pre><code>Syntax:  captcha_width pixels;\nDefault: 130\nContext: http, server, location\n</code></pre> <p>Sets width of captcha image.</p> <pre><code>Syntax:  captcha_charset string;\nDefault: abcdefghkmnprstuvwxyzABCDEFGHKMNPRSTUVWXYZ23456789\nContext: http, server, location\n</code></pre> <p>Sets characters used in captcha text.</p> <pre><code>Syntax:  captcha_csrf string;\nDefault: csrf\nContext: http, server, location\n</code></pre> <p>Sets name of csrf var of captcha.</p> <pre><code>Syntax:  captcha_font string;\nDefault: /usr/share/fonts/ttf-liberation/LiberationSans-Regular.ttf\nContext: http, server, location\n</code></pre> <p>Sets font of captcha text.</p> <pre><code>Syntax:  captcha_name string;\nDefault: Captcha\nContext: http, server, location\n</code></pre> <p>Sets name of captcha cookie.</p> <pre><code>Syntax:  captcha_secret string;\nDefault: secret\nContext: http, server, location\n</code></pre> <p>Sets secret of captcha.</p>"},{"location":"modules/captcha/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-captcha.</p>"},{"location":"modules/cgi/","title":"cgi: CGI support for NGINX","text":""},{"location":"modules/cgi/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-cgi\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-cgi\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_cgi_module.so;\n</code></pre> <p>This document describes nginx-module-cgi v0.14.1  released on Sep 15 2025.</p> <p>Brings CGI support to Nginx and Angie webserver.</p> OS Tested with Nginx Angie Linux AlmaLinux 9, Debian 12 and Ubuntu 24.04/20.04 okay okay Darwin MacOS 15.1 okay okay BSD FreeBSD 14.2 and OpenBSD 7.6 okay okay Solaris OmniOS r1510521 okay okay Windows No plan, nginx barely supports Windows"},{"location":"modules/cgi/#before-everything","title":"Before everything","text":"<p>CGI is neither a demon nor an angel. It is simply a tool. Just like a chef's knife in the hands of a cook or a sword in the hands of a warrior, you won't use a sword for cooking, nor you take a chef's knife to the battlefield. The same goes for CGI, it has its appropriate scenarios, and it should not be misused or demonized.</p> <p>CGI is good for:</p> <ul> <li>Low frequency applications, such as system management</li> <li>Resource limited systems, such as embeding system</li> <li>Low budget projects, such as personal websites</li> <li>Prototyping, for fast iterate</li> </ul> <p>CGI is bad for:</p> <ul> <li>High QPS</li> <li>High traffic</li> <li>High concurrency</li> </ul> <p>I created a discord channel. If:</p> <ul> <li>You are also a fun of CGI</li> <li>If you have any problem with nginx-cgi</li> <li>If you want to get update of nginx-cgi</li> <li>If you want to know more friends</li> </ul> <p>Please join us: https://discord.gg/EJSfqHHmaR.</p>"},{"location":"modules/cgi/#quick-start-with-debian-12-ubuntu-2404","title":"Quick start (with Debian 12+, Ubuntu 24.04+)","text":"<p>Build and install:</p> <pre><code>## checkout source code\ngit clone https://github.com/pjincz/nginx-cgi\ncd nginx-cgi\n\n#!/bin/bash\n\necho \"Content-Type: text/plain\"\necho\n\necho Hello CGI\n</code></pre> <p>Add x perm to cgi script:</p> <pre><code>chmod +x /var/www/html/cgi-bin/hello.sh\n</code></pre> <p>Now, try it:</p> <pre><code>curl http://127.0.0.1/cgi-bin/hello.sh\n</code></pre> <p>If you nothing wrong, you will get an output of <code>Hello CGI</code>.</p>"},{"location":"modules/cgi/#usage","title":"Usage","text":""},{"location":"modules/cgi/#loading-plugin","title":"Loading plugin","text":"<p>If this plugin is installed to nginx's default module path (such as <code>/usr/lib/nginx/modules</code>), the plugin will be loaded automatically. Otherwise, you need to manually load the plugin by <code>load_module</code>.</p> <p>Add following statement to nginx's top level context to load the plugin:</p> <pre><code>load_module &lt;dir-of-plugin&gt;/ngx_http_cgi_module.so;\n</code></pre>"},{"location":"modules/cgi/#enable-cgi","title":"Enable cgi","text":"<p>After loading the plugin, you can add <code>cgi on</code> to location contexts to enable cgi. Example:</p> <pre><code>location /cgi-bin {\n    cgi on;\n}\n</code></pre> <p>Once cgi turned on on a location, all nested locations will also have cgi turned on. If you want to disable cgi for a child location, just use <code>cgi off</code>.</p> <p>When the location is accessed, nginx-cgi will find the script under the document root (it's specified by <code>root</code> statement). For example, if you have specify the document root as <code>/var/www/html</code>, then when you access <code>/cgi-bin/hello.sh</code>, <code>/var/www/html/cgi-bin/hello.sh</code> will be executed.</p> <p>Nginx-cgi also support <code>alias</code>, it like <code>root</code> statement in nginx, the only difference is the location prefix will be removed from uri. For example, if you want <code>/cgi/hello.sh</code> also reference to the same script, you can do this:</p> <pre><code>location /cgi {\n    alias /var/www/html/cgi-bin;\n    cgi on;\n}\n</code></pre>"},{"location":"modules/cgi/#hello-script","title":"Hello script","text":"<p>A cgi script can be wrotten by any language. Here's an exmaple with shell. You can save it to <code>/var/www/html/cgi-bin/hello.sh</code> for testing (if you didn't change the default document root):</p> <pre><code>#!/bin/sh\n\necho \"Status: 200 OK\"\necho \"Content-Type: text/plain\"\necho\n\necho \"Hello world\"\n</code></pre> <p>The first line of the script is a shebang. If you clearly set <code>cgi_interpreter</code>, it's okay to remove this line, otherwise missing of shebang will causes a 500 error. Some shell allows script be executable even without shebang, but it's not allowed here. If a script runable by shell, but return 500 error, check the shebang.</p> <p>The output of cgi script contains 2 sections: the header section and body section. The first 2 <code>echo</code> statements output the header section, and the last <code>echo</code> statement outputs the body section. The <code>echo</code> statement in middle outputs the separator. Both header section and body section can be empty, but the separator is mandatory. Missing of separator will causes an 500 error.</p> <p>All lines in header section will be parsed as normal http response header line. And then passed to the client side. There's one special header <code>Status</code>, it will be passed in response status line. If <code>cgi_strict</code> is on, nginx-cgi will check all cgi output headers, and 500 error will be responsed if invalid header found. Otherwise, invalid headers will be forwarded to client side too. It's fully recommanded to keep <code>cgi_strict</code> on.</p> <p>After separator, all output will be sent to client as body as it is.</p>"},{"location":"modules/cgi/#x-permission","title":"x permission","text":"<p>After all, you need to add the x permission to the file:</p> <pre><code>chmod +x /var/www/html/cgi-bin/hello.sh\n</code></pre> <p>Normally, you need x-permission to make script runable. Missing of x-permission can cause 403 error. If can't do this for any reason, <code>cgi_interpreter</code> can help.</p>"},{"location":"modules/cgi/#request-header","title":"Request header","text":"<p>Request headers will be parsed and then translated to environment variables and then passed to cgi script.</p> <p>For example, you can find the query string in <code>QUERY_STRING</code> environment var. And access <code>Http-Accept</code> by <code>HTTP_ACCPET</code>.</p> <p>Here's an example:</p> <pre><code>#!/bin/sh\necho \"\"\n\necho \"query string: $QUERY_STRING\"\necho \"http accept: $HTTP_ACCEPT\"\n</code></pre> <p>For full list of environment variables, see environment section.</p>"},{"location":"modules/cgi/#request-body","title":"Request body","text":"<p>The request body will be passed via stdin. Here's an example to read all request body and echo it:</p> <pre><code>#!/bin/sh\necho \"\"\n\nbody=$(cat)\n\necho \"request body: $body\"\n</code></pre>"},{"location":"modules/cgi/#streaming","title":"Streaming","text":"<p>Nginx-cgi has streaming support for both request and response body. For example, we can implement a simplest online caculator by <code>bc</code>:</p> <pre><code>#!/bin/sh\necho \"\"\n\nbc 2&gt;&amp;1\n</code></pre> <p>Then we can test our caculator by <code>curl</code>:</p> <pre><code>curl 127.0.0.1/cgi-bin/bc.sh --no-progress-meter -T .\n</code></pre> <p>The nginx-cgi plugin is smart enough to choose the correct way to return the request body. If it got all output soon enough, it will output the body in once. If the output is delayed, it will output the body chunkly(HTTP 1.1) or streamingly (HTTP 1.0).</p>"},{"location":"modules/cgi/#hop-by-hop-http-headers","title":"Hop-by-hop http headers","text":"<p>Hop-by-hop http headers are not allowed in cgi script output. If it appears in response here, a 500 error will response to the client.</p> <p>For more information: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers#hop-by-hop_headers</p>"},{"location":"modules/cgi/#tricks-faq","title":"Tricks &amp;&amp; FAQ","text":""},{"location":"modules/cgi/#i-want-to-list-all-environment-variables","title":"I want to list all environment variables","text":"<p>Put following script to your cgi directory, and curl it form your terminal:</p> <pre><code>#!/bin/sh\n\necho 'Content-Type: text/plain'\necho\n\nprintenv\n</code></pre>"},{"location":"modules/cgi/#i-want-root-permission","title":"I want root permission","text":"<p>Put a sudo file to <code>/etc/sudoers.d</code> and run <code>sudo</code> in your script or set <code>cgi_interpreter</code> as <code>/usr/bin/sudo</code>.</p> <p>Here's an example of sudo config file:</p> <pre><code>## allow wwww-data run /var/www/bin/my-danger-script with root account\nwww-data ALL=(root) NOPASSWD: /var/www/bin/my-danger-script\n\n## allow all CGI script be launched with sudo by nginx-cgi directly\nwww-data ALL=(root) NOPASSWD: SETENV: /var/www/html/cgi-bin/*\n</code></pre>"},{"location":"modules/cgi/#how-can-i-run-cgi-scripts-with-chroot","title":"How can I run CGI scripts with chroot","text":"<p>It's highly not recommanded to run CGI script with chroot. Because chroot is not designed for security purpose. It still shared a lot of kernel spaces with host system. For example, run <code>ps -ef</code> in chrooted process, all processes in host system will return. That sould not too aweful? No, that's really terrible, because you can also do <code>kill</code> in chrooted script for the same reason. And people normally run programs with root permission in chrooted environment. That's terribly bad. It causes system on high risk than just run script with <code>www-data</code>.</p> <p>If you want a sandbox environment, <code>lxc</code>, <code>docker</code> and <code>jails</code> are much better for this purpose.</p> <p>If you still want <code>chroot</code>, okay let me show you how to do it.</p> <p>In this example, I assume you're using <code>/var/www/html</code> as the document root.</p> <p>Prepare a CGI script first:</p> <pre><code>mkdir -p /var/www/html/cgi-bin\ncat &gt; /var/www/html/cgi-bin/ls.sh &lt;&lt;EOF\n#!/bin/sh\necho \"Status: 200\"\necho \"Content-Type: text-plain\"\necho\necho \"files under /:\"\nls /\nEOF\nchmod +x /var/www/html/cgi-bin/ls.sh\n\n## try it\n/var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Step 1: prepare a chroot directory.</p> <p>That're a lot of ways to do this step. <code>debootstrap</code> is a popular way on debian based system. <code>busybox</code> is the most light way. <code>docker</code> is a modern way.</p> <p>Let's make a lightest directory with <code>busybox</code> here:</p> <pre><code>## In this example, I put everything to /var/www/chroot\n## Be careful, I download x86_64 busybox version here, you may need to change it\n## You need root permission to run all following commands, I'm too lazy to\n## prepend sudo to every commands here.\n\nroot_dir=/var/www/chroot\n\nmkdir -p \"$root_dir/bin\" &amp;&amp; cd \"$root_dir/bin\"\nwget https://www.busybox.net/downloads/binaries/1.35.0-x86_64-linux-musl/busybox\nchmod +x busybox\n\ncd \"$root_dir\"\nmkdir -p $(dirname $(./bin/busybox --list-full) | sort -u)\n./bin/busybox --list-full | while read line; do ln -sf /bin/busybox $line; done\n\n## try it\nchroot \"$root_dir\" ls\n</code></pre> <p>Step 2: mount document root into chroot dir</p> <pre><code>mkdir -p /var/www/chroot/var/www/html\nmount --bind /var/www/html /var/www/chroot/var/www/html\n\n## try it\nls /var/www/chroot/var/www/html\n</code></pre> <p>Notice:</p> <ul> <li> <p>I use a trick here, after chroot, the document root is still the same. By this   we can same some time to do path mapping.</p> </li> <li> <p>The mounting will not persist after a reboot. You may need to add an entry to   /etc/fstab. Or move /var/www/html into chroot, and make a symbolic link   outside.</p> </li> </ul> <p>Step 3: allow <code>www-data</code> to run <code>chroot</code> with root permission.</p> <pre><code>cat &gt;/etc/sudoers.d/www-run-with-chroot &lt;&lt;EOF\n## allow and only allow www-data run chroot with /var/www/chroot\nwww-data ALL=(root) NOPASSWD: /usr/sbin/chroot /var/www/chroot *\nEOF\n</code></pre> <p>Now everything is ready, add following section to your nginx/angie:</p> <pre><code>location /cgi-bin {\n    cgi on;\n    cgi_interpreter /usr/bin/sudo /usr/sbin/chroot /var/www/chroot;\n}\n</code></pre> <p>try it:</p> <pre><code>curl 127.0.0.1/cgi-bin/ls.sh\n</code></pre>"},{"location":"modules/cgi/#how-can-i-run-cgi-scripts-with-docker","title":"How can I run CGI scripts with docker","text":"<p>In this example, I assume you're using <code>/var/www/html</code> as the document root.</p> <p>Prepare a CGI script first:</p> <pre><code>mkdir -p /var/www/html/cgi-bin\ncat &gt; /var/www/html/cgi-bin/ls.sh &lt;&lt;EOF\n#!/bin/sh\necho \"Status: 200\"\necho \"Content-Type: text-plain\"\necho\necho \"files under /:\"\nls /\nEOF\nchmod +x /var/www/html/cgi-bin/ls.sh\n\n## try it\n/var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Create a container and keep running in the background:</p> <pre><code>## Change -v if necessary\n## -d: runs background\n## -i -t: keep a terminal\n## --restart always: keep container alive\ndocker run -dit --restart always --name my_cgi_docker -v /var/www:/var/www busybox sh\n\n## try it\ndocker exec my_cgi_docker /var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Allow <code>www-data</code> to run <code>docker</code> commands:</p> <pre><code>sudo usermod -aG docker www-data\n\n## try it\nsudo -u www-data docker exec my_cgi_docker /var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Now everything is ready, add following section to your nginx/angie:</p> <pre><code>location /cgi-bin {\n    cgi on;\n    cgi_interpreter /usr/bin/docker exec my_cgi_docker;\n}\n</code></pre>"},{"location":"modules/cgi/#how-can-i-run-cgi-scripts-with-jails","title":"How can I run CGI scripts with jails","text":"<p>Okay, you're a fan of FreeBSD? Me too.</p> <p>It's really similar to running scripts with <code>chroot</code>.</p> <p>Here I assume you're using <code>/var/www/html</code> as the document root too.</p> <p>Prepare a CGI script first:</p> <pre><code>mkdir -p /var/www/html/cgi-bin\ncat &gt; /var/www/html/cgi-bin/ls.sh &lt;&lt;EOF\n#!/bin/sh\necho \"Status: 200\"\necho \"Content-Type: text-plain\"\necho\necho \"files under /:\"\nls /\nEOF\nchmod +x /var/www/html/cgi-bin/ls.sh\n\n## try it\n/var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Step 1: create a jail</p> <p>Let's put the jail to <code>/var/www/jail</code>.</p> <pre><code>mkdir -p /var/www/jail &amp;&amp; cd /var/www/jail\nfetch https://download.freebsd.org/ftp/releases/$(uname -m)/$(uname -m)/$(uname -r)/base.txz\ntar -xvf base.txz -C .\n\n## create mount points\nmkdir -p /var/www/jail/var/www/html\ntouch /var/www/jail/etc/resolv.conf\n</code></pre> <p>Put following config to <code>/etc/jail.conf</code>:</p> <pre><code>www-jail {\n    path = \"/var/www/jail\";\n    host.hostname = \"www-jail.local\";\n\n    exec.clean;\n    exec.start = \"/bin/sh /etc/rc\";\n    exec.stop = \"/bin/sh /etc/rc.shutdown\";\n\n    # mount /var/www/html =&gt; /var/www/jail/var/www/html\n    exec.prestart += \"mount_nullfs /var/www/html /var/www/jail/var/www/html || true\";\n    mount.devfs;\n\n    # uncomment following lines, if you want to allow network access in jail\n    # ip4 = inherit;\n    # ip6 = inherit;\n    # exec.prestart += \"mount_nullfs /etc/resolv.conf /var/www/jail/etc/resolv.conf || true\";\n\n    # uncomment fowlling lines, if you also want `ping` available in jail\n    # allow.raw_sockets = 1;\n\n    persist; # keep jail if no process runs\n}\n</code></pre> <p>And ensure that following line appears in <code>/etc/rc.conf</code>:</p> <pre><code>jail_enable=\"YES\"\n</code></pre> <p>And start the jail:</p> <pre><code>service jail start www-jail\n\n## try it\njexec www-jail ls /\njexec www-jail /var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Step 2: allow <code>www</code> to run <code>jexec</code> with root permission.</p> <p>I uses <code>sudo</code> here. I'm not familiar with <code>doas</code>, if you prefer <code>doas</code> you can try it yourself. Anyhow, neither <code>sudo</code> nor <code>doas</code> preloaded with FreeBSD. You need to manually install one of them.</p> <pre><code>cat &gt;/usr/local/etc/sudoers.d/www-jexec &lt;&lt;EOF\n## allow and only allow `www` run `jexec` with `www-jail`\nwww ALL=(root) NOPASSWD: /usr/sbin/jexec www-jail *\nEOF\n\n## try it\nsudo -u www sudo jexec www-jail /var/www/html/cgi-bin/ls.sh\n</code></pre> <p>Now everything is ready, add following section to your nginx/angie:</p> <pre><code>location /cgi-bin {\n    cgi on;\n    cgi_interpreter /usr/local/bin/sudo /usr/sbin/jexec www-jail;\n}\n</code></pre> <p>try it:</p> <pre><code>curl 127.0.0.1/cgi-bin/ls.sh\n</code></pre>"},{"location":"modules/cgi/#i-want-create-a-long-run-background-process","title":"I want create a long-run background process","text":"<p>Just make sure not to inherit <code>stdout</code> when creating the process (ideally, avoid inheriting <code>stdin</code> and <code>stderr</code> as well). Here's an example write in shell.</p> <pre><code>taskid=1234\nlogfile=\"/var/lib/my-project/$taskid\"\n./long-run-task.sh \"$taskid\" &lt;/dev/null &gt;\"$logfile\" 2&gt;&amp;1 &amp;\n</code></pre> <p>Or if you are familiar with pipe operation, just close <code>stdout</code> (also, it's better to close <code>stdin</code> and <code>stderr</code> as well), http request will finished immediently. And you can use the process as background process.</p> <pre><code>exec &lt;/dev/null &gt;somewhere 2&gt;&amp;1\n\n## now http response is done, do what every you like\nsleep 9999\n</code></pre>"},{"location":"modules/cgi/#my-http-request-hangs","title":"My http request hangs","text":"<p>As you see abvoing. In CGI world, http request's lifecycle depends on pipe's (stdout's) lifecycle.</p> <p>Each child process might inherit the CGI process's pipe. If any process that inherited stdout remains alive, the HTTP request will never finish.</p> <p>This may causes confiusing, when you want a long run background or killing CGI process.</p> <p>For creating long-run process, see aboving topic.</p> <p>For killing CGI process, kill the whole process group rather than CGI process itself.</p> <pre><code>cgi_pid=...\n\n## don't do this\n## kill \"$cgi_pid\"\n\n## do this\nkill -- \"-$cgi_pid\"\n</code></pre>"},{"location":"modules/cgi/#i-want-to-kill-my-cgi-script","title":"I want to kill my cgi script","text":"<p>See aboving topic.</p>"},{"location":"modules/cgi/#i-want-to-generate-content-dynamicaly","title":"I want to generate content dynamicaly","text":"<p>Traditionally, people use rewriting to archive this. But it's much easier here. You can do it with <code>cgi pass</code>. Here's an example to render markdone dynamically:</p> <pre><code>{\n    location ~ ^.*\\.md$ {\n        cgi_pass /var/www/bin/cgi/render-markdown.sh;\n    }\n}\n</code></pre> <pre><code>#!/bin/sh\n\nset -e\n\nif [ ! -f \"${DOCUMENT_ROOT}${PATH_INFO}\" ]; then\n    echo \"Status: 404\"\n    echo\n    exit\nfi\n\necho \"Status: 200\"\necho \"Content-Type: text/html\"\necho\n\necho \"&lt;html&gt;&lt;body&gt;\"\nmarkdown \"${DOCUMENT_ROOT}${PATH_INFO}\"\necho \"&lt;/body&gt;&lt;/html&gt;\"\n</code></pre>"},{"location":"modules/cgi/#i-dont-like-suffixes-in-url","title":"I don't like suffixes in url","text":"<p>Way 1: Removing CGI script's suffix</p> <p>Way 2: do rewriting</p> <p>Way 3: <code>cgi pass</code></p>"},{"location":"modules/cgi/#how-can-i-response-status-other-than-200","title":"How can I response status other than 200","text":"<pre><code>#!/bin/sh\n\necho \"Status: 404\"\necho \"Content-Type: text/plain\"\necho\n\necho \"Welcome to the void\"\n</code></pre>"},{"location":"modules/cgi/#how-can-i-response-a-redirection","title":"How can I response a redirection","text":"<pre><code>#!/bin/sh\n\necho \"Status: 302\"\necho \"Location: https://theuselessweb.com\"\necho\n</code></pre>"},{"location":"modules/cgi/#how-can-i-get-http-request-body","title":"How can I get http request body","text":"<p>You can read the request body from <code>stdin</code>. If you're using shell, <code>cat</code> can quickly save request body to a file.</p>"},{"location":"modules/cgi/#how-can-send-file-to-the-client","title":"How can send file to the client","text":"<p>For small files, you can write file to <code>stdout</code> directly.</p> <p>For large files, it's much better to send a 302 response. Because CGI response is streaming, protocol cannot easily handle caching, chunked downloads, or resume support.</p>"},{"location":"modules/cgi/#i-want-to-write-cgi-with-python-ruby-perl-c-c","title":"I want to write CGI with python, ruby, perl, C, C++...","text":"<p>Go for it. Nginx-cgi don't care what language you use. Just grabs information from environment var, and read request body from <code>stdin</code>, and write output to <code>stdout</code>.</p>"},{"location":"modules/cgi/#manual","title":"Manual","text":""},{"location":"modules/cgi/#options","title":"Options","text":""},{"location":"modules/cgi/#cgi-onoff-or-cgi-pass-script_path-script_args","title":"<code>cgi &lt;on|off&gt;</code> or <code>cgi pass &lt;script_path&gt; [script_args...]</code>","text":"<p>Enable or disable cgi module on giving location block.</p> <p>If you specify <code>on</code> here, the plugin will work in traditional mode. It parses the request uri first, and then locate the script under document root directory with request uri. After all it splits request uri to <code>SCRIPT_NAME</code> and <code>PATH_INFO</code>. This is good if you have an old CGI project or you want to strictly follow rfc3875.</p> <p>I also provided a nginx style syntax here. If you specify <code>cgi pass</code> here, the plugin will skip the step to locate the CGI script. It uses the the value you provided directly. You can references nginx variables in the second argument, eg: <code>cgi pass $document_root$uri</code>. The aboving example do something similar to rfc3875, but not equal. In this form, request uri will be assigned to <code>PATH_INFO</code> directly. And <code>SCRIPT_NAME</code> will be empty. This form is really good for dynamic content generating. It gets around the complex and unnecessary uri re-writing.</p> <p>Additionally, the second form also provides you the ability to pass additional args to script, eg: <code>cgi pass my_script.sh $uri</code>. With this, you can totally avoid confusing rfc3875 environment variables.</p> <p>If you specify <code>off</code> here, the plugin will be disabled.</p> <p>Default: off</p>"},{"location":"modules/cgi/#cgi_pass-script_path","title":"<code>cgi_pass &lt;script_path&gt;</code>","text":"<p>Alias of <code>cgi pass &lt;script_path&gt;</code>.</p>"},{"location":"modules/cgi/#cgi_interpreter-interpreter-args","title":"<code>cgi_interpreter [interpreter] [args...]</code>","text":"<p>Set interpreter and interpreter args for cgi script.</p> <p>When this option is not empty, cgi script will be run with giving interpreter. Otherwise, script will be executed directly.</p> <p>This option can contains nginx variables, see https://nginx.org/en/docs/varindex.html for more details.</p> <p>This option is extremely useful in a lot of senarios, for example:</p> <ul> <li>run CGI scripts missing x-perm</li> <li>do sudo before executing CGI script</li> <li>wrap general binary as CGI script</li> <li>filter CGI script output</li> <li>...</li> </ul> <p>Default: empty</p>"},{"location":"modules/cgi/#cgi_working_dir-dir","title":"<code>cgi_working_dir &lt;dir&gt;</code>","text":"<p>Set the working directory of CGI script.</p> <p>If this value is set to empty, CGI scripts will inherit nginx' working directory.</p> <p>If this value is set to an non-empty string, the CGI script will be launched with giving working directory.</p> <p>The action of changing working directory may failed. For example, giving directory doesn't exist, no perm or name too long. In this case, script will failed to execute.</p> <p>This option doesn't change the way to find interpreter or script (if they are specified with related path, they are always related to nginx' working directory).</p> <p>This option can contain nginx variable. Althrough I don't know what use this is. Maybe you can setup different working dir for different server_name by this.</p> <p>Default: empty</p>"},{"location":"modules/cgi/#cgi_body_only-onoff","title":"<code>cgi_body_only &lt;on|off&gt;</code>","text":"<p>A standard CGI script should output two parts: header and body. And an empty line to split those two parts.</p> <p>If you want to simply run a normal program as CGI program. You can turn this on.</p> <p>Once this option is enabled, all outout will be treated as response body, and be sent to the client.</p> <p>Default: off</p>"},{"location":"modules/cgi/#cgi_path-path","title":"<code>cgi_path &lt;PATH&gt;</code>","text":"<p>Change cgi script PATH environment variable.</p> <p>Default: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</p>"},{"location":"modules/cgi/#cgi_strict-onoff","title":"<code>cgi_strict &lt;on|off&gt;</code>","text":"<p>Enable or disable strict mode.</p> <p>When strict mode turns on, bad cgi header will cause 500 error. When strict mode turns off, bad cgi header be forward as it is.</p> <p>Default: on</p>"},{"location":"modules/cgi/#cgi_set_var-name-value","title":"<code>cgi_set_var &lt;name&gt; &lt;value&gt;</code>","text":"<p>Add and pass extra environment variables to CGI script. The first argument of this command is the name of environment variable. It should contains only alphabets, numbers and underscore, and doesn't start with number. The second argument of this command is the value express of the var. It can contains nginx variables, see https://nginx.org/en/docs/varindex.html for more details.</p> <p>This option can appears more than 1 time to set multiple variables. If more than one option set the same var, then the last one works. These directives are inherited from the previous configuration level if and only if there's no cgi_set_var directives defined on the current level.</p> <p>This option can also be used to override standard CGI vars. This may be useful in some case, for example hacking old CGI script or simulate standard vars that are not supported by this plugin now (Such as <code>PATH_TRANSLATED</code>, <code>REMOTE_IDENT</code>). But it's not recommanded, it may introduce confusing issues to your system.</p>"},{"location":"modules/cgi/#cgi_stderr-path","title":"<code>cgi_stderr &lt;path&gt;</code>","text":"<p>Redirect cgi stderr to giving file.</p> <p>By default, nginx-cgi grab cgi script's stderr output and dump it to nginx log. But this action is somewhat expensive, because it need to create an extra connection to listen stderr output. If you want to avoid this, you can use this option to redirect cgi script's stderr output to a file. Or you can even discard all stderr output by redirect to <code>/dev/null</code>. Also you can use this to redirect all stderr output to nginx's stderr by set it as <code>/dev/stderr</code>.</p>"},{"location":"modules/cgi/#cgi_rdns-onoffdouble-required","title":"<code>cgi_rdns &lt;on|off|double&gt; [required]</code>","text":"<p>Enable or disable reverse dns.</p> <p><code>off</code>: disable rdns feature.</p> <p><code>on</code>: Do reverse dns before launching cgi script, and pass rdns result to cgi script via <code>REMOTE_HOST</code> environment variable.</p> <p><code>double</code>: After reverse dns, do a forward dns again to check the rdns result. if result matches, pass result as <code>REMOTE_HOST</code>.</p> <p><code>required</code>: If rdns failed, 403, 503 or 500 returns to the client. Depends on the failure reason of rdns.</p> <p>If you turns this option on, you need to setup a <code>resolver</code> in nginx too. Otherwise you will get an error of <code>no resolver defined to resolve</code>.</p> <p>author notes: do not enable this option, it will makes every request slower. this feature can be easily implemented by <code>dig -x</code> or <code>nslookup</code> in script. the only reason I implement this is just to make the module fully compliant with the rfc3875 standard.</p>"},{"location":"modules/cgi/#cgi_timeout-t1-t2","title":"<code>cgi_timeout &lt;t1&gt; [t2]</code>","text":"<p>Send <code>TERM</code>/<code>KILL</code> signals to the CGI process if it runs too long.</p> <p>If both <code>t1</code> and <code>t2</code> equal to <code>0</code>. Timeout feature is disabled.</p> <p>If <code>t1</code> or <code>t2</code> doesn't equal to <code>0</code>. A <code>TERM</code> or <code>KILL</code> signal will be sent to the process after timeout.</p> <p>If both <code>t1</code> and <code>t2</code> not zero. Send <code>TERM</code> at <code>t1</code> timestamp first. And send <code>KILL</code> again at <code>t1+t2</code> timestamp (if process still alive at that timestamp).</p> <p>If <code>t2</code> doesn't present, it treated as <code>0</code>.</p> <p>Default: 0 0</p>"},{"location":"modules/cgi/#standard-environment-variables","title":"Standard Environment Variables","text":"<p>Nginx-cgi implemented almost all rfc3875 standard variables. If they cannot cover all of your usage, you can add your own variable by <code>cgi_set_var</code>. Also those variables can be overrided by <code>cgi_set_var</code> if you really want to.</p> <ul> <li><code>AUTH_TYPE</code>, <code>REMOTE_USER</code> (rfc3875 standard)</li> </ul> <p>If cgi script is behind an authorization module (such as <code>ngx_http_auth_basic_module</code>), and the authorization is succeed, the value is set to auth type (such as <code>Basic</code>) and authorized user.</p> <p>If no authorization module enabled, no matter client passes autoriazation header or not. Those 2 fields are not present.</p> <p><code>Authorization</code> header is not visible in cgi script for security reason. If you really want to do authorization in CGI script, try <code>cgi_set_var</code>.</p> <ul> <li><code>CONTENT_LENGTH</code>, <code>CONTENT_TYPE</code> (rfc3875 standard)</li> </ul> <p>Same to request header's <code>Content-Length</code> and <code>Content-Type</code>.</p> <ul> <li><code>GATEWAY_INTERFACE</code> (rfc3875 standard)</li> </ul> <p>Always be <code>CGI/1.1</code> in this plugin.</p> <ul> <li><code>PATH_INFO</code> (rfc3875 standard)</li> </ul> <p>Let's say if you have a script under <code>/cgi-bin/hello.sh</code>, and you access <code>http://127.0.0.1/cgi-bin/hello.sh/somewhat</code>.</p> <p>Then <code>PATH_INFO</code> contains the string <code>/somewhat</code>.</p> <p>Combination with url <code>rewrite</code> or <code>cgi pass</code>, this variable can be used for dynamic content generating.</p> <ul> <li><code>PATH_TRANSLATED</code> (rfc3875 standard)</li> </ul> <p>Note: this option is not implemented strictly compliant with rfc3875. Please avoid this, if you are writing new CGI script.</p> <p>This is related to <code>PATH_INFO</code>.</p> <p>Let's say if you have a script under <code>/cgi-bin/hello.sh</code>, and you access <code>http://127.0.0.1/cgi-bin/hello.sh/somewhat</code>.</p> <p>The standard says, the server should try again with <code>http://127.0.0.1/somewhat</code>, and found out where the uri should mapped to.</p> <p>For technical reason, I just construct this variable by document root and <code>PATH_INFO</code>.</p> <p>The behaviour may be changed in future version.</p> <ul> <li><code>QUERY_STRING</code> (rfc3875 standard)</li> </ul> <p>Contains the query string of the request. For example, if you are accessing <code>http://127.0.0.1/cgi-bin/hello.sh?a=1&amp;b=2</code>, <code>QUERY_STRING</code> will contains <code>a=1&amp;b=2</code>.</p> <ul> <li><code>REMOTE_ADDR</code>, (rfc3875 standard)</li> </ul> <p>Client ip address.</p> <ul> <li><code>REMOTE_HOST</code> (rfc3875 standard)</li> </ul> <p>Client host name. Only available if <code>cgi_rdns</code> is turns on.</p> <p>If <code>cgi_rdns</code> is on, nginx-cgi will do a reverse DNS, and find a domain matches <code>REMOTE_ADDR</code>. If any found, it will be set to <code>REMOTE_HOST</code>.</p> <p>If <code>cgi_rdns</code> is double, after the RDNS, nginx-cgi will do a forward DNS again. <code>REMOTE_HOST</code> will only be set if the forward DNS result matches the original address.</p> <p>See <code>cgi_rdns</code> for more information.</p> <ul> <li><code>REMOTE_IDENT</code> (rfc3875 standard)</li> </ul> <p>Nginx-cgi plugin doesn't support this for security reason.</p> <ul> <li><code>REQUEST_METHOD</code> (rfc3875 standard)</li> </ul> <p>Request method of the request, for example: <code>GET</code>, <code>POST</code>...</p> <ul> <li><code>SCRIPT_NAME</code> (rfc3875 standard)</li> </ul> <p>Path to current script. Normally, you don't need this. It doesn't contains the full path. See <code>SCRIPT_FILENAME</code>.</p> <p>The only reason to use this is construct the URI after rewriting. You can use <code>SCRIPT_NAME</code> + <code>PATH_INFO</code> to get the URI after rewriting.</p> <ul> <li><code>SERVER_NAME</code> (rfc3875 standard)</li> </ul> <p>Server name, normally it equals to <code>Host</code> header without port part. If <code>Host</code> header doesn't appear in the request (HTTP/1.0) or contains invalid value, then this value is set to the reflect server ip address. If the ip address is an ipv6 address, it will be quoted with bracket like <code>[::1]</code>.</p> <ul> <li><code>SERVER_PORT</code> (rfc3875 standard)</li> </ul> <p>Server listening port, such as <code>80</code>, <code>443</code>...</p> <ul> <li><code>SERVER_PROTOCOL</code> (rfc3875 standard)</li> </ul> <p>The protocol used between client and server. Such as <code>HTTP/1.0</code>, <code>HTTP/1.1</code>...</p> <ul> <li><code>SERVER_SOFTWARE</code> (rfc3875 standard)</li> </ul> <p>Contains a string of nginx and version, such as <code>nginx/1.27.4</code>.</p> <ul> <li><code>X_</code> (rfc3875 standard)</li> </ul> <p>All <code>X-</code> prefixed http request header will be convert to <code>X_</code> variables. For example:</p> <p>If <code>X-a: 123</code> appears in header, <code>X_A</code> will be set to <code>123</code>.</p> <ul> <li><code>HTTP_</code> (rfc3875 standard)</li> </ul> <p>All other http request header will be convert to <code>HTTP_</code> variables, for example:</p> <p>If <code>Accept: */*</code> appears in header, <code>HTTP_ACCEPT</code> will be set to <code>*/*</code>.</p> <ul> <li><code>DOCUMENT_ROOT</code> (non-standard, impled by apache2)</li> </ul> <p>Document root of current location block, see <code>root</code> stmt in nginx.</p> <ul> <li><code>REMOTE_PORT</code> (non-standard, impled by apache2)</li> </ul> <p>Client port number.</p> <ul> <li><code>REQUEST_SCHEME</code> (non-standard, impled by apache2)</li> </ul> <p><code>http</code> or <code>https</code>.</p> <ul> <li><code>REQUEST_URI</code> (non-standard, impled by apache2)</li> </ul> <p>The raw uri before rewriting. If you want the URL after rewriting, try <code>SCRIPT_NAME</code> + <code>PATH_INFO</code>.</p> <p>Note: this variable doesn't same to nginx varible <code>$request_uri</code>. You can find the document at https://httpd.apache.org/docs/2.4/mod/mod_rewrite.html.</p> <ul> <li><code>SCRIPT_FILENAME</code> (non-standard, impled by apache2)</li> </ul> <p>The full path to the CGI script.</p> <ul> <li><code>SERVER_ADDR</code> (non-standard, impled by apache2)</li> </ul> <p>Server ip address. If the server has multiple ip addresses. The value of this variable can be different if requests came from different interfaces.</p>"},{"location":"modules/cgi/#known-issues","title":"Known Issues","text":""},{"location":"modules/cgi/#path_translated-impl-not-accurate","title":"<code>PATH_TRANSLATED</code> impl not accurate","text":"<p>By rfc3875, <code>PATH_TRANSLATED</code> should point to the file that as if <code>$PATH_INFO</code> accessed as <code>uri</code>. But that's really hard to impl on nginx, it need re-trigger nginx's location process. And those functions are private, cannot access by plugin directly. The another way to impl it is starting a sub-request, but it's too expensive, and this var is really rearly used. It's really not worth to do it. So I simply construct this var by document root and <code>path_info</code> vars.</p>"},{"location":"modules/cgi/#rdns-impl-doesnt-access-etchosts","title":"RDNS impl doesn't access /etc/hosts","text":"<p>Nginx's resolver impl doesn't access /etc/hosts. I don't want to impl an extra resolver in plugin. So I just ignore this problem.</p>"},{"location":"modules/cgi/#reference","title":"Reference","text":""},{"location":"modules/cgi/#rfc3875","title":"rfc3875","text":"<p>https://datatracker.ietf.org/doc/html/rfc3875</p>"},{"location":"modules/cgi/#nginx","title":"nginx","text":"<p>https://nginx.org/en/docs/dev/development_guide.html https://hg.nginx.org/nginx-tests</p>"},{"location":"modules/cgi/#hop-by-hop-headers","title":"Hop-by-hop headers","text":"<p>https://datatracker.ietf.org/doc/html/rfc2616#section-13.5.1</p>"},{"location":"modules/cgi/#cgi-environments","title":"CGI environments","text":"<p>https://datatracker.ietf.org/doc/html/rfc3875#section-4.1</p>"},{"location":"modules/cgi/#apache-cgi","title":"Apache CGI","text":"<p>https://httpd.apache.org/docs/2.4/howto/cgi.html</p>"},{"location":"modules/cgi/#lighttpd-cgi","title":"Lighttpd CGI","text":"<p>https://redmine.lighttpd.net/projects/lighttpd/wiki/Mod_cgi</p>"},{"location":"modules/cgi/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-cgi.</p>"},{"location":"modules/combined-upstreams/","title":"combined-upstreams: NGINX Combined Upstreams module","text":""},{"location":"modules/combined-upstreams/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-combined-upstreams\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-combined-upstreams\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_combined_upstreams_module.so;\n</code></pre> <p>This document describes nginx-module-combined-upstreams v2.3.1  released on Apr 15 2025.</p> <p>The module introduces three directives add_upstream, combine_server_singlets, and extend_single_peers available inside upstream configuration blocks, and a new configuration block upstrand for building super-layers of upstreams. Additionally, directive dynamic_upstrand is introduced for choosing upstrands in run-time.</p>"},{"location":"modules/combined-upstreams/#directive-add_upstream","title":"Directive add_upstream","text":"<p>Populates the host upstream with servers listed in an already defined upstream specified by the mandatory 1st parameter of the directive. The server attributes such as weights, max_fails and others are kept in the host upstream. Optional parameters may include values backup to mark all servers of the sourced upstream as backup servers and weight=N to calibrate weights of servers of the sourced upstream by multiplying them by factor N.</p>"},{"location":"modules/combined-upstreams/#an-example","title":"An example","text":"<pre><code>upstream  combined {\n    add_upstream    upstream1;            # src upstream 1\n    add_upstream    upstream2 weight=2;   # src upstream 2\n    server          some_another_server;  # if needed\n    add_upstream    upstream3 backup;     # src upstream 3\n}\n</code></pre>"},{"location":"modules/combined-upstreams/#directive-combine_server_singlets","title":"Directive combine_server_singlets","text":"<p>Produces multiple singlet upstreams from servers so far defined in the host upstream. A singlet upstream contains only one active server whereas other servers are marked as backup or down. If no parameters were passed then the singlet upstreams will have names of the host upstream appended by the ordering number of the active server in the host upstream. Optional 2 parameters can be used to adjust their names. The 1st parameter is a suffix added after the name of the host upstream and before the ordering number. The 2nd parameter must be an integer value which defines zero-alignment of the ordering number. For example, if it has value 2 then the ordering numbers could be <code>'01', '02', ..., '10', ... '100' ...</code>.</p> <p>To mark secondary servers as down rather than backup, use another optional parameter nobackup. This parameter must be put in the end, after all other parameters.</p>"},{"location":"modules/combined-upstreams/#an-example_1","title":"An example","text":"<pre><code>upstream  uhost {\n    server                   s1;\n    server                   s2;\n    server                   s3 backup;\n    server                   s4;\n    # build singlet upstreams uhost_single_01,\n    # uhost_single_02, uhost_single_03 and uhost_single_04\n    combine_server_singlets  _single_ 2;\n    server                   s5;\n}\n</code></pre>"},{"location":"modules/combined-upstreams/#why-numbers-not-names","title":"Why numbers, not names?","text":"<p>In the example above, singlet upstreams will have names like uhost_single_01, but names that contain server names like uhost_single_s1 would look better and more convenient. Why not use them instead ordering numbers? Unfortunately, Nginx does not remember server names after a server has been added into an upstream, therefore we cannot simply fetch them.</p> <p>Update. There is a good news! Since version 1.7.2, Nginx remembers server names in upstream data and now we can use them when referring to a special keyword byname. For example,</p> <pre><code>    combine_server_singlets  byname;\n    # or\n    combine_server_singlets  _single_ byname;\n</code></pre> <p>All colons (:) in the server names get replaced with underscores (_).</p>"},{"location":"modules/combined-upstreams/#where-this-can-be-useful","title":"Where this can be useful","text":"<p>A singlet upstream acts like a single server with fallback mode. This can be used to manage sticky HTTP sessions when backend servers identify themselves with a proper mechanism such as HTTP cookies.</p> <pre><code>upstream  uhost {\n    server  s1;\n    server  s2;\n    combine_server_singlets;\n}\n\nserver {\n    listen       8010;\n    server_name  main;\n    location / {\n        proxy_pass http://uhost$cookie_rt;\n    }\n}\nserver {\n    listen       8020;\n    server_name  server1;\n    location / {\n        add_header Set-Cookie \"rt=1\";\n        echo \"Passed to $server_name\";\n    }\n}\nserver {\n    listen       8030;\n    server_name  server2;\n    location / {\n        add_header Set-Cookie \"rt=2\";\n        echo \"Passed to $server_name\";\n    }\n}\n</code></pre> <p>In this configuration, the first client request will choose backend server randomly, the chosen server will set cookie rt to a predefined value (1 or 2), and all further requests from this client will be proxied to the chosen server automatically until it goes down. Say, it was server1, then when it goes down, the cookie rt on the client side will still be 1. Directive proxy_pass will route the next client request to a singlet upstream uhost1 where server1 is declared active and server2 is backed up. As soon as server1 is not reachable any longer, Nginx will route the request to server2 which will rewrite the cookie rt and all further client requests will be proxied to server2 until it goes down.</p>"},{"location":"modules/combined-upstreams/#directive-extend_single_peers","title":"Directive extend_single_peers","text":"<p>Peers in upstreams fail according to the rules listed in directive proxy_next_upstream. If an upstream has only one peer in its main or backup part then this peer will never fail. This can be a serious problem when writing a custom algorithm for active health checks of upstream peers. Directive extend_single_peers, being declared in an upstream block, adds a fake peer marked as down in the main or the backup part of the upstream if the part originally contains only one peer. This makes Nginx mark the original single peer as failed when it fails to pass the rules of proxy_next_upstream just like in the general case of multiple peers.</p>"},{"location":"modules/combined-upstreams/#an-example_2","title":"An example","text":"<pre><code>upstream  upstream1 {\n    server  s1;\n    extend_single_peers;\n}\n\nupstream  upstream2 {\n    server  s1;\n    server  s2;\n    server  s3 backup;\n    extend_single_peers;\n}\n</code></pre> <p>Notice that if a part (the main or the backup) of an upstream contains more than one peer (like the main part in upstream2 from the example) then the directive has no effect: particularly, in the upstream2 it only affects the backup part of the upstream.</p>"},{"location":"modules/combined-upstreams/#block-upstrand","title":"Block upstrand","text":"<p>Is aimed to configure a super-layer of upstreams that do not lose their identities. Accepts a number of directives including upstream, order, next_upstream_statuses and others. Upstreams with names starting with tilde (~) match a regular expression. Only upstreams that already have been declared before the upstrand block definition are regarded as candidates.</p>"},{"location":"modules/combined-upstreams/#an-example_3","title":"An example","text":"<pre><code>upstrand us1 {\n    upstream ~^u0 blacklist_interval=60s;\n    upstream b01 backup;\n    order start_random;\n    next_upstream_statuses error timeout non_idempotent 204 5xx;\n    next_upstream_timeout 60s;\n    intercept_statuses 5xx /Internal/failover;\n}\n</code></pre> <p>Upstrand us1 will combine all upstreams whose names start with u0 and upstream b01 as backup. Backup upstreams are checked if all normal upstreams fail. The failure means that all upstreams in normal or backup cycles have responded with statuses listed in directive next_upstream_statuses or been blacklisted. Here, the upstream's response means the status returned by the last server of the upstream, which is strongly affected by value of directive proxy_next_upstream. An upstream is set as blacklisted when it has parameter blacklist_interval and responds with a status listed in the next_upstream_statuses. Blacklisting state is not shared between Nginx worker processes.</p> <p>The next four upstrand directives are akin to those from the Nginx proxy module.</p> <p>Directive next_upstream_statuses accepts 4xx and 5xx statuses notation and values error and timeout to distinguish between cases when errors happen with the upstream's peer connections from those when backends send statuses 502 or 504 (plain values 502 and 504 as well as 5xx refer to both cases). It also accepts value non_idempotent to allow further processing of non-idempotent requests when they were responded by the last server from an upstream but failed according to other statuses listed in the directive. Requests are considered to be non-idempotent when their methods are POST, LOCK or PATCH just like in directive proxy_next_upstream.</p> <p>Directive next_upstream_timeout limits the overall duration time the upstrand cycles through all of its upstreams. If the time elapses while the upstrand is ready to pass to a next upstream, the last upstream cycle result is returned.</p> <p>Directive intercept_statuses allows upstrand failover by intercepting the final response in location that matches the given URI. Interceptions must happen even when the upstrand times out. Notice also that walking through upstreams in an upstrand and the upstrand failover URI are not interceptable. Speaking more generally, any internal redirection (by error_page, proxy_intercept_errors, X-Accel-Redirect etc.) will break nested subrequests on which the upstrand's implementation is based which leads to returning empty responses. These are extremely bad cases, and this is why walking through upstreams was protected against interceptions. The upstrand failover URI is more affected by this as the implementation has less control over its location. Particularly, the upstrand failover has only protection against interceptions by error_page and proxy_intercept_errors. This means that the upstrand failover URI location must be as simple as possible (e.g. using simple directives like return or echo).</p> <p>That said, there is a decent solution to the problem with upstrand failover locations and internal redirections in them. How exactly do internal redirections break subrequests? Well, they erase subrequest contexts needed in response filters of the module. So, if we could make subrequest context persistent, would we solve the problem? The answer is yes! Nginx module nginx-easy-context enables building persistent request contexts. Upstrands can benefit from them by turning on a switch in file config and building both modules. See details in section Build and test.</p> <p>Directive order currently accepts only one value start_random which means that starting upstreams in normal and backup cycles after worker fired up will be chosen randomly. Starting upstreams in further requests will be cycled in round-robin manner. Additionally, a modifier per_request is also accepted in the order directive: it turns off the global per-worker round-robin cycle. The combination of per_request and start_random makes the starting upstream in every new request be chosen randomly.</p> <p>Such a failover between failure statuses can be reached during a single request by feeding a special variable that starts with upstrand_ to the proxy_pass directive like so:</p> <pre><code>location /us1 {\n    proxy_pass http://$upstrand_us1;\n}\n</code></pre> <p>Be careful when accessing this variable from other directives! It starts up the subrequests machinery which may be not desirable in many cases.</p>"},{"location":"modules/combined-upstreams/#upstrand-status-variables","title":"Upstrand status variables","text":"<p>There are a number of upstrand status variables available: upstrand_addr, upstrand_cache_status, upstrand_connect_time, upstrand_header_time, upstrand_response_length, upstrand_response_time and upstrand_status. They all are counterparts of corresponding upstream variables and contain the values of the latter for all upstreams passed through a request and all subrequests chronologically. Variable upstrand_path contains path of all upstreams visited during request.</p>"},{"location":"modules/combined-upstreams/#where-this-can-be-useful_1","title":"Where this can be useful","text":"<p>The upstrand looks very similar to a simple combined upstream but it also has a crucial difference: the upstreams inside of an upstrand do not get flattened and keep holding their identities. This gives a possibility to configure a failover status for a group of servers associated with a single upstream without need to check them all by turn. In the above example, upstrand us1 may hold a list of upstreams like u01, u02 etc. Imagine that upstream u01 holds 10 servers inside and represents a part of a geographically distributed backend system. Let upstrand us1 combine all such parts in a whole, and let us run a client application that polls the parts for doing some tasks. Let the backends send HTTP status 204 if they do not have new tasks. In a flat combined upstream, all 10 servers may have been polled before the application will finally receive a new task from another upstream. The upstrand us1 allows skipping to the next upstream after checking the first server in an upstream that does not have tasks. This machinery is apparently suitable for upstream broadcasting, when messages are being sent to all upstreams in an upstrand.</p> <p>The examples above show that an upstrand can be regarded as a 2-dimensional upstream that comprises a number of clusters representing natural upstreams and allows short-cycling over them.</p> <p>To illustrate this, let's emulate an upstream without round-robin balancing. Every new client request will start by proxying to the first server in the upstream list and then failing over to the next server.</p> <pre><code>    upstream u1 {\n        server localhost:8020;\n        server localhost:8030;\n        combine_server_singlets _single_ nobackup;\n    }\n\n    upstrand us1 {\n        upstream ~^u1_single_ blacklist_interval=60s;\n        order per_request;\n        next_upstream_statuses error timeout non_idempotent 5xx;\n        intercept_statuses 5xx /Internal/failover;\n    }\n</code></pre> <p>Directive combine_server_singlets in upstream u1 generates two singlet upstreams u1_single_1 and u1_single_2 to inhabit upstrand us1. Due to per_request ordering inside the upstrand, the two upstreams will be traversed in order u1_single_1 \u2192 u1_single_2 in each client request.</p>"},{"location":"modules/combined-upstreams/#directive-dynamic_upstrand","title":"Directive dynamic_upstrand","text":"<p>Allows choosing an upstrand from passed variables in run-time. The directive can be set in server, location and location-if clauses.</p> <p>In the following configuration</p> <pre><code>    upstrand us1 {\n        upstream ~^u0;\n        upstream b01 backup;\n        order start_random;\n        next_upstream_statuses 5xx;\n    }\n    upstrand us2 {\n        upstream ~^u0;\n        upstream b02 backup;\n        order start_random;\n        next_upstream_statuses 5xx;\n    }\n\n    server {\n        listen       8010;\n        server_name  main;\n\n        dynamic_upstrand $dus1 $arg_a us2;\n\n        location / {\n            dynamic_upstrand $dus2 $arg_b;\n            if ($arg_b) {\n                proxy_pass http://$dus2;\n                break;\n            }\n            proxy_pass http://$dus1;\n        }\n    }\n</code></pre> <p>upstrands returned in variables dus1 and dus2 are to be chosen from values of variables arg_a and arg_b. If arg_b is set then the client request will be sent to an upstrand with name equal to the value of arg_b. If there is not an upstrand with this name then dus2 will be empty and proxy_pass will return HTTP status 500. To prevent initialization of a dynamic upstrand variable with empty value, its declaration must be terminated with a literal name that corresponds to an existing upstrand. In this example, dynamic upstrand variable dus1 will be initialized by the upstrand us2 if arg_a is empty or not set. Altogether, if arg_b is not set or empty and arg_a is set and has a value equal to an existing upstrand, the request will be sent to this upstrand, otherwise (if arg_b is not set or empty and arg_a is set but does not refer to an existing upstrand) proxy_pass will most likely return HTTP status 500 (except there is a variable composed from literal string upstrand_ and the value of arg_a that points to a valid destination), otherwise (both arg_b and arg_a are not set or empty) the request will be sent to the upstrand us2.</p>"},{"location":"modules/combined-upstreams/#see-also","title":"See also","text":"<p>There are several articles about the module in my blog, in chronological order:</p> <ol> <li>\u041f\u0440\u043e\u0441\u0442\u043e\u0439 \u043c\u043e\u0434\u0443\u043b\u044c nginx \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u043a\u043e\u043c\u0431\u0438\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0430\u043f\u0441\u0442\u0440\u0438\u043c\u043e\u0432 (in Russian). A comprehensive article discovering details of implementation of directive add_upstream which can also be regarded as a small tutorial for Nginx modules development.</li> <li>nginx upstrand to configure super-layers of upstreams. An overview of block upstrand usage and some details on its implementation.</li> <li>\u041d\u0435 \u0442\u0430\u043a\u043e\u0439 \u0443\u0436 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u043c\u043e\u0434\u0443\u043b\u044c nginx \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u043a\u043e\u043c\u0431\u0438\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0430\u043f\u0441\u0442\u0440\u0438\u043c\u043e\u0432 (in Russian). An overview of all features of the module with configuration examples and testing session samples.</li> </ol>"},{"location":"modules/combined-upstreams/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-combined-upstreams.</p>"},{"location":"modules/concat/","title":"concat: HTTP Concatenation module for NGINX","text":""},{"location":"modules/concat/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-concat\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-concat\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_concat_module.so;\n</code></pre> <p>This document describes nginx-module-concat v1.2.3  released on Jan 15 2020.</p>"},{"location":"modules/concat/#introduction","title":"Introduction","text":"<p>This is a module that is distributed with tengine which is a distribution of Nginx that is used by the e-commerce/auction site Taobao.com. This distribution contains some modules that are new on the Nginx scene. The <code>ngx_http_concat</code> module is one of them.</p> <p>The module is inspired by Apache's <code>modconcat</code>. It follows the same pattern for enabling the concatenation. It uses two <code>?</code>, like this: </p> <pre><code>http://example.com/??style1.css,style2.css,foo/style3.css\n</code></pre> <p>If a third <code>?</code> is present it's treated as version string. Like this:</p> <pre><code>http://example.com/??style1.css,style2.css,foo/style3.css?v=102234\n</code></pre>"},{"location":"modules/concat/#configuration-example","title":"Configuration example","text":"<pre><code>location /static/css/ {\n    concat on;\n    concat_max_files 20;\n}\n\nlocation /static/js/ {\n    concat on;\n    concat_max_files 30;\n}\n</code></pre>"},{"location":"modules/concat/#module-directives","title":"Module directives","text":"<p>concat <code>on</code> | <code>off</code></p> <p>default: <code>concat off</code></p> <p>context: <code>http, server, location</code></p> <p>It enables the concatenation in a given context.</p> <p> </p> <p>concat_types <code>MIME types</code></p> <p>default: <code>concat_types: text/css application/x-javascript</code></p> <p>context: <code>http, server, location</code></p> <p>Defines the MIME types which can be concatenated in a given context.</p> <p> </p> <p>concat_unique <code>on</code> | <code>off</code></p> <p>default: <code>concat_unique on</code></p> <p>context: <code>http, server, location</code></p> <p>Defines if only files of a given MIME type can concatenated or if several MIME types can be concatenated. For example if set to <code>off</code> then in a given context you can concatenate Javascript and CSS files.</p> <p>Note that the default value is <code>on</code>, meaning that only files with same MIME type are concatenated in a given context. So if you have CSS and JS you cannot do something like this:</p> <pre><code>http://example.com/static/??foo.css,bar/foobaz.js\n</code></pre> <p>In order to do that you must set <code>concat_unique off</code>. This applies to any other type of files that you decide to concatenate by adding the respective MIME type via <code>concat_types</code>,</p> <p> </p> <p>concat_max_files <code>number</code>p</p> <p>default: <code>concat_max_files 10</code></p> <p>context: <code>http, server, location</code></p> <p>Defines the maximum number of files that can be concatenated in a given context. Note that a given URI cannot be bigger than the page size of your platform. On Linux you can get the page size issuing:</p> <pre><code>getconf PAGESIZE\n</code></pre> <p>Usually is 4k. So if you try to concatenate a lot of files together in a given context you might hit this barrier. To overcome that OS defined limitation you must use the <code>large_client_header_buffers</code> directive. Set it to the value you need.</p> <p> </p> <p>concat_delimiter: string</p> <p>default: NONE</p> <p>context: <code>http, server, locatione</code></p> <p>Defines the delimiter between two files. If the config is concat_delimiter \"\\n\",a '\\n' would be inserted betwen 1.js and 2.js when visted http://example.com/??1.js,2.js</p> <p> </p> <p>concat_ignore_file_error: <code>on</code> | <code>off</code></p> <p>default: off</p> <p>context: <code>http, server, location</code></p> <p>Whether to ignore 404 and 403 or not.</p> <p> </p>"},{"location":"modules/concat/#tagging-releases","title":"Tagging releases","text":"<p>Perusio is maintaing a tagged release at http://github.com/alibaba/nginx-http-concat in synch with the Tengine releases. Refer there for the latest uncommitted tags.</p>"},{"location":"modules/concat/#other-tengine-modules-on-github","title":"Other tengine modules on Github","text":"<ul> <li> <p>footer filter:    allows to add some extra data (markup or not) at the end of a    request body. It's pratical for things like adding time stamps or    other miscellaneous stuff without having to tweak your application.</p> </li> <li> <p>http slice: allows    to serve a file by slices. A sort of reverse byte-range. Useful for    serving large files while not hogging the network.</p> </li> </ul>"},{"location":"modules/concat/#other-builds","title":"Other builds","text":"<ol> <li> <p>As referred at the outset this module is part of the     <code>tengine</code> Nginx distribution. So you     might want to save yourself some work and just build it from     scratch using <code>tengine</code> in lieu if the official Nginx source.</p> </li> <li> <p>If you fancy a bleeding edge Nginx package (from the dev releases)     for Debian made to measure then you might be interested in Perusio's HA/HP     debian Nginx     package with built-in support for nginx-http-concat.     Instructions for using the repository and making the     package live happily inside a stable distribution installation are     provided.</p> </li> </ol>"},{"location":"modules/concat/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-concat.</p>"},{"location":"modules/cookie-flag/","title":"cookie-flag: NGINX cookie flag module","text":""},{"location":"modules/cookie-flag/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-cookie-flag\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-cookie-flag\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_cookie_flag_filter_module.so;\n</code></pre> <p>This document describes nginx-module-cookie-flag v1.1.0  released on Dec 15 2017.</p> <p></p> <p>The Nginx module for adding cookie flag</p>"},{"location":"modules/cookie-flag/#synopsis","title":"Synopsis","text":"<pre><code>location / {\n    set_cookie_flag Secret HttpOnly secure SameSite;\n    set_cookie_flag * HttpOnly;\n    set_cookie_flag SessionID SameSite=Lax secure;\n    set_cookie_flag SiteToken SameSite=Strict;\n}\n</code></pre>"},{"location":"modules/cookie-flag/#description","title":"Description","text":"<p>This module for Nginx allows to set the flags \"HttpOnly\", \"secure\" and \"SameSite\" for cookies in the \"Set-Cookie\" response headers. The register of letters for the flags doesn't matter as it will be converted to the correct value. The order of cookie declaration among multiple directives doesn't matter too. It is possible to set a default value using symbol \"*\". In this case flags will be added to the all cookies if no other value for them is overriden.</p>"},{"location":"modules/cookie-flag/#directives","title":"Directives","text":""},{"location":"modules/cookie-flag/#set_cookie_flag","title":"set_cookie_flag","text":"- - Syntax set_cookie_flag \\&lt;cookie_name|*&gt; [HttpOnly] [secure] [SameSite|SameSite=[Lax|Strict]]; Default - Context server, location <p>Description: Add flag to desired cookie.</p>"},{"location":"modules/cookie-flag/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-cookie-flag.</p>"},{"location":"modules/cookie-limit/","title":"cookie-limit: NGINX module to limit the number of malicious ip forged cookies","text":""},{"location":"modules/cookie-limit/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-cookie-limit\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-cookie-limit\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_cookie_limit_req_module.so;\n</code></pre> <p>This document describes nginx-module-cookie-limit v1.2  released on Jun 23 2022.</p>"},{"location":"modules/cookie-limit/#introduction","title":"Introduction","text":"<p>The ngx_cookie_limit_req_module module not only limits the access rate of cookies but also limits the number of malicious ip forged cookies.</p>"},{"location":"modules/cookie-limit/#donate","title":"Donate","text":"<p>The developers work tirelessly to improve and develop ngx_cookie_limit_req_module. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.</p> <p>### Alipay: </p> <p>Author Gandalf zhibu1991@gmail.com</p>"},{"location":"modules/cookie-limit/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-cookie-limit.</p>"},{"location":"modules/coolkit/","title":"coolkit: NGINX CoolKit Module","text":""},{"location":"modules/coolkit/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-coolkit\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-coolkit\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_coolkit_module.so;\n</code></pre> <p>This document describes nginx-module-coolkit v0.2  released on Aug 23 2020.</p> <p>ngx_coolkit is collection of small and useful nginx add-ons.</p>"},{"location":"modules/coolkit/#configuration-directives","title":"CONFIGURATION DIRECTIVES:","text":""},{"location":"modules/coolkit/#override_method-off-methods-source-context-http-server-location","title":"override_method off | [methods] source (context: http, server, location)","text":"<p>Override HTTP method.</p> <p>default: none</p>"},{"location":"modules/coolkit/#configuration-variables","title":"CONFIGURATION VARIABLES:","text":""},{"location":"modules/coolkit/#remote_passwd","title":"$remote_passwd","text":"<p>Decoded password from \"Authorization\" header (Basic HTTP Authentication).</p>"},{"location":"modules/coolkit/#location","title":"$location","text":"<p>Name of the matched location block.</p>"},{"location":"modules/coolkit/#example-configuration-1","title":"EXAMPLE CONFIGURATION #1:","text":"<p>http {     server {         location / {             override_method  $arg_method;             proxy_pass       http://127.0.0.1:8100;         }     } }</p> <p>Pass request with changed HTTP method (based on \"?method=XXX\") to the backend.</p>"},{"location":"modules/coolkit/#example-configuration-2","title":"EXAMPLE CONFIGURATION #2:","text":"<p>http {     upstream database {         postgres_server        127.0.0.1 dbname=test                                user=monty password=some_pass;     }</p> <pre><code>server {\n    location = /auth {\n        internal;\n\n        set_quote_sql_str  $user $remote_user;\n        set_quote_sql_str  $pass $remote_passwd;\n\n        postgres_pass      database;\n        postgres_query     \"SELECT login FROM users WHERE login=$user AND pass=$pass\";\n        postgres_rewrite   no_rows 403;\n        postgres_output    none;\n    }\n\n    location / {\n        auth_request       /auth;\n        root               /files;\n    }\n}\n</code></pre> <p>}</p> <p>Restrict access to local files by authenticating against SQL database.</p> <p>Required modules (other than ngx_coolkit): - ngx_http_auth_request_module, - ngx_postgres (PostgreSQL) or ngx_drizzle (MySQL, Drizzle, SQLite), - ngx_set_misc.</p>"},{"location":"modules/coolkit/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-coolkit.</p>"},{"location":"modules/dav-ext/","title":"dav-ext: NGINX WebDAV PROPFIND,OPTIONS,LOCK,UNLOCK support","text":""},{"location":"modules/dav-ext/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-dav-ext\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-dav-ext\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_dav_ext_module.so;\n</code></pre> <p>This document describes nginx-module-dav-ext v3.0.0  released on Dec 17 2018.</p>"},{"location":"modules/dav-ext/#nginx-dav-ext-module","title":"nginx-dav-ext-module","text":"<p>nginx WebDAV PROPFIND,OPTIONS,LOCK,UNLOCK support.</p>"},{"location":"modules/dav-ext/#about","title":"About","text":"<p>The standard ngxhhttpddavmmodule provides partial WebDAV implementation and only supports GET,HEAD,PUT,DELETE,MKCOL,COPY,MOVE methods.</p> <p>For full WebDAV support in nginx you need to enable the standard ngxhhttpddavmmodule as well as this module for the missing methods.</p>"},{"location":"modules/dav-ext/#build","title":"Build","text":"<p>Building nginx with the module:</p> <p>``` {.sourceCode .bash}</p>"},{"location":"modules/dav-ext/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-dav-ext.</p>"},{"location":"modules/doh/","title":"doh: NGINX module for serving DNS-over-HTTPS (DOH) requests","text":""},{"location":"modules/doh/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-doh\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-doh\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_doh_module.so;\n</code></pre> <p>This document describes nginx-module-doh v0.1  released on Jan 15 2020.</p> <p>Simple Nginx module for serving DNS-over-HTTPS (DOH) requests.</p> <p>CAVEAT EMPTOR: This module is experimental, even though I have been using it successfully with both Firefox and Curl, there may be undiscovered bugs. Zone transfer is currently not officially supported.</p> <p>Tested with Nginx versions: 1.16.1 (stable) 1.17.6 1.17.7 (mainline).</p> <p>Instructions for building installing and using Nginx modules can be found at the links below.</p> <p>dynamic: https://www.nginx.com/resources/wiki/extending/converting/#compiling-dynamic</p> <p>static: https://www.nginx.com/resources/wiki/extending/compiling/</p> <p>I have included a config file for both building as both a dynamic and static module.</p> <p>This module is only allowed to be used in an http location block.</p> <p>MODULE DIRECTIVES</p> <p>doh: (takes no arguments) enable DOH at this location block, default upstream DNS server address is 127.0.0.1, default port is 53, and default timeout is 5 seconds.</p> <p>doh_address: (takes 1 argument) sets the address of the upstream DNS server, can be either IPv4 or IPv6.</p> <p>doh_port: (takes 1 argument) sets the port to contact the upstream DNS server on (appies to both TCP and UDP connections).</p> <p>doh_timeout: (takes 1 argument) sets the timeout in seconds.</p> <p>EXAMPLES</p> <p>simplest use case with upstream DNS server listening on 127.0.0.1 on port 53:</p> <pre><code>location /dns-query { \n    doh;\n}\n</code></pre> <p>set an upstream address of 127.0.2.1, a port of 5353, and a timeout of 2 seconds:</p> <pre><code>location /dns-query { \n    doh;\n    doh_address 127.0.2.1;\n    doh_port 5353;\n    doh_timeout 2;\n}\n</code></pre>"},{"location":"modules/doh/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-doh.</p>"},{"location":"modules/dynamic-etag/","title":"dynamic-etag: NGINX module for adding ETag to dynamic content","text":""},{"location":"modules/dynamic-etag/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-dynamic-etag\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-dynamic-etag\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_dynamic_etag_module.so;\n</code></pre> <p>This document describes nginx-module-dynamic-etag v0.2.3  released on Sep 18 2025.</p> <p> </p> <p>This NGINX module empowers your dynamic content with automatic <code>ETag</code> header. It allows client browsers to issue conditional <code>GET</code> requests to  dynamic pages. And thus saves bandwidth and ensures better performance! </p>"},{"location":"modules/dynamic-etag/#caveats-first","title":"Caveats first!","text":"<p>This module is a real hack: it calls a header filter from a body filter, etc. </p> <p>The original author abandoned it, having to say:</p> <p>It never really worked.</p> <p>I largely rewrote it to deal with existing obvious faults, but the key part with buffers,  which, myself being old, I probably wil l never understand, is untouched.</p> <p>To be reliable, the module has to read entire response and take a hash of it.  Reading entire response is against NGINX lightweight design. I am not sure whether the buffer part waits for the entire response.</p> <p>Having said that, the tests which I added showcase that this whole stuff works!</p> <p>Note that the <code>HEAD</code> requests will not have any <code>ETag</code> returned, because we have no data to play with,  since NGINX rightfully discards body for this request method.</p> <p>Consider this as a feature or a bug :-) If we remove this, then all <code>HEAD</code> requests end up having same <code>ETag</code> (hash on emptiness), which is definitely worse.</p> <p>Thus, be sure you check headers like this:</p> <pre><code>curl -IL -X GET https://www.example.com/\n</code></pre> <p>And not like this:</p> <p>```bash curl -IL https://www.example.com/ <pre><code>Another worthy thing to mention is that it makes little to no sense applying dynamic `ETag` on a page that changes on \neach reload. E.g. I found I wasn't using the dynamic `ETag` with benefits, because of `&lt;?= antispambot(get_option('admin_email')) ?&gt;`,\nin my WordPress theme's `header.php`, since in this function:\n\n&gt; the selection is random and changes each time the function is called \n\nTo quickly check if your page is changing on reload, use:\n\n```bash\ndiff &lt;(curl http://www.example.com\") &lt;(curl http://www.example.com\")\n</code></pre></p> <p>Now that we're done with the \"now you know\" yada-yada, you can proceed with trying out this stuff :)    </p>"},{"location":"modules/dynamic-etag/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    server {\n        location ~ \\.php$ {\n            dynamic_etag on;\n            fastcgi_pass ...;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/dynamic-etag/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/dynamic-etag/#dynamic_etag","title":"<code>dynamic_etag</code>","text":"<ul> <li>syntax: <code>dynamic_etag on|off|$var</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables or disables applying ETag automatically.</p>"},{"location":"modules/dynamic-etag/#dynamic_etag_types","title":"<code>dynamic_etag_types</code>","text":"<ul> <li>syntax: <code>dynamic_etag_types &lt;mime_type&gt; [..]</code></li> <li>default: <code>text/html</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables applying ETag automatically for the specified MIME types in addition to <code>text/html</code>. The special value <code>*</code> matches any MIME type. Responses with the <code>text/html</code> MIME type are always included.</p>"},{"location":"modules/dynamic-etag/#dynamic_etag_strength","title":"<code>dynamic_etag_strength</code>","text":"<ul> <li>syntax: <code>dynamic_etag_strength strong|weak|$var</code></li> <li>default: <code>strong</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Controls whether generated ETags are strong or weak. Weak ETags are useful for dynamic content where semantic equality should be considered even if the bytes differ (e.g., timestamps, randomized attributes). When using <code>$var</code>, map to values <code>strong</code> or <code>weak</code>.</p> <p>Note: These directives are not valid in the <code>if</code> context. Prefer using <code>$var</code> with <code>map</code> to achieve conditional behavior.</p> <p>Example with <code>map</code>:</p> <pre><code>map $arg_w $etag_strength {\n    default strong;\n    1       weak;\n}\n\nlocation /example {\n    dynamic_etag on;\n    dynamic_etag_types text/html;\n    dynamic_etag_strength $etag_strength;\n    proxy_pass http://backend;\n}\n</code></pre>"},{"location":"modules/dynamic-etag/#tips","title":"Tips","text":"<p>You can use <code>map</code> directive for conditionally enabling dynamic <code>ETag</code> based on URLs, e.g.:</p> <pre><code>map $request_uri $dyn_etag {\n    default \"off\";\n    /foo \"on\";\n    /bar \"on\";\n}\nserver { \n   ...\n   location / {\n       dynamic_etag $dyn_etag;\n       fastcgi_pass ...\n   }\n}       \n</code></pre>"},{"location":"modules/dynamic-etag/#original-authors-readme","title":"Original author's README","text":"<p>Attempt at handling ETag / If-None-Match on proxied content.</p> <p>I plan on using this to front a Varnish server using a lot of ESI.</p> <p>It does kind of work, but... be aware, this is my first attempt at developing a nginx plugin, and dealing with headers after having read the body was not exactly in the how-to.</p> <p>Any comment and/or improvement and/or fork is welcome.</p> <p>Thanks to http://github.com/kkung/nginx-static-etags/ for... inspiration.</p>"},{"location":"modules/dynamic-etag/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-dynamic-etag.</p>"},{"location":"modules/dynamic-limit-req/","title":"dynamic-limit-req: NGINX module to dynamically lock IP and release it periodically","text":""},{"location":"modules/dynamic-limit-req/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-dynamic-limit-req\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-dynamic-limit-req\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_dynamic_limit_req_module.so;\n</code></pre> <p>This document describes nginx-module-dynamic-limit-req v1.9.3  released on Jan 29 2021.</p>"},{"location":"modules/dynamic-limit-req/#introduction","title":"Introduction","text":"<p>The ngx_dynamic_limit_req_module module is used to dynamically lock IP and release it periodically.</p>"},{"location":"modules/dynamic-limit-req/#principle","title":"principle","text":"<p>The ngx_dynamic_limit_req_module module is used to limit the request processing rate per a defined key, in particular, the processing rate of requests coming from a single IP address. The limitation is done using the \u201cleaky bucket\u201d method.</p>"},{"location":"modules/dynamic-limit-req/#about","title":"About","text":"<p>This module is an extension based on ngx_http_limit_req_module.</p>"},{"location":"modules/dynamic-limit-req/#donate","title":"Donate","text":"<p>The developers work tirelessly to improve and develop ngx_dynamic_limit_req_module. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.</p> <p>### Alipay: </p>"},{"location":"modules/dynamic-limit-req/#extend","title":"Extend","text":"<p>This module can be works with RedisPushIptables,  the application layer matches then the network layer to intercept. Although network layer interception will save resources, there are also deficiencies. Assuming that only one specific interface is filtered and no other interfaces are filtered, those that do not need to be filtered will also be inaccessible. Although precise control is not possible at the network layer or the transport layer, it can be precisely controlled at the application layer. Users need to weigh which solution is more suitable for the event at the time.</p>"},{"location":"modules/dynamic-limit-req/#api-count","title":"Api-count","text":""},{"location":"modules/dynamic-limit-req/#if-you-want-to-use-the-api-counting-function-please-use-limithit-api_alerts-because-not-everyone-needs-this-feature-so-it-doesnt-merge-into-the-trunk-users-who-do-not-need-this-feature-can-skip-this-paragraph-description","title":"If you want to use the api counting function, please use limithit-API_alerts. Because not everyone needs this feature, so it doesn't merge into the trunk. Users who do not need this feature can skip this paragraph description.","text":"<p><pre><code>git clone https://github.com/limithit/ngx_dynamic_limit_req_module.git\ncd ngx_dynamic_limit_req_module\ngit checkout limithit-API_alerts\n</code></pre> <pre><code>root@debian:~# redis-cli \n127.0.0.1:6379&gt; SELECT 3\n127.0.0.1:6379[3]&gt; scan 0 match *12/Dec/2018* count 10000 \n127.0.0.1:6379[3]&gt; scan 0 match *PV count 10000\n1) \"0\"\n2) 1) \"[13/Dec/2018]PV\"\n   2) \"[12/Dec/2018]PV\"\n127.0.0.1:6379[3]&gt; get [12/Dec/2018]PV\n\"9144\"\n127.0.0.1:6379[3]&gt; get [13/Dec/2018]PV\n\"8066\"\n127.0.0.1:6379[3]&gt; get [13/Dec/2018]UV\n\"214\"\n</code></pre></p> <p>This module is compatible with following nginx releases:</p> <p>Author Gandalf zhibu1991@gmail.com</p>"},{"location":"modules/dynamic-limit-req/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-dynamic-limit-req.</p>"},{"location":"modules/echo/","title":"echo: nginx Echo module","text":""},{"location":"modules/echo/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-echo\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-echo\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_echo_module.so;\n</code></pre> <p>This document describes nginx-module-echo v0.64  released on Oct 30 2025.</p> <p>ngx_echo - Brings \"echo\", \"sleep\", \"time\", \"exec\" and more shell-style goodies to Nginx config file.</p>"},{"location":"modules/echo/#status","title":"Status","text":"<p>This module is production ready.</p>"},{"location":"modules/echo/#synopsis","title":"Synopsis","text":"<pre><code>   location /hello {\n     echo \"hello, world!\";\n   }\n</code></pre> <pre><code>   location /hello {\n     echo -n \"hello, \";\n     echo \"world!\";\n   }\n</code></pre> <pre><code>   location /timed_hello {\n     echo_reset_timer;\n     echo hello world;\n     echo \"'hello world' takes about $echo_timer_elapsed sec.\";\n     echo hiya igor;\n     echo \"'hiya igor' takes about $echo_timer_elapsed sec.\";\n   }\n</code></pre> <pre><code>   location /echo_with_sleep {\n     echo hello;\n     echo_flush;  # ensure the client can see previous output immediately\n     echo_sleep   2.5;  # in sec\n     echo world;\n   }\n</code></pre> <pre><code>   # in the following example, accessing /echo yields\n   #   hello\n   #   world\n   #   blah\n   #   hiya\n   #   igor\n   location /echo {\n       echo_before_body hello;\n       echo_before_body world;\n       proxy_pass $scheme://127.0.0.1:$server_port$request_uri/more;\n       echo_after_body hiya;\n       echo_after_body igor;\n   }\n   location /echo/more {\n       echo blah;\n   }\n</code></pre> <pre><code>   # the output of /main might be\n   #   hello\n   #   world\n   #   took 0.000 sec for total.\n   # and the whole request would take about 2 sec to complete.\n   location /main {\n       echo_reset_timer;\n\n       # subrequests in parallel\n       echo_location_async /sub1;\n       echo_location_async /sub2;\n\n       echo \"took $echo_timer_elapsed sec for total.\";\n   }\n   location /sub1 {\n       echo_sleep 2;\n       echo hello;\n   }\n   location /sub2 {\n       echo_sleep 1;\n       echo world;\n   }\n</code></pre> <pre><code>   # the output of /main might be\n   #   hello\n   #   world\n   #   took 3.003 sec for total.\n   # and the whole request would take about 3 sec to complete.\n   location /main {\n       echo_reset_timer;\n\n       # subrequests in series (chained by CPS)\n       echo_location /sub1;\n       echo_location /sub2;\n\n       echo \"took $echo_timer_elapsed sec for total.\";\n   }\n   location /sub1 {\n       echo_sleep 2;\n       echo hello;\n   }\n   location /sub2 {\n       echo_sleep 1;\n       echo world;\n   }\n</code></pre> <pre><code>   # Accessing /dup gives\n   #   ------ END ------\n   location /dup {\n     echo_duplicate 3 \"--\";\n     echo_duplicate 1 \" END \";\n     echo_duplicate 3 \"--\";\n     echo;\n   }\n</code></pre> <pre><code>   # /bighello will generate 1000,000,000 hello's.\n   location /bighello {\n     echo_duplicate 1000_000_000 'hello';\n   }\n</code></pre> <pre><code>   # echo back the client request\n   location /echoback {\n     echo_duplicate 1 $echo_client_request_headers;\n     echo \"\\r\";\n\n     echo_read_request_body;\n\n     echo_request_body;\n   }\n</code></pre> <pre><code>   # GET /multi will yields\n   #   querystring: foo=Foo\n   #   method: POST\n   #   body: hi\n   #   content length: 2\n   #   ///\n   #   querystring: bar=Bar\n   #   method: PUT\n   #   body: hello\n   #   content length: 5\n   #   ///\n   location /multi {\n       echo_subrequest_async POST '/sub' -q 'foo=Foo' -b 'hi';\n       echo_subrequest_async PUT '/sub' -q 'bar=Bar' -b 'hello';\n   }\n   location /sub {\n       echo \"querystring: $query_string\";\n       echo \"method: $echo_request_method\";\n       echo \"body: $echo_request_body\";\n       echo \"content length: $http_content_length\";\n       echo '///';\n   }\n</code></pre> <pre><code>   # GET /merge?/foo.js&amp;/bar/blah.js&amp;/yui/baz.js will merge the .js resources together\n   location /merge {\n       default_type 'text/javascript';\n       echo_foreach_split '&amp;' $query_string;\n           echo \"/* JS File $echo_it */\";\n           echo_location_async $echo_it;\n           echo;\n       echo_end;\n   }\n</code></pre> <pre><code>   # accessing /if?val=abc yields the \"hit\" output\n   # while /if?val=bcd yields \"miss\":\n   location ^~ /if {\n       set $res miss;\n       if ($arg_val ~* '^a') {\n           set $res hit;\n           echo $res;\n       }\n       echo $res;\n   }\n</code></pre>"},{"location":"modules/echo/#description","title":"Description","text":"<p>This module wraps lots of Nginx internal APIs for streaming input and output, parallel/sequential subrequests, timers and sleeping, as well as various meta data accessing.</p> <p>Basically it provides various utilities that help testing and debugging of other modules by trivially emulating different kinds of faked subrequest locations.</p> <p>People will also find it useful in real-world applications that need to</p> <ol> <li>serve static contents directly from memory (loading from the Nginx config file).</li> <li>wrap the upstream response with custom header and footer (kinda like the addition module but with contents read directly from the config file and Nginx variables).</li> <li>merge contents of various \"Nginx locations\" (i.e., subrequests) together in a single main request (using echo_location and its friends).</li> </ol> <p>This is a special dual-role module that can lazily serve as a content handler or register itself as an output filter only upon demand. By default, this module does not do anything at all.</p> <p>Technically, this module has also demonstrated the following techniques that might be helpful for module writers:</p> <ol> <li>Issue parallel subrequests directly from content handler.</li> <li>Issue chained subrequests directly from content handler, by passing continuation along the subrequest chain.</li> <li>Issue subrequests with all HTTP 1.1 methods and even an optional faked HTTP request body.</li> <li>Interact with the Nginx event model directly from content handler using custom events and timers, and resume the content handler back if necessary.</li> <li>Dual-role module that can (lazily) serve as a content handler or an output filter or both.</li> <li>Nginx config file variable creation and interpolation.</li> <li>Streaming output control using output_chain, flush and its friends.</li> <li>Read client request body from the content handler, and returns back (asynchronously) to the content handler after completion.</li> <li>Use Perl-based declarative test suite to drive the development of Nginx C modules.</li> </ol>"},{"location":"modules/echo/#content-handler-directives","title":"Content Handler Directives","text":"<p>Use of the following directives register this module to the current Nginx location as a content handler. If you want to use another module, like the standard proxy module, as the content handler, use the filter directives provided by this module.</p> <p>All the content handler directives can be mixed together in a single Nginx location and they're supposed to run sequentially just as in the Bash scripting language.</p> <p>Every content handler directive supports variable interpolation in its arguments (if any).</p> <p>The MIME type set by the standard default_type directive is respected by this module, as in:</p> <pre><code>   location /hello {\n     default_type text/plain;\n     echo hello;\n   }\n</code></pre> <p>Then on the client side:</p> <pre><code>   $ curl -I 'http://localhost/echo'\n   HTTP/1.1 200 OK\n   Server: nginx/0.8.20\n   Date: Sat, 17 Oct 2009 03:40:19 GMT\n   Content-Type: text/plain\n   Connection: keep-alive\n</code></pre> <p>Since the v0.22 release, all of the directives are allowed in the rewrite module's if directive block, for instance:</p> <pre><code> location ^~ /if {\n     set $res miss;\n     if ($arg_val ~* '^a') {\n         set $res hit;\n         echo $res;\n     }\n     echo $res;\n }\n</code></pre>"},{"location":"modules/echo/#echo","title":"echo","text":"<p>syntax: echo [options] &lt;string&gt;...</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Sends arguments joined by spaces, along with a trailing newline, out to the client.</p> <p>Note that the data might be buffered by Nginx's underlying buffer. To force the output data flushed immediately, use the echo_flush command just after <code>echo</code>, as in</p> <pre><code>    echo hello world;\n    echo_flush;\n</code></pre> <p>When no argument is specified, echo emits the trailing newline alone, just like the echo command in shell.</p> <p>Variables may appear in the arguments. An example is</p> <pre><code>    echo The current request uri is $request_uri;\n</code></pre> <p>where $request_uri is a variable exposed by the ngx_http_core_module.</p> <p>This command can be used multiple times in a single location configuration, as in</p> <pre><code> location /echo {\n     echo hello;\n     echo world;\n }\n</code></pre> <p>The output on the client side looks like this</p> <pre><code> $ curl 'http://localhost/echo'\n hello\n world\n</code></pre> <p>Special characters like newlines (<code>\\n</code>) and tabs (<code>\\t</code>) can be escaped using C-style escaping sequences. But a notable exception is the dollar sign (<code>$</code>). As of Nginx 0.8.20, there's still no clean way to escape this character. (A work-around might be to use a <code>$echo_dollor</code> variable that is always evaluated to the constant <code>$</code> character. This feature will possibly be introduced in a future version of this module.)</p> <p>As of the echo v0.28 release, one can suppress the trailing newline character in the output by using the <code>-n</code> option, as in</p> <pre><code> location /echo {\n     echo -n \"hello, \";\n     echo \"world\";\n }\n</code></pre> <p>Accessing <code>/echo</code> gives</p> <pre><code> $ curl 'http://localhost/echo'\n hello, world\n</code></pre> <p>Leading <code>-n</code> in variable values won't take effect and will be emitted literally, as in</p> <pre><code> location /echo {\n     set $opt -n;\n     echo $opt \"hello,\";\n     echo \"world\";\n }\n</code></pre> <p>This gives the following output</p> <pre><code> $ curl 'http://localhost/echo'\n -n hello,\n world\n</code></pre> <p>One can output leading <code>-n</code> literals and other options using the special <code>--</code> option like this</p> <pre><code> location /echo {\n     echo -- -n is an option;\n }\n</code></pre> <p>which yields</p> <pre><code> $ curl 'http://localhost/echo'\n -n is an option\n</code></pre> <p>Use this form when you want to output anything leading with a dash (<code>-</code>).</p>"},{"location":"modules/echo/#echo_duplicate","title":"echo_duplicate","text":"<p>syntax: echo_duplicate &lt;count&gt; &lt;string&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Outputs duplication of a string indicated by the second argument, using the count specified in the first argument.</p> <p>For instance,</p> <pre><code>   location /dup {\n       echo_duplicate 3 \"abc\";\n   }\n</code></pre> <p>will lead to the output of <code>\"abcabcabc\"</code>.</p> <p>Underscores are allowed in the count number, just like in Perl. For example, to emit 1000,000,000 instances of <code>\"hello, world\"</code>:</p> <pre><code>   location /many_hellos {\n       echo_duplicate 1000_000_000 \"hello, world\";\n   }\n</code></pre> <p>The <code>count</code> argument could be zero, but not negative. The second <code>string</code> argument could be an empty string (\"\") likewise.</p> <p>Unlike the echo directive, no trailing newline is appended to the result. So it's possible to \"abuse\" this directive as a no-trailing-newline version of echo by using \"count\" 1, as in</p> <pre><code>   location /echo_art {\n       echo_duplicate 2 '---';\n       echo_duplicate 1 ' END ';  # we don't want a trailing newline here\n       echo_duplicate 2 '---';\n       echo;  # we want a trailing newline here...\n   }\n</code></pre> <p>You get</p> <pre><code>   ------ END ------\n</code></pre> <p>But use of the <code>-n</code> option in echo is more appropriate for this purpose.</p> <p>This directive was first introduced in version 0.11.</p>"},{"location":"modules/echo/#echo_flush","title":"echo_flush","text":"<p>syntax: echo_flush</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Forces the data potentially buffered by underlying Nginx output filters to send immediately to the client side via socket.</p> <p>Note that techically the command just emits a ngx_buf_t object with <code>flush</code> slot set to 1, so certain weird third-party output filter module could still block it before it reaches Nginx's (last) write filter.</p> <p>This directive does not take any argument.</p> <p>Consider the following example:</p> <pre><code>   location /flush {\n      echo hello;\n\n      echo_flush;\n\n      echo_sleep 1;\n      echo world;\n   }\n</code></pre> <p>Then on the client side, using curl to access <code>/flush</code>, you'll see the \"hello\" line immediately, but only after 1 second, the last \"world\" line. Without calling <code>echo_flush</code> in the example above, you'll most likely see no output until 1 second is elapsed due to the internal buffering of Nginx.</p> <p>This directive will fail to flush the output buffer in case of subrequests get involved. Consider the following example:</p> <pre><code>   location /main {\n       echo_location_async /sub;\n       echo hello;\n       echo_flush;\n   }\n   location /sub {\n       echo_sleep 1;\n   }\n</code></pre> <p>Then the client won't see \"hello\" appear even if <code>echo_flush</code> has been executed before the subrequest to <code>/sub</code> has actually started executing. The outputs of <code>/main</code> that are sent after echo_location_async will be postponed and buffered firmly.</p> <p>This does not apply to outputs sent before the subrequest initiated. For a modified version of the example given above:</p> <pre><code>   location /main {\n       echo hello;\n       echo_flush;\n       echo_location_async /sub;\n   }\n   location /sub {\n       echo_sleep 1;\n   }\n</code></pre> <p>The client will immediately see \"hello\" before <code>/sub</code> enters sleeping.</p> <p>See also echo, echo_sleep, and echo_location_async.</p>"},{"location":"modules/echo/#echo_sleep","title":"echo_sleep","text":"<p>syntax: echo_sleep &lt;seconds&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Sleeps for the time period specified by the argument, which is in seconds.</p> <p>This operation is non-blocking on server side, so unlike the echo_blocking_sleep directive, it won't block the whole Nginx worker process.</p> <p>The period might takes three digits after the decimal point and must be greater than 0.001.</p> <p>An example is</p> <pre><code>    location /echo_after_sleep {\n        echo_sleep 1.234;\n        echo resumed!;\n    }\n</code></pre> <p>Behind the scene, it sets up a per-request \"sleep\" ngx_event_t object, and adds a timer using that custom event to the Nginx event model and just waits for a timeout on that event. Because the \"sleep\" event is per-request, this directive can work in parallel subrequests.</p>"},{"location":"modules/echo/#echo_blocking_sleep","title":"echo_blocking_sleep","text":"<p>syntax: echo_blocking_sleep &lt;seconds&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>This is a blocking version of the echo_sleep directive.</p> <p>See the documentation of echo_sleep for more detail.</p> <p>Behind the curtain, it calls the ngx_msleep macro provided by the Nginx core which maps to usleep on POSIX-compliant systems.</p> <p>Note that this directive will block the current Nginx worker process completely while being executed, so never use it in production environment.</p>"},{"location":"modules/echo/#echo_reset_timer","title":"echo_reset_timer","text":"<p>syntax: echo_reset_timer</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Reset the timer begin time to now, i.e., the time when this command is executed during request.</p> <p>The timer begin time is default to the starting time of the current request and can be overridden by this directive, potentially multiple times in a single location. For example:</p> <pre><code>   location /timed_sleep {\n       echo_sleep 0.03;\n       echo \"$echo_timer_elapsed sec elapsed.\";\n\n       echo_reset_timer;\n\n       echo_sleep 0.02;\n       echo \"$echo_timer_elapsed sec elapsed.\";\n   }\n</code></pre> <p>The output on the client side might be</p> <pre><code> $ curl 'http://localhost/timed_sleep'\n 0.032 sec elapsed.\n 0.020 sec elapsed.\n</code></pre> <p>The actual figures you get on your side may vary a bit due to your system's current activities.</p> <p>Invocation of this directive will force the underlying Nginx timer to get updated to the current system time (regardless the timer resolution specified elsewhere in the config file). Furthermore, references of the $echo_timer_elapsed variable will also trigger timer update forcibly.</p> <p>See also echo_sleep and $echo_timer_elapsed.</p>"},{"location":"modules/echo/#echo_read_request_body","title":"echo_read_request_body","text":"<p>syntax: echo_read_request_body</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Explicitly reads request body so that the $request_body variable will always have non-empty values (unless the body is so big that it has been saved by Nginx to a local temporary file).</p> <p>Note that this might not be the original client request body because the current request might be a subrequest with a \"artificial\" body specified by its parent.</p> <p>This directive does not generate any output itself, just like echo_sleep.</p> <p>Here's an example for echo'ing back the original HTTP client request (both headers and body are included):</p> <pre><code>   location /echoback {\n     echo_duplicate 1 $echo_client_request_headers;\n     echo \"\\r\";\n     echo_read_request_body;\n     echo $request_body;\n   }\n</code></pre> <p>The content of <code>/echoback</code> looks like this on my side (I was using Perl's LWP utility to access this location on the server):</p> <pre><code>   $ (echo hello; echo world) | lwp-request -m POST 'http://localhost/echoback'\n   POST /echoback HTTP/1.1\n   TE: deflate,gzip;q=0.3\n   Connection: TE, close\n   Host: localhost\n   User-Agent: lwp-request/5.818 libwww-perl/5.820\n   Content-Length: 12\n   Content-Type: application/x-www-form-urlencoded\n\n   hello\n   world\n</code></pre> <p>Because <code>/echoback</code> is the main request, $request_body holds the original client request body.</p> <p>Before Nginx 0.7.56, it makes no sense to use this directive because $request_body was first introduced in Nginx 0.7.58.</p> <p>This directive itself was first introduced in the echo module's v0.14 release.</p>"},{"location":"modules/echo/#echo_location_async","title":"echo_location_async","text":"<p>syntax: echo_location_async &lt;location&gt; [&lt;url_args&gt;]</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Issue GET subrequest to the location specified (first argument) with optional url arguments specified in the second argument.</p> <p>As of Nginx 0.8.20, the <code>location</code> argument does not support named location, due to a limitation in the <code>ngx_http_subrequest</code> function. The same is true for its brother, the echo_location directive.</p> <p>A very simple example is</p> <pre><code> location /main {\n     echo_location_async /sub;\n     echo world;\n }\n location /sub {\n     echo hello;\n }\n</code></pre> <p>Accessing <code>/main</code> gets</p> <pre><code>   hello\n   world\n</code></pre> <p>Calling multiple locations in parallel is also possible:</p> <pre><code> location /main {\n     echo_reset_timer;\n     echo_location_async /sub1;\n     echo_location_async /sub2;\n     echo \"took $echo_timer_elapsed sec for total.\";\n }\n location /sub1 {\n     echo_sleep 2; # sleeps 2 sec\n     echo hello;\n }\n location /sub2 {\n     echo_sleep 1; # sleeps 1 sec\n     echo world;\n }\n</code></pre> <p>Accessing <code>/main</code> yields</p> <pre><code>   $ time curl 'http://localhost/main'\n   hello\n   world\n   took 0.000 sec for total.\n\n   real  0m2.006s\n   user  0m0.000s\n   sys   0m0.004s\n</code></pre> <p>You can see that the main handler <code>/main</code> does not wait the subrequests <code>/sub1</code> and <code>/sub2</code> to complete and quickly goes on, hence the \"0.000 sec\" timing result. The whole request, however takes approximately 2 sec in total to complete because <code>/sub1</code> and <code>/sub2</code> run in parallel (or \"concurrently\" to be more accurate).</p> <p>If you use echo_blocking_sleep in the previous example instead, then you'll get the same output, but with 3 sec total response time, because \"blocking sleep\" blocks the whole Nginx worker process.</p> <p>Locations can also take an optional querystring argument, for instance</p> <pre><code> location /main {\n     echo_location_async /sub 'foo=Foo&amp;bar=Bar';\n }\n location /sub {\n     echo $arg_foo $arg_bar;\n }\n</code></pre> <p>Accessing <code>/main</code> yields</p> <pre><code>   $ curl 'http://localhost/main'\n   Foo Bar\n</code></pre> <p>Querystrings is not allowed to be concatenated onto the <code>location</code> argument with \"?\" directly, for example, <code>/sub?foo=Foo&amp;bar=Bar</code> is an invalid location, and shouldn't be fed as the first argument to this directive.</p> <p>Technically speaking, this directive is an example that Nginx content handler issues one or more subrequests directly. AFAIK, the fancyindex module also does such kind of things ;)</p> <p>Nginx named locations like <code>@foo</code> is not supported here.</p> <p>This directive is logically equivalent to the GET version of echo_subrequest_async. For example,</p> <pre><code>   echo_location_async /foo 'bar=Bar';\n</code></pre> <p>is logically equivalent to</p> <pre><code>   echo_subrequest_async GET /foo -q 'bar=Bar';\n</code></pre> <p>But calling this directive is slightly faster than calling echo_subrequest_async using <code>GET</code> because we don't have to parse the HTTP method names like <code>GET</code> and options like <code>-q</code>.</p> <p>This directive is first introduced in version 0.09 of this module and requires at least Nginx 0.7.46.</p>"},{"location":"modules/echo/#echo_location","title":"echo_location","text":"<p>syntax: echo_location &lt;location&gt; [&lt;url_args&gt;]</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Just like the echo_location_async directive, but <code>echo_location</code> issues subrequests in series rather than in parallel. That is, the content handler directives following this directive won't be executed until the subrequest issued by this directive completes.</p> <p>The final response body is almost always equivalent to the case when echo_location_async is used instead, only if timing variables is used in the outputs.</p> <p>Consider the following example:</p> <pre><code> location /main {\n     echo_reset_timer;\n     echo_location /sub1;\n     echo_location /sub2;\n     echo \"took $echo_timer_elapsed sec for total.\";\n }\n location /sub1 {\n     echo_sleep 2;\n     echo hello;\n }\n location /sub2 {\n     echo_sleep 1;\n     echo world;\n }\n</code></pre> <p>The location <code>/main</code> above will take for total 3 sec to complete (compared to 2 sec if echo_location_async is used instead here). Here's the result in action on my machine:</p> <pre><code>   $ curl 'http://localhost/main'\n   hello\n   world\n   took 3.003 sec for total.\n\n   real  0m3.027s\n   user  0m0.020s\n   sys   0m0.004s\n</code></pre> <p>This directive is logically equivalent to the GET version of echo_subrequest. For example,</p> <pre><code>   echo_location /foo 'bar=Bar';\n</code></pre> <p>is logically equivalent to</p> <pre><code>   echo_subrequest GET /foo -q 'bar=Bar';\n</code></pre> <p>But calling this directive is slightly faster than calling echo_subrequest using <code>GET</code> because we don't have to parse the HTTP method names like <code>GET</code> and options like <code>-q</code>.</p> <p>Behind the scene, it creates an <code>ngx_http_post_subrequest_t</code> object as a continuation and passes it into the <code>ngx_http_subrequest</code> function call. Nginx will later reopen this \"continuation\" in the subrequest's <code>ngx_http_finalize_request</code> function call. We resumes the execution of the parent-request's content handler and starts to run the next directive (command) if any.</p> <p>Nginx named locations like <code>@foo</code> is not supported here.</p> <p>This directive was first introduced in the release v0.12.</p> <p>See also echo_location_async for more details about the meaning of the arguments.</p>"},{"location":"modules/echo/#echo_subrequest_async","title":"echo_subrequest_async","text":"<p>syntax: echo_subrequest_async &lt;HTTP_method&gt; &lt;location&gt; [-q &lt;url_args&gt;] [-b &lt;request_body&gt;] [-f &lt;request_body_path&gt;]</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Initiate an asynchronous subrequest using HTTP method, an optional url arguments (or querystring) and an optional request body which can be defined as a string or as a path to a file which contains the body.</p> <p>This directive is very much like a generalized version of the echo_location_async directive.</p> <p>Here's a small example demonstrating its usage:</p> <pre><code> location /multi {\n     # body defined as string\n     echo_subrequest_async POST '/sub' -q 'foo=Foo' -b 'hi';\n     # body defined as path to a file, relative to nginx prefix path if not absolute\n     echo_subrequest_async PUT '/sub' -q 'bar=Bar' -f '/tmp/hello.txt';\n }\n location /sub {\n     echo \"querystring: $query_string\";\n     echo \"method: $echo_request_method\";\n     echo \"body: $echo_request_body\";\n     echo \"content length: $http_content_length\";\n     echo '///';\n }\n</code></pre> <p>Then on the client side:</p> <pre><code>   $ echo -n hello &gt; /tmp/hello.txt\n   $ curl 'http://localhost/multi'\n   querystring: foo=Foo\n   method: POST\n   body: hi\n   content length: 2\n   ///\n   querystring: bar=Bar\n   method: PUT\n   body: hello\n   content length: 5\n   ///\n</code></pre> <p>Here's more funny example using the standard proxy module to handle the subrequest:</p> <pre><code> location /main {\n     echo_subrequest_async POST /sub -b 'hello, world';\n }\n location /sub {\n     proxy_pass $scheme://127.0.0.1:$server_port/proxied;\n }\n location /proxied {\n     echo \"method: $echo_request_method.\";\n\n     # we need to read body explicitly here...or $echo_request_body\n     #   will evaluate to empty (\"\")\n     echo_read_request_body;\n\n     echo \"body: $echo_request_body.\";\n }\n</code></pre> <p>Then on the client side, we can see that</p> <pre><code>   $ curl 'http://localhost/main'\n   method: POST.\n   body: hello, world.\n</code></pre> <p>Nginx named locations like <code>@foo</code> is not supported here.</p> <p>This directive takes several options:</p> <pre><code>-q &lt;url_args&gt;        Specify the URL arguments (or URL querystring) for the subrequest.\n\n-f &lt;path&gt;            Specify the path for the file whose content will be serve as the\n                     subrequest's request body.\n\n-b &lt;data&gt;            Specify the request body data\n</code></pre> <p>This directive was first introduced in the release v0.15.</p> <p>The <code>-f</code> option to define a file path for the body was introduced in the release v0.35.</p> <p>See also the echo_subrequest and echo_location_async directives.</p>"},{"location":"modules/echo/#echo_subrequest","title":"echo_subrequest","text":"<p>syntax: echo_subrequest &lt;HTTP_method&gt; &lt;location&gt; [-q &lt;url_args&gt;] [-b &lt;request_body&gt;] [-f &lt;request_body_path&gt;]</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>This is the synchronous version of the echo_subrequest_async directive. And just like echo_location, it does not block the Nginx worker process (while echo_blocking_sleep does), rather, it uses continuation to pass control along the subrequest chain.</p> <p>See echo_subrequest_async for more details.</p> <p>Nginx named locations like <code>@foo</code> is not supported here.</p> <p>This directive was first introduced in the release v0.15.</p>"},{"location":"modules/echo/#echo_foreach_split","title":"echo_foreach_split","text":"<p>syntax: echo_foreach_split &lt;delimiter&gt; &lt;string&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Split the second argument <code>string</code> using the delimiter specified in the first argument, and then iterate through the resulting items. For instance:</p> <pre><code>   location /loop {\n     echo_foreach_split ',' $arg_list;\n       echo \"item: $echo_it\";\n     echo_end;\n   }\n</code></pre> <p>Accessing /main yields</p> <pre><code>   $ curl 'http://localhost/loop?list=cat,dog,mouse'\n   item: cat\n   item: dog\n   item: mouse\n</code></pre> <p>As seen in the previous example, this directive should always be accompanied by an echo_end directive.</p> <p>Parallel <code>echo_foreach_split</code> loops are allowed, but nested ones are currently forbidden.</p> <p>The <code>delimiter</code> argument could contain multiple arbitrary characters, like</p> <pre><code>   # this outputs \"cat\\ndog\\nmouse\\n\"\n   echo_foreach_split -- '-a-' 'cat-a-dog-a-mouse';\n     echo $echo_it;\n   echo_end;\n</code></pre> <p>Logically speaking, this looping structure is just the <code>foreach</code> loop combined with a <code>split</code> function call in Perl (using the previous example):</p> <pre><code>    foreach (split ',', $arg_list) {\n        print \"item $_\\n\";\n    }\n</code></pre> <p>People will also find it useful in merging multiple <code>.js</code> or <code>.css</code> resources into a whole. Here's an example:</p> <pre><code>   location /merge {\n       default_type 'text/javascript';\n\n       echo_foreach_split '&amp;' $query_string;\n           echo \"/* JS File $echo_it */\";\n           echo_location_async $echo_it;\n           echo;\n       echo_end;\n   }\n</code></pre> <p>Then accessing /merge to merge the <code>.js</code> resources specified in the query string:</p> <pre><code>   $ curl 'http://localhost/merge?/foo/bar.js&amp;/yui/blah.js&amp;/baz.js'\n</code></pre> <p>One can also use third-party Nginx cache module to cache the merged response generated by the <code>/merge</code> location in the previous example.</p> <p>This directive was first introduced in the release v0.17.</p>"},{"location":"modules/echo/#echo_end","title":"echo_end","text":"<p>syntax: echo_end</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>This directive is used to terminate the body of looping and conditional control structures like echo_foreach_split.</p> <p>This directive was first introduced in the release v0.17.</p>"},{"location":"modules/echo/#echo_request_body","title":"echo_request_body","text":"<p>syntax: echo_request_body</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Outputs the contents of the request body previous read.</p> <p>Behind the scene, it's implemented roughly like this:</p> <pre><code>   if (r-&gt;request_body &amp;&amp; r-&gt;request_body-&gt;bufs) {\n       return ngx_http_output_filter(r, r-&gt;request_body-&gt;bufs);\n   }\n</code></pre> <p>Unlike the $echo_request_body and $request_body variables, this directive will show the whole request body even if some parts or all parts of it are saved in temporary files on the disk.</p> <p>It is a \"no-op\" if no request body has been read yet.</p> <p>This directive was first introduced in the release v0.18.</p> <p>See also echo_read_request_body and the chunkin module.</p>"},{"location":"modules/echo/#echo_exec","title":"echo_exec","text":"<p>syntax: echo_exec &lt;location&gt; [&lt;query_string&gt;]</p> <p>syntax: echo_exec &lt;named_location&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Does an internal redirect to the location specified. An optional query string can be specified for normal locations, as in</p> <pre><code>   location /foo {\n       echo_exec /bar weight=5;\n   }\n   location /bar {\n       echo $arg_weight;\n   }\n</code></pre> <p>Or equivalently</p> <pre><code>   location /foo {\n       echo_exec /bar?weight=5;\n   }\n   location /bar {\n       echo $arg_weight;\n   }\n</code></pre> <p>Named locations are also supported. Here's an example:</p> <pre><code>   location /foo {\n       echo_exec @bar;\n   }\n   location @bar {\n       # you'll get /foo rather than @bar\n       #  due to a potential bug in nginx.\n       echo $echo_request_uri;\n   }\n</code></pre> <p>But query string (if any) will always be ignored for named location redirects due to a limitation in the <code>ngx_http_named_location</code> function.</p> <p>Never try to echo things before the <code>echo_exec</code> directive or you won't see the proper response of the location you want to redirect to. Because any echoing will cause the original location handler to send HTTP headers before the redirection happens.</p> <p>Technically speaking, this directive exposes the Nginx internal API functions <code>ngx_http_internal_redirect</code> and <code>ngx_http_named_location</code>.</p> <p>This directive was first introduced in the v0.21 release.</p>"},{"location":"modules/echo/#echo_status","title":"echo_status","text":"<p>syntax: echo_status &lt;status-num&gt;</p> <p>default: echo_status 200</p> <p>context: location, location if</p> <p>phase: content</p> <p>Specify the default response status code. Default to <code>200</code>. This directive is declarative and the relative order with other echo-like directives is not important.</p> <p>Here is an example,</p> <pre><code> location = /bad {\n     echo_status 404;\n     echo \"Something is missing...\";\n }\n</code></pre> <p>then we get a response like this:</p> <pre><code>HTTP/1.1 404 Not Found\nServer: nginx/1.2.1\nDate: Sun, 24 Jun 2012 03:58:18 GMT\nContent-Type: text/plain\nTransfer-Encoding: chunked\nConnection: keep-alive\n\nSomething is missing...\n</code></pre> <p>This directive was first introduced in the <code>v0.40</code> release.</p>"},{"location":"modules/echo/#filter-directives","title":"Filter Directives","text":"<p>Use of the following directives trigger the filter registration of this module. By default, no filter will be registered by this module.</p> <p>Every filter directive supports variable interpolation in its arguments (if any).</p>"},{"location":"modules/echo/#echo_before_body","title":"echo_before_body","text":"<p>syntax: echo_before_body [options] [argument]...</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: output filter</p> <p>It's the filter version of the echo directive, and prepends its output to the beginning of the original outputs generated by the underlying content handler.</p> <p>An example is</p> <pre><code> location /echo {\n     echo_before_body hello;\n     proxy_pass $scheme://127.0.0.1:$server_port$request_uri/more;\n }\n location /echo/more {\n     echo world\n }\n</code></pre> <p>Accessing <code>/echo</code> from the client side yields</p> <pre><code>   hello\n   world\n</code></pre> <p>In the previous sample, we borrow the standard proxy module to serve as the underlying content handler that generates the \"main contents\".</p> <p>Multiple instances of this filter directive are also allowed, as in:</p> <pre><code> location /echo {\n     echo_before_body hello;\n     echo_before_body world;\n     echo !;\n }\n</code></pre> <p>On the client side, the output is like</p> <pre><code>   $ curl 'http://localhost/echo'\n   hello\n   world\n   !\n</code></pre> <p>In this example, we also use the content handler directives provided by this module as the underlying content handler.</p> <p>This directive also supports the <code>-n</code> and <code>--</code> options like the echo directive.</p> <p>This directive can be mixed with its brother directive echo_after_body.</p>"},{"location":"modules/echo/#echo_after_body","title":"echo_after_body","text":"<p>syntax: echo_after_body [argument]...</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: output filter</p> <p>It's very much like the echo_before_body directive, but appends its output to the end of the original outputs generated by the underlying content handler.</p> <p>Here's a simple example:</p> <pre><code> location /echo {\n     echo_after_body hello;\n     proxy_pass http://127.0.0.1:$server_port$request_uri/more;\n }\n location /echo/more {\n     echo world\n }\n</code></pre> <p>Accessing <code>/echo</code> from the client side yields</p> <pre><code>  world\n  hello\n</code></pre> <p>Multiple instances are allowed, as in:</p> <pre><code> location /echo {\n     echo_after_body hello;\n     echo_after_body world;\n     echo i;\n     echo say;\n }\n</code></pre> <p>The output on the client side while accessing the <code>/echo</code> location looks like</p> <pre><code>  i\n  say\n  hello\n  world\n</code></pre> <p>This directive also supports the <code>-n</code> and <code>--</code> options like the echo directive.</p> <p>This directive can be mixed with its brother directive echo_before_body.</p>"},{"location":"modules/echo/#variables","title":"Variables","text":""},{"location":"modules/echo/#echo_it","title":"$echo_it","text":"<p>This is a \"topic variable\" used by echo_foreach_split, just like the <code>$_</code> variable in Perl.</p>"},{"location":"modules/echo/#echo_timer_elapsed","title":"$echo_timer_elapsed","text":"<p>This variable holds the seconds elapsed since the start of the current request (might be a subrequest though) or the last invocation of the echo_reset_timer command.</p> <p>The timing result takes three digits after the decimal point.</p> <p>References of this variable will force the underlying Nginx timer to update to the current system time, regardless the timer resolution settings elsewhere in the config file, just like the echo_reset_timer directive.</p>"},{"location":"modules/echo/#echo_request_body_1","title":"$echo_request_body","text":"<p>Evaluates to the current (sub)request's request body previously read if no part of the body has been saved to a temporary file. To always show the request body even if it's very large, use the echo_request_body directive.</p>"},{"location":"modules/echo/#echo_request_method","title":"$echo_request_method","text":"<p>Evaluates to the HTTP request method of the current request (it can be a subrequest).</p> <p>Behind the scene, it just takes the string data stored in <code>r-&gt;method_name</code>.</p> <p>Compare it to the $echo_client_request_method variable.</p> <p>At least for Nginx 0.8.20 and older, the $request_method variable provided by the http core module is actually doing what our $echo_client_request_method is doing.</p> <p>This variable was first introduced in our v0.15 release.</p>"},{"location":"modules/echo/#echo_client_request_method","title":"$echo_client_request_method","text":"<p>Always evaluates to the main request's HTTP method even if the current request is a subrequest.</p> <p>Behind the scene, it just takes the string data stored in <code>r-&gt;main-&gt;method_name</code>.</p> <p>Compare it to the $echo_request_method variable.</p> <p>This variable was first introduced in our v0.15 release.</p>"},{"location":"modules/echo/#echo_client_request_headers","title":"$echo_client_request_headers","text":"<p>Evaluates to the original client request's headers.</p> <p>Just as the name suggests, it will always take the main request (or the client request) even if it's currently executed in a subrequest.</p> <p>A simple example is below:</p> <pre><code>   location /echoback {\n      echo \"headers are:\"\n      echo $echo_client_request_headers;\n   }\n</code></pre> <p>Accessing <code>/echoback</code> yields</p> <pre><code>   $ curl 'http://localhost/echoback'\n   headers are\n   GET /echoback HTTP/1.1\n   User-Agent: curl/7.18.2 (i486-pc-linux-gnu) libcurl/7.18.2 OpenSSL/0.9.8g\n   Host: localhost:1984\n   Accept: */*\n</code></pre> <p>Behind the scene, it recovers <code>r-&gt;main-&gt;header_in</code> (or the large header buffers, if any) on the C level and does not construct the headers itself by traversing parsed results in the request object.</p> <p>This varible is always evaluated to an empty value in HTTP/2 requests for now due to the current implementation.</p> <p>This variable was first introduced in version 0.15.</p>"},{"location":"modules/echo/#echo_cacheable_request_uri","title":"$echo_cacheable_request_uri","text":"<p>Evaluates to the parsed form of the URI (usually led by <code>/</code>) of the current (sub-)request. Unlike the $echo_request_uri variable, it is cacheable.</p> <p>See $echo_request_uri for more details.</p> <p>This variable was first introduced in version 0.17.</p>"},{"location":"modules/echo/#echo_request_uri","title":"$echo_request_uri","text":"<p>Evaluates to the parsed form of the URI (usually led by <code>/</code>) of the current (sub-)request. Unlike the $echo_cacheable_request_uri variable, it is not cacheable.</p> <p>This is quite different from the $request_uri variable exported by the ngx_http_core_module, because <code>$request_uri</code> is the unparsed form of the current request's URI.</p> <p>This variable was first introduced in version 0.17.</p>"},{"location":"modules/echo/#echo_incr","title":"$echo_incr","text":"<p>It is a counter that always generate the current counting number, starting from 1. The counter is always associated with the main request even if it is accessed within a subrequest.</p> <p>Consider the following example</p> <pre><code> location /main {\n     echo \"main pre: $echo_incr\";\n     echo_location_async /sub;\n     echo_location_async /sub;\n     echo \"main post: $echo_incr\";\n }\n location /sub {\n     echo \"sub: $echo_incr\";\n }\n</code></pre> <p>Accessing <code>/main</code> yields</p> <pre><code>main pre: 1\nsub: 3\nsub: 4\nmain post: 2\n</code></pre> <p>This directive was first introduced in the v0.18 release.</p>"},{"location":"modules/echo/#echo_response_status","title":"$echo_response_status","text":"<p>Evaluates to the status code of the current (sub)request, null if not any.</p> <p>Behind the scene, it's just the textual representation of <code>r-&gt;headers_out-&gt;status</code>.</p> <p>This directive was first introduced in the v0.23 release.</p>"},{"location":"modules/echo/#modules-that-use-this-module-for-testing","title":"Modules that use this module for testing","text":"<p>The following modules take advantage of this <code>echo</code> module in their test suite:</p> <ul> <li>The memc module that supports almost the whole memcached TCP protocol.</li> <li>The chunkin module that adds HTTP 1.1 chunked input support to Nginx.</li> <li>The headers_more module that allows you to add, set, and clear input and output headers under the conditions that you specify.</li> <li>The <code>echo</code> module itself.</li> </ul> <p>Please mail me other modules that use <code>echo</code> in any form and I'll add them to the list above :)</p>"},{"location":"modules/echo/#changes","title":"Changes","text":"<p>The changes of every release of this module can be obtained from the OpenResty bundle's change logs:</p> <p>http://openresty.org/#Changes</p>"},{"location":"modules/echo/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too. Thanks to the Test::Nginx module in the Perl world.</p> <p>To run it on your side:</p> <pre><code> $ PATH=/path/to/your/nginx-with-echo-module:$PATH prove -r t\n</code></pre> <p>You need to terminate any Nginx processes before running the test suite if you have changed the Nginx server binary.</p> <p>Because a single nginx server (by default, <code>localhost:1984</code>) is used across all the test scripts (<code>.t</code> files), it's meaningless to run the test suite in parallel by specifying <code>-jN</code> when invoking the <code>prove</code> utility.</p> <p>Some parts of the test suite requires standard modules proxy, rewrite and SSI to be enabled as well when building Nginx.</p>"},{"location":"modules/echo/#see-also","title":"See Also","text":"<ul> <li>The original blog post about this module's initial development.</li> <li>The standard addition filter module.</li> <li>The standard proxy module.</li> <li>The OpenResty bundle.</li> </ul>"},{"location":"modules/echo/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-echo.</p>"},{"location":"modules/encrypted-session/","title":"encrypted-session: Encrypt and decrypt NGINX variable values","text":""},{"location":"modules/encrypted-session/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-encrypted-session\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-encrypted-session\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_encrypted_session_module.so;\n</code></pre> <p>This document describes nginx-module-encrypted-session v0.9  released on Nov 18 2021.</p> <p>encrypted-session-nginx-module - encrypt and decrypt nginx variable values</p> <p>installation instructions.</p>"},{"location":"modules/encrypted-session/#status","title":"Status","text":"<p>This module is production ready.</p>"},{"location":"modules/encrypted-session/#synopsis","title":"Synopsis","text":"<pre><code>## key must be of 32 bytes long\nencrypted_session_key \"abcdefghijklmnopqrstuvwxyz123456\";\n\n## iv must not be longer than 16 bytes\n## default: \"deadbeefdeadbeef\" (w/o quotes)\nencrypted_session_iv \"1234567812345678\";\n\n## default: 1d (1 day)\nencrypted_session_expires 3600; # in sec\n\nlocation /encrypt {\n    set $raw 'text to encrypted'; # from the ngx_rewrite module\n    set_encrypt_session $session $raw;\n    set_encode_base32 $session; # from the ngx_set_misc module\n\n    add_header Set-Cookie 'my_login=$session';  # from the ngx_headers module\n\n    # your content handler goes here...\n}\n\nlocation /decrypt {\n    set_decode_base32 $session $cookie_my_login; # from the ngx_set_misc module\n    set_decrypt_session $raw $session;\n\n    if ($raw = '') {\n        # bad session\n    }\n\n    # your content handler goes here...\n}\n</code></pre>"},{"location":"modules/encrypted-session/#description","title":"Description","text":"<p>This module provides encryption and decryption support for nginx variables based on AES-256 with Mac.</p> <p>This module is usually used with the ngx_set_misc module and the standard rewrite module's directives.</p> <p>This module can be used to implement simple user login and ACL.</p> <p>Usually, you just decrypt data in nginx level, and pass the unencrypted data to your FastCGI/HTTP backend, as in</p> <pre><code>location /blah {\n    set_decrypt_session $raw_text $encrypted;\n\n    # this directive is from the ngx_set_misc module\n    set_escape_uri $escaped_raw_text $raw_text;\n\n    fastcgi_param QUERY_STRING \"uid=$uid\";\n    fastcgi_pass unix:/path/to/my/php/or/python/fastcgi.sock;\n}\n</code></pre> <p>Lua web applications running directly on ngx_lua can call this module's directives directly from within Lua code:</p> <pre><code>local raw_text = ndk.set_var.set_decrypt_session(encrypted_text)\n</code></pre>"},{"location":"modules/encrypted-session/#directives","title":"Directives","text":""},{"location":"modules/encrypted-session/#encrypted_session_key","title":"encrypted_session_key","text":"<p>syntax: encrypted_session_key &lt;key&gt;</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Sets the key for the cipher (must be 32 bytes long). For example,</p> <pre><code>encrypted_session_key \"abcdefghijklmnopqrstuvwxyz123456\";\n</code></pre>"},{"location":"modules/encrypted-session/#encrypted_session_iv","title":"encrypted_session_iv","text":"<p>syntax: encrypted_session_iv &lt;iv&gt;</p> <p>default: encrypted_session_iv \"deadbeefdeadbeef\";</p> <p>context: http, server, server if, location, location if</p> <p>Sets the initial vector used for the cipher (must be no longer than 16 bytes).</p> <p>For example,</p> <pre><code>encrypted_session_iv \"12345678\";\n</code></pre>"},{"location":"modules/encrypted-session/#encrypted_session_expires","title":"encrypted_session_expires","text":"<p>syntax: encrypted_session_expires &lt;time&gt;</p> <p>default: encrypted_session_expires 1d;</p> <p>context: http, server, server if, location, location if</p> <p>Sets expiration time difference (in seconds by default).</p> <p>For example, consider the following configuration:</p> <pre><code>encypted_session_expires 1d;\n</code></pre> <p>When your session is being generated, ngx_encrypted_session will plant an expiration time (1 day in the future in this example) into the encrypted session string, such that when the session is being decrypted later, the server can pull the expiration time out of the session and compare it with the server's current system time. No matter how you transfer and store your session, like using cookies, or URI query arguments, or whatever.</p> <p>People may confuse this setting with the expiration date of HTTP cookies. This directive simply controls when the session gets expired; it knows nothing about HTTP cookies. Even if the end user intercepted this session from cookie by himself and uses it later manually, the server will still reject it when the expiration time gets passed.</p>"},{"location":"modules/encrypted-session/#set_encrypt_session","title":"set_encrypt_session","text":"<p>syntax: set_encrypt_session $target &lt;value&gt;</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Encrypts the string value specified by the <code>value</code> argument and saves the result into the variable specified by <code>$target</code>.</p> <p>For example,</p> <pre><code>set_encrypt_session $res $value;\n</code></pre> <p>will encrypts the value in the variable $value into the target variable <code>$res</code>.</p> <p>The <code>value</code> argument can also be an nginx string value, for example,</p> <pre><code>set_encrypt_session $res \"my value = $value\";\n</code></pre> <p>The resulting data can later be decrypted via the set_decrypt_session directive.</p>"},{"location":"modules/encrypted-session/#set_decrypt_session","title":"set_decrypt_session","text":"<p>syntax: set_decrypt_session $target &lt;value&gt;</p> <p>default: no</p> <p>context: http, server, server if, location, location if</p> <p>Similar to set_encrypt_session, but performs the inverse operation, that is, to decrypt things.</p>"},{"location":"modules/encrypted-session/#see-also","title":"See Also","text":"<ul> <li>NDK</li> <li>ngx_set_misc module</li> </ul>"},{"location":"modules/encrypted-session/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-encrypted-session.</p>"},{"location":"modules/execute/","title":"execute: NGINX Execute module","text":""},{"location":"modules/execute/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-execute\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-execute\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_execute_module.so;\n</code></pre> <p>This document describes nginx-module-execute v1.6.1  released on May 21 2018.</p>"},{"location":"modules/execute/#introduction","title":"Introduction","text":"<p>The ngx_http_execute_module is used to execute commands remotely and return results.</p> <p>Configuration example\uff1a</p> <pre><code>worker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  localhost;\n        location / {\n            root   html;\n            index  index.html index.htm;\n            command on;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n</code></pre> <p>Usage:  <code>view-source:http://192.168.18.22/?system.run[command]</code> The <code>command</code> can be any system command. The command you will want to use depends on the permissions that nginx runs with.</p> <pre><code>view-source:http://192.168.18.22/?system.run[ifconfig]\n</code></pre> <p>If using browser to send command, make sure to use \"view source\" if you want to see formatted output. Alternatively, you can also use some tools such as Postman, Fiddler.</p> <p>The commands which require user interaction or constantly update their output (e.g. <code>top</code>) will not run properly, so do not file a bug for this.</p>"},{"location":"modules/execute/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-execute.</p>"},{"location":"modules/f4fhds/","title":"f4fhds: NGINX module for Adobe f4f format","text":""},{"location":"modules/f4fhds/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-f4fhds\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-f4fhds\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_f4fhds_module.so;\n</code></pre> <p>This document describes nginx-module-f4fhds v0.0.1  released on Oct 24 2020.</p> <p>Nginx module for Adobe f4f format.</p> <p>This module implements handling of HTTP Dynamic Streaming requests in the \u201c/videoSeg1-Frag1\u201d form \u2014 extracting the  needed fragment from the videoSeg1.f4f file using the videoSeg1.f4x index file. This module is an alternative to the  Adobe\u2019s f4f module (HTTP Origin Module) for Apache.</p> <p>It is open-source equivalent for commercial ngx_http_f4f_module module.</p>"},{"location":"modules/f4fhds/#synopsis","title":"Synopsis","text":"<pre><code>location /video/ {\n    f4fhds;\n    ...\n}\n</code></pre>"},{"location":"modules/f4fhds/#limitations","title":"Limitations","text":"<ul> <li>The assumption is that all files contain a single (first) segment, e.g. Seg1</li> <li>The files should reside in a local non-networked filesystem, due to use of <code>mmap(2)</code>.</li> </ul>"},{"location":"modules/f4fhds/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-f4fhds.</p>"},{"location":"modules/fancyindex/","title":"fancyindex: NGINX Fancy Index module","text":""},{"location":"modules/fancyindex/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-fancyindex\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-fancyindex\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_fancyindex_module.so;\n</code></pre> <p>This document describes nginx-module-fancyindex v0.5.2  released on Oct 28 2021.</p>"},{"location":"modules/fancyindex/#nginx-fancy-index-module","title":"Nginx Fancy Index module","text":"<p>The Fancy Index module makes possible the generation of file listings, like the built-in autoindex module does, but adding a touch of style. This is possible because the module allows a certain degree of customization of the generated content:</p> <ul> <li>Custom headers. Either local or stored remotely.</li> <li>Custom footers. Either local or stored remotely.</li> <li>Add you own CSS style rules.</li> <li>Allow choosing to sort elements by name (default), modification time, or size; both ascending (default), or descending.</li> </ul> <p>This module is designed to work with Nginx, a high performance open source web server written by Igor Sysoev.</p>"},{"location":"modules/fancyindex/#requirements","title":"Requirements","text":""},{"location":"modules/fancyindex/#centos-7","title":"CentOS 7","text":"<p>For users of the official stable Nginx repository, extra packages repository with dynamic modules is available and fancyindex is included.</p> <p>Install directly:</p> <pre><code>yum install https://extras.getpagespeed.com/redhat/7/x86_64/RPMS/nginx-module-fancyindex-1.12.0.0.4.1-1.el7.gps.x86_64.rpm\n</code></pre> <p>Alternatively, add extras repository first (for future updates) and install the module:</p> <pre><code>yum install nginx-module-fancyindex\n</code></pre> <p>Then load the module in /etc/nginx/nginx.conf using:</p> <pre><code>load_module \"modules/ngx_http_fancyindex_module.so\";\n</code></pre>"},{"location":"modules/fancyindex/#other-platforms","title":"Other platforms","text":"<p>In most other cases you will need the sources for Nginx. Any version starting from the 0.8 series should work.</p> <p>In order to use the <code>fancyindex_header_</code> and <code>fancyindex_footer_</code> directives you will also need the ngx_http_addition_module built into Nginx.</p>"},{"location":"modules/fancyindex/#building","title":"Building","text":"<ol> <li> <p>Unpack the Nginx sources:</p> <pre><code>$ gunzip -c nginx-?.?.?.tar.gz | tar -xvf -\n</code></pre> </li> <li> <p>Unpack the sources for the fancy indexing module:</p> <pre><code>$ gunzip -c nginx-fancyindex-?.?.?.tar.gz | tar -xvf -\n</code></pre> </li> <li> <p>Change to the directory which contains the Nginx sources, run the configuration script with the desired options and be sure to put an <code>--add-module</code> flag pointing to the directory which contains the source of the fancy indexing module:</p> <pre><code>$ cd nginx-?.?.?\n$ ./configure --add-module=../nginx-fancyindex-?.?.? \\\n   [--with-http_addition_module] [extra desired options]\n</code></pre> <p>Since version 0.4.0, the module can also be built as a dynamic module, using <code>--add-dynamic-module=\u2026</code> instead and <code>load_module \"modules/ngx_http_fancyindex_module.so\";</code> in the configuration file</p> </li> <li> <p>Build and install the software:</p> <pre><code>$ make\n</code></pre> <p>And then, as <code>root</code>:</p> <pre><code># make install\n</code></pre> </li> <li> <p>Configure Nginx by using the modules' configuration directives_.</p> </li> </ol>"},{"location":"modules/fancyindex/#example","title":"Example","text":"<p>You can test the default built-in style by adding the following lines into a <code>server</code> section in your Nginx configuration file:</p> <pre><code>location / {\n  fancyindex on;              # Enable fancy indexes.\n  fancyindex_exact_size off;  # Output human-readable file sizes.\n}\n</code></pre>"},{"location":"modules/fancyindex/#themes","title":"Themes","text":"<p>The following themes demonstrate the level of customization which can be achieved using the module:</p> <ul> <li>Theme by @TheInsomniac. Uses custom header and footer.</li> <li>Theme by @Naereen. Uses custom header and footer, the header includes search field to filter by filename using JavaScript.</li> <li>Theme by @fraoustin. Responsive theme using Material Design elements.</li> <li>Theme by @alehaa. Simple, flat theme based on Bootstrap 4 and FontAwesome.</li> </ul>"},{"location":"modules/fancyindex/#directives","title":"Directives","text":""},{"location":"modules/fancyindex/#fancyindex","title":"fancyindex","text":"<p>Syntax fancyindex [on | off]</p> <p>Default fancyindex off</p> <p>Context http, server, location</p> <p>Description Enables or disables fancy directory indexes.</p>"},{"location":"modules/fancyindex/#fancyindex_default_sort","title":"fancyindex_default_sort","text":"<p>Syntax fancyindex_default_sort [name | size | date | name_desc | size_desc | date_desc]</p> <p>Default fancyindex_default_sort name</p> <p>Context http, server, location</p> <p>Description Defines sorting criterion by default.</p>"},{"location":"modules/fancyindex/#fancyindex_directories_first","title":"fancyindex_directories_first","text":"<p>Syntax fancyindex_directories_first [on | off]</p> <p>Default fancyindex_directories_first on</p> <p>Context http, server, location</p> <p>Description If enabled (default setting), groups directories together and sorts them before all regular files. If disabled, directories are sorted together with files.</p>"},{"location":"modules/fancyindex/#fancyindex_css_href","title":"fancyindex_css_href","text":"<p>Syntax fancyindex_css_href uri</p> <p>Default fancyindex_css_href \"\"</p> <p>Context http, server, location</p> <p>Description Allows inserting a link to a CSS style sheet in generated listings. The provided uri parameter will be inserted as-is in a <code>&lt;link&gt;</code> HTML tag. The link is inserted after the built-in CSS rules, so you can override the default styles.</p>"},{"location":"modules/fancyindex/#fancyindex_exact_size","title":"fancyindex_exact_size","text":"<p>Syntax fancyindex_exact_size [on | off]</p> <p>Default fancyindex_exact_size on</p> <p>Context http, server, location</p> <p>Description Defines how to represent file sizes in the directory listing; either accurately, or rounding off to the kilobyte, the megabyte and the gigabyte.</p>"},{"location":"modules/fancyindex/#fancyindex_name_length","title":"fancyindex_name_length","text":"<p>Syntax fancyindex_name_length length</p> <p>Default fancyindex_name_length 50</p> <p>Context http, server, location</p> <p>Description Defines the maximum file name length limit in bytes.</p>"},{"location":"modules/fancyindex/#fancyindex_footer","title":"fancyindex_footer","text":"<p>Syntax fancyindex_footer path [subrequest | local]</p> <p>Default fancyindex_footer \"\"</p> <p>Context http, server, location</p> <p>Description Specifies which file should be inserted at the foot of directory listings. If set to an empty string, the default footer supplied by the module will be sent. The optional parameter indicates whether the path is to be treated as an URI to load using a subrequest (the default), or whether it refers to a local file.</p> <p>note</p> <p>Using this directive needs the ngx_http_addition_module_ built into Nginx.</p> <p>warning</p> <p>When inserting custom header/footer a subrequest will be issued so potentially any URL can be used as source for them. Although it will work with external URLs, only using internal ones is supported. External URLs are totally untested and using them will make Nginx block while waiting for the subrequest to complete. If you feel like external header/footer is a must-have for you, please let me know.</p>"},{"location":"modules/fancyindex/#fancyindex_header","title":"fancyindex_header","text":"<p>Syntax fancyindex_header path [subrequest | local]</p> <p>Default fancyindex_header \"\"</p> <p>Context http, server, location</p> <p>Description Specifies which file should be inserted at the head of directory listings. If set to an empty string, the default header supplied by the module will be sent. The optional parameter indicates whether the path is to be treated as an URI to load using a subrequest (the default), or whether it refers to a local file.</p> <p>note</p> <p>Using this directive needs the ngx_http_addition_module_ built into Nginx.</p>"},{"location":"modules/fancyindex/#fancyindex_show_path","title":"fancyindex_show_path","text":"<p>Syntax fancyindex_show_path [on | off]</p> <p>Default fancyindex_show_path on</p> <p>Context http, server, location</p> <p>Description Whether to output or not the path and the closing \\&lt;/h1&gt; tag after the header. This is useful when you want to handle the path displaying with a PHP script for example.</p> <p>warning</p> <p>This directive can be turned off only if a custom header is provided using fancyindex_header.</p> <p>fancyindex_show_dotfiles \\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~ :Syntax: fancyindex_show_dotfiles [on | off] :Default: fancyindex_show_dotfiles off :Context: http, server, location :Description: Whether to list files that are proceeded with a dot. Normal convention is to hide these.</p>"},{"location":"modules/fancyindex/#fancyindex_ignore","title":"fancyindex_ignore","text":"<p>Syntax fancyindex_ignore string1 [string2 [... stringN]]</p> <p>Default No default.</p> <p>Context http, server, location</p> <p>Description Specifies a list of file names which will be not be shown in generated listings. If Nginx was built with PCRE support strings are interpreted as regular expressions.</p>"},{"location":"modules/fancyindex/#fancyindex_hide_symlinks","title":"fancyindex_hide_symlinks","text":"<p>Syntax fancyindex_hide_symlinks [on | off]</p> <p>Default fancyindex_hide_symlinks off</p> <p>Context http, server, location</p> <p>Description When enabled, generated listings will not contain symbolic links.</p> <p>fancyindex_hide_parent_dir \\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~ :Syntax: fancyindex_hide_parent_dir [on | off] :Default: fancyindex_hide_parent_dir off :Context: http, server, location :Description: When enabled, it will not show parent directory.</p>"},{"location":"modules/fancyindex/#fancyindex_localtime","title":"fancyindex_localtime","text":"<p>Syntax fancyindex_localtime [on | off]</p> <p>Default fancyindex_localtime off</p> <p>Context http, server, location</p> <p>Description Enables showing file times as local time. Default is \u201coff\u201d (GMT time).</p>"},{"location":"modules/fancyindex/#fancyindex_time_format","title":"fancyindex_time_format","text":"<p>Syntax fancyindex_time_format string</p> <p>Default fancyindex_time_format \"%Y-%b-%d %H:%M\"</p> <p>Context http, server, location</p> <p>Description Format string used for timestamps. The format specifiers are a subset of those supported by the strftime function, and the behavior is locale-independent (for example, day and month names are always in English). The supported formats are:</p> <ul> <li><code>%a</code>: Abbreviated name of the day of the week.</li> <li><code>%A</code>: Full name of the day of the week.</li> <li><code>%b</code>: Abbreviated month name.</li> <li><code>%B</code>: Full month name.</li> <li><code>%d</code>: Day of the month as a decimal number (range 01 to 31).</li> <li><code>%e</code>: Like <code>%d</code>, the day of the month as a decimal number, but a leading zero is replaced by a space.</li> <li><code>%F</code>: Equivalent to <code>%Y-%m-%d</code> (the ISO 8601 date format).</li> <li><code>%H</code>: Hour as a decimal number using a 24-hour clock (range 00 to 23).</li> <li><code>%I</code>: Hour as a decimal number using a 12-hour clock (range 01 to 12).</li> <li><code>%k</code>: Hour (24-hour clock) as a decimal number (range 0 to 23); single digits are preceded by a blank.</li> <li><code>%l</code>: Hour (12-hour clock) as a decimal number (range 1 to 12); single digits are preceded by a blank.</li> <li><code>%m</code>: Month as a decimal number (range 01 to 12).</li> <li><code>%M</code>: Minute as a decimal number (range 00 to 59).</li> <li><code>%p</code>: Either \"AM\" or \"PM\" according to the given time value.</li> <li><code>%P</code>: Like <code>%p</code> but in lowercase: \"am\" or \"pm\".</li> <li><code>%r</code>: Time in a.m. or p.m. notation. Equivalent to <code>%I:%M:%S %p</code>.</li> <li><code>%R</code>: Time in 24-hour notation (<code>%H:%M</code>).</li> <li><code>%S</code>: Second as a decimal number (range 00 to 60).</li> <li><code>%T</code>: Time in 24-hour notation (<code>%H:%M:%S</code>).</li> <li><code>%u</code>: Day of the week as a decimal, range 1 to 7, Monday being 1.</li> <li><code>%w</code>: Day of the week as a decimal, range 0 to 6, Monday being 0.</li> <li><code>%y</code>: Year as a decimal number without a century (range 00 to 99).</li> <li><code>%Y</code>: Year as a decimal number including the century.</li> </ul>"},{"location":"modules/fancyindex/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-fancyindex.</p>"},{"location":"modules/fips-check/","title":"fips-check: FIPS status check module for NGINX","text":""},{"location":"modules/fips-check/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 6, 7, 8, 9</li> <li>CentOS 6, 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2</li> </ul> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install nginx-module-fips-check\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_fips_check_module.so;\n</code></pre> <p>This document describes nginx-module-fips-check v0.1  released on Jan 11 2021.</p>"},{"location":"modules/fips-check/#introduction","title":"Introduction","text":"<p>This module applies to NGINX builds that use OpenSSL for SSL/TLS crypto.  It runs after  NGINX startup and queries the OpenSSL library, reporting if the library is in FIPS mode or not.</p> <pre><code>sudo tail /var/log/nginx/error.log\n2020/04/03 07:45:54 [notice] 11250#11250: using the \"epoll\" event method\n2020/04/03 07:45:54 [notice] 11250#11250: OpenSSL FIPS Mode is enabled\n2020/04/03 07:45:54 [notice] 11250#11250: nginx/1.17.6 (nginx-plus-r20)\n2020/04/03 07:45:54 [notice] 11250#11250: built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)\n2020/04/03 07:45:54 [notice] 11250#11250: OS: Linux 3.10.0-1062.el7.x86_64\n</code></pre> <p>For more information on using NGINX in FIPS mode, see the NGINX Plus FIPS documentation, which applies to both NGINX open source builds and NGINX Plus. To determine which TLS ciphers NGINX offers, the nmap ssl-enum-ciphers script is useful.</p>"},{"location":"modules/fips-check/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-fips-check.</p>"},{"location":"modules/flv/","title":"flv: Media streaming server based on nginx-module-rtmp","text":""},{"location":"modules/flv/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-flv\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-flv\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_flv_live_module.so;\n</code></pre> <p>This document describes nginx-module-flv v1.2.12  released on Dec 31 2024.</p> <p></p> <p>A media streaming server based on nginx-rtmp-module.</p> <p>\u4e2d\u6587\u8bf4\u660e.</p> <p>Donate if you like this module. Many thanks to you!</p> <p></p>"},{"location":"modules/flv/#features","title":"Features","text":"<ul> <li> <p>All features nginx-rtmp-module provides.</p> </li> <li> <p>Other features provided by nginx-http-flv-module vs nginx-rtmp-module:</p> </li> </ul> Features nginx-http-flv-module nginx-rtmp-module Remarks HTTP-FLV (for play) \u221a x HTTPS-FLV and chunked response supported GOP cache \u221a x Virtual Host \u221a x Omit <code>listen</code> directive \u221a See remarks There MUST be at least one <code>listen</code> directive Audio-only support for RTMP/HTTP-FLV \u221a See remarks Won't work if <code>wait_video</code> or <code>wait_key</code> is on Single-track support for HLS \u221a x <code>reuseport</code> support \u221a x Timer for access log \u221a x JSON style statistics \u221a x Statistics for recordings \u221a x Independent of endianness \u221a See remarks Partially supported in branch <code>big-endian</code>"},{"location":"modules/flv/#systems-supported","title":"Systems supported","text":"<ul> <li>Linux (recommended) / FreeBSD / MacOS / Windows (limited).</li> </ul>"},{"location":"modules/flv/#players-supported","title":"Players supported","text":"<ul> <li>VLC (RTMP &amp; HTTP-FLV) / OBS (RTMP &amp; HTTP-FLV) / JW Player (RTMP) / flv.js (HTTP-FLV).</li> </ul>"},{"location":"modules/flv/#note","title":"Note","text":"<ul> <li> <p>Flash player will be no longer supported officially by Adobe after December 31, 2020, refer to Adobe Flash Player EOL General Information Page for details. Plugins that use flash player won't work after the major browsers subsequently remove flash player.</p> </li> <li> <p>flv.js can only run with browsers that support Media Source Extensions.</p> </li> </ul>"},{"location":"modules/flv/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>GNU make for activating compiler on Unix-like systems to compile software.</p> </li> <li> <p>GCC for compilation on Unix-like systems or MSVC for compilation on Windows.</p> </li> <li> <p>GDB for debug on Unix-like systems.</p> </li> <li> <p>FFmpeg or OBS for publishing media streams.</p> </li> <li> <p>VLC (recommended) or flv.js (recommended) for playing media streams.</p> </li> <li> <p>PCRE for NGINX if regular expressions needed.</p> </li> <li> <p>OpenSSL for NGINX if encrypted access needed.</p> </li> <li> <p>zlib for NGINX if compression needed.</p> </li> </ul>"},{"location":"modules/flv/#usage","title":"Usage","text":"<p>For details of usages of nginx-rtmp-module, please refer to README.md.</p>"},{"location":"modules/flv/#publish","title":"Publish","text":"<p>For simplicity, transcoding is not used (so -c copy is used):</p> <pre><code>ffmpeg -re -i MEDIA_FILE_NAME -c copy -f flv rtmp://example.com[:port]/appname/streamname\n</code></pre>"},{"location":"modules/flv/#note_1","title":"Note","text":"<p>Some legacy versions of FFmpeg don't support the option <code>-c copy</code>, the options <code>-vcodec copy -acodec copy</code> can be used instead.</p> <p>The <code>appname</code> is used to match an application block in rtmp block (see below for details).</p> <p>The <code>streamname</code> can be specified at will but can NOT be omitted.</p> <p>The default port for RTMP is 1935, if some other ports were used, <code>:port</code> must be specified.</p>"},{"location":"modules/flv/#play","title":"Play","text":""},{"location":"modules/flv/#via-http-flv","title":"via HTTP-FLV","text":"<pre><code>http://example.com[:port]/dir?[port=xxx&amp;]app=appname&amp;stream=streamname\n</code></pre>"},{"location":"modules/flv/#note_2","title":"Note","text":"<ul> <li> <p>If ffplay is used in command line to play the stream, the url above MUST be enclosed by quotation marks, or arguments in url will be discarded (some shells not so smart will interpret \"&amp;\" as \"run in background\").</p> </li> <li> <p>If flv.js is used to play the stream, make sure that the published stream is encoded properly, for flv.js supports ONLY H.264 encoded video and AAC/MP3 encoded audio.</p> </li> </ul> <p>The <code>dir</code> is used to match location blocks in http block (see below for details).</p> <p>The default port for HTTP is 80, if some other ports were used, <code>:port</code> must be specified.</p> <p>The default port for RTMP is 1935, if some other ports were used, <code>port=xxx</code> must be specified.</p> <p>The value of <code>app</code> (appname) is used to match an application block, but if the requested <code>app</code> appears in several server blocks and those blocks have the same address and port configuration, host name matches <code>server_name</code> directive will be additionally used to identify the requested application block, otherwise the first one is matched.</p> <p>The value of <code>stream</code> (streamname) is used to match the name of published stream.</p>"},{"location":"modules/flv/#example","title":"Example","text":"<p>Assume that <code>listen</code> directive specified in <code>http</code> block is:</p> <pre><code>http {\n    ...\n    server {\n        listen 8080; #not default port 80\n        ...\n\n        location /live {\n            flv_live on;\n        }\n    }\n}\n</code></pre> <p>And <code>listen</code> directive specified in <code>rtmp</code> block is:</p> <pre><code>rtmp {\n    ...\n    server {\n        listen 1985; #not default port 1935\n        ...\n\n        application myapp {\n            live on;\n        }\n    }\n}\n</code></pre> <p>And the name of published stream is <code>mystream</code>, then the url of playback based on HTTP is:</p> <pre><code>http://example.com:8080/live?port=1985&amp;app=myapp&amp;stream=mystream\n</code></pre>"},{"location":"modules/flv/#note_3","title":"Note","text":"<p>Since some players don't support HTTP chunked transmission, it's better to specify <code>chunked_transfer_encoding off;</code> in location where <code>flv_live on;</code> is specified in this case, or play will fail.</p>"},{"location":"modules/flv/#via-rtmp","title":"via RTMP","text":"<pre><code>rtmp://example.com[:port]/appname/streamname\n</code></pre>"},{"location":"modules/flv/#via-hls","title":"via HLS","text":"<pre><code>http://example.com[:port]/dir/streamname.m3u8\n</code></pre>"},{"location":"modules/flv/#via-dash","title":"via DASH","text":"<pre><code>http://example.com[:port]/dir/streamname.mpd\n</code></pre>"},{"location":"modules/flv/#sample-pictures","title":"Sample Pictures","text":""},{"location":"modules/flv/#rtmp-jw-player-http-flv-vlc","title":"RTMP (JW Player) &amp; HTTP-FLV (VLC)","text":""},{"location":"modules/flv/#http-flv-flvjs","title":"HTTP-FLV (flv.js)","text":""},{"location":"modules/flv/#example-nginxconf","title":"Example nginx.conf","text":""},{"location":"modules/flv/#note_4","title":"Note","text":"<p>The directives <code>rtmp_auto_push</code>, <code>rtmp_auto_push_reconnect</code> and <code>rtmp_socket_dir</code> will not function on Windows except on Windows 10 17063 and later versions, because <code>relay</code> in multiple processes mode needs help of Unix domain socket, please refer to Unix domain socket on Windows 10 for details.</p> <p>It's better to specify the directive <code>worker_processes</code> as 1, because <code>ngx_rtmp_stat_module</code> may not get statistics from a specified worker process in multi-processes mode, for HTTP requests are randomly distributed to worker processes. <code>ngx_rtmp_control_module</code> has the same problem. The problem can be optimized by this patch per-worker-listener.</p> <p>In addtion, <code>vhost</code> feature is OK in single process mode but not perfect in multi-processes mode yet, waiting to be fixed. For example, the following configuration is OK in multi-processes mode:</p> <pre><code>rtmp {\n    ...\n    server {\n        listen 1935;\n        server_name domain_name;\n\n        application myapp {\n            ...\n        }\n    }\n}\n</code></pre> <p>While the following configuration doesn't work properly for play requests distinated to the second <code>server</code> (whether port is 1935 or not) of non-publisher worker processes:</p> <pre><code>rtmp {\n    ...\n    server {\n        listen 1935;\n        server_name 1st_domain_name;\n\n        application myapp {\n            ...\n        }\n    }\n\n    server {\n        listen 1945;\n        server_name 2nd_domain_name;\n\n        application myapp {\n            ...\n        }\n    }\n}\n</code></pre> <p>If NGINX is running in muti-processes mode and socket option <code>SO_REUSEPORT</code> is supported by platform, adding option <code>reuseport</code> for the directive <code>listen</code> will resolve the thundering herd problem.</p> <pre><code>rtmp {\n    ...\n\n    server {\n        listen 1935 reuseport;\n        ...\n    }\n}\n</code></pre>"},{"location":"modules/flv/#example-configuration","title":"Example configuration","text":"<pre><code>worker_processes  1; #should be 1 for Windows, for it doesn't support Unix domain socket\n#worker_processes  auto; #from versions 1.3.8 and 1.2.5\n\n#worker_cpu_affinity  0001 0010 0100 1000; #only available on FreeBSD and Linux\n#worker_cpu_affinity  auto; #from version 1.9.10\n\nerror_log logs/error.log error;\n\n#if the module is compiled as a dynamic module and features relevant\n#to RTMP are needed, the command below MUST be specified and MUST be\n#located before events directive, otherwise the module won't be loaded\n#or will be loaded unsuccessfully when NGINX is started\n\n#load_module modules/ngx_http_flv_live_module.so;\n\nevents {\n    worker_connections  4096;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    keepalive_timeout  65;\n\n    server {\n        listen       80;\n\n        location / {\n            root   /var/www;\n            index  index.html index.htm;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n        location /live {\n            flv_live on; #open flv live streaming (subscribe)\n            chunked_transfer_encoding  on; #open 'Transfer-Encoding: chunked' response\n\n            add_header 'Access-Control-Allow-Origin' '*'; #add additional HTTP header\n            add_header 'Access-Control-Allow-Credentials' 'true'; #add additional HTTP header\n        }\n\n        location /hls {\n            types {\n                application/vnd.apple.mpegurl m3u8;\n                video/mp2t ts;\n            }\n\n            root /tmp;\n            add_header 'Cache-Control' 'no-cache';\n        }\n\n        location /dash {\n            root /tmp;\n            add_header 'Cache-Control' 'no-cache';\n        }\n\n        location /stat {\n            #configuration of streaming &amp; recording statistics\n\n            rtmp_stat all;\n            rtmp_stat_stylesheet stat.xsl;\n        }\n\n        location /stat.xsl {\n            root /var/www/rtmp; #specify in where stat.xsl located\n        }\n\n        #if JSON style stat needed, no need to specify\n        #stat.xsl but a new directive rtmp_stat_format\n\n        #location /stat {\n        #    rtmp_stat all;\n        #    rtmp_stat_format json;\n        #}\n\n        location /control {\n            rtmp_control all; #configuration of control module of rtmp\n        }\n    }\n}\n\nrtmp_auto_push on;\nrtmp_auto_push_reconnect 1s;\nrtmp_socket_dir /tmp;\n\nrtmp {\n    out_queue           4096;\n    out_cork            8;\n    max_streams         128;\n    timeout             15s;\n    drop_idle_publisher 15s;\n\n    log_interval 5s; #interval used by log module to log in access.log, it is very useful for debug\n    log_size     1m; #buffer size used by log module to log in access.log\n\n    server {\n        listen 1935;\n        server_name www.test.*; #for suffix wildcard matching of virtual host name\n\n        application myapp {\n            live on;\n            gop_cache on; #open GOP cache for reducing the wating time for the first picture of video\n        }\n\n        application hls {\n            live on;\n            hls on;\n            hls_path /tmp/hls;\n        }\n\n        application dash {\n            live on;\n            dash on;\n            dash_path /tmp/dash;\n        }\n    }\n\n    server {\n        listen 1935;\n        server_name *.test.com; #for prefix wildcard matching of virtual host name\n\n        application myapp {\n            live on;\n            gop_cache on; #open GOP cache for reducing the wating time for the first picture of video\n        }\n    }\n\n    server {\n        listen 1935;\n        server_name www.test.com; #for completely matching of virtual host name\n\n        application myapp {\n            live on;\n            gop_cache on; #open GOP cache for reducing the wating time for the first picture of video\n        }\n    }\n}\n</code></pre>"},{"location":"modules/flv/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-flv.</p>"},{"location":"modules/form-input/","title":"form-input: NGINX form input module","text":""},{"location":"modules/form-input/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-form-input\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-form-input\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_form_input_module.so;\n</code></pre> <p>This document describes nginx-module-form-input v0.12  released on May 16 2016.</p> <p>form-input-nginx-module - NGINX module that reads HTTP POST and PUT request body encoded in \"application/x-www-form-urlencoded\" and parses the arguments into nginx variables.</p>"},{"location":"modules/form-input/#description","title":"Description","text":"<p>This is a nginx module that reads HTTP POST and PUT request body encoded in \"application/x-www-form-urlencoded\", and parse the arguments in request body into nginx variables.</p> <p>This module depends on the ngx_devel_kit (NDK) module.</p>"},{"location":"modules/form-input/#usage","title":"Usage","text":"<pre><code>set_form_input $variable;\nset_form_input $variable argument;\n\nset_form_input_multi $variable;\nset_form_input_multi $variable argument;\n</code></pre> <p>example:</p> <pre><code>#nginx.conf\n\nlocation /foo {\n    # ensure client_max_body_size == client_body_buffer_size\n    client_max_body_size 100k;\n    client_body_buffer_size 100k;\n\n    set_form_input $data;    # read \"data\" field into $data\n    set_form_input $foo foo; # read \"foo\" field into $foo\n}\n\nlocation /bar {\n    # ensure client_max_body_size == client_body_buffer_size\n    client_max_body_size 1m;\n    client_body_buffer_size 1m;\n\n    set_form_input_multi $data; # read all \"data\" field into $data\n    set_form_input_multi $foo data; # read all \"data\" field into $foo\n\n    array_join ' ' $data; # now $data is an string\n    array_join ' ' $foo;  # now $foo is an string\n}\n</code></pre>"},{"location":"modules/form-input/#limitations","title":"Limitations","text":"<ul> <li>ngx_form_input will discard request bodies that are buffered to disk files. When the client_max_body_size setting is larger than client_body_buffer_size, request bodies that are larger than client_body_buffer_size (but no larger than client_max_body_size) will be buffered to disk files. So it's important to ensure these two config settings take the same values to avoid confustion.</li> </ul>"},{"location":"modules/form-input/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-form-input.</p>"},{"location":"modules/geoip/","title":"geoip: NGINX GeoIP dynamic modules","text":""},{"location":"modules/geoip/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-geoip\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-geoip\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <p><pre><code>load_module modules/ngx_http_geoip_module.so;\n</code></pre> <pre><code>load_module modules/ngx_stream_geoip_module.so;\n</code></pre></p> <p>This module is built from the same source as the NGINX core.</p>"},{"location":"modules/geoip/#directives","title":"Directives","text":"<p>You may find information about configuration directives for this module at the following links:        </p> <ul> <li>http://nginx.org/en/docs/http/ngx_http_geoip_module.html#directives</li> </ul>"},{"location":"modules/geoip2/","title":"geoip2: NGINX GeoIP2 module","text":""},{"location":"modules/geoip2/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-geoip2\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-geoip2\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <p><pre><code>load_module modules/ngx_http_geoip2_module.so;\n</code></pre> <pre><code>load_module modules/ngx_stream_geoip2_module.so;\n</code></pre></p> <p>This document describes nginx-module-geoip2 v3.4  released on Jun 22 2022.</p> <p>ngx_http_geoip2_module - creates variables with values from the maxmind geoip2 databases based on the client IP (default) or from a specific variable (supports both IPv4 and IPv6)</p> <p>The module now supports nginx streams and can be used in the same way the http module can be used.</p>"},{"location":"modules/geoip2/#download-maxmind-geolite2-database-optional","title":"Download Maxmind GeoLite2 Database (optional)","text":"<p>The free GeoLite2 databases are available from Maxminds website (requires signing up)</p>"},{"location":"modules/geoip2/#example-usage","title":"Example Usage:","text":"<pre><code>http {\n    ...\n    geoip2 /etc/maxmind-country.mmdb {\n        auto_reload 5m;\n        $geoip2_metadata_country_build metadata build_epoch;\n        $geoip2_data_country_code default=US source=$variable_with_ip country iso_code;\n        $geoip2_data_country_name country names en;\n    }\n\n    geoip2 /etc/maxmind-city.mmdb {\n        $geoip2_data_city_name default=London city names en;\n    }\n    ....\n\n    fastcgi_param COUNTRY_CODE $geoip2_data_country_code;\n    fastcgi_param COUNTRY_NAME $geoip2_data_country_name;\n    fastcgi_param CITY_NAME    $geoip2_data_city_name;\n    ....\n}\n\nstream {\n    ...\n    geoip2 /etc/maxmind-country.mmdb {\n        $geoip2_data_country_code default=US source=$remote_addr country iso_code;\n    }\n    ...\n}\n</code></pre>"},{"location":"modules/geoip2/#metadata","title":"Metadata:","text":"<p>Retrieve metadata regarding the geoip database. <pre><code>$variable_name metadata &lt;field&gt;\n</code></pre> Available fields:   - build_epoch: the build timestamp of the maxmind database.   - last_check: the last time the database was checked for changes (when using auto_reload)   - last_change: the last time the database was reloaded (when using auto_reload)</p>"},{"location":"modules/geoip2/#autoreload-default-disabled","title":"Autoreload (default: disabled):","text":"<p>Enabling auto reload will have nginx check the modification time of the database at the specified interval and reload it if it has changed. <pre><code>auto_reload &lt;interval&gt;\n</code></pre></p>"},{"location":"modules/geoip2/#geoip","title":"GeoIP:","text":"<p><pre><code>$variable_name [default=&lt;value] [source=$variable_with_ip] path ...\n</code></pre> If default is not specified, the variable will be empty if not found.</p> <p>If source is not specified, $remote_addr will be used to perform the lookup.</p> <p>To find the path of the data you want (eg: country names en), use the mmdblookup tool:</p> <pre><code>$ mmdblookup --file /usr/share/GeoIP/GeoIP2-Country.mmdb --ip 8.8.8.8\n\n  {\n    \"country\":\n      {\n        \"geoname_id\":\n          6252001 &lt;uint32&gt;\n        \"iso_code\":\n          \"US\" &lt;utf8_string&gt;\n        \"names\":\n          {\n            \"de\":\n              \"USA\" &lt;utf8_string&gt;\n            \"en\":\n              \"United States\" &lt;utf8_string&gt;\n          }\n      }\n  }\n\n$ mmdblookup --file /usr/share/GeoIP/GeoIP2-Country.mmdb --ip 8.8.8.8 country names en\n\n  \"United States\" &lt;utf8_string&gt;\n</code></pre> <p>This translates to:</p> <pre><code>$country_name \"default=United States\" source=$remote_addr country names en\n</code></pre>"},{"location":"modules/geoip2/#additional-commands","title":"Additional Commands:","text":"<p>These commands works the same as the original ngx_http_geoip_module documented here: http://nginx.org/en/docs/http/ngx_http_geoip_module.html#geoip_proxy.</p> <p>However, if you provide the <code>source=$variable_with_ip</code> option on a variable, these settings will be ignored for that particular variable.</p> <p><pre><code>geoip2_proxy &lt; cidr &gt;\n</code></pre> Defines trusted addresses.  When a request comes from a trusted address, an address from the \"X-Forwarded-For\" request header field will be used instead.</p> <p><pre><code>geoip2_proxy_recursive &lt; on | off &gt;\n</code></pre> If recursive search is disabled then instead of the original client address that matches one of the trusted addresses, the last address sent in \"X-Forwarded-For\" will be used. If recursive search is enabled then instead of the original client address that matches one of the trusted addresses, the last non-trusted address sent in \"X-Forwarded-For\" will be used.</p>"},{"location":"modules/geoip2/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-geoip2.</p>"},{"location":"modules/google/","title":"google: NGINX Module for Google Mirror creation","text":""},{"location":"modules/google/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-google\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-google\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_google_filter_module.so;\n</code></pre> <p>This document describes nginx-module-google v0.2.4  released on Jun 17 2023.</p> <p></p>"},{"location":"modules/google/#description","title":"Description","text":"<p><code>ngx_http_google_filter_module</code> is a filter module which makes google mirror much easier to deploy.   Regular expressions, uri locations and other complex configurations have been built-in already.   The native nginx module ensure the efficiency of handling cookies, gstatic scoures and redirections.  Let's see how <code>easy</code> it is to setup a google mirror. <pre><code>location / {\n  google on;\n}\n</code></pre></p> <p>What? Are you kidding me? Yes, it's just that simple!</p>"},{"location":"modules/google/#demo-site-httpsg2wenlu","title":"Demo site https://g2.wen.lu","text":""},{"location":"modules/google/#dependency","title":"Dependency","text":"<ol> <li><code>pcre</code> regular expression support</li> <li><code>ngx_http_proxy_module</code> backend proxy support</li> <li><code>ngx_http_substitutions_filter_module</code> mutiple substitutions support</li> </ol>"},{"location":"modules/google/#_1","title":"NGINX Module for Google Mirror creation","text":""},{"location":"modules/google/#download-the-newest-source","title":"download the newest source","text":""},{"location":"modules/google/#see-httpnginxorgendownloadhtml","title":"@see http://nginx.org/en/download.html","text":""},{"location":"modules/google/#_2","title":"NGINX Module for Google Mirror creation","text":"<p>wget http://nginx.org/download/nginx-1.7.8.tar.gz</p>"},{"location":"modules/google/#_3","title":"NGINX Module for Google Mirror creation","text":""},{"location":"modules/google/#clone-ngx_http_google_filter_module","title":"clone ngx_http_google_filter_module","text":""},{"location":"modules/google/#see-httpsgithubcomcuberngx_http_google_filter_module","title":"@see https://github.com/cuber/ngx_http_google_filter_module","text":""},{"location":"modules/google/#_4","title":"NGINX Module for Google Mirror creation","text":"<p>git clone https://github.com/cuber/ngx_http_google_filter_module</p>"},{"location":"modules/google/#_5","title":"NGINX Module for Google Mirror creation","text":""},{"location":"modules/google/#clone-ngx_http_substitutions_filter_module","title":"clone ngx_http_substitutions_filter_module","text":""},{"location":"modules/google/#see-httpsgithubcomyaoweibinngx_http_substitutions_filter_module","title":"@see https://github.com/yaoweibin/ngx_http_substitutions_filter_module","text":""},{"location":"modules/google/#_6","title":"NGINX Module for Google Mirror creation","text":"<p>git clone https://github.com/yaoweibin/ngx_http_substitutions_filter_module <pre><code>##### Brand new installation #####\n``` bash\n#\n## configure nginx customly\n## replace &lt;/path/to/&gt; with your real path\n#\n./configure \\\n  &lt;your configuration&gt; \\\n  --add-module=&lt;/path/to/&gt;ngx_http_google_filter_module \\\n  --add-module=&lt;/path/to/&gt;ngx_http_substitutions_filter_module\n</code></pre></p>"},{"location":"modules/google/#migrate-from-existed-distribution","title":"Migrate from existed distribution","text":"<pre><code>#\n## get the configuration of existed nginx\n## replace &lt;/path/to/&gt; with your real path\n#\n&lt;/path/to/&gt;nginx -V\n&gt; nginx version: nginx/ &lt;version&gt;\n&gt; built by gcc 4.x.x\n&gt; configure arguments: &lt;configuration&gt;\n\n#\n## download the same version of nginx source\n## @see http://nginx.org/en/download.html\n## replace &lt;version&gt; with your nginx version\n#\nwget http://nginx.org/download/nginx-&lt;version&gt;.tar.gz\n\n#\n## configure nginx\n## replace &lt;configuration&gt; with your nginx configuration\n## replace &lt;/path/to/&gt; with your real path\n#\n./configure \\\n  &lt;configuration&gt; \\\n  --add-module=&lt;/path/to/&gt;ngx_http_google_filter_module \\\n  --add-module=&lt;/path/to/&gt;ngx_http_substitutions_filter_module\n#\n## if some libraries were missing, you should install them with the package manager\n## eg. apt-get, pacman, yum ...\n#\n</code></pre>"},{"location":"modules/google/#usage","title":"Usage","text":""},{"location":"modules/google/#basic-configuration","title":"Basic Configuration","text":"<p><code>resolver</code> is needed to resolve domains. <pre><code>server {\n  # ... part of server configuration\n  resolver 8.8.8.8;\n  location / {\n    google on;\n  }\n  # ...\n}\n</code></pre></p>"},{"location":"modules/google/#google-scholar","title":"Google Scholar","text":"<p><code>google_scholar</code> depends on <code>google</code>, so <code>google_scholar</code> cannot be used independently.   Nowadays google scholar has migrate from <code>http</code> to <code>https</code>, and <code>ncr</code> is supported, so the <code>tld</code> of google scholar is no more needed.    <pre><code>location / {\n  google on;\n  google_scholar on;\n}\n</code></pre></p>"},{"location":"modules/google/#google-language","title":"Google Language","text":"<p>The default language can be set through <code>google_language</code>, if it is not setup, <code>zh-CN</code> will be the default language. <pre><code>location / {\n  google on;\n  google_scholar on;\n  # set language to German\n  google_language de; \n}\n</code></pre></p> <p>Supported languages are listed below. <pre><code>ar    -&gt; Arabic\nbg    -&gt; Bulgarian\nca    -&gt; Catalan\nzh-CN -&gt; Chinese (Simplified)\nzh-TW -&gt; Chinese (Traditional)\nhr    -&gt; Croatian\ncs    -&gt; Czech\nda    -&gt; Danish\nnl    -&gt; Dutch\nen    -&gt; English\ntl    -&gt; Filipino\nfi    -&gt; Finnish\nfr    -&gt; French\nde    -&gt; German\nel    -&gt; Greek\niw    -&gt; Hebrew\nhi    -&gt; Hindi\nhu    -&gt; Hungarian\nid    -&gt; Indonesian\nit    -&gt; Italian\nja    -&gt; Japanese\nko    -&gt; Korean\nlv    -&gt; Latvian\nlt    -&gt; Lithuanian\nno    -&gt; Norwegian\nfa    -&gt; Persian\npl    -&gt; Polish\npt-BR -&gt; Portuguese (Brazil)\npt-PT -&gt; Portuguese (Portugal)\nro    -&gt; Romanian\nru    -&gt; Russian\nsr    -&gt; Serbian\nsk    -&gt; Slovak\nsl    -&gt; Slovenian\nes    -&gt; Spanish\nsv    -&gt; Swedish\nth    -&gt; Thai\ntr    -&gt; Turkish\nuk    -&gt; Ukrainian\nvi    -&gt; Vietnamese\n</code></pre></p>"},{"location":"modules/google/#spider-exclusion","title":"Spider Exclusion","text":"<p>The spiders of any search engines are not allowed to crawl google mirror.   Default <code>robots.txt</code> listed below was build-in aleady. <pre><code>User-agent: *\nDisallow: /\n</code></pre> If <code>google_robots_allow</code> set to <code>on</code>, the <code>robots.txt</code> will be replaced with the version of google itself.  <pre><code>  #...\n  location / {\n    google on;\n    google_robots_allow on;\n  }\n  #...\n</code></pre></p>"},{"location":"modules/google/#upstreaming","title":"Upstreaming","text":"<p><code>upstream</code> can help you to avoid name resolving cost, decrease the possibility of google robot detection and proxy through some specific servers.  <pre><code>upstream www.google.com {\n  server 173.194.38.1:443;\n  server 173.194.38.2:443;\n  server 173.194.38.3:443;\n  server 173.194.38.4:443;\n}\n</code></pre></p>"},{"location":"modules/google/#proxy-protocol","title":"Proxy Protocol","text":"<p>By default, the proxy will use <code>https</code> to communicate with backend servers.     You can use <code>google_ssl_off</code> to force some domains to fall back to <code>http</code> protocol.     It is useful, if you want to proxy some domains through another gateway without ssl certificate. <pre><code>#\n## eg. \n## i want to proxy the domain 'www.google.com' like this\n## vps(hk) -&gt; vps(us) -&gt; google\n#\n\n#\n## configuration of vps(hk)\n#\nserver {\n  # ...\n  location / {\n    google on;\n    google_ssl_off \"www.google.com\";\n  }\n  # ...\n}\n\nupstream www.google.com {\n  server &lt; ip of vps(us) &gt;:80;\n}\n\n#\n## configuration of vps(us)\n#\nserver {\n  listen 80;\n  server_name www.google.com;\n  # ...\n  location / {\n    proxy_pass https://www.google.com;\n  }\n  # ...\n}\n</code></pre></p>"},{"location":"modules/google/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-google.</p>"},{"location":"modules/graphite/","title":"graphite: An NGINX module for collecting stats into Graphite","text":""},{"location":"modules/graphite/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-graphite\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-graphite\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_graphite_module.so;\n</code></pre> <p>This document describes nginx-module-graphite v4.3  released on Jan 20 2023.</p> <p>An nginx module for collecting location stats into Graphite.</p>"},{"location":"modules/graphite/#features","title":"Features","text":"<ul> <li>Aggregation of location, server or http metrics</li> <li>Calculation of percentiles</li> <li>Sending data to Graphite over UDP or TCP in non-blocking way</li> <li>Sending custom metrics from lua</li> </ul>"},{"location":"modules/graphite/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    graphite_config prefix=playground server=127.0.0.1;\n    server {\n        location /foo/ {\n            graphite_data nginx.foo;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/graphite/#description","title":"Description","text":"<p>This module use shared memory segment to collect aggregated stats from all workers and send calculated values for last minute to Graphite every 60s (default) over UDP or TCP in non-blocking way. Stats aggegation made on the fly in fixed size buffer allocated on server start and does't affect server performance.</p> <p>This module is in active use on Mail.Ru Sites (one of largest web-services in Russia) for about a year and considered stable and well-tested.</p> <p>To collect metrics from nginx core modules (ssl, gzip, upstream) little patch must be applied on nginx source tree. See the installation instructions. You can build this module as a dynamic one, but then you won't be able to collect metrics from nginx core modules (ssl, gzip, upstream) and lua functions.</p>"},{"location":"modules/graphite/#directives","title":"Directives","text":""},{"location":"modules/graphite/#graphite_config","title":"graphite_config","text":"<p>syntax: graphite_config key1=&lt;value1&gt; key2=&lt;value2&gt; ... keyN=&lt;valueN&gt;</p> <p>context: http</p> <p>Specify global settings for a whole server instance.</p> Param Required Default Description prefix path prefix for all graphs host gethostname() host name for all graphs server Yes carbon-cache server IP address protocol udp carbon-cache server protocol (udp or tcp) port 2003 carbon-cache server port frequency 60 how often send values to Graphite (seconds) intervals 1m aggregation intervals, time interval list, vertical bar separator (<code>m</code> - minutes) params * limit metrics list to track, vertical bar separator shared 2m shared memory size, increase in case of <code>too small shared memory</code> error buffer 64k network buffer size, increase in case of <code>too small buffer size</code> error package 1400 maximum UDP packet size template template for graph name (default is $prefix.$host.$split.$param_$interval) error_log path suffix for error logs graphs (*) <p>(*): works only when nginx_error_log_limiting*.patch is applied to the nginx source code</p> <p>Example (standard):</p> <pre><code>http {\n    graphite_config prefix=playground server=127.0.0.1;\n}\n</code></pre> <p>Example (custom):</p> <pre><code>http {\n    graphite_config prefix=playground server=127.0.0.1 intervals=1m|5m|15m params=rps|request_time|upstream_time template=$prefix.$host.$split.$param_$interval;\n}\n</code></pre> <p>Example (error_log):</p> <pre><code>http {\n    graphite_config prefix=playground server=127.0.0.1 error_log=log;\n}\n</code></pre>"},{"location":"modules/graphite/#graphite_default_data","title":"graphite_default_data","text":"<p>syntax: graphite_default_data &lt;path prefix&gt; [params=&lt;params&gt;] [if=&lt;condition&gt;]</p> <p>context: http, server</p> <p>Create measurement point in all nested locations. You can use \"$location\" or \"$server\" variables which represent the name of the current location and the name of current server with all non-alphanumeric characters replaced with \"_.\" Leading and trailing \"_\" are deleted.</p> <p>Example:</p> <pre><code>   graphite_default_data nginx.$location;\n\n   location /foo/ {\n   }\n\n   location /bar/ {\n   }\n</code></pre> <p>Data for <code>/foo/</code> will be sent to <code>nginx.foo</code>, data for <code>/bar/</code> - to <code>nginx.bar</code>. The <code>&lt;params&gt;</code> parameter (1.3.0) specifies list of params to be collected for all nested locations. To add all default params, use *. The <code>&lt;if&gt;</code> parameter (1.1.0) enables conditional logging. A request will not be logged if the condition evaluates to \"0\" or an empty string.</p> <p>Example(with $server): <pre><code>    graphite_default_data nginx.$server.$location\n\n    server {\n        server_name foo_host;\n\n        location /foo/ {\n        }\n    }\n\n    server {\n        server_name bar_host;\n\n        location /bar/ {\n        }\n    }\n</code></pre></p> <p>Data for <code>/foo/</code> will be sent to <code>nginx.foo_host.foo</code>, data for <code>/bar/</code> - to <code>nginx.bar_host.bar</code>.</p>"},{"location":"modules/graphite/#graphite_data","title":"graphite_data","text":"<p>syntax: graphite_data &lt;path prefix&gt; [params=&lt;params&gt;] [if=&lt;condition&gt;]</p> <p>context: http, server, location, if</p> <p>Create measurement point in specific location.</p> <p>Example:</p> <pre><code>    location /foo/ {\n        graphite_data nginx.foo;\n    }\n</code></pre> <p>The <code>&lt;params&gt;</code> parameter (1.3.0) specifies list of params to be collected for this location. To add all default params, use *. The <code>&lt;if&gt;</code> parameter (1.1.0) enables conditional logging. A request will not be logged if the condition evaluates to \"0\" or an empty string.</p> <p>Example:</p> <pre><code>    map $scheme $is_http { http 1; }\n    map $scheme $is_https { https 1; }\n\n    ...\n\n    location /bar/ {\n        graphite_data nginx.all.bar;\n        graphite_data nginx.http.bar if=$is_http;\n        graphite_data nginx.https.bar if=$is_https;\n        graphite_data nginx.arg params=rps|request_time;\n        graphite_data nginx.ext params=*|rps|request_time;\n    }\n</code></pre>"},{"location":"modules/graphite/#graphite_param","title":"graphite_param","text":"<p>syntax: graphite_param name=&lt;path&gt; interval=&lt;time value&gt; aggregate=&lt;func&gt;</p> <p>context: location</p> Param Required Description name Yes path prefix for all graphs interval Yes* aggregation interval, time intrval value format (<code>m</code> - minutes) aggregate Yes* aggregation function on values percentile Yes* percentile level"},{"location":"modules/graphite/#aggregate-functions","title":"aggregate functions","text":"func Description sum sum of values per interval persec sum of values per second  (<code>sum</code> divided on seconds in <code>interval</code>) avg average value on interval gauge gauge value <p>Example: see below.</p>"},{"location":"modules/graphite/#nginx-api-for-lua","title":"Nginx API for Lua","text":"<p>syntax: ngx.graphite.param(&lt;name&gt;)</p> <p>Get a link on a graphite parameter name, to use it in place of the name for the functions below. The link is valid up to nginx reload. After getting the link of a parameter, you can still pass the parameter name to the functions below. You can get the link of a parameter multiple times, you'll always get the same object by the same name (a lightuserdata). The function returns false if the parameter specified by name doesn't exist. The function returns nil on link getting errors. Functions access parameters information by link faster than by name.</p> <p>Available after applying patch to lua-nginx-module. The feature is present in the patch for lua module v0.10.12. See the installation instructions.</p> <p>syntax: ngx.graphite(&lt;name_or_link&gt;,&lt;value&gt;[,&lt;config&gt;])</p> <p>Write stat value into aggregator function. Floating point numbers accepted in <code>value</code>.</p> <p>Available after applying patch to lua-nginx-module. See the installation instructions.</p> <pre><code>ngx.graphite(name, value, config)\n</code></pre> <p>Example:</p> <pre><code>location /foo/ {\n    graphite_param name=lua.foo_sum aggregate=sum interval=1m;\n    graphite_param name=lua.foo_rps aggregate=persec interval=1m;\n    graphite_param name=lua.foo_avg aggregate=avg interval=1m;\n    graphite_param name=lua.foo_gauge aggregate=gauge;\n\n    content_by_lua '\n        ngx.graphite(\"lua.foo_sum\", 0.01)\n        ngx.graphite(\"lua.foo_rps\", 1)\n        ngx.graphite(\"lua.foo_avg\", ngx.var.request_uri:len())\n        local foo_gauge_link = ngx.graphite.param(\"lua.foo_gauge\")\n        ngx.graphite(foo_gauge_link, 10)\n        ngx.graphite(foo_gauge_link, -2)\n        ngx.graphite(\"lua.auto_rps\", 1, \"aggregate=persec interval=1m percentile=50|90|99\")\n        ngx.say(\"hello\")\n    ';\n}\n</code></pre> <p>You must either specify the <code>graphite_param</code> command or pass the <code>config</code> argument. If you choose the second option, the data for this graph will not be sent until the first call to ngx.graphite.</p> <p>Warning: If you do not declare graph using <code>graphite_param</code> command then memory for the graph will be allocated dynamically in module's shared memory. If module's shared memory is exhausted while nginx is running, no new graphs will be created and an error message will be logged.</p> <p>syntax: ngx.graphite.get(&lt;name_or_link&gt;)</p> <p>Get value of the gauge param with specified <code>name_or_link</code>.</p> <p>syntax: ngx.graphite.set(&lt;name&gt;,&lt;value&gt;)</p> <p>Set <code>value</code> to the gauge param with specified <code>name_or_link</code>.</p>"},{"location":"modules/graphite/#params","title":"Params","text":"Param Units Func Description request_time ms avg total time spent on serving request bytes_sent bytes avg http response length body_bytes_sent bytes avg http response body length request_length bytes avg http request length ssl_handshake_time ms avg time spent on ssl handsake ssl_cache_usage % last how much SSL cache used content_time ms avg time spent generating content inside nginx gzip_time ms avg time spent gzipping content ob-the-fly upstream_time ms avg time spent tailking with upstream upstream_connect_time ms avg time spent on upstream connect (nginx &gt;= 1.9.1) upstream_header_time ms avg time spent on upstream header (nginx &gt;= 1.9.1) rps rps sum total requests number per second keepalive_rps rps sum requests number sent over previously opened keepalive connection response_2xx_rps rps sum total responses number with 2xx code response_3xx_rps rps sum total responses number with 3xx code response_4xx_rps rps sum total responses number with 4xx code response_5xx_rps rps sum total responses number with 5xx code response_[0-9]{3}_rps rps sum total responses number with given code upstream_cache_(miss|bypass|expired|stale|updating|revalidated|hit)_rps rps sum totar responses with a given upstream cache status lua_time ms avg time spent on lua code"},{"location":"modules/graphite/#percentiles","title":"Percentiles","text":"<p>To calculate percentile value for any parameter, set percentile level via <code>/</code>. E.g. <code>request_time/50|request_time/90|request_time/99</code>.</p>"},{"location":"modules/graphite/#patch-to-add-api-for-sending-metrics-from-lua-code-optional","title":"patch to add api for sending metrics from lua code (optional)","text":"<p>patch -p1 &lt; /path/to/graphite-nginx-module/lua_module_v0_9_11.patch cd ..</p> <p>wget 'http://nginx.org/download/nginx-1.9.2.tar.gz' tar -xzf nginx-1.9.2.tar.gz cd nginx-1.9.2/</p>"},{"location":"modules/graphite/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-graphite.</p>"},{"location":"modules/headers-more/","title":"headers-more: NGINX Headers More dynamic module","text":""},{"location":"modules/headers-more/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-headers-more\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-headers-more\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_headers_more_filter_module.so;\n</code></pre> <p>This document describes nginx-module-headers-more v0.33  released on Jun 28 2022.</p> <p>ngx_headers_more - Set and clear input and output headers...more than \"add\"!</p>"},{"location":"modules/headers-more/#synopsis","title":"Synopsis","text":"<pre><code> # set the Server output header\n more_set_headers 'Server: my-server';\n\n # set and clear output headers\n location /bar {\n     more_set_headers 'X-MyHeader: blah' 'X-MyHeader2: foo';\n     more_set_headers -t 'text/plain text/css' 'Content-Type: text/foo';\n     more_set_headers -s '400 404 500 503' -s 413 'Foo: Bar';\n     more_clear_headers 'Content-Type';\n\n     # your proxy_pass/memcached_pass/or any other config goes here...\n }\n\n # set output headers\n location /type {\n     more_set_headers 'Content-Type: text/plain';\n     # ...\n }\n\n # set input headers\n location /foo {\n     set $my_host 'my dog';\n     more_set_input_headers 'Host: $my_host';\n     more_set_input_headers -t 'text/plain' 'X-Foo: bah';\n\n     # now $host and $http_host have their new values...\n     # ...\n }\n\n # replace input header X-Foo *only* if it already exists\n more_set_input_headers -r 'X-Foo: howdy';\n</code></pre>"},{"location":"modules/headers-more/#description","title":"Description","text":"<p>This module allows you to add, set, or clear any output or input header that you specify.</p> <p>This is an enhanced version of the standard headers module because it provides more utilities like resetting or clearing \"builtin headers\" like <code>Content-Type</code>, <code>Content-Length</code>, and <code>Server</code>.</p> <p>It also allows you to specify an optional HTTP status code criteria using the <code>-s</code> option and an optional content type criteria using the <code>-t</code> option while modifying the output headers with the more_set_headers and more_clear_headers directives. For example,</p> <pre><code> more_set_headers -s 404 -t 'text/html' 'X-Foo: Bar';\n</code></pre> <p>You can also specify multiple MIME types to filter out in a single <code>-t</code> option. For example,</p> <pre><code>more_set_headers -t 'text/html text/plain' 'X-Foo: Bar';\n</code></pre> <p>Never use other paramemters like <code>charset=utf-8</code> in the <code>-t</code> option values; they will not work as you would expect.</p> <p>Input headers can be modified as well. For example</p> <pre><code> location /foo {\n     more_set_input_headers 'Host: foo' 'User-Agent: faked';\n     # now $host, $http_host, $user_agent, and\n     #   $http_user_agent all have their new values.\n }\n</code></pre> <p>The option <code>-t</code> is also available in the more_set_input_headers and more_clear_input_headers directives (for request header filtering) while the <code>-s</code> option is not allowed.</p> <p>Unlike the standard headers module, this module's directives will by default apply to all the status codes, including <code>4xx</code> and <code>5xx</code>.</p>"},{"location":"modules/headers-more/#directives","title":"Directives","text":""},{"location":"modules/headers-more/#more_set_headers","title":"more_set_headers","text":"<p>syntax: more_set_headers [-t &lt;content-type list&gt;]... [-s &lt;status-code list&gt;]... &lt;new-header&gt;...</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>Replaces (if any) or adds (if not any) the specified output headers when the response status code matches the codes specified by the <code>-s</code> option AND the response content type matches the types specified by the <code>-t</code> option.</p> <p>If either <code>-s</code> or <code>-t</code> is not specified or has an empty list value, then no match is required. Therefore, the following directive set the <code>Server</code> output header to the custom value for any status code and any content type:</p> <pre><code>   more_set_headers    \"Server: my_server\";\n</code></pre> <p>Existing response headers with the same name are always overridden. If you want to add headers incrementally, use the standard add_header directive instead.</p> <p>A single directive can set/add multiple output headers. For example</p> <pre><code>   more_set_headers 'Foo: bar' 'Baz: bah';\n</code></pre> <p>Multiple occurrences of the options are allowed in a single directive. Their values will be merged together. For instance</p> <pre><code>   more_set_headers -s 404 -s '500 503' 'Foo: bar';\n</code></pre> <p>is equivalent to</p> <pre><code>   more_set_headers -s '404 500 503' 'Foo: bar';\n</code></pre> <p>The new header should be the one of the forms:</p> <ol> <li><code>Name: Value</code></li> <li><code>Name:</code></li> <li><code>Name</code></li> </ol> <p>The last two effectively clear the value of the header <code>Name</code>.</p> <p>Nginx variables are allowed in header values. For example:</p> <pre><code>    set $my_var \"dog\";\n    more_set_headers \"Server: $my_var\";\n</code></pre> <p>But variables won't work in header keys due to performance considerations.</p> <p>Multiple set/clear header directives are allowed in a single location, and they're executed sequentially.</p> <p>Directives inherited from an upper level scope (say, http block or server blocks) are executed before the directives in the location block.</p> <p>Note that although <code>more_set_headers</code> is allowed in location if blocks, it is not allowed in the server if blocks, as in</p> <pre><code>   ?  # This is NOT allowed!\n   ?  server {\n   ?      if ($args ~ 'download') {\n   ?          more_set_headers 'Foo: Bar';\n   ?      }\n   ?      ...\n   ?  }\n</code></pre> <p>Behind the scene, use of this directive and its friend more_clear_headers will (lazily) register an ouput header filter that modifies <code>r-&gt;headers_out</code> the way you specify.</p>"},{"location":"modules/headers-more/#more_clear_headers","title":"more_clear_headers","text":"<p>syntax: more_clear_headers [-t &lt;content-type list&gt;]... [-s &lt;status-code list&gt;]... &lt;new-header&gt;...</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>Clears the specified output headers.</p> <p>In fact,</p> <pre><code>    more_clear_headers -s 404 -t 'text/plain' Foo Baz;\n</code></pre> <p>is exactly equivalent to</p> <pre><code>    more_set_headers -s 404 -t 'text/plain' \"Foo: \" \"Baz: \";\n</code></pre> <p>or</p> <pre><code>    more_set_headers -s 404 -t 'text/plain' Foo Baz\n</code></pre> <p>See more_set_headers for more details.</p> <p>The wildcard character, <code>*</code>, can also be used at the end of the header name to specify a pattern. For example, the following directive effectively clears any output headers starting by \"<code>X-Hidden-</code>\":</p> <pre><code> more_clear_headers 'X-Hidden-*';\n</code></pre> <p>The <code>*</code> wildcard support was first introduced in v0.09.</p>"},{"location":"modules/headers-more/#more_set_input_headers","title":"more_set_input_headers","text":"<p>syntax: more_set_input_headers [-r] [-t &lt;content-type list&gt;]... &lt;new-header&gt;...</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: rewrite tail</p> <p>Very much like more_set_headers except that it operates on input headers (or request headers) and it only supports the <code>-t</code> option.</p> <p>Note that using the <code>-t</code> option in this directive means filtering by the <code>Content-Type</code> request header, rather than the response header.</p> <p>Behind the scene, use of this directive and its friend more_clear_input_headers will (lazily) register a <code>rewrite phase</code> handler that modifies <code>r-&gt;headers_in</code> the way you specify. Note that it always run at the end of the <code>rewrite</code> phase so that it runs after the standard rewrite module and works in subrequests as well.</p> <p>If the <code>-r</code> option is specified, then the headers will be replaced to the new values only if they already exist.</p>"},{"location":"modules/headers-more/#more_clear_input_headers","title":"more_clear_input_headers","text":"<p>syntax: more_clear_input_headers [-t &lt;content-type list&gt;]... &lt;new-header&gt;...</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: rewrite tail</p> <p>Clears the specified input headers.</p> <p>In fact,</p> <pre><code>    more_clear_input_headers -t 'text/plain' Foo Baz;\n</code></pre> <p>is exactly equivalent to</p> <pre><code>    more_set_input_headers -t 'text/plain' \"Foo: \" \"Baz: \";\n</code></pre> <p>or</p> <pre><code>    more_set_input_headers -t 'text/plain' Foo Baz\n</code></pre> <p>To remove request headers \"Foo\" and \"Baz\" for all incoming requests regardless of the content type, we can write</p> <pre><code>    more_clear_input_headers \"Foo\" \"Baz\";\n</code></pre> <p>See more_set_input_headers for more details.</p> <p>The wildcard character, <code>*</code>, can also be used at the end of the header name to specify a pattern. For example, the following directive effectively clears any input headers starting by \"<code>X-Hidden-</code>\":</p> <pre><code>     more_clear_input_headers 'X-Hidden-*';\n</code></pre>"},{"location":"modules/headers-more/#limitations","title":"Limitations","text":"<ul> <li>Unlike the standard headers module, this module does not automatically take care of the constraint among the <code>Expires</code>, <code>Cache-Control</code>, and <code>Last-Modified</code> headers. You have to get them right yourself or use the headers module together with this module.</li> <li>You cannot remove the <code>Connection</code> response header using this module because the <code>Connection</code> response header is generated by the standard <code>ngx_http_header_filter_module</code> in the Nginx core, whose output header filter runs always after the filter of this module. The only way to actually remove the <code>Connection</code> header is to patch the Nginx core, that is, editing the C function <code>ngx_http_header_filter</code> in the <code>src/http/ngx_http_header_filter_module.c</code> file.</li> </ul>"},{"location":"modules/headers-more/#changes","title":"Changes","text":"<p>The changes of every release of this module can be obtained from the OpenResty bundle's change logs:</p> <p>http://openresty.org/#Changes</p>"},{"location":"modules/headers-more/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too. Thanks to the Test::Nginx module in the Perl world.</p> <p>To run it on your side:</p> <pre><code> $ PATH=/path/to/your/nginx-with-headers-more-module:$PATH prove -r t\n</code></pre> <p>To run the test suite with valgrind's memcheck, use the following commands:</p> <pre><code> $ export PATH=/path/to/your/nginx-with-headers-more-module:$PATH\n $ TEST_NGINX_USE_VALGRIND=1 prove -r t\n</code></pre> <p>You need to terminate any Nginx processes before running the test suite if you have changed the Nginx server binary.</p> <p>Because a single nginx server (by default, <code>localhost:1984</code>) is used across all the test scripts (<code>.t</code> files), it's meaningless to run the test suite in parallel by specifying <code>-jN</code> when invoking the <code>prove</code> utility.</p> <p>Some parts of the test suite requires modules proxy, rewrite, and echo to be enabled as well when building Nginx.</p>"},{"location":"modules/headers-more/#see-also","title":"See Also","text":"<ul> <li>The original thread on the Nginx mailing list that inspires this module's development: \"A question about add_header replication\".</li> <li>The orginal announcement thread on the Nginx mailing list: \"The \"headers_more\" module: Set and clear output headers...more than 'add'!\".</li> <li>The original blog post about this module's initial development.</li> <li>The echo module for Nginx module's automated testing.</li> <li>The standard headers module.</li> </ul>"},{"location":"modules/headers-more/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-headers-more.</p>"},{"location":"modules/hmac-secure-link/","title":"hmac-secure-link: Alternative NGINX HMAC Secure Link module with support for OpenSSL hashes","text":""},{"location":"modules/hmac-secure-link/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-hmac-secure-link\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-hmac-secure-link\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_hmac_secure_link_module.so;\n</code></pre> <p>This document describes nginx-module-hmac-secure-link v0.3  released on Mar 06 2019.</p>"},{"location":"modules/hmac-secure-link/#description","title":"Description:","text":"<p>The Nginx HMAC secure link module enhances the security and functionality of the standard secure link module. Secure token is created using secure HMAC construction with an arbitrary hash algorithm supported by OpenSSL, e.g.: <code>blake2b512</code>, <code>blake2s256</code>, <code>gost</code>, <code>md4</code>, <code>md5</code>, <code>rmd160</code>, <code>sha1</code>, <code>sha224</code>, <code>sha256</code>, <code>sha3-224</code>, <code>sha3-256</code>, <code>sha3-384</code>, <code>sha3-512</code>, <code>sha384</code>, <code>sha512</code>, <code>sha512-224</code>, <code>sha512-256</code>, <code>shake128</code>, <code>shake256</code>, <code>sm3</code>.</p> <p>Furthermore, secure token is created as described in RFC2104, that is, <code>H(secret_key XOR opad,H(secret_key XOR ipad, message))</code> instead of a simple <code>MD5(secret_key,message, expire)</code>.</p>"},{"location":"modules/hmac-secure-link/#usage","title":"Usage:","text":"<p>Message to be hashed is defined by <code>secure_link_hmac_message</code>, <code>secret_key</code> is given by <code>secure_link_hmac_secret</code>, and hashing algorithm H is defined by <code>secure_link_hmac_algorithm</code>.</p> <p>For improved security the timestamp in ISO 8601 the format <code>2017-12-08T07:54:59+00:00</code> (one possibility according to ISO 8601) or as <code>Unix Timestamp</code> should be appended to the message to be hashed.</p> <p>It is possible to create links with limited lifetime. This is defined by an optional parameter. If the expiration period is zero or it is not specified, a link has the unlimited lifetime.</p> <p>Configuration example for server side.</p> <pre><code>location ^~ /files/ {\n    # Variable to be passed are secure token, timestamp, expiration period (optional)\n    secure_link_hmac  $arg_st,$arg_ts,$arg_e;\n\n    # Secret key\n    secure_link_hmac_secret my_secret_key;\n\n    # Message to be verified\n    secure_link_hmac_message $uri$arg_ts$arg_e;\n\n    # Cryptographic hash function to be used\n    secure_link_hmac_algorithm sha256;\n\n    # If the hash is incorrect then $secure_link_hmac is a null string.\n    # If the hash is correct but the link has already expired then $secure_link_hmac is zero.\n    # If the hash is correct and the link has not expired then $secure_link_hmac is one.\n\n    # In production environment, we should not reveal to potential attacker\n    # why hmac authentication has failed\n    if ($secure_link_hmac != \"1\") {\n        return 404;\n    }\n\n    rewrite ^/files/(.*)$ /files/$1 break;\n}\n</code></pre> <p>Application side should use a standard hash_hmac function to generate hash, which then needs to be base64url encoded. Example in Perl below.</p>"},{"location":"modules/hmac-secure-link/#variable-data-contains-secure-token-timestamp-in-iso-8601-format-and-expiration-period-in-seconds","title":"Variable $data contains secure token, timestamp in ISO 8601 format, and expiration period in seconds","text":"<pre><code>perl_set $secure_token '\n    sub {\n        use Digest::SHA qw(hmac_sha256_base64);\n        use POSIX qw(strftime);\n\n        my $now = time();\n        my $key = \"my_very_secret_key\";\n        my $expire = 60;\n        my $tz = strftime(\"%z\", localtime($now));\n        $tz =~ s/(\\d{2})(\\d{2})/$1:$2/;\n        my $timestamp = strftime(\"%Y-%m-%dT%H:%M:%S\", localtime($now)) . $tz;\n        my $r = shift;\n        my $data = $r-&gt;uri;\n        my $digest = hmac_sha256_base64($data . $timestamp . $expire,  $key);\n        $digest =~ tr(+/)(-_);\n        $data = \"st=\" . $digest . \"&amp;ts=\" . $timestamp . \"&amp;e=\" . $expire;\n        return $data;\n    }\n';\n</code></pre> <p>A similar function in PHP</p> <pre><code>$secret = 'my_very_secret_key';\n$expire = 60;\n$algo = 'sha256';\n$timestamp = date('c');\n$stringtosign = \"/files/top_secret.pdf{$timestamp}{$expire}\";\n$hashmac = base64_encode(hash_hmac($algo, $stringtosign, $secret, true));\n$hashmac = strtr($hashmac, '+/', '-_'));\n$hashmac = str_replace('=', '', $hashmac);\n$host = $_SERVER['HTTP_HOST'];\n$loc = \"https://{$host}/files/top_secret.pdf?st={$hashmac}&amp;ts={$timestamp}&amp;e={$expire}\";\n</code></pre> <p>Using Unix timestamp in Node.js</p> <pre><code>const crypto = require(\"crypto\");\nconst secret = 'my_very_secret_key';\nconst expire = 60;\nconst unixTimestamp = Math.round(Date.now() / 1000.);\nconst stringToSign = `/files/top_secret.pdf${unixTimestamp}${expire}`;\nconst hashmac = crypto.createHmac('sha256', secret).update(stringToSign).digest('base64')\n      .replace(/=/g, '')\n      .replace(/\\+/g, '-')\n      .replace(/\\//g, '_');\nconst loc = `https://host/files/top_secret.pdf?st=${hashmac}&amp;ts=${unixTimestamp}&amp;e=${expire}`;\n</code></pre> <p>It is also possible to use this module with a Nginx acting as proxy server.</p> <p>The string to be signed is defined in <code>secure_link_hmac_message</code>, the <code>secure_link_hmac_token</code> variable contains then a secure token to be passed to backend server.</p> <pre><code>location ^~ /backend_location/ {\n    set $expire 60;\n\n    secure_link_hmac_message \"$uri$time_iso8601$expire\";\n    secure_link_hmac_secret \"my_very_secret_key\";\n    secure_link_hmac_algorithm sha256;\n\n    proxy_pass \"http://backend_server$uri?st=$secure_link_hmac_token&amp;ts=$time_iso8601&amp;e=$expire\";\n}\n</code></pre>"},{"location":"modules/hmac-secure-link/#embedded-variables","title":"Embedded Variables","text":"<ul> <li><code>$secure_link_hmac</code> - </li> <li><code>$secure_link_hmac_token</code> - </li> <li><code>$secure_link_hmac_expires</code> - The lifetime of a link passed in a request.</li> </ul>"},{"location":"modules/hmac-secure-link/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-hmac-secure-link.</p>"},{"location":"modules/html-sanitize/","title":"html-sanitize: NGINX module to sanitize HTML 5 with whitelisted elements, attributes and CSS","text":""},{"location":"modules/html-sanitize/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-html-sanitize\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-html-sanitize\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_html_sanitize_module.so;\n</code></pre> <p>This document describes nginx-module-html-sanitize v0.2.4  released on Aug 08 2019.</p>"},{"location":"modules/html-sanitize/#name","title":"Name","text":"<p>ngx_http_html_sanitize_module - It's base on google's gumbo-parser as HTML5 parser and hackers-painters's katana-parser as inline CSS parser to sanitize HTML with whitelisted elements, whitelisted attributes and whitelisted CSS property.</p>"},{"location":"modules/html-sanitize/#status","title":"Status","text":"<p>Production Ready :-)</p>"},{"location":"modules/html-sanitize/#example","title":"Example","text":"<p>There is a example of nginx configuration according to the https://dev.w3.org/html5/html-author/#the-elements as the following:</p> <pre><code>server {\n    listen 8888;\n\n    location = /sanitize {\n        # Explicitly set utf-8 encoding\n        add_header Content-Type \"text/html; charset=UTF-8\";\n\n        client_body_buffer_size 10M;\n        client_max_body_size 10M;\n\n        html_sanitize on;\n\n        # Check https://dev.w3.org/html5/html-author/#the-elements\n\n        # Root Element\n        html_sanitize_element html;\n\n        # Document Metadata\n        html_sanitize_element head title base link meta style;\n\n        # Scripting\n        html_sanitize_element script noscript;\n\n        # Sections\n        html_sanitize_element body section nav article aside h1 h2 h3 h4 h5 h6 header footer address;\n\n        # Grouping Content\n        html_sanitize_element p hr br pre dialog blockquote ol ul li dl dt dd;\n\n        # Text-Level Semantics\n        html_sanitize_element a q cite em strong small mark dfn abbr time progress meter code var samp kbd sub sup span i b bdo ruby rt rp;\n\n        # Edits\n        html_sanitize_element ins del;\n\n        # Embedded Content\n        htlm_sanitize_element figure img iframe embed object param video audio source canvas map area;\n\n        # Tabular Data\n        html_sanitize_element table caption colgroup col tbody thead tfoot tr td th;\n\n        # Forms\n        html_sanitize_element form fieldset label input button select datalist optgroup option textare output;\n\n        # Interactive Elements\n        html_sanitize_element details command bb menu;\n\n        # Miscellaneous Elements\n        html_sanitize_element legend div;\n\n        html_sanitize_attribute *.style;\n        html_sanitize_attribute a.href a.hreflang a.name a.rel;\n        html_sanitize_attribute col.span col.width colgroup.span colgroup.width;\n        html_sanitize_attribute data.value del.cite del.datetime;\n        html_sanitize_attribute img.align img.alt img.border img.height img.src img.width;\n        html_sanitize_attribute ins.cite ins.datetime li.value ol.reversed ol.stasrt ol.type ul.type;\n        html_sanitize_attribute table.align table.bgcolor table.border table.cellpadding table.cellspacing table.frame table.rules table.sortable table.summary table.width;\n        html_sanitize_attribute td.abbr td.align td.axis td.colspan td.headers td.rowspan td.valign td.width;\n        html_sanitize_attribute th.abbr th.align th.axis th.colspan th.rowspan th.scope th.sorted th.valign th.width;\n\n        html_sanitize_style_property color font-size;\n\n        html_sanitize_url_protocol http https tel;\n        html_sanitize_url_domain *.google.com google.com;\n\n        html_sanitize_iframe_url_protocol http https;\n        html_sanitize_iframe_url_domain  facebook.com *.facebook.com;\n    }\n}\n</code></pre> <p>And It's recommanded to use the below commnand to sanitize HTML5:</p> <pre><code>$ curl -X POST -d \"&lt;h1&gt;Hello World &lt;/h1&gt;\" http://127.0.0.1:8888/sanitize?element=2&amp;attribute=1&amp;style_property=1&amp;style_property_value=1&amp;url_protocol=1&amp;url_domain=0&amp;iframe_url_protocol=1&amp;iframe_url_domain=0\n\n&lt;h1&gt;Hello World &lt;/h1&gt;\n</code></pre> <p>This querystring <code>element=2&amp;attribute=1&amp;style_property=1&amp;style_property_value=1&amp;url_protocol=1&amp;url_domain=0&amp;iframe_url_protocol=1&amp;iframe_url_domain=0</code> is the as following:</p> <ul> <li>element=2: output whitelisted element by html_sanitize_element</li> <li>attribute=1: output any attribute by html_sanitize_attribute</li> <li>style_property=1: output any style property by html_sanitize_style_property</li> <li>style_property_value=1: check the style value for url function and expression function to avoid XSS inject by  style_property_value</li> <li>url_protocol=1: check whitelisted url_protocol for absoluted URL by html_sanitize_url_protocol</li> <li>url_domain=0: do not check url domain for absoluted URL</li> <li>iframe_url_protocol=1: is the same as url_protocol but only for <code>iframe.src</code> by html_sanitize_iframe_url_protocol</li> <li>iframe_url_domain=0: is the same as url_domain but only for <code>iframe.src</code> by html_sanitize_iframe_url_domain</li> </ul> <p>With ngx_http_html_sanitize_module, we have the ability to specify whether output HTML5's element \u3001attribute and inline CSS's property by directive and querystring as the following:</p>"},{"location":"modules/html-sanitize/#whitelisted-element","title":"whitelisted element","text":"<ul> <li>disable element:</li> </ul> <p>if we do not want to output any element, we can do this as the following:</p> <pre><code>curl -X POST -d \"&lt;h1&gt;h1&lt;/h1&gt;\" http://127.0.0.1:8888/sanitize?element=0\n</code></pre> <ul> <li>enable element:</li> </ul> <p>if we want to output any element, we can do this as the following: <pre><code>$ curl -X POST -d \"&lt;h1&gt;h1&lt;/h1&gt;&lt;h7&gt;h7&lt;/h7&gt;\" http://127.0.0.1:8888/sanitize?element=1\n\n&lt;h1&gt;h1&lt;/h1&gt;&lt;h7&gt;h7&lt;/h7&gt;\n</code></pre></p> <ul> <li>enable whitelisted element:</li> </ul> <p>if we want to output whitelisted element, we can do this as the following</p> <pre><code>$ curl -X POST -d \"&lt;h1&gt;h1&lt;/h1&gt;&lt;h7&gt;h7&lt;/h7&gt;\" http://127.0.0.1:8888/sanitize?element=1\n\n&lt;h1&gt;h1&lt;/h1&gt;\n</code></pre>"},{"location":"modules/html-sanitize/#whitelisted-attribute","title":"whitelisted attribute","text":"<ul> <li>disable attribute:</li> </ul> <p>if we do not want to output any attribute, we can do this as the following:</p> <pre><code>curl -X POST -d \"&lt;h1 ha=\\\"ha\\\"&gt;h1&lt;/h1&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=0\"\n\n&lt;h1&gt;h1&lt;/h1&gt;\n</code></pre> <ul> <li>enable attribute:</li> </ul> <p>if we want to output any attribute, we can do this as the following: <pre><code>$ curl -X POST -d \"&lt;h1 ha=\\\"ha\\\"&gt;h1&lt;/h1&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=1\"\n\n&lt;h1 ha=\"ha\"&gt;h1&lt;/h1&gt;\n</code></pre></p> <ul> <li>enable whitelisted attribute:</li> </ul> <p>if we want to output whitelisted element, we can do this as the following:</p> <pre><code>$ curl -X POST -d \"&lt;img src=\\\"/\\\" ha=\\\"ha\\\" /&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=2\"\n\n&lt;img src=\"/\" /&gt;\n</code></pre>"},{"location":"modules/html-sanitize/#whitelisted-style-property","title":"whitelisted style property","text":"<ul> <li>disable style property:</li> </ul> <p>if we do not want to output any style property, we can do this as the following:</p> <pre><code>## It will do not output any style property\ncurl -X POST -d \"&lt;h1 style=\\\"color:red;\\\"&gt;h1&lt;/h1&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=1&amp;style_property=0\"\n\n&lt;h1&gt;h1&lt;/h1&gt;\n</code></pre> <ul> <li>enable style property:</li> </ul> <p>if we want to output any style property, we can do this as the following: <pre><code>$ curl -X POST -d \"&lt;h1 style=\\\"color:red;text-align:center;\\\"&gt;h1&lt;/h1&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=1&amp;style_property=1\"\n\n&lt;h1 style=\"color:red;text-align:center\"&gt;h1&lt;/h1&gt;\n</code></pre></p> <ul> <li>enable whitelisted style property:</li> </ul> <p>if we want to output whitelisted style property, we can do this as the following:</p> <pre><code>$ curl -X POST -d \"&lt;h1 style=\\\"color:red;text-align:center;\\\" &gt;h1&lt;/h1&gt;\" \"http://127.0.0.1:8888/sanitize?element=1&amp;attribute=1&amp;style_property=2\"\n\n&lt;h1 style=\"color:red;\"&gt;h1&lt;/h1&gt;\n</code></pre>"},{"location":"modules/html-sanitize/#description","title":"Description","text":"<p>Now the implement of ngx_http_html_sanitize_module is based on gumbo-parser and katana-parser. And we make the combo upon it then run it on nginx to as a center web service maintained by professional security people for discarding language-level difference. If we want to gain more higher performance (here is the brenchmark), it's recommanded to write language-level library wrapering above pure c library to overcome the overhead of network transmission.</p>"},{"location":"modules/html-sanitize/#benchmark","title":"Benchmark","text":"<p>Testing with <code>wrk -s benchmarks/shot.lua -d 60s \"http://127.0.0.1:8888\"</code> on Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz and 64GB memory</p> Name Size Avg Latency QPS hacker_news.html 30KB 9.06ms 2921.82 baidu.html 76KB 13.41ms 1815.75 arabic_newspapers.html 78KB 16.58ms 1112.70 bbc.html 115KB 17.96ms 993.12 xinhua.html 323KB 33.37ms 275.39 google.html 336KB 26.78ms 351.54 yahoo.html 430KB 29.16ms 323.04 wikipedia.html 511KB 57.62ms 160.10 html5_spec.html 7.7MB 1.63s 2.00"},{"location":"modules/html-sanitize/#directive","title":"Directive","text":""},{"location":"modules/html-sanitize/#html_sanitize","title":"html_sanitize","text":"<p>syntax: html_sanitize on | off</p> <p>default: html_sanitize on</p> <p>context: location</p> <p>Specifies whether enable html sanitize handler on location context</p>"},{"location":"modules/html-sanitize/#html_sanitize_hash_max_size","title":"html_sanitize_hash_max_size","text":"<p>syntax: html_sanitize_hash_max_size size</p> <p>default: html_sanitize_hash_max_size 2048</p> <p>context: location</p> <p>Sets the maximum size of the element\u3001attribute\u3001style_property\u3001url_protocol\u3001url_domain\u3001iframe_url_protocol\u3001iframe_url_domain hash tables.</p>"},{"location":"modules/html-sanitize/#html_sanitize_hash_bucket_size","title":"html_sanitize_hash_bucket_size","text":"<p>syntax: html_sanitize_hash_bucket_size size</p> <p>default: html_sanitize_hash_bucket_size 32|64|128</p> <p>context: location</p> <p>Sets the bucket size for element\u3001attribute\u3001style_property\u3001url_protocol\u3001url_domain\u3001iframe_url_protocol\u3001iframe_url_domain. The default value depends on the size of the processor\u2019s cache line.</p>"},{"location":"modules/html-sanitize/#html_sanitize_element","title":"html_sanitize_element","text":"<p>syntax: html_sanitize_element element ...</p> <p>default: -</p> <p>context: location</p> <p>Set the whitelisted HTML5 elements when enable whitelisted element by setting the querystring element whitelist mode as the following:</p> <pre><code>html_sanitize_element html head body;\n</code></pre>"},{"location":"modules/html-sanitize/#html_sanitize_attribute","title":"html_sanitize_attribute","text":"<p>syntax: html_sanitize_attribute attribute ...</p> <p>default: -</p> <p>context: location</p> <p>Set the whitelisted HTML5 attributes when enable whitelisted element by setting the querystring attribute whitelist mode as the following:</p> <pre><code>html_sanitize_attribute a.href h1.class;\n</code></pre> <p>PS: attribute format must be the same as <code>element.attribute</code> and support <code>*.attribute</code> (prefix asterisk) and <code>element.*</code> (suffix asterisk)</p>"},{"location":"modules/html-sanitize/#html_sanitize_style_property","title":"html_sanitize_style_property","text":"<p>syntax: html_sanitize_style_property property ...</p> <p>default: -</p> <p>context: location</p> <p>Set the whitelisted CSS property when enable whitelisted element by setting the querystring style_property whitelist mode as the following:</p> <pre><code>html_sanitize_style_property color background-color;\n</code></pre>"},{"location":"modules/html-sanitize/#html_sanitize_url_protocol","title":"html_sanitize_url_protocol","text":"<p>syntax: html_sanitize_url_protocol [protocol] ...</p> <p>default: -</p> <p>context: location</p> <p>Set the allowed URL protocol at linkable attribute when only the URL is absoluted rahter than related and enable URL protocol check by setting the querystring url_protocol check mode as the following:</p> <pre><code>html_sanitize_url_protocol http https tel;\n</code></pre>"},{"location":"modules/html-sanitize/#html_sanitize_url_domain","title":"html_sanitize_url_domain","text":"<p>syntax: html_sanitize_url_domain domain ...</p> <p>default: -</p> <p>context: location</p> <p>Set the allowed URL domain at linkable attribute when only the URL is absoluted rahter than relatived and enable URL protocol check\u3001URL domain check by setting the querystring url_protocol check mode and the querystring url_domain[#url_domain] check mode as the following:</p> <pre><code>html_sanitize_url_domain *.google.com google.com;\n</code></pre>"},{"location":"modules/html-sanitize/#html_sanitize_iframe_url_protocol","title":"html_sanitize_iframe_url_protocol","text":"<p>syntax: html_sanitize_iframe_url_protocol [protocol] ...</p> <p>default: -</p> <p>context: location</p> <p>is the same as html_sanitize_url_protocol but only for <code>iframe.src</code> attribute</p> <pre><code>html_sanitize_iframe_url_protocol http https tel;\n</code></pre>"},{"location":"modules/html-sanitize/#html_sanitize_iframe_url_domain","title":"html_sanitize_iframe_url_domain","text":"<p>syntax: html_sanitize_iframe_url_domain [protocol] ...</p> <p>default: -</p> <p>context: location</p> <p>is the same as html_sanitize_url_domain but only for <code>iframe.src</code> attribute</p> <pre><code>html_sanitize_iframe_url_domain *.facebook.com facebook.com;\n</code></pre>"},{"location":"modules/html-sanitize/#linkable_attribute","title":"linkable_attribute","text":"<p>The linkable attribute is the following:</p> <ul> <li>a.href</li> <li>blockquote.cite</li> <li>q.cite</li> <li>del.cite</li> <li>img.src</li> <li>ins.cite</li> <li>iframe.src</li> <li>CSS URL function</li> </ul>"},{"location":"modules/html-sanitize/#querystring","title":"Querystring","text":"<p>the querystring from request URL is used to control the ngx_http_html_sanitize_module internal action.</p>"},{"location":"modules/html-sanitize/#document","title":"document","text":"<p>value: 0 or 1</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether append <code>&lt;!DOCTYPE&gt;</code> to response body</p>"},{"location":"modules/html-sanitize/#html","title":"html","text":"<p>value: 0 or 1</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether append <code>&lt;html&gt;&lt;/html&gt;</code> to response body</p>"},{"location":"modules/html-sanitize/#script","title":"script","text":"<p>value: 0 or 1</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether allow <code>&lt;script&gt;&lt;/script&gt;</code></p>"},{"location":"modules/html-sanitize/#style","title":"style","text":"<p>value: 0 or 1</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether allow <code>&lt;style&gt;&lt;/style&gt;</code></p>"},{"location":"modules/html-sanitize/#namespace","title":"namespace","text":"<p>value: 0\u30011 or 2</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies the mode of gumbo-parser with the value as the following:</p> <ul> <li>GUMBO_NAMESPACE_HTML: 0</li> <li>GUMBO_NAMESPACE_SVG: 1</li> <li>GUMBO_NAMESPACE_MATHML: 2</li> </ul>"},{"location":"modules/html-sanitize/#context","title":"context","text":"<p>value: [0, 150)</p> <p>default: 38(GUMBO_TAG_DIV)</p> <p>context: querystring</p> <p>Specifies the context of gumbo-parser with the value at the this file tag_enum.h</p>"},{"location":"modules/html-sanitize/#element","title":"element","text":"<p>value: 0\u30011\u30012</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies the mode of output element with the value as the following:</p> <ul> <li>0: do not output element</li> <li>1: output all elements</li> <li>2: output whitelisted elements</li> </ul>"},{"location":"modules/html-sanitize/#attribute","title":"attribute","text":"<p>value: 0\u30011\u30012</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies the mode of output attribute with the value as the following:</p> <ul> <li>0: do not output attributes</li> <li>1: output all attributes</li> <li>2: output whitelisted attributes</li> </ul>"},{"location":"modules/html-sanitize/#style_property","title":"style_property","text":"<p>value: 0\u30011\u30012</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies the mode of output CSS property with the value as the following:</p> <ul> <li>0: do not output CSS property</li> <li>1: output all CSS property</li> <li>2: output whitelisted CSS property</li> </ul>"},{"location":"modules/html-sanitize/#style_property_value","title":"style_property_value","text":"<p>value: 0\u30011</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies the mode of output CSS property_value with the value as the following:</p> <ul> <li>0: do not check the CSS property's value</li> <li>1: check the CSS property's value for URL function and IE's expression function to avoid XSS inject</li> </ul>"},{"location":"modules/html-sanitize/#url_protocol","title":"url_protocol","text":"<p>value: 0\u30011</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether check the URL protocol at linkable_attribute. The value is as the following:</p> <ul> <li>0: do not check the URL protocol</li> <li>1: output whitelisted URL protocol</li> </ul>"},{"location":"modules/html-sanitize/#url_domain","title":"url_domain","text":"<p>value: 0\u30011</p> <p>default: 0</p> <p>context: querystring</p> <p>Specifies whether check the URL domain at linkable_attribute when enable url_protocol check. The value is  as the following:</p> <ul> <li>0: do not check the URL domain</li> <li>1: output whitelisted URL domain</li> </ul>"},{"location":"modules/html-sanitize/#iframe_url_protocol","title":"iframe_url_protocol","text":"<p>value: 0\u30011</p> <p>default: 0</p> <p>context: querystring</p> <p>is the same as url_protocol but only for <code>iframe.src</code></p>"},{"location":"modules/html-sanitize/#iframe_url_domain","title":"iframe_url_domain","text":"<p>value: 0\u30011</p> <p>default: 0</p> <p>context: querystring</p> <p>is the same as url_domain but only for <code>iframe.src</code></p>"},{"location":"modules/html-sanitize/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-html-sanitize.</p>"},{"location":"modules/iconv/","title":"iconv: NGINX iconv module","text":""},{"location":"modules/iconv/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-iconv\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-iconv\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_iconv_module.so;\n</code></pre> <p>This document describes nginx-module-iconv v0.14  released on May 15 2016.</p>"},{"location":"modules/iconv/#name","title":"Name","text":"<p>iconv-nginx-module</p>"},{"location":"modules/iconv/#description","title":"Description","text":"<p>This is a nginx module that uses libiconv to convert characters of different encoding. It brings the 'set_iconv' command to nginx.</p> <p>This module depends on the ngx_devel_kit(NDK) module.</p>"},{"location":"modules/iconv/#usage","title":"Usage","text":""},{"location":"modules/iconv/#set_iconv","title":"set_iconv","text":"<p>syntax: set_iconv &lt;destination_variable&gt; &lt;from_variable&gt; from=&lt;from_encoding&gt; to=&lt;to_encoding&gt;</p> <p>default: none</p> <p>phase: rewrite</p>"},{"location":"modules/iconv/#iconv_buffer_size","title":"iconv_buffer_size","text":"<p>syntax: iconv_buffer_size &lt;size&gt;</p> <p>default: iconv_buffer_size &lt;pagesize&gt;</p>"},{"location":"modules/iconv/#iconv_filter","title":"iconv_filter","text":"<p>syntax: iconv_filter from=&lt;from_encoding&gt; to=&lt;to_encoding&gt;</p> <p>default: none</p> <p>phase: output-filter</p> <p>Here is a basic example:</p> <pre><code> #nginx.conf\n\n location /foo {\n     set $src '\u4f60\u597d'; #in UTF-8\n     set_iconv $dst $src from=utf8 to=gbk; #now $dst holds \u4f60\u597d in GBK\n }\n\n #everything generated from /foo will be converted from utf8 to gbk\n location /bar {\n     iconv_filter from=utf-8 to=gbk;\n     iconv_buffer_size 1k;\n     #content handler here\n }\n</code></pre>"},{"location":"modules/iconv/#changelog","title":"Changelog","text":"<p>This module's change logs are part of the OpenResty bundle's change logs. Please see See http://openresty.org/#Changes</p>"},{"location":"modules/iconv/#see-also","title":"See Also","text":"<ul> <li>The OpenResty bundle.</li> </ul>"},{"location":"modules/iconv/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-iconv.</p>"},{"location":"modules/image-filter/","title":"image-filter: NGINX image filter dynamic module","text":""},{"location":"modules/image-filter/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-image-filter\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-image-filter\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_image_filter_module.so;\n</code></pre> <p>This module is built from the same source as the NGINX core.</p>"},{"location":"modules/image-filter/#directives","title":"Directives","text":"<p>You may find information about configuration directives for this module at the following links:        </p> <ul> <li>https://nginx.org/en/docs/http/ngx_http_image_filter_module.html#directives</li> </ul>"},{"location":"modules/immutable/","title":"immutable: NGINX module for setting immutable caching on static assets","text":""},{"location":"modules/immutable/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-immutable\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-immutable\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_immutable_module.so;\n</code></pre> <p>This document describes nginx-module-immutable v0.0.4  released on Nov 21 2022.</p> <p></p> <p>This tiny NGINX module can help improve caching of your public static assets, by setting far future expiration with <code>immutable</code> attribute.</p>"},{"location":"modules/immutable/#intended-audience","title":"Intended audience","text":"<p>Websites and frameworks which rely on the cache-busting pattern:</p> <ul> <li>static resources include version/hashes in their URLs, while never modifying the resources</li> <li>when necessary, updating the resources with newer versions that have new version-numbers/hashes,  so that their URLs are different</li> </ul> <p>Popular frameworks which use cache-busting:</p> <ul> <li>Magento 2</li> <li>Include your own here! </li> </ul>"},{"location":"modules/immutable/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    server {\n        location /static/ {\n            immutable on;\n        }\n    }\n}\n</code></pre> <p>will yield the following HTTP headers:</p> <pre><code>...\nCache-Control: public,max-age=31536000,stale-while-revalidate=31536000,stale-if-error=31536000,immutable\nExpires: Thu, 31 Dec 2037 23:55:55 GMT \n...\n</code></pre> <p>How it's different to <code>expires max;</code>:</p> <ul> <li>Sets <code>immutable</code> attribute, e.g. <code>Cache-Control: public,max-age=31536000,immutable</code> for improved caching.  That is 1 year and not 10 years, see why below.</li> <li>Sends <code>Expires</code> only when it's really necessary, e.g. when a client is requesting resources over <code>HTTP/1.0</code></li> <li>Sets <code>public</code> attribute to ensure the assets can be cached by public caches, which is typically a desired thing.</li> </ul> <p>Due to the lacking support of <code>immutable</code> in Chromium-based browsers,  we also add <code>stale-while-revalidate=31536000,stale-if-error=31536000</code> which helps to improve cache hit-ratio in edge cases.  Use of these directives allows serving cached responses beyond their cache lifetime, which is forever in case of immutable resources.</p> <p>Thus, in most cases, <code>immutable on;</code> can be used as a better alternative to <code>expires max;</code> to implement the cache-busting pattern.</p>"},{"location":"modules/immutable/#why-31536000-seconds-1-year","title":"Why 31536000 seconds (1 year?)","text":"<p>The RFC defines to use one year to make a response as \"never expires\":</p> <p>To mark a response as \u201cnever expires,\u201d an origin server sends an Expires date approximately one year from the time the response is sent. HTTP/1.1 servers SHOULD NOT send Expires dates more than one year in the future.</p> <p>More details in the article.</p>"},{"location":"modules/immutable/#example-magento-2-production-configuration","title":"Example: Magento 2 production configuration","text":"<p>Provided that your store runs in production mode, you have already compiled all the assets. This sample config can be optimized to:</p> <pre><code>location /static/ {\n    immutable on;\n\n    # Remove signature of the static files that is used to overcome the browser cache\n    location ~ ^/static/version {\n        rewrite ^/static/(version\\d*/)?(.*)$ /static/$2 last;\n    }\n\n    location ~* \\.(ico|jpg|jpeg|png|gif|svg|js|css|swf|eot|ttf|otf|woff|woff2|json)$ {\n        add_header X-Frame-Options \"SAMEORIGIN\";\n    }\n    location ~* \\.(zip|gz|gzip|bz2|csv|xml)$ {\n        add_header Cache-Control \"no-store\";\n        add_header X-Frame-Options \"SAMEORIGIN\";\n        immutable off;\n    }\n    add_header X-Frame-Options \"SAMEORIGIN\";\n}\n</code></pre> <p>When used together with <code>ngx_security_headers</code>, it can be simplified further:</p> <pre><code>security_headers on;\n\nlocation /static/ {\n    immutable on;\n\n\n    location ~ ^/static/version {\n        rewrite ^/static/(version\\d*/)?(.*)$ /static/$2 last;\n    }\n\n    location ~* \\.(zip|gz|gzip|bz2|csv|xml)$ {\n        add_header Cache-Control \"no-store\";\n        immutable off;\n    }\n}\n</code></pre>"},{"location":"modules/immutable/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-immutable.</p>"},{"location":"modules/ipscrub/","title":"ipscrub: IP address anonymizer module for NGINX","text":""},{"location":"modules/ipscrub/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ipscrub\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ipscrub\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_ipscrub_module.so;\n</code></pre> <p>This document describes nginx-module-ipscrub v1.0.1  released on May 29 2018.</p> <p><code>ipscrub</code> is an IP address anonymizer for nginx log files. It's an nginx module that generates an IP-based hash. You can use this hash to link requests from the same source, without identifying your users by IP address.</p> <p></p>"},{"location":"modules/ipscrub/#security-model","title":"Security Model","text":"<ol> <li>On initialization, and again every <code>PERIOD</code>, generate <code>salt</code> using 128bits from <code>arc4random_buf()</code>.</li> <li>On each request, generate masked IP address as <code>HASH(salt ++ IP address)</code>.</li> <li>Log masked IP address.</li> </ol> <p><code>ipscrub</code> uses <code>arc4random</code> to generate random nonces (see Theo de Raat's talk on arc4random for a great overview). On Linux this requires installing libbsd (package libbsd-dev on Ubuntu/Debian). </p> <p>ALSO NOTE: the generated hash WILL change on each <code>PERIOD</code> transition, so you will only have continuity within each <code>PERIOD</code>. But because users can transition between networks at any time (e.g. wifi -&gt; cellular), you'd have this type of issue even if you were storing raw IPs.</p>"},{"location":"modules/ipscrub/#threat-model","title":"Threat Model","text":"<ol> <li>Government presents you with an IP address and demands identification of user corresponding to that address.</li> <li>Government identifies a user e.g. by email address, and demands IP address they had at some point in time.</li> </ol> <p>In threat scenario (1), the goal is to compute the masked IP corresponding to a target IP address. This will only be possible if the demand is made before the end of the current <code>PERIOD</code>.</p> <p>Scenario (2) is defended against because the server operator does not know the salt, and cannot infer it based on the request timestamp, because the salt is generated from a nonce that is only stored in memory. The server operator would have to be an accomplice in this case, but that is more simply accomplished by the server operator just recording the unmasked IP. So this security/threat model does not defend against a malicious server operator, but that is not the point. It does defend against an honest server operator being compelled in threat scenarios (1) and (2).</p>"},{"location":"modules/ipscrub/#usage","title":"Usage","text":""},{"location":"modules/ipscrub/#configuration","title":"Configuration","text":"<p>In your <code>nginx.conf</code>,</p> <ol> <li>At the top-level, load the module by adding the line <code>load_module ngx_ipscrub_module.so;</code> (NOTE: only if you built as a dynamic module).</li> <li>Set <code>ipscrub_period_seconds &lt;NUM SECONDS PER PERIOD&gt;;</code> (optional).</li> <li>In your <code>log_format</code> directives, replace <code>$remote_addr</code> with <code>$remote_addr_ipscrub</code>.</li> <li>Reload your nginx config.</li> </ol> <p>NOTE: nginx may still leak IP addresses in the error log. If this is a concern, disable error logging or wipe the log regularly.</p>"},{"location":"modules/ipscrub/#running-tests","title":"Running Tests","text":"<p><code>make test</code></p>"},{"location":"modules/ipscrub/#changelog","title":"Changelog","text":"<ul> <li>1.0.1 fixed vulnerability to unmasking hashed IPs (thanks to @marcan)</li> <li>1.0.0 initial release</li> </ul>"},{"location":"modules/ipscrub/#gdpr","title":"GDPR","text":"<p>GDPR goes into effect on May 25, 2018. It legislates the handling of personal data about your users, including IP addresses.</p> <p>From https://www.eugdpr.org/gdpr-faqs.html:</p> <pre><code>What constitutes personal data?\n\nAny information related to a natural person or \u2018Data Subject\u2019, that can be used to directly or indirectly identify the person. It can be anything from a name, a photo, [...], or a computer IP address.\n</code></pre> <p>The hashes generated by <code>ipscrub</code> let you correlate nginx log entries by IP address, without actually storing IP addresses, reducing your GDPR surface area.</p>"},{"location":"modules/ipscrub/#yagni","title":"YAGNI","text":"<p>Why are you logging IP addresses anyway? You Ain't Gonna Need It. If you want geolocation, just use MaxMind's GeoIP module in conjunction with <code>ipscrub</code>.</p>"},{"location":"modules/ipscrub/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ipscrub.</p>"},{"location":"modules/ipset-access/","title":"ipset-access: NGINX ipset access module","text":"<p>Requires the Enterprise plan of the GetPageSpeed NGINX Extras subscription.</p>"},{"location":"modules/ipset-access/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ipset-access\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ipset-access\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_ipset_access.so;\n</code></pre> <p>This document describes nginx-module-ipset-access v2.0.2  released on Dec 09 2025.</p> <p>Enterprise-grade IP-based access control for NGINX using Linux ipset. Block threats, rate-limit abusers, challenge bots, and protect your infrastructure.</p> <p> </p> <p>\u26a0\ufe0f Commercial Software This is a closed-source premium module available exclusively through the GetPageSpeed Repository.</p>"},{"location":"modules/ipset-access/#_1","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#_2","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#features","title":"\u2728 Features","text":""},{"location":"modules/ipset-access/#core-features","title":"Core Features","text":"Feature Description Whitelist/Blacklist Allow or deny based on ipset membership Multiple ipsets Check against multiple ipsets in one directive Live updates Modify ipsets without reloading NGINX Custom status codes Return any HTTP status when blocking"},{"location":"modules/ipset-access/#performance-features","title":"Performance Features","text":"Feature Description Per-thread sessions Thread-local libipset sessions eliminate lock contention LRU Cache Shared memory cache with configurable TTL Cache hit rates Typically 95%+ hit rate reduces kernel calls"},{"location":"modules/ipset-access/#security-features","title":"Security Features","text":"Feature Description Rate limiting Limit requests per IP with configurable windows Auto-ban Automatically blacklist rate limit violators JS Challenge Proof-of-work challenge stops automated bots Honeypot traps Auto-blacklist IPs hitting trap URLs Entry timeout Auto-expire blacklist entries"},{"location":"modules/ipset-access/#operational-features","title":"Operational Features","text":"Feature Description Dry-run mode Test configuration without blocking Fail-open/close Control behavior on ipset errors Prometheus metrics Native <code>/metrics</code> endpoint for Grafana JSON stats Detailed statistics API NGINX variables <code>$ipset_result</code> and <code>$ipset_matched_set</code> ##"},{"location":"modules/ipset-access/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"modules/ipset-access/#1-create-ipsets","title":"1. Create ipsets","text":"<pre><code>## Create a blacklist\nsudo ipset create bad_guys hash:ip timeout 86400\n\n## Create a rate-limit ban list  \nsudo ipset create ratelimited hash:ip timeout 1800\n\n## Create a honeypot trap list\nsudo ipset create honeypot hash:ip timeout 86400\n</code></pre>"},{"location":"modules/ipset-access/#2-configure-nginx","title":"2. Configure NGINX","text":"<pre><code>load_module modules/ngx_http_ipset_access_module.so;\n\nhttp {\n    server {\n        listen 80;\n\n        # Block known bad IPs\n        ipset_blacklist bad_guys;\n\n        # Rate limit: 100 requests per minute\n        ipset_ratelimit rate=100 window=60s autoban=ratelimited;\n\n        # Your content\n        location / {\n            root /var/www/html;\n        }\n\n        # Honeypot trap\n        location /wp-admin.php {\n            ipset_autoadd honeypot;\n            return 200 \"OK\";\n        }\n\n        # Metrics endpoint\n        location /metrics {\n            ipset_metrics;\n            allow 127.0.0.1;\n            deny all;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/ipset-access/#3-test-and-reload","title":"3. Test and reload","text":"<pre><code>sudo nginx -t &amp;&amp; sudo nginx -s reload\n</code></pre>"},{"location":"modules/ipset-access/#_3","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#installation_1","title":"\ud83d\udce6 Installation","text":"<p>This module is available exclusively through the GetPageSpeed Premium Repository.</p>"},{"location":"modules/ipset-access/#step-1-subscribe-to-getpagespeed-repository","title":"Step 1: Subscribe to GetPageSpeed Repository","text":"<p>Visit GetPageSpeed Repository Subscription to get access.</p>"},{"location":"modules/ipset-access/#step-2-install-the-repository","title":"Step 2: Install the Repository","text":"<pre><code>## RHEL/CentOS/Rocky/Alma Linux 8+\nsudo dnf install https://extras.getpagespeed.com/release-latest.rpm\n</code></pre>"},{"location":"modules/ipset-access/#step-3-install-the-module","title":"Step 3: Install the Module","text":"<pre><code>sudo dnf install nginx-module-ipset-access\n</code></pre>"},{"location":"modules/ipset-access/#step-4-enable-the-module","title":"Step 4: Enable the Module","text":"<p>Add to <code>/etc/nginx/nginx.conf</code> before any <code>http {}</code> blocks:</p> <pre><code>load_module modules/ngx_http_ipset_access_module.so;\n</code></pre>"},{"location":"modules/ipset-access/#step-5-reload-nginx","title":"Step 5: Reload NGINX","text":"<pre><code>sudo nginx -t &amp;&amp; sudo systemctl reload nginx\n</code></pre>"},{"location":"modules/ipset-access/#_4","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#configuration-reference","title":"\ud83d\udcd6 Configuration Reference","text":""},{"location":"modules/ipset-access/#access-control","title":"Access Control","text":""},{"location":"modules/ipset-access/#ipset_blacklist-set1-set2","title":"<code>ipset_blacklist</code> set1 [set2 ...]","text":"<p>Context: <code>server</code> Default: \u2014</p> <p>Blocks requests if the client IP appears in any of the listed ipsets. Multiple ipsets are checked in order until a match is found.</p> <pre><code>## Single set\nipset_blacklist bad_guys;\n\n## Multiple sets (OR logic - blocked if in ANY set)\nipset_blacklist spammers hackers tor_exits;\n\n## Disable\nipset_blacklist off;\n</code></pre>"},{"location":"modules/ipset-access/#ipset_whitelist-set1-set2","title":"<code>ipset_whitelist</code> set1 [set2 ...]","text":"<p>Context: <code>server</code> Default: \u2014</p> <p>Allows requests only if the client IP appears in at least one of the listed ipsets. All other IPs are rejected.</p> <pre><code>## Only allow trusted IPs\nipset_whitelist trusted_partners office_ips;\n</code></pre>"},{"location":"modules/ipset-access/#ipset_status-code","title":"<code>ipset_status</code> code","text":"<p>Context: <code>server</code> Default: <code>403</code></p> <p>HTTP status code returned when a request is blocked.</p> <pre><code>ipset_status 403;   # Forbidden (default)\nipset_status 444;   # Close connection without response (NGINX special)\nipset_status 429;   # Too Many Requests\nipset_status 503;   # Service Unavailable\n</code></pre>"},{"location":"modules/ipset-access/#_5","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#caching-performance","title":"Caching &amp; Performance","text":""},{"location":"modules/ipset-access/#ipset_cache_ttl-time","title":"<code>ipset_cache_ttl</code> time","text":"<p>Context: <code>server</code> Default: <code>60s</code></p> <p>How long to cache ipset lookup results. Cached results avoid repeated kernel calls for the same IP.</p> <pre><code>ipset_cache_ttl 30s;    # 30 seconds\nipset_cache_ttl 5m;     # 5 minutes\nipset_cache_ttl 1h;     # 1 hour\n</code></pre> <p>Performance Impact: - Higher TTL = Better performance, but slower to reflect ipset changes - Lower TTL = More responsive to ipset changes, but more kernel calls - Recommended: <code>30s</code> to <code>5m</code> for most use cases</p>"},{"location":"modules/ipset-access/#ipset_fail_open-onoff","title":"<code>ipset_fail_open</code> on|off","text":"<p>Context: <code>server</code> Default: <code>off</code></p> <p>Controls behavior when an ipset lookup fails (e.g., set doesn't exist).</p> <pre><code>ipset_fail_open off;   # Deny on error (secure, default)\nipset_fail_open on;    # Allow on error (available but risky)\n</code></pre>"},{"location":"modules/ipset-access/#ipset_dryrun-onoff","title":"<code>ipset_dryrun</code> on|off","text":"<p>Context: <code>server</code> Default: <code>off</code></p> <p>When enabled, logs what would be blocked but doesn't actually block. Perfect for testing new rules in production.</p> <pre><code>ipset_dryrun on;   # Log but don't block\n</code></pre> <p>Check logs for messages like: <pre><code>ipset: DRYRUN would block 1.2.3.4 (matched: bad_guys)\n</code></pre></p>"},{"location":"modules/ipset-access/#_6","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#rate-limiting","title":"Rate Limiting","text":""},{"location":"modules/ipset-access/#ipset_ratelimit-parameters","title":"<code>ipset_ratelimit</code> parameters","text":"<p>Context: <code>server</code> Default: \u2014</p> <p>Limits requests per IP within a time window. Can automatically add violators to an ipset.</p> <p>Parameters:</p> Parameter Required Description <code>rate=N</code> Yes Maximum requests per window <code>window=TIME</code> No Time window (default: 60s) <code>autoban=SET</code> No ipset to add violators <code>ban_time=N</code> No Seconds until auto-expire (default: 3600) <p>Examples:</p> <pre><code>## Basic: 100 requests per minute\nipset_ratelimit rate=100;\n\n## With custom window: 1000 requests per hour\nipset_ratelimit rate=1000 window=1h;\n\n## With auto-ban: Add violators to ipset for 30 minutes\nipset_ratelimit rate=60 window=1m autoban=ratelimited ban_time=1800;\n\n## Strict API protection\nipset_ratelimit rate=10 window=1s autoban=api_abusers ban_time=3600;\n</code></pre> <p>How it works: 1. Each IP gets a request counter and window start time 2. Counter increments on each request 3. When window expires, counter resets 4. If counter exceeds <code>rate</code>, returns <code>429 Too Many Requests</code> 5. If <code>autoban</code> is set, IP is added to specified ipset</p> <p>Note: Rate limit state is stored in shared memory and survives worker restarts.</p>"},{"location":"modules/ipset-access/#_7","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#javascript-challenge","title":"JavaScript Challenge","text":""},{"location":"modules/ipset-access/#ipset_challenge-onoff","title":"<code>ipset_challenge</code> on|off","text":"<p>Context: <code>server</code> Default: <code>off</code></p> <p>Enables JavaScript challenge mode. Browsers must solve a proof-of-work puzzle to access the site. Effective against automated bots and scrapers.</p> <pre><code>ipset_challenge on;\n</code></pre> <p>How it works: 1. First request receives a challenge page (HTTP 503) 2. Browser executes JavaScript that solves a hash puzzle 3. Solution is stored in a cookie (<code>_ipset_verified</code>) 4. Subsequent requests with valid cookie pass through 5. Cookie expires after 24 hours</p>"},{"location":"modules/ipset-access/#ipset_challenge_difficulty-level","title":"<code>ipset_challenge_difficulty</code> level","text":"<p>Context: <code>server</code> Default: <code>2</code></p> <p>Controls challenge difficulty (1-8). Higher = longer solve time.</p> Level Approximate Solve Time 1 ~100ms 2 ~500ms (default) 3 ~1 second 4 ~2 seconds 5 ~5 seconds 6+ ~10+ seconds <pre><code>ipset_challenge on;\nipset_challenge_difficulty 3;  # ~1 second solve time\n</code></pre> <p>Challenge Page Features: - Modern, responsive design - Animated loading spinner - Progress feedback - Auto-redirect on success - No external dependencies</p>"},{"location":"modules/ipset-access/#_8","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#honeypot-auto-add","title":"Honeypot Auto-add","text":""},{"location":"modules/ipset-access/#ipset_autoadd-setname-timeoutseconds","title":"<code>ipset_autoadd</code> setname [timeout=seconds]","text":"<p>Context: <code>location</code> Default: \u2014</p> <p>Automatically adds client IP to specified ipset when the location is accessed. Perfect for honeypot traps.</p> <p>Parameters:</p> Parameter Required Description setname Yes Target ipset name <code>timeout=N</code> No Entry timeout in seconds <p>Examples:</p> <pre><code>## Basic: Add to honeypot set (permanent until manual removal)\nlocation /config.php {\n    ipset_autoadd honeypot;\n    return 200 \"OK\";\n}\n\n## With timeout: Auto-expire after 24 hours\nlocation /wp-admin.php {\n    ipset_autoadd scanners timeout=86400;\n    return 200 \"OK\";\n}\n\n## Severe: Block for 1 week\nlocation ~ \\.(sh|pl|cgi)$ {\n    ipset_autoadd malicious timeout=604800;\n    return 200 \"OK\";\n}\n</code></pre> <p>Common Honeypot Paths: <pre><code>## WordPress traps\nlocation ~ ^/(wp-admin\\.php|wp-login\\.php|xmlrpc\\.php)$ {\n    ipset_autoadd honeypot timeout=86400;\n    return 200 \"OK\";\n}\n\n## Config file traps\nlocation ~ ^/(\\\\.env|config\\\\.php|phpinfo\\\\.php)$ {\n    ipset_autoadd honeypot timeout=86400;\n    return 200 \"OK\";\n}\n\n## Shell/exploit traps\nlocation ~ ^/(shell|cmd|eval|exec)\\\\.php$ {\n    ipset_autoadd malicious timeout=604800;\n    return 200 \"OK\";\n}\n</code></pre></p> <p>Note: When an IP is auto-added, the connection's keep-alive is disabled to prevent further requests on the same connection.</p>"},{"location":"modules/ipset-access/#_9","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#observability","title":"Observability","text":""},{"location":"modules/ipset-access/#ipset_stats","title":"<code>ipset_stats</code>","text":"<p>Context: <code>location</code> Default: \u2014</p> <p>Enables the JSON statistics endpoint.</p> <pre><code>location = /_stats {\n    ipset_stats;\n    allow 127.0.0.1;\n    allow 10.0.0.0/8;\n    deny all;\n}\n</code></pre> <p>See JSON Stats API for response format.</p>"},{"location":"modules/ipset-access/#ipset_metrics","title":"<code>ipset_metrics</code>","text":"<p>Context: <code>location</code> Default: \u2014</p> <p>Enables the Prometheus metrics endpoint.</p> <pre><code>location = /metrics {\n    ipset_metrics;\n    allow 127.0.0.1;\n    allow 10.0.0.0/8;\n    deny all;\n}\n</code></pre> <p>See Prometheus Metrics for available metrics.</p>"},{"location":"modules/ipset-access/#_10","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#nginx-variables","title":"\ud83d\udcdd NGINX Variables","text":"<p>The module exposes two variables for use in logging, headers, or conditionals.</p>"},{"location":"modules/ipset-access/#ipset_result","title":"<code>$ipset_result</code>","text":"<p>The access decision made for this request.</p> Value Description <code>allow</code> Request allowed <code>deny</code> Request blocked <code>dryrun</code> Would be blocked (dry-run mode) <code>ratelimited</code> Rate limit exceeded <code>challenged</code> Challenge page served"},{"location":"modules/ipset-access/#ipset_matched_set","title":"<code>$ipset_matched_set</code>","text":"<p>Name of the ipset that matched (if any). Empty if no match.</p>"},{"location":"modules/ipset-access/#usage-examples","title":"Usage Examples","text":"<p>Custom access log:</p> <pre><code>log_format security '$remote_addr - $remote_user [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    'ipset_result=\"$ipset_result\" '\n                    'matched_set=\"$ipset_matched_set\"';\n\naccess_log /var/log/nginx/security.log security;\n</code></pre> <p>Add headers for debugging:</p> <pre><code>add_header X-IPSet-Result $ipset_result always;\nadd_header X-IPSet-Matched $ipset_matched_set always;\n</code></pre> <p>Conditional logging:</p> <pre><code>## Only log blocked requests\nmap $ipset_result $loggable {\n    \"deny\"  1;\n    default 0;\n}\n\naccess_log /var/log/nginx/blocked.log combined if=$loggable;\n</code></pre>"},{"location":"modules/ipset-access/#_11","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#prometheus-metrics","title":"\ud83d\udcca Prometheus Metrics","text":"<p>The <code>/metrics</code> endpoint returns metrics in Prometheus exposition format.</p>"},{"location":"modules/ipset-access/#available-metrics","title":"Available Metrics","text":"<pre><code>## HELP nginx_ipset_requests_total Total requests processed\n## TYPE nginx_ipset_requests_total counter\nnginx_ipset_requests_total{result=\"checked\"} 1234567\nnginx_ipset_requests_total{result=\"allowed\"} 1234000\nnginx_ipset_requests_total{result=\"blocked\"} 500\nnginx_ipset_requests_total{result=\"error\"} 67\n\n## HELP nginx_ipset_cache_total Cache operations\n## TYPE nginx_ipset_cache_total counter\nnginx_ipset_cache_total{result=\"hit\"} 1200000\nnginx_ipset_cache_total{result=\"miss\"} 34567\n\n## HELP nginx_ipset_cache_entries Current cache entries\n## TYPE nginx_ipset_cache_entries gauge\nnginx_ipset_cache_entries 5432\n\n## HELP nginx_ipset_autoadd_total Auto-add operations\n## TYPE nginx_ipset_autoadd_total counter\nnginx_ipset_autoadd_total{result=\"success\"} 42\nnginx_ipset_autoadd_total{result=\"failed\"} 3\n\n## HELP nginx_ipset_ratelimit_total Rate limit events\n## TYPE nginx_ipset_ratelimit_total counter\nnginx_ipset_ratelimit_total{action=\"triggered\"} 156\nnginx_ipset_ratelimit_total{action=\"autobanned\"} 23\n\n## HELP nginx_ipset_challenge_total Challenge events\n## TYPE nginx_ipset_challenge_total counter\nnginx_ipset_challenge_total{result=\"issued\"} 1000\nnginx_ipset_challenge_total{result=\"passed\"} 950\nnginx_ipset_challenge_total{result=\"failed\"} 50\n\n## HELP nginx_ipset_uptime_seconds Module uptime\n## TYPE nginx_ipset_uptime_seconds gauge\nnginx_ipset_uptime_seconds 86400\n</code></pre>"},{"location":"modules/ipset-access/#grafana-dashboard-queries","title":"Grafana Dashboard Queries","text":"<p>Request rate by result: <pre><code>rate(nginx_ipset_requests_total[5m])\n</code></pre></p> <p>Block rate: <pre><code>rate(nginx_ipset_requests_total{result=\"blocked\"}[5m])\n</code></pre></p> <p>Cache hit rate: <pre><code>rate(nginx_ipset_cache_total{result=\"hit\"}[5m]) / \n(rate(nginx_ipset_cache_total{result=\"hit\"}[5m]) + rate(nginx_ipset_cache_total{result=\"miss\"}[5m]))\n</code></pre></p> <p>Rate limit triggers per minute: <pre><code>rate(nginx_ipset_ratelimit_total{action=\"triggered\"}[1m]) * 60\n</code></pre></p>"},{"location":"modules/ipset-access/#_12","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#json-stats-api","title":"\ud83d\udcc8 JSON Stats API","text":"<p>The <code>/_stats</code> endpoint returns detailed statistics in JSON format.</p>"},{"location":"modules/ipset-access/#response-format","title":"Response Format","text":"<pre><code>{\n  \"version\": \"2.0.2\",\n  \"uptime_seconds\": 86400,\n  \"requests\": {\n    \"checked\": 1234567,\n    \"allowed\": 1234000,\n    \"blocked\": 500,\n    \"errors\": 67\n  },\n  \"cache\": {\n    \"hits\": 1200000,\n    \"misses\": 34567,\n    \"entries\": 5432,\n    \"hit_rate\": 97.20\n  },\n  \"autoadd\": {\n    \"success\": 42,\n    \"failed\": 3\n  },\n  \"ratelimit\": {\n    \"triggered\": 156,\n    \"autobanned\": 23\n  },\n  \"challenge\": {\n    \"issued\": 1000,\n    \"passed\": 950,\n    \"failed\": 50\n  }\n}\n</code></pre>"},{"location":"modules/ipset-access/#field-descriptions","title":"Field Descriptions","text":"Field Description <code>version</code> Module version <code>uptime_seconds</code> Seconds since module loaded <code>requests.checked</code> Total requests processed <code>requests.allowed</code> Requests that passed <code>requests.blocked</code> Requests that were blocked <code>requests.errors</code> ipset lookup errors <code>cache.hits</code> Cache hits (avoided kernel call) <code>cache.misses</code> Cache misses (required kernel call) <code>cache.entries</code> Current cached entries <code>cache.hit_rate</code> Hit rate percentage <code>autoadd.success</code> Successful honeypot additions <code>autoadd.failed</code> Failed honeypot additions <code>ratelimit.triggered</code> Rate limit violations <code>ratelimit.autobanned</code> IPs auto-added to ban list <code>challenge.issued</code> Challenge pages served <code>challenge.passed</code> Challenges solved successfully <code>challenge.failed</code> Challenge failures ##"},{"location":"modules/ipset-access/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           REQUEST FLOW                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502   Incoming Request                                                   \u2502\n\u2502         \u2502                                                            \u2502\n\u2502         \u25bc                                                            \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502  Rate Limit   \u2502\u2500\u2500\u2500\u2500 Exceeded? \u2500\u2500\u2500\u2500\u25b6 429 + Auto-ban              \u2502\n\u2502   \u2502    Check      \u2502                                                  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502 OK                                                       \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502   Challenge   \u2502\u2500\u2500\u2500\u2500 No cookie? \u2500\u2500\u2500\u2500\u25b6 Serve JS Puzzle            \u2502\n\u2502   \u2502    Check      \u2502                                                  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502 Passed                                                   \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502   \u2502  Cache Check  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   HIT       \u2502\u2500\u2500\u2500\u2500\u25b6 Use cached result      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502           \u2502 MISS                                                     \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502  ipset Query  \u2502\u2500\u2500\u2500\u2500 Thread-local libipset session               \u2502\n\u2502   \u2502  (kernel)     \u2502                                                  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502                                                          \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502 Store in Cache\u2502                                                  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502                                                          \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502    Decision   \u2502\u2500\u2500\u2500\u2500 Blacklist match? \u2500\u2500\u2500\u2500\u25b6 Block (403/444)      \u2502\n\u2502   \u2502               \u2502\u2500\u2500\u2500\u2500 Whitelist miss?  \u2500\u2500\u2500\u2500\u25b6 Block (403/444)      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502 Allow                                                    \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\n\u2502   \u2502   Honeypot    \u2502\u2500\u2500\u2500\u2500 Location match? \u2500\u2500\u2500\u2500\u25b6 Add to ipset          \u2502\n\u2502   \u2502    Check      \u2502                                                  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\n\u2502           \u2502                                                          \u2502\n\u2502           \u25bc                                                          \u2502\n\u2502       Continue to                                                    \u2502\n\u2502       Content Handler                                                \u2502\n\u2502                                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                        SHARED MEMORY                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502     Stats      \u2502    LRU Cache    \u2502    Rate Limit Buckets       \u2502 \u2502\n\u2502  \u2502   (counters)   \u2502  (IP \u2192 Result)  \u2502   (IP \u2192 Request Count)      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"modules/ipset-access/#memory-layout","title":"Memory Layout","text":"Component Location Purpose libipset session Thread-local Per-worker session to avoid locks Lookup cache Shared memory LRU cache of IP\u2192result mappings Rate limit buckets Shared memory Per-IP request counters Statistics Shared memory Atomic counters for metrics ##"},{"location":"modules/ipset-access/#examples","title":"\ud83d\udcda Examples","text":""},{"location":"modules/ipset-access/#example-1-basic-blacklist","title":"Example 1: Basic Blacklist","text":"<pre><code>## Create ipset\nsudo ipset create blacklist hash:ip\nsudo ipset add blacklist 1.2.3.4\n</code></pre> <pre><code>    server {\n    listen 80;\n\n    ipset_blacklist blacklist;\n\n    location / {\n        root /var/www/html;\n    }\n}\n</code></pre>"},{"location":"modules/ipset-access/#example-2-api-with-rate-limiting","title":"Example 2: API with Rate Limiting","text":"<pre><code>server {\n    listen 80;\n\n    # Strict rate limiting for API\n    ipset_ratelimit rate=100 window=1m autoban=api_banned ban_time=3600;\n\n    # Only allow known partners\n    ipset_whitelist api_partners;\n    ipset_status 401;\n\n    location /api/ {\n        proxy_pass http://backend;\n    }\n}\n</code></pre>"},{"location":"modules/ipset-access/#example-3-full-security-stack","title":"Example 3: Full Security Stack","text":"<pre><code>    server {\n        listen 80 default_server;\n\n    # Layer 1: Known threats\n    ipset_blacklist malware_ips tor_exits datacenter_ranges;\n    ipset_status 444;\n    ipset_cache_ttl 5m;\n\n    # Layer 2: Rate limiting\n    ipset_ratelimit rate=60 window=1m autoban=ratelimited ban_time=1800;\n\n    # Layer 3: Bot challenge\n    ipset_challenge on;\n    ipset_challenge_difficulty 2;\n\n    # Real content\n        location / {\n        root /var/www/html;\n    }\n\n    # Honeypot traps\n    location ~ ^/(wp-admin|phpmyadmin|admin)\\.php$ {\n        ipset_autoadd honeypot timeout=86400;\n        return 200 \"OK\";\n    }\n\n    # Monitoring\n    location = /metrics {\n        ipset_metrics;\n        allow 10.0.0.0/8;\n        deny all;\n    }\n}\n</code></pre>"},{"location":"modules/ipset-access/#example-4-dry-run-testing","title":"Example 4: Dry-run Testing","text":"<pre><code>server {\n    listen 80;\n\n    # Test new rules without blocking\n    ipset_blacklist new_threat_list;\n    ipset_dryrun on;\n\n    location / {\n        root /var/www/html;\n    }\n}\n</code></pre> <p>Check logs: <pre><code>tail -f /var/log/nginx/error.log | grep \"DRYRUN\"\n</code></pre></p>"},{"location":"modules/ipset-access/#_13","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#troubleshooting","title":"\ud83d\udd27 Troubleshooting","text":""},{"location":"modules/ipset-access/#module-not-loading","title":"Module not loading","text":"<pre><code>nginx: [emerg] dlopen() failed\n</code></pre> <p>Solution: Ensure NGINX was built with <code>--with-compat</code> and the module was built against the same NGINX version.</p>"},{"location":"modules/ipset-access/#ipset-not-found","title":"ipset not found","text":"<pre><code>ipset: INVALID_SETNAME\n</code></pre> <p>Solution: Create the ipset before starting NGINX: <pre><code>sudo ipset create myset hash:ip\n</code></pre></p>"},{"location":"modules/ipset-access/#permission-denied","title":"Permission denied","text":"<pre><code>ipset: kernel error\n</code></pre> <p>Solution: NGINX worker needs <code>CAP_NET_ADMIN</code> capability: <pre><code>sudo setcap cap_net_admin+ep /usr/sbin/nginx\n</code></pre></p>"},{"location":"modules/ipset-access/#selinux-denials-rhelcentosalmalinux","title":"SELinux denials (RHEL/CentOS/AlmaLinux)","text":"<pre><code>SELinux is preventing /usr/sbin/nginx from getattr access on the netlink_netfilter_socket\n</code></pre> <p>Solution: Install the included SELinux policy module:</p> <pre><code>cd selinux/\nsudo ./install.sh\n</code></pre> <p>Or manually: <pre><code>## Verify\nsemodule -l | grep nginx_ipset\n</code></pre></p> <p>The policy allows <code>httpd_t</code> (NGINX's SELinux domain) to use netlink_netfilter sockets required by libipset.</p>"},{"location":"modules/ipset-access/#high-memory-usage","title":"High memory usage","text":"<p>Solution: Reduce cache TTL or limit cache size in shared memory configuration.</p>"},{"location":"modules/ipset-access/#rate-limiting-not-working","title":"Rate limiting not working","text":"<p>Solution: Ensure the ipset for auto-ban exists and has timeout support: <pre><code>sudo ipset create ratelimited hash:ip timeout 3600\n</code></pre></p>"},{"location":"modules/ipset-access/#_14","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#requirements","title":"\ud83d\udccb Requirements","text":"<ul> <li>NGINX \u2265 1.22 (built with <code>--with-compat</code>)</li> <li>Linux kernel with ipset support (nf_tables or xt_set module)</li> <li>libipset library and development headers</li> <li>Capabilities: <code>CAP_NET_ADMIN</code> for ipset operations</li> </ul>"},{"location":"modules/ipset-access/#_15","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#license","title":"\ud83d\udcdc License","text":"<p>This is proprietary software. All rights reserved.</p> <p>Available exclusively through GetPageSpeed Premium Repository.</p>"},{"location":"modules/ipset-access/#_16","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#author","title":"\ud83d\udc64 Author","text":"<p>Danila Vershinin GetPageSpeed LLC</p>"},{"location":"modules/ipset-access/#_17","title":"NGINX ipset access module","text":""},{"location":"modules/ipset-access/#support","title":"\ud83c\udd98 Support","text":"<ul> <li>Honeypot v2.0 Using ipset-access for auto-banning bots</li> <li>Support: Available for premium subscribers</li> <li>Contact: GetPageSpeed Support</li> </ul>"},{"location":"modules/ipset-access/#_18","title":"NGINX ipset access module","text":"<p> NGINX IPSet Access Module A premium NGINX module by GetPageSpeed LLC www.getpagespeed.com </p>"},{"location":"modules/ipset-access/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ipset-access.</p>"},{"location":"modules/jpeg/","title":"jpeg: NGINX JPEG filter module","text":""},{"location":"modules/jpeg/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-jpeg\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-jpeg\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_jpeg_filter_module.so;\n</code></pre> <p>This document describes nginx-module-jpeg v1.0.1  released on Sep 04 2018.</p> <p>Nginx filter module for adding overlays on JPEGs on-the-fly with libmodjpeg.</p> <p>With libmodjpeg you can overlay a (masked) image onto an existing JPEG as lossless as possible. Changes in the JPEG only take place where the overlayed image is applied. All modifications happen in the DCT domain, thus the JPEG is decoded and encoded losslessly.</p> <ul> <li>Typical Uses</li> <li>Try it out</li> <li>Installation</li> <li>Compatibility</li> <li>Synopsis</li> <li>Directives</li> <li>jpeg_filter</li> <li>jpeg_filter_max_pixel</li> <li>jpeg_filter_buffer</li> <li>jpeg_filter_optimize</li> <li>jpeg_filter_progressive</li> <li>jpeg_filter_arithmetric</li> <li>jpeg_filter_graceful</li> <li>jpeg_filter_effect</li> <li>jpeg_filter_dropon_align</li> <li>jpeg_filter_dropon_offset</li> <li>jpeg_filter_dropon_file</li> <li>jpeg_filter_dropon_memory</li> <li>Notes</li> <li>License</li> <li>Acknowledgement</li> </ul>"},{"location":"modules/jpeg/#typical-uses","title":"Typical Uses","text":"<p>This filter module can add overlays (e.g. a logo, visual watermark) on JPEGs when they are requested.</p> <p>A few ideas:</p> <ul> <li>Consider you are a photographer and have a image gallery on your website. Without hardcoding your logo (brand, watermark, ...) into these images you can apply it the moment the image is requested. Whenever you update your logo, just update the nginx configuration and it's done. No need to re-process all your images.</li> <li>You have an online shop with thousands of product images. With just configuring nginx you can add your logo to all of the product images. You don't have to process all product images.</li> <li>You have a paid service. Add a watermark to all images if the user is not subscribed. If the user is subscribed, don't apply the watermark or put just a small logo on the images without touching the original images.</li> <li>On your website, registered users can upload images. Add the avatar of the user to the image who uploaded the image without processing it after the upload. If the user changes her avatar, all her images will automatically have the new avatar on them.</li> </ul>"},{"location":"modules/jpeg/#try-it-out","title":"Try it out","text":"<p>In order to try out this filter module, pull the docker image</p> <pre><code>docker pull ioppermann/modjpeg-nginx:latest\n</code></pre> <p>The docker container exposes TCP port 80 and expects a directory with images mounted on <code>/images</code>, e.g.</p> <pre><code>docker run -it --rm --name=modjpeg-nginx \\\n   --mount type=bind,src=$PWD/images,dst=/images,readonly \\\n   -p 8080:80 \\\n   ioppermann/modjpeg-nginx:latest\n</code></pre> <p>Now you can browse to http://localhost:8080/ and click on the listed images. The modjpeg logo will be applied in the top left corner. By default only images that are smaller than 10MB are processed by the filter. Stop the container by pressing <code>Ctrl-c</code>.</p> <p>The filter can be controlled by these environment variables:</p> Name Default Description MJ_GRACEFUL on See jpeg_filter_graceful MJ_BUFFER 10M See jpeg_filter_buffer MJ_MAX_PIXEL 0 See jpeg_filter_max_pixel MJ_DROPON_ALIGN \"top left\" See jpeg_filter_dropon_align MJ_DROPON_OFFSET \"0 0\" See jpeg_filter_dropon_offset MJ_DROPON_FILE \"/usr/local/nginx/conf/dropon.png\" See jpeg_filter_dropon_file <p>The following example will allow images with up to 150 megapixel (<code>MJ_MAX_PIXEL</code>) and 100MB in file size (<code>MJ_BUFFER</code>). The logo will be placed in bottom right corner (<code>MJ_DROPON_ALIGN</code>) with an offset of -15px horizontally and vertically (<code>MJ_DROPON_OFFSET</code>).</p> <pre><code>docker run -it --rm --name=modjpeg-nginx \\\n   --mount type=bind,src=$PWD/images,dst=/images,readonly \\\n   -p 8080:80 \\\n   -e MJ_MAX_PIXEL=150000000 \\\n   -e MJ_BUFFER=100M \\\n   -e MJ_DROPON_ALIGN=\"bottom right\" \\\n   -e MJ_DROPON_OFFSET=\"-15 -15\" \\\n   ioppermann/modjpeg-nginx:latest\n</code></pre> <p>In order to change the logo, you can mount an additional volume or put it into the directory you already mount, e.g.</p> <pre><code>docker run -it --rm --name=modjpeg-nginx \\\n   --mount type=bind,src=$PWD/images,dst=/images,readonly \\\n   -p 8080:80 \\\n   -e MJ_DROPON_FILE=\"/images/logo.png\" \\\n   ioppermann/modjpeg-nginx:latest\n</code></pre>"},{"location":"modules/jpeg/#clone-and-install-libmodjpeg","title":"Clone and install libmodjpeg","text":"<p>git clone https://github.com/ioppermann/libmodjpeg.git cd libmodjpeg cmake . make make install cd ..</p>"},{"location":"modules/jpeg/#clone-modjpeg-nginx","title":"Clone modjpeg-nginx","text":"<p>git clone https://github.com/ioppermann/modjpeg-nginx.git</p>"},{"location":"modules/jpeg/#download-and-install-nginx","title":"Download and install nginx","text":"<p>wget 'http://nginx.org/download/nginx-1.15.1.tar.gz' tar -xvzf nginx-1.15.1.tar.gz cd nginx-1.15.1</p>"},{"location":"modules/jpeg/#configure-as-static-module-or","title":"Configure as static module, or ...","text":"<p>./configure --add_module=../modjpeg-nginx</p>"},{"location":"modules/jpeg/#configure-as-dynamic-module-as-of-nginx-1911","title":"... configure as dynamic module (as of nginx 1.9.11)","text":"<p>./configure --add_dynamic_module=../modjpeg-nginx</p>"},{"location":"modules/jpeg/#if-the-libmodjpeg-library-is-not-found-add-eg-with-ld-opt-lusrlocallib-to","title":"If the libmodjpeg library is not found, add e.g. '--with-ld-opt=-L/usr/local/lib' to","text":""},{"location":"modules/jpeg/#the-configure-options-if-it-was-installed-to-usrlocallib","title":"the configure options if it was installed to /usr/local/lib","text":""},{"location":"modules/jpeg/#you-may-want-to-use-the-other-configure-options-that-are-used","title":"You may want to use the other './configure' options that are used","text":""},{"location":"modules/jpeg/#in-your-current-nginx-build-check-the-output-of-nginx-v","title":"in your current nginx build. Check the output of 'nginx -V'.","text":"<p>make make install <pre><code>If you configured modjpeg-nginx as dynamic module, you have to load the module in the beginning of the config\n\n```nginx\n...\nload_module modules/ngx_http_jpeg_filter_module.so;\n...\n</code></pre></p>"},{"location":"modules/jpeg/#synopsis","title":"Synopsis","text":"<pre><code>   ...\n\n   location /gallery {\n      # enable jpeg filter module\n      jpeg_filter on;\n\n      # limit image sizes to 9 megapixel\n      jpeg_filter_max_pixel 9000000;\n\n      # limit image file size to 5 megabytes\n      jpeg_filter_buffer 5M;\n\n      # deliver the images unmodified if one of the limits apply\n      jpeg_filter_graceful on;\n\n      # pixelate the image\n      jpeg_filter_effect pixelate;\n\n      # add a masked logo in the bottom right corner\n      # with a distance of 10 pixel from the border\n      jpeg_filter_dropon_align bottom right;\n      jpeg_filter_dropon_offset -10 -10;\n      jpeg_filter_dropon_file /path/to/logo.jpg /path/to/mask.jpg;\n   }\n\n   ...\n</code></pre> <p>Or use it with OpenResty's ngx_http_lua_module and a PNG logo:</p> <pre><code>   ...\n\n   location /gallery {\n      set_by_lua_block $valign {\n         local a = { 'top', 'center', 'bottom' }\n         return a[math.random(#a)]\n      }\n\n      set_by_lua_block $halign {\n         local a = { 'left', 'center', 'right' }\n         return a[math.random(#a)]\n      }\n\n      # enable jpeg filter module\n      jpeg_filter on;\n\n      # limit image sizes to 9 megapixel\n      jpeg_filter_max_pixel 9000000;\n\n      # limit image file size to 5 megabytes\n      jpeg_filter_buffer 5M;\n\n      # deliver the images unmodified if one of the limits apply\n      jpeg_filter_graceful on;\n\n      # pixelate the image\n      jpeg_filter_effect pixelate;\n\n      # add a logo in a random position\n      jpeg_filter_dropon_align $valign $halign;\n      jpeg_filter_dropon_file /path/to/logo.png;\n   }\n\n   ...\n</code></pre> <p>Or generate a logo with Lua-GD:</p> <pre><code>http {\n   ...\n   ...\n   server {\n      ...\n      location /gallery {\n           set_by_lua_block $logobytestream {\n              local gd = require \"gd\"\n\n              local im = gd.create(210, 70)\n              local white = im:colorAllocate(255, 255, 255)\n              local black = im:colorAllocate(0, 0, 0)\n              im:filledRectangle(0, 0, 140, 80, white)\n              im:string(gd.FONT_LARGE, 10, 10, \"Hello modjpeg\", black)\n              im:string(gd.FONT_LARGE, 10, 40, os.date(\"%c\"), black);\n              return im:jpegStr(85)\n           }\n\n       # enable jpeg filter module\n       jpeg_filter on;\n\n           # limit image sizes to 9 megapixel\n           jpeg_filter_max_pixel 9000000;\n\n           # limit image file size to 5 megabytes\n           jpeg_filter_buffer 5M;\n\n           # deliver the images unmodified if one of the limits apply\n           jpeg_filter_graceful on;\n\n           # pixelate the image\n           jpeg_filter_effect pixelate;\n\n           # add a generated logo in the bottom right corner\n           # with a distance of 10 pixel from the border\n           jpeg_filter_dropon_align bottom right;\n           jpeg_filter_dropon_offset -10 -10;\n           jpeg_filter_dropon_memory $logobytestream;\n      }\n      ...\n   }\n   ...\n}\n</code></pre>"},{"location":"modules/jpeg/#directives","title":"Directives","text":"<ul> <li>jpeg_filter</li> <li>jpeg_filter_max_pixel</li> <li>jpeg_filter_buffer</li> <li>jpeg_filter_optimize</li> <li>jpeg_filter_progressive</li> <li>jpeg_filter_arithmetric</li> <li>jpeg_filter_graceful</li> <li>jpeg_filter_effect</li> <li>jpeg_filter_dropon_align</li> <li>jpeg_filter_dropon_offset</li> <li>jpeg_filter_dropon_file</li> <li>jpeg_filter_dropon_memory</li> <li>Notes</li> </ul>"},{"location":"modules/jpeg/#jpeg_filter","title":"jpeg_filter","text":"<p>Syntax: <code>jpeg_filter on | off</code></p> <p>Default: <code>jpeg_filter off</code></p> <p>Context: <code>location</code></p> <p>Enable the jpeg filter module.</p> <p>This directive is turned off by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_max_pixel","title":"jpeg_filter_max_pixel","text":"<p>Syntax: <code>jpeg_filter_max_pixel pixel</code></p> <p>Default: <code>0</code></p> <p>Context: <code>http, server, location</code></p> <p>Maximum number of pixel in image to operate on. If the image has more pixel (width * height) than <code>pixel</code>, the jpeg filter will return a  \"415 Unsupported Media Type\". Set jpeg_filter_graceful to <code>on</code> to deliver the image unchanged. Set the maximum pixel to 0 in order ignore the image dimensions.</p> <p>This directive is set to 0 by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_buffer","title":"jpeg_filter_buffer","text":"<p>Syntax: <code>jpeg_filter_buffer size</code></p> <p>Default: <code>2M</code></p> <p>Context: <code>http, server, location</code></p> <p>The maximum file size of the image to operate on. If the file size if bigger than <code>size</code>, the jpeg filter will return a \"415 Unsupported Media Type\". Set jpeg_filter_graceful to <code>on</code> to deliver the image unchanged.</p> <p>This directive is set to 2 megabyte by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_optimize","title":"jpeg_filter_optimize","text":"<p>Syntax: <code>jpeg_filter_optimize on | off</code></p> <p>Default: <code>off</code></p> <p>Context: <code>http, server, location</code></p> <p>Upon delivery, optimize the Huffman tables of the image.</p> <p>This directive is turned off by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_progressive","title":"jpeg_filter_progressive","text":"<p>Syntax: <code>jpeg_filter_progressive on | off</code></p> <p>Default: <code>off</code></p> <p>Context: <code>http, server, location</code></p> <p>Upon delivery, enable progressive encoding of the image.</p> <p>This directive is turned off by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_arithmetric","title":"jpeg_filter_arithmetric","text":"<p>Syntax: <code>jpeg_filter_arithmetric on | off</code></p> <p>Default: <code>off</code></p> <p>Context: <code>http, server, location</code></p> <p>Upon delivery, enable arithmetric encoding of the image. This will override the jpeg_filter_optimize directive. Arithmetric encoding is usually not supported by browsers.</p> <p>This directive is turned off by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_graceful","title":"jpeg_filter_graceful","text":"<p>Syntax: <code>jpeg_filter_graceful on | off</code></p> <p>Default: <code>off</code></p> <p>Context: <code>http, server, location</code></p> <p>Allow to deliver the unchanged image in case the directives jpeg_filter_max_width, jpeg_filter_max_height, or jpeg_filter_buffer would return a \"415 Unsupported Media Type\" error.</p> <p>This directive is turned off by default.</p>"},{"location":"modules/jpeg/#jpeg_filter_effect","title":"jpeg_filter_effect","text":"<p>Syntax: <code>jpeg_filter_effect grayscale | pixelate</code></p> <p>Syntax: <code>jpeg_filter_effect darken | brighten value</code></p> <p>Syntax: <code>jpeg_filter_effect tintblue | tintyellow | tintred | tintgreen value</code></p> <p>Default: <code>-</code></p> <p>Context: <code>location</code></p> <p>Apply an effect to the image.</p> <p><code>grayscale</code> will remove all color components from the image. This only applies to images in the YCbCr color space.</p> <p><code>pixelate</code> will pixelate the image in blocks of 8x8 pixel by setting the AC coefficients in all components to 0.</p> <p><code>darken</code> will darken the image by decreasing the DC coefficients in the Y component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p><code>brighten</code> will brighten the image by increasing the DC coefficients in the Y component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p><code>tintblue</code> will tint the image blue by increasing the DC coefficients in the Cb component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p><code>tintyellow</code> will tint the image blue by decreasing the DC coefficients in the Cb component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p><code>tintred</code> will tint the image red by increasing the DC coefficients in the Cr component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p><code>tintgreen</code> will tint the image green by decreasing the DC coefficients in the Cr component by <code>value</code>. This only applies to images in the YCbCr color space.</p> <p>This directive is not set by default.</p> <p>All parameters can contain variables.</p>"},{"location":"modules/jpeg/#jpeg_filter_dropon_align","title":"jpeg_filter_dropon_align","text":"<p>Syntax: <code>jpeg_filter_dropon_align [top | center | bottom] [left | center | right]</code></p> <p>Default: <code>center center</code></p> <p>Context: <code>location</code></p> <p>Align the dropon on the image. Use the directive jpeg_filter_dropon_offset to offset the dropon from the alignment.</p> <p>This directive must be set before jpeg_filter_dropon in order to have an effect on the dropon.</p> <p>This directive will apply the dropon in the center of the image by default.</p> <p>All parameters can contain variables.</p>"},{"location":"modules/jpeg/#jpeg_filter_dropon_offset","title":"jpeg_filter_dropon_offset","text":"<p>Syntax: <code>jpeg_filter_dropon_offset vertical horizontal</code></p> <p>Default: <code>0 0</code></p> <p>Context: <code>location</code></p> <p>Offset the dropon by <code>vertical</code> and <code>horizontal</code> pixels from the alignment given with the jpeg_filter_dropon_align directive. Use a negative value to move the dropon up or left and a positive value to move the dropon down or right.</p> <p>This directive must be set before jpeg_filter_dropon in order to have an effect on the dropon.</p> <p>This directive will not apply an offset by default.</p> <p>All parameters can contain variables.</p>"},{"location":"modules/jpeg/#jpeg_filter_dropon_file","title":"jpeg_filter_dropon_file","text":"<p>Syntax: <code>jpeg_filter_dropon_file image</code></p> <p>Syntax: <code>jpeg_filter_dropon_file image mask</code></p> <p>Default: <code>-</code></p> <p>Context: <code>location</code></p> <p>Apply a dropon to the image. The dropon is given by a path to a JPEG or PNG image for <code>image</code> and optionally a path to a JPEG image for <code>mask</code>. If no mask image is provided, the image will be applied without transcluency. If a mask image is provided, only the luminance component will be used. For the mask, black means fully transcluent and white means fully opaque. Any values inbetween will blend the underlying image and the dropon accordingly. If <code>image</code> is a path to a PNG, the mask will be ignored.</p> <p>This directive is not set by default.</p> <p>All parameters can contain variables.</p> <p>If none of the parameters contain variables, the dropon is loaded during loading of the configuration. If at least one parameter contains variables, the dropon will be loaded during processing of the request. After processing the request, the dropon will be unloaded.</p> <p>PNG files as dropon are supported only if libmodjpeg has been compiled with PNG support.</p>"},{"location":"modules/jpeg/#jpeg_filter_dropon_memory","title":"jpeg_filter_dropon_memory","text":"<p>Syntax: <code>jpeg_filter_dropon_memory $image</code></p> <p>Syntax: <code>jpeg_filter_dropon_memory $image $mask</code></p> <p>Default: <code>-</code></p> <p>Context: <code>location</code></p> <p>Apply a dropon to the image. The dropon is given by a variable holding a JPEG or PNG image bytestream for <code>$image</code> and optionally a variable to a JPEG image bytestream for <code>$mask</code>. If no mask image is provided, the image will be applied without transcluency. If a mask image is provided, only the luminance component will be used. For the mask, black means fully transcluent and white means fully opaque. Any values inbetween will blend the underlying image and the dropon accordingly. If <code>$image</code> is a PNG, the mask will be ignored.</p> <p>This directive is not set by default.</p> <p>All parameters are expected to be variables.</p> <p>The dropon will always be loaded during processing of the request. After processing the request, the dropon will be unloaded.</p> <p>PNG bytestreams as dropon are supported only if libmodjpeg has been compiled with PNG support.</p>"},{"location":"modules/jpeg/#notes","title":"Notes","text":"<p>The directives <code>jpeg_filter_effect</code>, <code>jpeg_filter_dropon_align</code>, <code>jpeg_filter_dropon_offset</code>, and <code>jpeg_filter_dropon</code> are applied in the order they appear in the nginx config file, i.e. it makes a difference if you apply first an effect and then add a dropon or vice versa. In the former case the dropon will be unaffected by the effect and in the latter case the effect will be also applied on the dropon.</p>"},{"location":"modules/jpeg/#acknowledgement","title":"Acknowledgement","text":"<p>This module is heavily inspired by the nginx image filter module with insights from \"Emiller\u2019s Guide To Nginx Module Development\" and the nginx development guide.</p>"},{"location":"modules/jpeg/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-jpeg.</p>"},{"location":"modules/js-challenge/","title":"js-challenge: NGINX Javascript challenge module","text":""},{"location":"modules/js-challenge/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-js-challenge\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-js-challenge\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_js_challenge_module.so;\n</code></pre> <p>This document describes nginx-module-js-challenge v0.0.2  released on Aug 21 2024.</p> <p>A request for stable release exists. Vote up here.</p>"},{"location":"modules/js-challenge/#ngx_http_js_challenge_module","title":"ngx_http_js_challenge_module","text":"<p>Demo website</p> <p>Simple javascript proof-of-work based access for Nginx with virtually no overhead.</p> <p>Easy installation: just add <code>load_module /path/to/ngx_http_js_challenge_module.so;</code> to your <code>nginx.conf</code> file and follow the configuration instructions.</p> <p> </p>"},{"location":"modules/js-challenge/#configuration","title":"Configuration","text":"<p>Simple configuration <pre><code>server {\n    js_challenge on;\n    js_challenge_secret \"change me!\";\n\n    # ...\n}\n</code></pre></p> <p>Advanced configuration <pre><code>server {\n    js_challenge on;\n    js_challenge_secret \"change me!\";\n    js_challenge_html /path/to/body.html;\n    js_challenge_bucket_duration 3600;\n    js_challenge_title \"Verifying your browser...\";\n\n    location /static {\n        js_challenge off;\n        alias /static_files/;\n    }\n\n    location /sensitive {\n        js_challenge_bucket_duration 600;\n        #...\n    }\n\n    #...\n}\n</code></pre></p> <ul> <li><code>js_challenge on|off</code> Toggle javascript challenges for this config block</li> <li><code>js_challenge_secret \"secret\"</code> Secret for generating the challenges. DEFAULT: \"changeme\"</li> <li><code>js_challenge_html \"/path/to/file.html\"</code> Path to html file to be inserted in the <code>&lt;body&gt;</code> tag of the interstitial page</li> <li><code>js_challenge_title \"title\"</code> Will be inserted in the <code>&lt;title&gt;</code> tag of the interstitial page. DEFAULT: \"Verifying your browser...\"</li> <li><code>js_challenge_bucket_duration time</code> Interval to prompt js challenge, in seconds. DEFAULT: 3600</li> </ul>"},{"location":"modules/js-challenge/#known-limitations-todo","title":"Known limitations / TODO","text":"<ul> <li>Users with cookies disabled will be stuck in an infinite refresh loop (TODO: redirect with a known query param, if no cookie is specified but the query arg is set, display an error page)</li> <li>If nginx is behind a reverse proxy/load balancer, the same challenge will be sent to different users and/or the response cookie will be invalidated when the user is re-routed to another server. (TODO: use the x-real-ip header when available) </li> </ul>"},{"location":"modules/js-challenge/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-js-challenge.</p>"},{"location":"modules/json-var/","title":"json-var: NGINX JSON variables module","text":""},{"location":"modules/json-var/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-json-var\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-json-var\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_json_var_module.so;\n</code></pre> <p>This document describes nginx-module-json-var v1.1  released on Feb 11 2022.</p>"},{"location":"modules/json-var/#json_var","title":"json_var","text":"<ul> <li>syntax: <code>json_var $variable { ... }</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code></li> </ul> <p>Creates a new variable whose value is a json containing the items listed within the block. Parameters inside the <code>json_var</code> block specify a field that should be included in the resulting json. Each parameter has to contain two arguments - key and value.  The value can contain nginx variables.</p>"},{"location":"modules/json-var/#sample-configuration","title":"Sample configuration","text":"<p><pre><code>http {\n    json_var $output {\n        timestamp $time_local;\n        remoteAddr $remote_addr;\n        xForwardedFor $http_x_forwarded_for;\n        userAgent $http_user_agent;\n        params $args;\n    }\n\n    server {\n        location /get_json/ {\n            return 200 $output;\n        }\n    }\n</code></pre> Hitting <code>http://domain/get_json/?key1=value1&amp;key2=value2</code> can return a json like: <pre><code>{\n    \"timestamp\": \"21/Jul/2017:12:44:18 -0400\",\n    \"remoteAddr\": \"127.0.0.1\",\n    \"xForwardedFor\": \"\",\n    \"userAgent\": \"curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3\",\n    \"params\": \"key1=value1&amp;key2=value2\"\n}\n</code></pre></p>"},{"location":"modules/json-var/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-json-var.</p>"},{"location":"modules/json/","title":"[BETA!] json: NGINX JSON module","text":""},{"location":"modules/json/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-json\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-json\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_json_module.so;\n</code></pre> <p>This document describes nginx-module-json v0  released on Dec 16 2023.</p> <p>Production stability is not guaranteed.</p>"},{"location":"modules/json/#directives","title":"Directives:","text":"<pre><code>Syntax:  json_load $json string;\nDefault: \u2014\u2014\nContext: http, server, location\n</code></pre> <p>Loads string (may contains variables) into (json) variable $json.</p> <pre><code>Syntax:  json_dump $string $json [name ...];\nDefault: \u2014\u2014\nContext: http, server, location\n</code></pre> <p>Dumps (json) variable $json into (string) variable $string (may point path by names).</p>"},{"location":"modules/json/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-json.</p>"},{"location":"modules/jwt/","title":"jwt: NGINX JWT Module","text":""},{"location":"modules/jwt/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-jwt\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-jwt\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_jwt_module.so;\n</code></pre> <p>This document describes nginx-module-jwt v3.4.3  released on Mar 14 2025.</p>"},{"location":"modules/jwt/#nginx-jwt-auth-module","title":"Nginx jwt auth module","text":"<p>This is an NGINX module to check for a valid JWT, this module intend to be as light as possible and to remain simple:  - Docker image based on the official nginx Dockerfile (alpine).  - Light image (~400KB more than the official one).</p>"},{"location":"modules/jwt/#module-configuration","title":"Module Configuration:","text":""},{"location":"modules/jwt/#example-configuration","title":"Example Configuration:","text":"<pre><code>## nginx.conf\nload_module /usr/lib/nginx/modules/ngx_http_auth_jwt_module.so;\n\nhttp {\n    server {\n        auth_jwt_key \"0123456789abcdef\" hex; # Your key as hex string\n        auth_jwt     off;\n\n        # Default auth method is \"Authentication\" header\n        location /secured-by-auth-header/ {\n            auth_jwt on;\n        }\n\n        # But you can use a cookie instead\n        location /secured-by-cookie/ {\n            auth_jwt $cookie_MyCookieName;\n        }\n\n        # JWT keys are inherited from the previous configuration level\n        # but you can have different keys for different locations\n        location /secured-by-auth-header-too/ {\n            auth_jwt_key \"another-secret\"; # Your key as utf8 string\n            auth_jwt on;\n        }\n\n        location /secured-by-rsa-key/ {\n            auth_jwt_key /etc/keys/rsa-public.pem file; # Your key from a PEM file\n            auth_jwt on;\n        }\n\n        location /not-secure/ {}\n    }\n}\n</code></pre> <p>Note: don't forget to load the module in the main context:  <pre><code>load_module /usr/lib/nginx/modules/ngx_http_auth_jwt_module.so;\n</code></pre></p>"},{"location":"modules/jwt/#directives","title":"Directives:","text":""},{"location":"modules/jwt/#auth_jwt","title":"auth_jwt","text":"<pre><code>Syntax:  auth_jwt $variable | on | off;\nDefault: auth_jwt off;\nContext: http, server, location\n</code></pre> <p>Enables validation of JWT.</p> <p>The <code>auth_jwt $variable</code> value can be used to set a custom way to get the JWT, for example to get it from a cookie instead of the default <code>Authentication</code> header: <code>auth_jwt $cookie_MyCookieName;</code></p>"},{"location":"modules/jwt/#auth_jwt_key","title":"auth_jwt_key","text":"<pre><code>Syntax:  auth_jwt_key value [encoding];\nDefault: \u2014\u2014\nContext: http, server, location\n</code></pre> <p>Specifies the key for validating JWT signature (must be hexadecimal). The encoding option may be <code>hex | utf8 | base64 | file</code> (default is <code>utf8</code>). The <code>file</code> option requires the value to be a valid file path (pointing to a PEM encoded key).</p>"},{"location":"modules/jwt/#auth_jwt_alg","title":"auth_jwt_alg","text":"<pre><code>Syntax:  auth_jwt_alg any | HS256 | HS384 | HS512 | RS256 | RS384 | RS512 | ES256 | ES384 | ES512;\nDefault: auth_jwt_alg any;\nContext: http, server, location\n</code></pre> <p>Specifies which algorithm the server expects to receive in the JWT.</p>"},{"location":"modules/jwt/#auth_jwt_require","title":"auth_jwt_require","text":"<pre><code>Syntax:  auth_jwt_require $value ... [error=401 | 403];\nDefault: \u2014\u2014\nContext: http, server, location\n</code></pre> <p>Specifies additional checks for JWT validation. The authentication will succeed only if all the values are not empty and are not equal to \u201c0\u201d.</p> <p>These directives are inherited from the previous configuration level if and only if there are no auth_jwt_require directives defined on the current level.</p> <p>If any of the checks fails, the 401 error code is returned. The optional error parameter allows redefining the error code to 403.</p> <p>Example: <pre><code>## server.conf\n\nmap $jwt_claim_role $jwt_has_admin_role {\n    \\\"admin\\\"  1;\n}\n\nmap $jwt_claim_scope $jwt_has_restricted_scope {\n    \\\"restricted\\\"  1;\n}\n\nserver {\n  # ...\n\n  location /auth-require {\n    auth_jwt_require $jwt_has_admin_role error=403;\n    # ...\n  }\n\n  location /auth-compound-require {\n    auth_jwt_require $jwt_has_admin_role $jwt_has_restricted_scope error=403;\n    # ...\n  }\n}\n</code></pre></p> <p>Note that as <code>$jwt_claim_</code> returns a JSON-encoded value, so we have to check <code>\\\"value\\\"</code> (and not  <code>value</code>)</p>"},{"location":"modules/jwt/#embedded-variables","title":"Embedded Variables:","text":"<p>The ngx_http_auth_jwt_module module supports embedded variables: - $jwt_header_name returns the specified header value - $jwt_claim_name returns the specified claim value - $jwt_headers returns headers - $jwt_payload returns payload</p> <p>Note that as all returned values are JSON-encoded, so string will be surrounded by <code>\"</code> character</p>"},{"location":"modules/jwt/#image","title":"Image:","text":"<p>Image is generated with Github Actions (see nginx-jwt-module:latest)</p> <pre><code>docker pull ghcr.io/max-lt/nginx-jwt-module:latest\n</code></pre>"},{"location":"modules/jwt/#simply-create-your-image-from-githubs-generated-one","title":"Simply create your image from Github's generated one","text":"<pre><code>FROM ghcr.io/max-lt/nginx-jwt-module:latest\n\n## Copy your nginx conf\n## Don't forget to include this module in your configuration\n## load_module /usr/lib/nginx/modules/ngx_http_auth_jwt_module.so;\nCOPY my-nginx-conf /etc/nginx\n\nEXPOSE 8000\n\nSTOPSIGNAL SIGTERM\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>"},{"location":"modules/jwt/#or-use-the-provided-one-directly","title":"Or use the provided one directly","text":"<pre><code>docker run -p 80:80 \\\n  -v ./nginx.conf:/etc/nginx/nginx.conf \\\n  ghcr.io/max-lt/nginx-jwt-module\n</code></pre>"},{"location":"modules/jwt/#or","title":"or","text":"<p>docker build -f Dockerfile -t jwt-nginx . <pre><code>### Test:\n\n#### Default usage:\n```bash\nmake test # Will build a test image and run the test suite\n</code></pre></p>"},{"location":"modules/jwt/#example-configurations","title":"Example configurations:","text":"<p>In this section, we will see some examples of how to use this module.</p>"},{"location":"modules/jwt/#redirect-to-login-page-if-jwt-is-invalid","title":"Redirect to login page if JWT is invalid:","text":"<pre><code>load_module /usr/lib/nginx/modules/ngx_http_auth_jwt_module.so;\n\n## ...\n\nhttp {\n    server {\n        listen 80;\n        server_name _;\n\n        auth_jwt_key \"0123456789abcdef\" hex; # Your key as hex string\n        auth_jwt     off;\n\n        location @login_err_redirect {\n            return 302 $scheme://$host:$server_port/login?redirect=$request_uri;\n        }\n\n        location /secure/ {\n            auth_jwt on;\n            error_page 401 = @login_err_redirect;\n        }\n\n        location / {\n            return 200 \"OK\";\n        }\n    }\n}\n</code></pre> <p>Trying <code>curl -i http://localhost/secure/path?param=value</code> will return a 302 redirect to <code>/login?redirect=/secure/path?param=value</code> if the JWT is invalid.</p>"},{"location":"modules/jwt/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-jwt.</p>"},{"location":"modules/keyval/","title":"keyval: Nginx module for the key-value store","text":""},{"location":"modules/keyval/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-keyval\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-keyval\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_keyval_module.so;\n</code></pre> <p>This document describes nginx-module-keyval v0.3.0  released on Mar 31 2024.</p> <p>This nginx module creates variables with values taken from key-value pairs.</p> <p>This module is heavily inspired by the nginx original http_keyval_module.</p>"},{"location":"modules/keyval/#dependency","title":"Dependency","text":"<p>Using the Redis store.</p> <ul> <li>hiredis</li> </ul>"},{"location":"modules/keyval/#docker","title":"Docker","text":"<pre><code>$ docker build -t nginx-keyval .\n$ : \"app.conf: Create nginx configuration\"\n$ docker run -p 80:80 -v $PWD/app.conf:/etc/nginx/http.d/default.conf nginx-keyval\n</code></pre> <p>Github package: ghcr.io/kjdev/nginx-keyval</p>"},{"location":"modules/keyval/#configuration-ngx_http_keyval_module","title":"Configuration: <code>ngx_http_keyval_module</code>","text":""},{"location":"modules/keyval/#example","title":"Example","text":"<pre><code>http {\n  keyval_zone zone=one:32k;\n  keyval $arg_text $text zone=one;\n  ...\n  server {\n    ...\n    location / {\n      return 200 $text;\n    }\n  }\n}\n</code></pre>"},{"location":"modules/keyval/#directives","title":"Directives","text":"<pre><code>Syntax: keyval key $variable zone=name;\nDefault: -\nContext: http\n</code></pre> <p>Creates a new <code>$variable</code> whose value is looked up by the <code>key</code> in the key-value database.</p> <p>The database is stored in shared memory or Redis as specified by the zone parameter.</p> <p>In <code>key</code>, you can use a mix of variables and text or just variables.</p> <p>For example: - <code>$remote_addr:$http_user_agent</code> - <code>'$remote_addr    $http_user_agent   $host \"a random text\"'</code></p> <pre><code>Syntax: keyval_zone zone=name:size [timeout=time] [ttl=time];\nDefault: -\nContext: http\n</code></pre> <p>Sets the <code>name</code> and <code>size</code> of the shared memory zone that keeps the key-value database.</p> <p>The optional <code>timeout</code> or <code>ttl</code> parameter sets the time to live which key-value pairs are removed (default value is <code>0</code> seconds).</p> <pre><code>Syntax: keyval_zone_redis zone=name [hostname=name] [port=number] [database=number] [connect_timeout=time] [ttl=time];\nDefault: -\nContext: http\n</code></pre> <p>Using the Redis store</p> <p>Sets the <code>name</code> of the Redis zone that keeps the key-value database.</p> <p>The optional <code>hostname</code> parameter sets the Redis hostname (default value is <code>127.0.0.1</code>).</p> <p>The optional <code>port</code> parameter sets the Redis port (default value is <code>6379</code>).</p> <p>The optional <code>database</code> parameter sets the Redis database number (default value is <code>0</code>).</p> <p>The optional <code>connect_timeout</code> parameter sets the Redis connection timeout seconds (default value is <code>3</code>).</p> <p>The optional <code>ttl</code> parameter sets the time to live which key-value pairs are removed (default value is <code>0</code> seconds).</p>"},{"location":"modules/keyval/#configuration-ngx_stream_keyval_module","title":"Configuration: <code>ngx_stream_keyval_module</code>","text":""},{"location":"modules/keyval/#example_1","title":"Example","text":"<pre><code>stream {\n  keyval_zone zone=one:32k;\n  keyval $ssl_server_name $name zone=one;\n\n  server {\n    listen 12345 ssl;\n    proxy_pass $name;\n    ssl_certificate /usr/share/nginx/conf/cert.pem;\n    ssl_certificate_key /usr/share/nginx/conf/cert.key;\n  }\n}\n</code></pre>"},{"location":"modules/keyval/#directives_1","title":"Directives","text":"<pre><code>Syntax: keyval key $variable zone=name;\nDefault: -\nContext: http\n</code></pre> <p>Creates a new <code>$variable</code> whose value is looked up by the <code>key</code> in the key-value database.</p> <p>The database is stored in shared memory or Redis as specified by the zone parameter.</p> <pre><code>Syntax: keyval_zone zone=name:size [timeout=time] [ttl=time];\nDefault: -\nContext: http\n</code></pre> <p>Sets the <code>name</code> and <code>size</code> of the shared memory zone that keeps the key-value database.</p> <p>The optional <code>timeout</code> or <code>ttl</code> parameter sets the time to live which key-value pairs are removed (default value is 0 seconds).</p> <pre><code>Syntax: keyval_zone_redis zone=name [hostname=name] [port=number] [database=number] [connect_timeout=time] [ttl=time];\nDefault: -\nContext: http\n</code></pre> <p>Using the Redis store</p> <p>Sets the <code>name</code> of the Redis zone that keeps the key-value database.</p> <p>The optional <code>hostname</code> parameter sets the Redis hostname (default value is <code>127.0.0.1</code>).</p> <p>The optional <code>port</code> parameter sets the Redis port (default value is <code>6379</code>).</p> <p>The optional <code>database</code> parameter sets the Redis database number (default value is <code>0</code>).</p> <p>The optional <code>connect_timeout</code> parameter sets the Redis connection timeout seconds (default value is <code>3</code>).</p> <p>The optional <code>ttl</code> parameter sets the time to live which key-value pairs are removed (default value is <code>0</code> seconds).</p>"},{"location":"modules/keyval/#example_2","title":"Example","text":"<ul> <li>OpenID Connect Authentication</li> </ul>"},{"location":"modules/keyval/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-keyval.</p>"},{"location":"modules/length-hiding/","title":"length-hiding: NGINX Length Hiding Filter Module","text":""},{"location":"modules/length-hiding/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-length-hiding\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-length-hiding\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_length_hiding_filter_module.so;\n</code></pre> <p>This document describes nginx-module-length-hiding v1.1.1  released on Jul 19 2017.</p>"},{"location":"modules/length-hiding/#nginx-length-hiding-filter-module","title":"Nginx Length Hiding Filter Module","text":""},{"location":"modules/length-hiding/#introduction","title":"Introduction","text":"<p>In BREACH site, the mitigations against BREACH attack are given as follows:</p> <ol> <li>Disabling HTTP compression</li> <li>Separating secrets from user input</li> <li>Randomizing secrets per request</li> <li>Masking secrets (effectively randomizing by XORing with a random secret per request)</li> <li>Protecting vulnerable pages with CSRF</li> <li>Length hiding (by adding random number of bytes to the responses)</li> <li>Rate-limiting the requests</li> </ol> <p>BREACH relies on HTTP compression and it's reasonable to disable it to secure your website. However without compresseion, some websites may meet severe performance degression or the cost may increase if you're charged based on the volume of traffic like AWS. In such case it may be difficult to turn off HTML compression for whole responses from your website and need to adopt other proper ways.</p> <p>Other mitigations listed from the 2nd to 5th above are basically applicable to your application but the 6th one, Length hiding, can be done on nginx. This filter module provides functionality to append randomly generated HTML comment to the end of response body to hide correct response length and make it difficult for attackers to guess secure token.</p> <p>The sample of randomly appended HTML comment is here. <pre><code>&lt;!-- random-length HTML comment: JnSLGWeWYWsoJ4dXS3ubLw3YOu3zfGTotlzx7UJUo26xuXICQ2cbpVy1Dprgv8Icj6QfOZx2Ptp9HxCVoevTxhKzMzV6xeYXao0oCngRWJRb4Tvive1iBAXLzrHlLg6jKwNKXrct0tJuA2TvWIRVIng6UoffIbCQLPbi63PwmWemOxVi6m3CPa6hCbAK2CaBR1jLux7UJa4WNN4H0yIDMElMglWWouY5m5FUqAn0afMmtErj0zkA2LMWxisZRES38XLoYycySmaBrIih5IixUsJFR0ei4uZ0IifgV5SnitoNzMusSQem9npObHuU2HKApneAjwnFdPSQZA9sRdSOE8agDI05P832mV1JIcOjsg0FgzxvSG7UEX0HdqBqp2jPOYYW0k5gGtmkiXWydRJfn9lGomxReUeqq2Aec69gplEM6a8aqH5TFgXrGK8jcaPISQlsKkMxJQ7Fp6fVDbmI59xCIvlk --&gt;\n</code></pre> For every response, length of the random strings will vary within a given range.</p> <p>This idea originally came from breach-mitigation-rails. Thanks team!</p>"},{"location":"modules/length-hiding/#warning","title":"Warning","text":"<p>As said in breach-migration-rails, BREACH is complicated and wide-ranging attack and this module provides only PARTIAL protection. To secure your website or service wholly, you need to review BREACH paper and find proper way according to your own website or service.</p>"},{"location":"modules/length-hiding/#configuration-directives","title":"Configuration Directives","text":""},{"location":"modules/length-hiding/#length_hiding","title":"length_hiding","text":"<ul> <li>syntax: length_hiding on | off</li> <li>default: off</li> <li>context: http, server, location, if in location</li> </ul> <p>Enables or disables adding random generated HTML comment.</p>"},{"location":"modules/length-hiding/#length_hiding_max","title":"length_hiding_max","text":"<ul> <li>syntax: length_hiding_max size</li> <li>default: 2048</li> <li>context: http, server, location</li> </ul> <p>Sets maximum length of random generated string used in HTML comment. The size should be within a range from 256 and 2048.</p>"},{"location":"modules/length-hiding/#example-configuration","title":"Example Configuration","text":"<p>Enable this module for specific location ('/hiding'). In this example, the length of random strings will be less than 1024. <pre><code>server {\n    listen       443 default_server deferred ssl spdy;\n    server_name  example.com;\n    length_hiding_max 1024;\n\n    location /hiding {\n        length_hiding on;\n    }\n}\n</code></pre></p> <p>If this module is built as dynamic module, do NOT forget including <code>load_module</code> line in nginx configuration. <pre><code>load_module modules/ngx_http_length_hiding_filter_module.so;\n</code></pre></p>"},{"location":"modules/length-hiding/#services-using-this-module","title":"Services using this module","text":"<ul> <li>Cacoo</li> <li>Backlog</li> <li>Typetalk</li> <li>Nulab Account</li> </ul>"},{"location":"modules/length-hiding/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-length-hiding.</p>"},{"location":"modules/let/","title":"let: NGINX let module","text":""},{"location":"modules/let/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-let\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-let\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_let_module.so;\n</code></pre> <p>This document describes nginx-module-let v0.0.5  released on Jan 27 2023.</p>"},{"location":"modules/let/#nginx-let-module","title":"NGINX let module","text":"<p>Adds support for arithmetic operations to NGINX config.</p> <p>(c) 2011 Roman Arutyunyan, arut@qip.ru</p>"},{"location":"modules/let/#examples","title":"Examples:","text":""},{"location":"modules/let/#adds-variable-value-equal-to-evaluated-expression-value","title":"adds variable $value equal to evaluated expression value","text":"<p>let $value ( $uid + 0x12 ) * $offset - 100 ;</p> <p>let $remainer $number % 100 ;</p> <p>let $welcome \"Hi, \" . $user . \", you have \" . $num . \" data items\";</p>"},{"location":"modules/let/#echo-welcome","title":"echo $welcome ;","text":"<p>let_rand $randval from to;</p> <p>IMPORTANT NOTE:</p> <p>let-module uses NGINX config parser as lexer. That means you should add spaces around each token.</p> <p>let $value (1+2);             # ERROR! let $value ( 1 + 2 );         # OK</p> <p>let $value 1 + (2 * $uid);    # ERROR! let $value 1 + ( 2 * $uid );  # OK</p>"},{"location":"modules/let/#features-supported","title":"Features supported:","text":"<ul> <li> <p>operations with unsigned integers:</p> </li> <li> <ul> <li> <ul> <li>/ %</li> </ul> </li> </ul> </li> <li> <p>string operations:</p> </li> </ul> <p>. (concatenation)</p> <ul> <li> <p>hexadecimal numbers</p> </li> <li> <p>grouping with parentheses</p> </li> </ul>"},{"location":"modules/let/#notes","title":"Notes:","text":"<p>Use the following command to rebuild parser generator if you need that</p> <p>bison -d let.y</p>"},{"location":"modules/let/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-let.</p>"},{"location":"modules/limit-traffic-rate/","title":"limit-traffic-rate: NGINX Limiting rate by given variables","text":""},{"location":"modules/limit-traffic-rate/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-limit-traffic-rate\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-limit-traffic-rate\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_limit_traffic_rate_filter_module.so;\n</code></pre> <p>This document describes nginx-module-limit-traffic-rate v1.0.0  released on Dec 30 2024.</p>"},{"location":"modules/limit-traffic-rate/#notes","title":"Notes","text":"<p>Nginx directive <code>limit_rate</code> could limit connection's speed, and <code>limit_conn</code> could limit connection number by given variable. If the client is a browser, it only open one connection to the server. The speed will be limited to <code>limit_rate</code>, unless the client is a multi-thread download tool.</p> <p><code>ngx_http_limit_traffic_ratefilter_module</code> provides a method to limit the total download rate by client IP or download URL, even there are several connections. The limit condition could be defined by the following directive.</p> <p>To install, compile nginx with this ./configure option:</p> <pre><code>--add-module=path/to/this/directory\n</code></pre> <p>The limit_traffic_rate module need to use a share memory pool.</p>"},{"location":"modules/limit-traffic-rate/#directive-syntax-is-same-to-limit_zone","title":"Directive syntax is same to limit_zone","text":"<pre><code>http {\n    #limit_traffic_rate_zone   rate $request_uri 32m;\n    limit_traffic_rate_zone   rate $remote_addr 32m;\n\n    server {\n        location /download/ {\n            limit_traffic_rate  rate 20k;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/limit-traffic-rate/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-limit-traffic-rate.</p>"},{"location":"modules/live-common/","title":"live-common: Kaltura Media Framework Common NGINX Module","text":""},{"location":"modules/live-common/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-live-common\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-live-common\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_api_module.so;\n</code></pre> <p>This document describes nginx-module-live-common v2.0.6  released on Nov 13 2025.</p> <p></p> <p>A distributed framework for live video streaming. The system is composed of multiple components, each one responsible for a specific function.</p> <p>The components can be deployed on a single server for small scale deployments/testing, but it is recommended to deploy them separately for a more optimal resource utilization. For example, the transcoder can utilize the GPU, so it would be more cost efficient to deploy the transcoders on GPU-enabled servers, while the other components would run on servers without GPU.</p> <p>Media is transmitted between the different components internally using custom protocols - 1. Kaltura Media Protocol (KMP) - a TCP-based protocol for delivering streaming media, conceptually, similar to a single track of fMP4/MPEG-TS 2. Kaltura Segmented Media Protocol (KSMP) - an HTTP-based protocol for delivering media in segments, conceptually, a super-set of LLHLS/DASH</p> <p>The orchestration of the different media components is performed by a \"controller\". The main responsibility of the controller is building the topology of the media pipeline, and updating it in case of failures. The controller gets JSON events from the media components sent as HTTP-POSTs. In addition, all the media processing components expose a JSON-based REST API, that is used by the controller to get the latest status and take actions. A sample controller implementation for an all-in-one server is provided in the conf folder.</p>"},{"location":"modules/live-common/#main-features","title":"Main Features","text":"<ul> <li>Publishing protocols: RTMP, MPEGTS (over SRT/HTTP/TCP)</li> <li>Playback protocols: HLS/LLHLS, DASH</li> <li>Live push/relay protocols: RTMP</li> <li>Video/audio transcoding - including GPU support, based on ffmpeg API</li> <li>Persistence - in S3 (or compatible) object storage</li> <li>Adaptive bitrate delivery</li> <li>Subtitle support - including conversion of 608/708 to WebVTT</li> <li>Alternative audio</li> <li>Media encryption and DRM</li> <li>Video frame capture</li> </ul>"},{"location":"modules/live-common/#getting-started","title":"Getting Started","text":"<p>The conf folder contains sample code and configuration for running an all-in-one server.</p>"},{"location":"modules/live-common/#glossary","title":"Glossary","text":"<ul> <li>Channel - a container that represents a live stream, may contain tracks, variants, timelines etc.</li> <li>Track - a single rendition of video/audio/subtitle. For example, a channel may have 3 video tracks: 1080p, 720p, 540p.</li> <li>Variant - a grouping of tracks used for packaging. Variants determine which audio track will be paired to each video track, when muxed segments are used.     A variant can point to multiple tracks, but no more than one track per media type.     Tracks must be associated to variants in order to be delivered via HLS/DASH.</li> <li>Segment - a group of frames of a specific track. Segments are always independent - video segments will always start with a key/IDR frame.</li> <li>Segment index - a number that identifies the segments of the different tracks that are associated with a specific time interval.</li> <li>Period - a set of segment indexes that can be played continuously.</li> <li>Timeline - a set of periods. Multiple timelines can be created, each with its own set of periods.     Timelines can be used, for example, in order to implement \"preview mode\" - the publisher consumes one timeline, while the viewers consume another.     The timeline of the publisher is always <code>active</code>, while the timeline of the viewers is activated upon the publisher's discretion.</li> </ul>"},{"location":"modules/live-common/#sample-topologies","title":"Sample Topologies","text":"<p>The diagrams below demonstrate a few sample topologies that can be created using the Media-Framework components.</p>"},{"location":"modules/live-common/#simple-rtmp-passthrough","title":"Simple RTMP Passthrough","text":"<pre><code>flowchart LR;\n    enc(Encoder);\n    ingest(nginx-rtmp-kmp-module);\n    live(nginx-live-module);\n    pckg(nginx-pckg-module);\n    play(Player);\n    enc--&gt;|RTMP|ingest;\n    ingest--&gt;|KMP|live;\n    live--&gt;|KSMP|pckg;\n    pckg--&gt;|LLHLS/DASH|play;\n</code></pre>"},{"location":"modules/live-common/#passthrough-s3-persistence","title":"Passthrough + S3 Persistence","text":"<pre><code>flowchart LR;\n    enc(Encoder);\n    ingest(nginx-rtmp-kmp-module);\n    live(nginx-live-module);\n    pckg(nginx-pckg-module);\n    s3(Amazon S3);\n    play(Player);\n    enc--&gt;|RTMP|ingest;\n    ingest--&gt;|KMP|live;\n    live--&gt;|HTTP|s3;\n    s3--&gt;|HTTP|live;\n    live--&gt;|KSMP|pckg;\n    pckg--&gt;|LLHLS/DASH|play;\n</code></pre>"},{"location":"modules/live-common/#srt-input-video-transcoding","title":"SRT Input + Video Transcoding","text":"<pre><code>flowchart LR;\n    enc(Encoder);\n    ingest(nginx-mpegts-kmp-module);\n    srt(nginx-srt-module);\n    trans(transcoder);\n    live(nginx-live-module);\n    pckg(nginx-pckg-module);\n    play(Player);\n    enc--&gt;|SRT|srt;\n    srt--&gt;|MPEG-TS|ingest;\n    ingest--&gt;|KMP video|trans;\n    trans--&gt;|KMP video|live;\n    ingest--&gt;|KMP audio|live;\n    live--&gt;|KSMP|pckg;\n    pckg--&gt;|LLHLS/DASH|play;\n</code></pre>"},{"location":"modules/live-common/#closed-captions-decoding","title":"Closed-captions Decoding","text":"<pre><code>flowchart LR;\n    enc(Encoder);\n    ingest(nginx-rtmp-kmp-module);\n    cc(nginx-cc-module);\n    live(nginx-live-module);\n    pckg(nginx-pckg-module);\n    play(Player);\n    enc--&gt;|RTMP|ingest;\n    ingest--&gt;|KMP video|cc;\n    cc--&gt;|KMP subtitle|live;\n    ingest--&gt;|KMP video|live;\n    ingest--&gt;|KMP audio|live;\n    live--&gt;|KSMP|pckg;\n    pckg--&gt;|LLHLS/DASH|play;\n</code></pre>"},{"location":"modules/live-common/#transcoding-rtmp-push","title":"Transcoding + RTMP Push","text":"<pre><code>flowchart LR;\n    enc(Encoder);\n    ingest(nginx-mpegts-kmp-module);\n    trans(transcoder);\n    live(nginx-live-module);\n    pckg(nginx-pckg-module);\n    push(nginx-kmp-rtmp-module);\n    yt(YouTube);\n    play(Player);\n    enc--&gt;|MPEG-TS/HTTP|ingest;\n    ingest--&gt;|KMP|trans;\n    trans--&gt;|KMP|live;\n    trans--&gt;|KMP|push;\n    push--&gt;|RTMP|yt;\n    live--&gt;|KSMP|pckg;\n    pckg--&gt;|LLHLS/DASH|play;\n</code></pre>"},{"location":"modules/live-common/#components-overview","title":"Components Overview","text":""},{"location":"modules/live-common/#media-components","title":"Media Components","text":"<ul> <li> <p>nginx-rtmp-kmp-module - live media ingestion, input: RTMP, output: KMP x N</p> </li> <li> <p>nginx-mpegts-kmp-module - live media ingestion, input: MPEG-TS over TCP/HTTP, output: KMP x N</p> </li> <li> <p>transcoder - video/audio transcoding, input: KMP, output: KMP x N</p> </li> <li> <p>nginx-live-module - live media segmenter, input: KMP x N, output: KSMP</p> <p>Additional features: persistence, filler, timeline support.</p> </li> <li> <p>nginx-pckg-module - live media packager (stateless), input: KSMP, output: HLS/LLHLS, DASH</p> <p>Additional features: adaptive bitrate, subtitles, alternative audio, media encryption / DRM, video frame capture</p> </li> <li> <p>nginx-kmp-cc-module - closed-captions decoder, input: KMP video (h264/5), output: KMP subtitle (WebVTT) x N</p> </li> <li> <p>nginx-kmp-rtmp-module - live media relay, input: KMP x N, output: RTMP</p> </li> </ul> <p>Important: All stateful nginx-based components (=all except nginx-pckg-module), must be deployed on a single process nginx server (<code>worker_processes 1;</code>).     The module state is kept per process, and when multiple processes are used, it is not possible to control which process will get the request.     For example, the request to create a channel on the segmenter may arrive to worker 1, while the KMP connection with the actual media, will hit worker 2.     In deployments that use containers, this shouldn't be a problem - multiple containers can be deployed on a single server, instead of using multiple nginx processes.     Another possibility is to use a patch like arut's per-worker listener,     but it will probably need to be updated to apply to <code>stream</code> connections as well.</p>"},{"location":"modules/live-common/#debug-options","title":"Debug Options","text":"<p>Some of the Media-Framework components support optional preprocessor macros for debugging purposes - - NGX_LBA_SKIP (nginx-common) - Skips the use of the \"Large Buffer Array\" (LBA) module. When enabled, LBA allocations are routed to ngx_alloc / ngx_free. - NGX_RTMP_VERBOSE (nginx-rtmp-module) - Enables additional debug log messages - NGX_LIVE_VALIDATIONS (nginx-live-module) - Enables runtime consistency checks on internal data structures, enabled by default when using <code>--with-debug</code> - NGX_BLOCK_POOL_SKIP (nginx-live-module) - Skips the use of block pools. When enabled, block pool allocations are routed to ngx_palloc / ngx_pfree.</p> <p>To test the modules with valgrind, it is recommended to the apply the no-pool-nginx patch, and configure nginx with <code>--with-cc-opt=\"-O0 -DNGX_BLOCK_POOL_SKIP -DNGX_LBA_SKIP\"</code> and <code>--with-debug</code>.</p>"},{"location":"modules/live-common/#kaltura-media-protocol-kmp","title":"Kaltura Media Protocol (KMP)","text":"<p>Kaltura Media Protocol is a simple packet-based protocol for streaming media over TCP. A KMP connection can deliver the media of a single video/audio/subtitle track - when multiple tracks are needed, multiple TCP connections are established.</p> <p>Each packet starts with a header that contains the following fields (32 bits each) - - Type - the type of the packet. The packet types are four-character codes, see below the list of currently defined types. - Header size - the size of the packet header, must be between sizeof(kmp_packet_header_t) and 64KB.     Parsers must use the header size in order to access the data of the packet, this enables the addition of new fields to packet headers without breaking existing parsers. - Data size - the size of the packet data, must be between 0 and 16MB. - Reserved - reserved for future use, must be set to 0.</p> <p>The structures and constants used in KMP can be found in ngx_live_kmp.h.</p>"},{"location":"modules/live-common/#kmp-frame-ids","title":"KMP Frame Ids","text":"<p>A frame id is a 64-bit integer that uniquely identifies an input frame. The ingest modules (nginx-rtmp-kmp-module / nginx-mpegts-kmp-module) allocate the initial frame id according to the server clock (in timescale units), when an output track is created. In order to avoid the need to send the frame id on each frame that is being sent, the frame ids in KMP are sequential - the id of the N-th frame that is sent on a KMP connection is <code>initial_frame_id + N</code>.</p> <p>If the input connection (e.g. RTMP) drops and gets re-established, new KMP frame ids will be allocated. Since the default timescale is high (90kHz), and the frame rate is unlikely to exceed 60fps, even in case of a reconnect after a short period of streaming, the initial frame id will be significantly higher than the frame id that was last sent on the previous connection. So, it is extremely unlikely to have a conflict with any previously used frame ids due to reconnect.</p> <p>Frame ids are used: - To identify which frames are being acked in KMP ack packets - To skip previously handled frames if a KMP connection is re-established</p> <p>The transcoder adds a few complexities to the management of frame ids - - Since the transcoder may change the input frame rate or drop frames, the frame ids in the transcoder input,     are not necessarily the same as the frame ids in the transcoder output.     If the transcoder is restarted, it needs to know what value to send as the <code>initial_frame_id</code> of its upstream server (usually nginx-live-module).     The <code>upstream_frame_id</code> field is used for this purpose. - The transcoder may be configured to change the sampling rate of an audio track, and, in this case, the transcoded frames do not align with the input frames.     To handle this scenario, the transcoder needs to have the ability to acknowledge only a part of an input frame.     This is the purpose of the <code>offset</code> field - it can store, for example, the number of audio samples that should be acknowledged within the frame.     The exact meaning of the <code>offset</code> field is determined by the KMP receiver -     the receiver sets the <code>offset</code> in the ack frames it returns, and gets it back in the <code>initial_offset</code> field of the connect packet, in case of reconnect.</p>"},{"location":"modules/live-common/#publisher-kmp-packets","title":"Publisher KMP Packets","text":"<p>The sections below list the KMP packets that can be sent by a KMP publisher.</p>"},{"location":"modules/live-common/#connect-cnct","title":"Connect (<code>cnct</code>)","text":"<p>Sent immediately after the KMP TCP connection is established.</p> <p>The header contains the following fields: - <code>channel_id</code> - string, the channel id that is being published. The maximum allowed length is 32 chars. - <code>track_id</code> - string, the track id that is being published. The maximum allowed length is 32 chars. - <code>initial_frame_id</code> - integer, the id of the first frame being sent. - <code>initial_upstream_frame_id</code> - integer, the initial frame id that should be sent to the upstream server (used by the transcoder) - <code>initial_offset</code> - integer, the offset to start from, within the initial frame. - <code>flags</code> - integer, a bit mask of flags, currently a single flag is defined -     <code>consistent</code> - this flag is set when the KMP publisher generates consistent (bit exact) output, given the same input.         nginx-rtmp-kmp-module and nginx-mpegts-kmp-module are examples of publishers that are consistent.         The transcoder, on the other hand, is not. The <code>consistent</code> flag is used by the LL segmenter in case of reconnect.         When the publisher is consistent, the LL segmenter can continue from the point it left off.         When the publisher is inconsistent, the LL segmenter can continue only from the next GOP -         it must not mix a partial GOP from before the disconnect, with the GOP received after the disconnect.</p> <p>The data of the connect packet is optional, the expected format of the data is defined by the specific KMP receiver.</p>"},{"location":"modules/live-common/#media-info-minf","title":"Media Info (<code>minf</code>)","text":"<p>Contains the parameters of the media. Some of the fields in the header are shared by all media types, while the rest are defined only for a specific type (union).</p> <p>The shared header fields are: - <code>media_type</code> - integer, the type of media - <code>video</code> / <code>audio</code> / <code>subtitle</code>, uses the KMP_MEDIA_XXX constants. - <code>codec_id</code> - integer, the codec id, uses the KMP_CODEC_XXX constants. - <code>timescale</code> - integer, the units used in the <code>dts</code> / <code>pts_delay</code> / <code>created</code> fields of frame packets, in Hz. - <code>bitrate</code> - integer, the bitrate, in bits per second.</p> <p>The video-specific header fields are: - <code>width</code> - integer, the width of the video, in pixels. - <code>height</code> - integer, the height of the video, in pixels. - <code>frame_rate</code> - rational, the frame rate of the video, in frames per second. - <code>cea_captions</code> - boolean, set to <code>1</code> when the video track contains EIA-608 / CTA-708 captions.</p> <p>The audio-specific header fields are: - <code>channels</code> - integer, the number of audio channels. - <code>bits_per_sample</code> - integer, the size of the audio samples, in bits. - <code>sample_rate</code> - integer, the sampling rate of the audio, in samples per second. - <code>channel_layout</code> - integer, a bit mask of channel positions, uses the KMP_CH_XXX constants.</p> <p>The data of the media info packet holds the codec private/extra data. For example, when using the <code>h264</code> codec, the data contains the body of an <code>avcC</code> MP4 box.</p> <p>KMP receivers should handle media info changes, for example, a change to the video resolution. However, the type of the media (video/audio/subtitle) that is sent in a KMP connection, must not change.</p> <p>KMP receivers should ignore media info packets, when they are identical to the previously received media info packet.</p>"},{"location":"modules/live-common/#frame-fram","title":"Frame (<code>fram</code>)","text":"<p>Represents a single video frame / audio frame / subtitle cue.</p> <p>The frame header contains the following fields: - <code>created</code> - integer, the time in which the frame was received by the first Media-Framework module in the pipeline, in timescale units. - <code>dts</code> - integer, the decode timestamp of the frame, in timescale units.     When the media type is <code>subtitle</code>, holds the start timestamp of the cue. - <code>flags</code> - integer, currently only one flag is defined -     <code>key</code> - enabled on video keyframes. - <code>pts_delay</code> - integer, the difference between the presentation timestamp of the frame, and the decode timestamp, in timescale units.     When the media type is <code>subtitle</code>, holds the duration of the cue - <code>end_pts - start_pts</code>.</p> <p>When the media type is video / audio, the data of the frame packet holds the compressed media. When the media type is subtitle and the codec is WebVTT, the data of the frame follows the WebVTT Sample Format, as specified in <code>ISO/IEC 14496-30</code> (usually, in this case, a sample is a <code>vttc</code> box, that contains a <code>payl</code> box).</p>"},{"location":"modules/live-common/#null-null","title":"Null (<code>null</code>)","text":"<p>Sent in order to signal \"liveness\", and prevent idle timers from expiring. Null packets do not carry any data other than the basic KMP header. Parsers must ignore null packets.</p>"},{"location":"modules/live-common/#end-of-stream-eost","title":"End Of Stream (<code>eost</code>)","text":"<p>Used to signal a graceful termination of the publishing session. End of stream packets do not carry any data other than the basic KMP header.</p>"},{"location":"modules/live-common/#receiver-kmp-packets","title":"Receiver KMP Packets","text":"<p>The sections below list the KMP packets that can be sent by a KMP receiver.</p>"},{"location":"modules/live-common/#ack-frames-ackf","title":"Ack Frames (<code>ackf</code>)","text":"<p>Acknowledge the receipt of frames.</p> <p>The KMP receiver decides on the appropriate time to send an ack packet. For example, when persistence is enabled, the segmenter sends an ack only after a segment that contains the frame is saved to storage.</p> <p>Some receivers do not send acks at all, in this case, the KMP producer must be configured to discard the frames after they are sent (using the <code>resume_from</code> setting)</p> <p>The packet header contains the following fields: - <code>frame_id</code> - integer, the id of the first frame that should be re-sent if the connection is dropped.     In other words, an ack frames packet, acknowledges all frames that have an id that is less <code>frame_id</code>.     If the KMP connection is re-established, this value will be sent in the <code>initial_frame_id</code> field. - <code>upstream_frame_id</code> - integer, the id of the frame that was sent to the upstream server.     If the KMP connection is re-established, this value will be sent in the <code>initial_upstream_frame_id</code> field. - <code>offset</code> - integer, the offset to acknowledge within the frame.     If the KMP connection is re-established, this value will be sent in the <code>initial_offset</code> field. - <code>padding</code> - integer, reserved for future use, must be set to zero.</p> <p>The data of the ack packets is not used.</p>"},{"location":"modules/live-common/#kaltura-segmented-media-protocol-ksmp","title":"Kaltura Segmented Media Protocol (KSMP)","text":"<p>Kaltura Segmented Media Protocol is an HTTP-based protocol for delivering media in segments, similarly to HLS/DASH.</p> <p>A KSMP request is an HTTP GET request, the following query parameters are defined - - <code>channel_id</code> - required string, the id of the channel - <code>timeline_id</code> - required string, the id of the timeline - <code>flags</code> - required hex integer, the flags:     - Select the subset of data that is required (like the column list in an SQL SELECT statement)     - Control various behaviors when servicing the request.         For example, the 'closest key' flag, returns only the key frame that is closest to the request timestamp, instead of returning the whole segment. - <code>variant_ids</code> - optional string, selects a subset of the variants that should be returned, by default, all variants are returned.     If multiple variants are specified, they should be delimited with an hyphen (-). - <code>media_type_mask</code> - optional hex integer, sets the media types that should be returned, by default, all media types are returned. - <code>time</code> - optional integer, the requested timestamp. The timestamp is used, for example, in order to capture a video frame at a specific time. - <code>segment_index</code> - optional integer, the index of the segment - <code>max_segment_index</code> - optional integer, used to limit the scope of segments returned in the response. This parameter can be used to replay a persisted stream for debugging. - <code>part_index</code> - optional integer, the zero based index of the partial segment within the segment. A request that uses <code>part_index</code> must send also <code>segment_index</code>. - <code>skip_boundary_percent</code> - optional integer, sets the skip boundary value as a percent of the target duration     (see the definition of the <code>CAN-SKIP-UNTIL</code> attribute in the HLS specification for more details) - <code>padding</code> - optional integer, adds additional zero bytes at the end of the response. Used to comply with ffmpeg's padding requirements without incurring additional copy operations.</p> <p>A KSMP response uses KLPF format (see below), with type Serve (<code>serv</code>). The KSMP-specific definitions can be found in ngx_ksmp.h</p>"},{"location":"modules/live-common/#kaltura-live-persist-file-klpf","title":"Kaltura Live Persist File (KLPF)","text":"<p>Kaltura Live Persist File is a serialization scheme that is used in KSMP responses and in the S3 objects created by nginx-live-module.</p> <p>A KLPF is composed of blocks, similar to MP4 atoms/boxes. Each block has the following header - - <code>id</code> - a four-character code identifying the block - <code>size</code> - uint32, the full size of the block (header &amp; data) - <code>flags</code> - 4 bits, the following flags are defined:    - container (0x1) - the block contains other blocks    - index (0x2) - the block is an index to another block, header size should not be used    - compressed (0x4) - the data of the block is zlib-compressed - <code>header_size</code> - 28 bits, the size of the block header. Parsers must use the header size in order to access the data of the block,     so that fields could be added to the header without breaking compatibility</p> <p>A KLPF file is a block whose id is set to <code>klpf</code>. Following the generic block header fields (listed above), a KLPF file has the following fields in its header - - <code>uncomp_size</code> - uint32, holds the uncompressed size of the data, when the KLPF data is compressed - <code>version</code> - uint32, the version of the file format. The version used for new files is updated on every breaking change to the format, the code will be updated to either    - support reading both the new format and the old format, or    - ignore files that use the old format - <code>type</code> - a four-character code that identifies the type of data stored in the KLPF. The type determines which block ids are supported, and their internal structure.     The type <code>serv</code> (Serve) is used for KSMP responses, in the communication between the packager and the segmenter. Additional types are used internally by the segmenter. - <code>created</code> - uint64, the unix timestamp when the KLPF was created</p> <p>For more details on the internal structure of KLPF blocks, see KLFP-SPEC.md.</p> <p>To inspect the contents of KLPF objects/KSMP responses, use klpf_parse.py. The script can show the block structure without any additional info, however, in order to parse the fields inside the blocks: - run generate_persist_spec.py, and save the output to a file - provide the file name to klpf_parse.py using the <code>-s / --spec-file</code> option</p>"},{"location":"modules/live-common/#api-overview","title":"API Overview","text":"<p>All the media processing components expose a JSON-based REST API. This section explains the general properties of the Media-Framework APIs. For a detailed reference of the available API endpoints, see the documentation of the specific modules.</p>"},{"location":"modules/live-common/#request-types","title":"Request Types","text":"<p>The following HTTP verbs are used in the API: - <code>GET</code> - get the full status of the module, or a subset of it. The argument <code>?pretty=1</code> can be added to the request, in order to return the response in a \"pretty\" / indented format. - <code>GET</code> with <code>?list=1</code> - return the names of the \"folders\" under a certain path in the API. Can be used to walk the tree of possible API routes. - <code>POST</code> - create an object. - <code>PUT</code> - update an object, the id of the object to update is passed on the URI. - <code>DELETE</code> - delete an object, the id of the object to delete is passed on the URI.</p> <p>The request body in <code>POST</code> / <code>PUT</code> requests must be a JSON (usually an object), and the request must use the header <code>Content-Type: application/json</code>.</p> <p>When the size of the request body exceeds a certain threshold, nginx writes it to a temporary file. However, the implementation of the Media-Framework API requires that the request body of <code>POST</code> / <code>PUT</code> requests will be available in memory. If needed, the nginx <code>client_body_buffer_size</code> directive can be used to increase the size of the buffer allocated for the request body.</p>"},{"location":"modules/live-common/#status-codes","title":"Status Codes","text":"<p>HTTP status codes are used to return the execution status of API requests.</p> <p>The following success codes are used: - <code>200</code> - a successful <code>GET</code> request, the response body is a JSON, usually a JSON object or array (the response includes the header <code>Content-Type: application/json</code>). - <code>201</code> - a successful <code>POST</code> request, that resulted in the creation of a new object. - <code>204</code> - a successful <code>POST</code> / <code>PUT</code> / <code>DELETE</code> request.     A <code>POST</code> request may return <code>204</code> when the object already existed, and <code>upsert</code> is enabled on the API location in nginx configuration.</p> <p>The following error codes are used: - <code>400</code> - invalid request, for example, the length of some input field exceeds the limit. - <code>403</code> - returned by nginx-live-module when getting a request to update a channel that is currently being read from storage. - <code>404</code> - some object referenced by the URI or request body was not found. - <code>409</code> - attempt to create an object that already exists, when <code>upsert</code> is not enabled on the API location in nginx configuration. - <code>415</code> - the request body is not a valid JSON, the type of the JSON is not expected (usually a JSON object is expected), or some required field is missing. - <code>500</code> - an unexpected error, for example, a memory allocation failure.</p>"},{"location":"modules/live-common/#multi-request","title":"Multi Request","text":"<p>Setting up a channel in nginx-live-module may require multiple API calls - create the channel, create a timeline, create a variant, etc. In order to avoid the penalty of multiple round trips, the API layer has support for \"multi\" requests. A multi request bundles together several API requests in a single HTTP request.</p> <p>Multi requests must use the <code>POST</code> verb, and their URI must be set to <code>/multi</code>. The request body must be a JSON array of objects, each object represents a single API request.</p> <p>The objects contains the following fields: - <code>uri</code> - string, required, the relative API path. - <code>method</code> - string, required, the HTTP verb of the request - <code>GET</code> / <code>POST</code> / <code>PUT</code> / <code>DELETE</code>. - <code>body</code> - any (usually object), optional, the body of <code>POST</code> / <code>PUT</code> requests.</p> <p>The response of multi requests is also a JSON array of objects. The number of elements in the response array always matches the number of elements in the request array, and the order of the objects in the response array matches the order in the request array. In other words, the N-th item of the response array, is the response of the N-th request in the request array.</p> <p>Each response object contains the following fields: - <code>code</code> - integer, required, the HTTP status code - <code>body</code> - any (usually object / array), optional, the response body</p>"},{"location":"modules/live-common/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-live-common.</p>"},{"location":"modules/log-sqlite/","title":"log-sqlite: SQLite logger module for NGINX","text":""},{"location":"modules/log-sqlite/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-log-sqlite\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-log-sqlite\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_sqlitelog_module.so;\n</code></pre> <p>This document describes nginx-module-log-sqlite v0.0.1  released on Feb 14 2025.</p> <ul> <li>Summary</li> <li>Directives<ul> <li>sqlitelog</li> <li>sqlitelog_format</li> <li>sqlitelog_async</li> </ul> </li> <li>Install</li> <li>Example</li> <li>Errors</li> <li>Usage<ul> <li>Locations</li> <li>Inheritance</li> <li>WAL mode</li> <li>Logrotate</li> <li>Column types</li> </ul> </li> </ul>"},{"location":"modules/log-sqlite/#summary","title":"Summary","text":"<p>This module uses SQLite format for access logs. GitHub fork of https://git.serope.com/me/ngx-sqlitelog</p>"},{"location":"modules/log-sqlite/#directives","title":"Directives","text":""},{"location":"modules/log-sqlite/#sqlitelog","title":"sqlitelog","text":"<ul> <li>Syntax: <code>sqlitelog</code> <code>path</code> <code>[format]</code> <code>[buffer=size [max=n] [flush=time]]</code> <code>[init=script]</code> <code>[if=condition]</code> | <code>off</code></li> <li>Default: <code>sqlitelog</code> <code>off</code></li> <li>Context: http, server</li> </ul> <p>This directive defines a logging database.</p> <p>The <code>path</code> parameter is the path of the database file. It must be located in a directory where the user or group that owns Nginx worker processes (defined by the <code>user</code> directive) has write permission so that it can create the database file and any possible temporary files.</p> <p>The <code>format</code> parameter is the name of a log format defined by the <code>sqlitelog_format</code> directive. If not given, the default combined format is used.</p> <p>The <code>buffer</code> parameter creates a memory zone where log entries are batched together and written to the database in a single <code>BEGIN</code> ... <code>COMMIT</code> transaction. This greatly improves performance as grouped inserts are faster than separate ones. The buffer is commited when one of the following happens: its <code>size</code> is exceeded; it accumulates <code>n</code> log entries; the flush <code>time</code> elapses; Nginx reloads or exits.</p> <p>The <code>init</code> parameter is a path to a SQL script file which is executed on each database connection. This can be used to run pragma commands or to create additional tables, views, and triggers to complement the logging table; such statements should include <code>IF NOT EXISTS</code> since they can be executed more than once.</p> <p>The <code>if</code> parameter sets a logging condition. Like in the standard log module, if <code>condition</code> evaluates to 0 or an empty string, logging is skipped for the current request.</p>"},{"location":"modules/log-sqlite/#sqlitelog_format","title":"sqlitelog_format","text":"<ul> <li>Syntax: <code>sqlitelog_format</code> <code>table</code> <code>var1</code> <code>[type1]</code> <code>var2</code> <code>[type2]</code> ... <code>varN</code> <code>[typeN]</code></li> <li>Default: <code>sqlitelog_format</code> <code>combined</code> <code>$remote_addr</code> <code>$remote_user</code> <code>$time_local</code> <code>$request</code> <code>$status</code> <code>$body_bytes_sent</code> <code>$http_referer</code> <code>$http_user_agent</code></li> <li>Context: http</li> </ul> <p>This directive defines a logging table.</p> <p>The first argument is the table's name. The remaining arguments are variables with optional column types. Some variables have preset column types, otherwise the default is <code>TEXT</code>. If a variable is <code>BLOB</code> type, its value is written as unescaped bytes.</p>"},{"location":"modules/log-sqlite/#sqlitelog_async","title":"sqlitelog_async","text":"<ul> <li>Syntax: <code>sqlitelog_async</code> <code>pool</code> | <code>on</code> | <code>off</code></li> <li>Default: <code>sqlitelog_async</code> <code>off</code></li> <li>Context: http</li> </ul> <p>This directive enables a thread pool, allowing SQLite file writes to occur without blocking. The argument can be an existing <code>pool</code> name, <code>on</code> for the default pool, or <code>off</code>. This directive is only available if Nginx is compiled with <code>--with-threads</code>.</p>"},{"location":"modules/log-sqlite/#errors","title":"Errors","text":"<p>When a SQLite error occurs, the module is disabled (equivalent to <code>sqlitelog off</code>) for the worker process that encountered the error. This is to prevent error.log from being quickly flooded with error messages if the database is unusable (e.g. located in a directory where worker processes don't have write permission).</p> <ul> <li>SQLITE_ERROR (1): This is a generic error code that covers several cases, such as SQL syntax errors in an <code>init</code> script.</li> <li>SQLITE_BUSY (5): Multiple worker processes attempted to use the database simultaneously and exceeded the busy timeout (1000 ms by default). This can be solved by creating a <code>buffer</code> to speed up insertions or by setting a longer timeout with <code>PRAGMA busy_timeout</code> in an <code>init</code> script.</li> <li>SQLITE_READONLY (8): Nginx can open the database, but can't write to it. This is likely due to file permissions.</li> <li>SQLITE_CANTOPEN (14): Nginx can't open or create the database. This is likely due to directory permissions. The user or group that owns worker processes (defined by the <code>user</code> directive) must have write permission on the directory.</li> <li>SQLITE_READONLY_DBMOVED (1032): The file was moved, renamed, or deleted at runtime. When this happens, Nginx attempts to recreate the file; if successful, the error is ignored and logging continues normally.</li> </ul>"},{"location":"modules/log-sqlite/#usage","title":"Usage","text":""},{"location":"modules/log-sqlite/#locations","title":"Locations","text":"<p>The <code>sqlitelog</code> directive can't be used in location contexts, but a regex condition can achieve a similar effect. In this example, only requests that start with \"/mylocation\" are logged.</p> <pre><code>map $request_uri $is_my_loc {\n    default            0;\n    ~^/mylocation.*$   1;\n}\n\nsqlitelog access.db if=$is_my_loc;\n</code></pre>"},{"location":"modules/log-sqlite/#inheritance","title":"Inheritance","text":"<p>Only one <code>sqlitelog</code> is allowed per context, with lower contexts taking priority. In this example, requests to server A are logged to global.db, while requests to server B are logged to b.db.</p> <pre><code>http {\n    sqlitelog global.db;\n    ...\n\n    server {\n        server_name a;\n        ...\n    }\n\n    server {\n        server_name b;\n        sqlitelog b.db;\n        ....\n    }\n````\n\n### WAL mode\n\n[WAL mode](https://www.sqlite.org/wal.html) is enabled by `PRAGMA journal_mode=wal` in an `init` script. [WAL checkpointing](https://www.sqlite.org/wal.html#ckpt) occurs when Nginx reloads or exits.\n\n### Logrotate\n\n[Logrotate](https://man.archlinux.org/man/logrotate.8) should be configured to stop Nginx, rotate logs, and start Nginx again. This way, Nginx gracefully closes its connections to the previous day's database(s) and opens new ones to the current day's database(s).\n\nBelow is an example script for Debian (`/etc/logrotate.d/nginx`). It assumes the worker process user, `www-data`, has been granted write permission on `/var/log/nginx`, which is normally only writeable by `root`.\n\n```sh\n/var/log/nginx/*.log\n/var/log/nginx/*.db\n{\n    daily\n    missingok\n    rotate 52\n    compress\n    delaycompress\n    notifempty\n    create 640 www-data adm\n    sharedscripts\n\n    # Force Logrotate to work in this directory even though\n    # its permissions have been modified to allow a non-root\n    # user to write in it\n    su root adm\n\n    # Send a quit signal to Nginx and wait for its PID file\n    # to be destroyed\n    firstaction\n        systemctl stop nginx.service\n        while [ -f /var/run/nginx.pid ]; do  \n            sleep 0.1s\n        done\n    endscript\n\n    # Start Nginx again\n    lastaction\n        systemctl restart nginx.service\n    endscript\n}\n</code></pre>"},{"location":"modules/log-sqlite/#column-types","title":"Column types","text":"<p>The following variables have preset column types, but can be overridden if needed.</p> Variable Type $binary_remote_addr <code>BLOB</code> $body_bytes_sent <code>INTEGER</code> $bytes_sent <code>INTEGER</code> $connection <code>INTEGER</code> $connection_requests <code>INTEGER</code> $connection_time <code>REAL</code> $connections_active <code>INTEGER</code> $connections_reading <code>INTEGER</code> $connections_waiting <code>INTEGER</code> $connections_writing <code>INTEGER</code> $content_length <code>INTEGER</code> $gzip_ratio <code>REAL</code> $limit_rate <code>INTEGER</code> $msec <code>REAL</code> $pid <code>INTEGER</code> $proxy_port <code>INTEGER</code> $proxy_protocol_port <code>INTEGER</code> $proxy_protocol_server_port <code>INTEGER</code> $remote_port <code>INTEGER</code> $request_time <code>REAL</code> $server_port <code>INTEGER</code> $status <code>INTEGER</code>"},{"location":"modules/log-sqlite/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-log-sqlite.</p>"},{"location":"modules/log-zmq/","title":"[BETA!] log-zmq: ZeroMQ logger module for NGINX","text":""},{"location":"modules/log-zmq/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-log-zmq\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-log-zmq\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_log_zmq_module.so;\n</code></pre> <p>This document describes nginx-module-log-zmq v0  released on Nov 28 2021.</p> <p>Production stability is not guaranteed.</p> <p>ZeroMQ logger module for nginx.</p> <p>ZeroMQ, \\zero-em-queue\\, is a protocol for messages exchange. It's a easy way to communicate using any language or platform via inproc, IPC, TCP, TPIC or multicast. It's asynchronous and only requires a small library.</p>"},{"location":"modules/log-zmq/#status","title":"Status","text":"<p>This module is already production ready.</p>"},{"location":"modules/log-zmq/#description","title":"Description","text":"<p>This is a nginx logger module integrated with ZeroMQ library.</p> <p><code>nginx-log-zmq</code> provides a very efficient way to log data for one or more PUB/SUB subscribers, over one or more different endpoints. This can be useful for data gathering and processing.</p> <p>The message format can be the same as the tradicional log format which gives a interesting way to <code>tail</code> data via the network or exploring other text formats like JSON. As with the traditional log, it's possible to use nginx variables updated each request.</p> <p>All messages are sent asynchronously and do not block the normal behaviour of the nginx server. As expected, the connections are resilient to network failures.</p>"},{"location":"modules/log-zmq/#synopsis","title":"Synopsis","text":"<pre><code>    http {\n        # simple message to an IPC endpoint with 4 threads and 1000 queue elements\n\n        log_zmq_server main \"/tmp/main.ipc\" ipc 4 1000;\n        log_zmq_endpoint  main \"/topic/\";\n\n        log_zmq_format main '{\"remote_addr\":\"$remote_addr\"}'\n\n        # send messages to a subscriber listening at 127.0.0.1:5556\n\n        log_zmq_server secondary 127.0.0.1:5556 tcp 4 1000;\n\n        # set secondary endpoint\n        log_zmq_endpoint secondary \"/endpoint/\";\n\n        # set format using multiline\n        log_zmq_format secondary '{\"request_uri\":\"$request_uri\",'\n                                   '{\"status\":\"$status\"}';\n\n\n        server {\n\n            location /status {\n                # mute all messages from log_zmq for this location\n\n                log_zmq_off all;\n            }\n\n            location /endpoint {\n                # mute main messages from log_zmq for this location\n\n                log_zmq_off main;\n            }\n        }\n    }\n</code></pre>"},{"location":"modules/log-zmq/#directives","title":"Directives","text":""},{"location":"modules/log-zmq/#log_zmq_server","title":"log_zmq_server","text":"<p>syntax: log_zmq_server &lt;definition_name&gt; &lt;address&gt; &lt;ipc|tcp&gt; &lt;threads&gt; &lt;queue size&gt;</p> <p>default: no</p> <p>context: http</p> <p>Configures a server (PUB/SUB subscriber) to connect to.</p> <p>The following options are required:</p> <p>definition_name &lt;name&gt; - the name that nginx will use to identify this logger instance.</p> <p>address &lt;path&gt;|&lt;ipaddress&gt;:&lt;port&gt; - the subscriber's address. If you are using the IPC protocol, you should specify the <code>&lt;path&gt;</code> for the unix socket. If you are using the TCP protocol, you should specify the <code>&lt;ipaddress&gt;</code> and <code>&lt;port&gt;</code> where your ZeroMQ subscriber is listening.</p> <p>protocol &lt;ipc|tcp&gt; - the protocol to be used for communication.</p> <p>threads &lt;integer&gt; - the number of I/O threads to be used.</p> <p>queue_size &lt;integer&gt; - the maximum queue size for messages waiting to be sent.</p>"},{"location":"modules/log-zmq/#log_zmq_endpoint","title":"log_zmq_endpoint","text":"<p>syntax: log_zmq_endpoint &lt;definition_name&gt; \"&lt;topic&gt;\"</p> <p>default: no</p> <p>context: http</p> <p>Configures the topic for the ZeroMQ messages.</p> <p>definition_name &lt;name&gt; - the name that nginx will use to identify this logger instance.</p> <p>topic &lt;topic&gt; - the topic for the messages. This is a string (which can be a nginx variable) prepended to every sent message. For example, if you send the message \"hello\" to the \"/talk:\" topic, the message will end up as \"/talk:hello\".</p> <p>Example:</p> <pre><code>http {\n    log_zmq_server main \"/tmp/example.ipc\" 4 1000;\n\n    # send a message for for an topic based on response status\n    log_zmq_endpoint main \"/remote/$status\";\n}\n</code></pre>"},{"location":"modules/log-zmq/#log_zmq_format","title":"log_zmq_format","text":"<p>syntax: log_zmq_format &lt;definition_name&gt; \"&lt;format&gt;\"</p> <p>default: no</p> <p>context: http</p> <p>Configures the ZeroMQ message format.</p> <p>definition_name &lt;name&gt; - the name that nginx will use to identify this logger instance.</p> <p>format &lt;format&gt; - the format for the messages. This defines the actual messages sent to the PUB/SUB subscriber. It follows the sames rules as the standard <code>log_format</code> directive. It is possible to use nginx variables here, and also to break it over multiple lines.</p> <pre><code>http {\n    log_zmq_format main '{\"line1\": value,'\n                          '{\"line2\": value}';\n}\n</code></pre>"},{"location":"modules/log-zmq/#log_zmq_off","title":"log_zmq_off","text":"<p>syntax: log_zmq_off &lt;definition_name&gt;|all</p> <p>default: no</p> <p>context: location</p> <p>Turn off ZeroMQ logging in the current context.</p> <p>definition_name &lt;name&gt; the name of the logger instance to be muted. If the special <code>all</code> name is used, all logger instances are muted.</p>"},{"location":"modules/log-zmq/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-log-zmq.</p>"},{"location":"modules/lua/","title":"lua: Lua scripting support for NGINX","text":""},{"location":"modules/lua/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-lua\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-lua\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_lua_module.so;\n</code></pre> <p>This document describes nginx-module-lua v0.10.29  released on Oct 24 2025.</p> <p>ngx_http_lua_module - Embed the power of Lua into Nginx HTTP Servers.</p> <p>This module is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty :)</p> <p>the installation instructions.</p>"},{"location":"modules/lua/#status","title":"Status","text":"<p>Production ready.</p>"},{"location":"modules/lua/#videos","title":"Videos","text":"<ul> <li> <p>YouTube video \"Hello World HTTP Example with OpenResty/Lua\"</p> <p></p> </li> <li> <p>YouTube video \"Write Your Own Lua Modules in OpenResty/Nginx Applications\"</p> <p></p> </li> <li> <p>YouTube video \"OpenResty's resty Command-Line Utility Demo\"</p> <p></p> </li> <li> <p>YouTube video \"Measure Execution Time of Lua Code Correctly in OpenResty\"</p> <p></p> </li> <li> <p>YouTube video \"Precompile Lua Modules into LuaJIT Bytecode to Speedup OpenResty Startup\"</p> <p></p> </li> </ul> <p>You are welcome to subscribe to our official YouTube channel, OpenResty.</p>"},{"location":"modules/lua/#synopsis","title":"Synopsis","text":"<pre><code> # set search paths for pure Lua external libraries (';;' is the default path):\n\n # set search paths for Lua external libraries written in C (can also use ';;'):\n\n server {\n     location /lua_content {\n         # MIME type determined by default_type:\n         default_type 'text/plain';\n\n         content_by_lua_block {\n             ngx.say('Hello,world!')\n         }\n     }\n\n     location /nginx_var {\n         # MIME type determined by default_type:\n         default_type 'text/plain';\n\n         # try access /nginx_var?a=hello,world\n         content_by_lua_block {\n             ngx.say(ngx.var.arg_a)\n         }\n     }\n\n     location = /request_body {\n         client_max_body_size 50k;\n         client_body_buffer_size 50k;\n\n         content_by_lua_block {\n             ngx.req.read_body()  -- explicitly read the req body\n             local data = ngx.req.get_body_data()\n             if data then\n                 ngx.say(\"body data:\")\n                 ngx.print(data)\n                 return\n             end\n\n             -- body may get buffered in a temp file:\n             local file = ngx.req.get_body_file()\n             if file then\n                 ngx.say(\"body is in file \", file)\n             else\n                 ngx.say(\"no body found\")\n             end\n         }\n     }\n\n     # transparent non-blocking I/O in Lua via subrequests\n     # (well, a better way is to use cosockets)\n     location = /lua {\n         # MIME type determined by default_type:\n         default_type 'text/plain';\n\n         content_by_lua_block {\n             local res = ngx.location.capture(\"/some_other_location\")\n             if res then\n                 ngx.say(\"status: \", res.status)\n                 ngx.say(\"body:\")\n                 ngx.print(res.body)\n             end\n         }\n     }\n\n     location = /foo {\n         rewrite_by_lua_block {\n             res = ngx.location.capture(\"/memc\",\n                 { args = { cmd = \"incr\", key = ngx.var.uri } }\n             )\n         }\n\n         proxy_pass http://blah.blah.com;\n     }\n\n     location = /mixed {\n         rewrite_by_lua_file /path/to/rewrite.lua;\n         access_by_lua_file /path/to/access.lua;\n         content_by_lua_file /path/to/content.lua;\n     }\n\n     # use nginx var in code path\n     # CAUTION: contents in nginx var must be carefully filtered,\n     # otherwise there'll be great security risk!\n     location ~ ^/app/([-_a-zA-Z0-9/]+) {\n         set $path $1;\n         content_by_lua_file /path/to/lua/app/root/$path.lua;\n     }\n\n     location / {\n        client_max_body_size 100k;\n        client_body_buffer_size 100k;\n\n        access_by_lua_block {\n            -- check the client IP address is in our black list\n            if ngx.var.remote_addr == \"132.5.72.3\" then\n                ngx.exit(ngx.HTTP_FORBIDDEN)\n            end\n\n            -- check if the URI contains bad words\n            if ngx.var.uri and\n                   string.match(ngx.var.request_body, \"evil\")\n            then\n                return ngx.redirect(\"/terms_of_use.html\")\n            end\n\n            -- tests passed\n        }\n\n        # proxy_pass/fastcgi_pass/etc settings\n     }\n }\n</code></pre>"},{"location":"modules/lua/#description","title":"Description","text":"<p>This module embeds LuaJIT 2.0/2.1 into Nginx. It is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty.</p> <p>Since version <code>v0.10.16</code> of this module, the standard Lua interpreter (also known as \"PUC-Rio Lua\") is not supported anymore. This document interchangeably uses the terms \"Lua\" and \"LuaJIT\" to refer to the LuaJIT interpreter.</p> <p>By leveraging Nginx's subrequests, this module allows the integration of the powerful Lua threads (known as Lua \"coroutines\") into the Nginx event model.</p> <p>Unlike Apache's mod_lua and Lighttpd's mod_magnet, Lua code executed using this module can be 100% non-blocking on network traffic as long as the Nginx API for Lua provided by this module is used to handle requests to upstream services such as MySQL, PostgreSQL, Memcached, Redis, or upstream HTTP web services.</p> <p>At least the following Lua libraries and Nginx modules can be used with this module:</p> <ul> <li>lua-resty-memcached</li> <li>lua-resty-mysql</li> <li>lua-resty-redis</li> <li>lua-resty-dns</li> <li>lua-resty-upload</li> <li>lua-resty-websocket</li> <li>lua-resty-lock</li> <li>lua-resty-logger-socket</li> <li>lua-resty-lrucache</li> <li>lua-resty-string</li> <li>ngx_memc</li> <li>ngx_postgres</li> <li>ngx_redis2</li> <li>ngx_redis</li> <li>ngx_proxy</li> <li>ngx_fastcgi</li> </ul> <p>Almost any Nginx modules can be used with this ngx_lua module by means of ngx.location.capture or ngx.location.capture_multi but it is recommended to use those <code>lua-resty-*</code> libraries instead of creating subrequests to access the Nginx upstream modules because the former is usually much more flexible and memory-efficient.</p> <p>The Lua interpreter (also known as \"Lua State\" or \"LuaJIT VM instance\") is shared across all the requests in a single Nginx worker process to minimize memory use. Request contexts are segregated using lightweight Lua coroutines.</p> <p>Loaded Lua modules persist in the Nginx worker process level resulting in a small memory footprint in Lua even when under heavy loads.</p> <p>This module is plugged into Nginx's \"http\" subsystem so it can only speak downstream communication protocols in the HTTP family (HTTP 0.9/1.0/1.1/2.0, WebSockets, etc...).  If you want to do generic TCP communications with the downstream clients, then you should use the ngx_stream_lua module instead, which offers a compatible Lua API.</p>"},{"location":"modules/lua/#typical-uses","title":"Typical Uses","text":"<p>Just to name a few:</p> <ul> <li>Mashup'ing and processing outputs of various Nginx upstream outputs (proxy, drizzle, postgres, redis, memcached, etc.) in Lua,</li> <li>doing arbitrarily complex access control and security checks in Lua before requests actually reach the upstream backends,</li> <li>manipulating response headers in an arbitrary way (by Lua)</li> <li>fetching backend information from external storage backends (like redis, memcached, mysql, postgresql) and use that information to choose which upstream backend to access on-the-fly,</li> <li>coding up arbitrarily complex web applications in a content handler using synchronous but still non-blocking access to the database backends and other storage,</li> <li>doing very complex URL dispatch in Lua at rewrite phase,</li> <li>using Lua to implement advanced caching mechanism for Nginx's subrequests and arbitrary locations.</li> </ul> <p>The possibilities are unlimited as the module allows bringing together various elements within Nginx as well as exposing the power of the Lua language to the user. The module provides the full flexibility of scripting while offering performance levels comparable with native C language programs both in terms of CPU time as well as memory footprint thanks to LuaJIT 2.x.</p> <p>Other scripting language implementations typically struggle to match this performance level.</p>"},{"location":"modules/lua/#nginx-compatibility","title":"Nginx Compatibility","text":"<p>The latest version of this module is compatible with the following versions of Nginx:</p> <ul> <li>1.29.x  (last tested: 1.29.2)</li> <li>1.27.x  (last tested: 1.27.1)</li> <li>1.25.x  (last tested: 1.25.1)</li> <li>1.21.x  (last tested: 1.21.4)</li> <li>1.19.x  (last tested: 1.19.3)</li> <li>1.17.x  (last tested: 1.17.8)</li> <li>1.15.x  (last tested: 1.15.8)</li> <li>1.14.x</li> <li>1.13.x  (last tested: 1.13.6)</li> <li>1.12.x</li> <li>1.11.x  (last tested: 1.11.2)</li> <li>1.10.x</li> <li>1.9.x (last tested: 1.9.15)</li> <li>1.8.x</li> <li>1.7.x (last tested: 1.7.10)</li> <li>1.6.x</li> </ul> <p>Nginx cores older than 1.6.0 (exclusive) are not supported.</p>"},{"location":"modules/lua/#code-repository","title":"Code Repository","text":"<p>The code repository of this project is hosted on GitHub at openresty/lua-nginx-module.</p>"},{"location":"modules/lua/#luajit-bytecode-support","title":"LuaJIT bytecode support","text":"<p>Watch YouTube video \"Measure Execution Time of Lua Code Correctly in OpenResty\"</p> <p></p> <p>As from the <code>v0.5.0rc32</code> release, all <code>*_by_lua_file</code> configure directives (such as content_by_lua_file) support loading LuaJIT 2.0/2.1 raw bytecode files directly:</p> <pre><code> /path/to/luajit/bin/luajit -b /path/to/input_file.lua /path/to/output_file.ljbc\n</code></pre> <p>The <code>-bg</code> option can be used to include debug information in the LuaJIT bytecode file:</p> <pre><code> /path/to/luajit/bin/luajit -bg /path/to/input_file.lua /path/to/output_file.ljbc\n</code></pre> <p>Please refer to the official LuaJIT documentation on the <code>-b</code> option for more details:</p> <p>https://luajit.org/running.html#opt_b</p> <p>Note that the bytecode files generated by LuaJIT 2.1 is not compatible with LuaJIT 2.0, and vice versa. The support for LuaJIT 2.1 bytecode was first added in ngx_lua v0.9.3.</p> <p>Attempts to load standard Lua 5.1 bytecode files into ngx_lua instances linked to LuaJIT 2.0/2.1 (or vice versa) will result in an Nginx error message such as the one below:</p> <pre><code>[error] 13909#0: *1 failed to load Lua inlined code: bad byte-code header in /path/to/test_file.luac\n</code></pre> <p>Loading bytecode files via the Lua primitives like <code>require</code> and <code>dofile</code> should always work as expected.</p>"},{"location":"modules/lua/#system-environment-variable-support","title":"System Environment Variable Support","text":"<p>If you want to access the system environment variable, say, <code>foo</code>, in Lua via the standard Lua API os.getenv, then you should also list this environment variable name in your <code>nginx.conf</code> file via the env directive. For example,</p> <pre><code> env foo;\n</code></pre>"},{"location":"modules/lua/#http-10-support","title":"HTTP 1.0 support","text":"<p>The HTTP 1.0 protocol does not support chunked output and requires an explicit <code>Content-Length</code> header when the response body is not empty in order to support the HTTP 1.0 keep-alive. So when a HTTP 1.0 request is made and the lua_http10_buffering directive is turned <code>on</code>, ngx_lua will buffer the output of ngx.say and ngx.print calls and also postpone sending response headers until all the response body output is received. At that time ngx_lua can calculate the total length of the body and construct a proper <code>Content-Length</code> header to return to the HTTP 1.0 client. If the <code>Content-Length</code> response header is set in the running Lua code, however, this buffering will be disabled even if the lua_http10_buffering directive is turned <code>on</code>.</p> <p>For large streaming output responses, it is important to disable the lua_http10_buffering directive to minimise memory usage.</p> <p>Note that common HTTP benchmark tools such as <code>ab</code> and <code>http_load</code> issue HTTP 1.0 requests by default. To force <code>curl</code> to send HTTP 1.0 requests, use the <code>-0</code> option.</p>"},{"location":"modules/lua/#statically-linking-pure-lua-modules","title":"Statically Linking Pure Lua Modules","text":"<p>With LuaJIT 2.x, it is possible to statically link the bytecode of pure Lua modules into the Nginx executable.</p> <p>You can use the <code>luajit</code> executable to compile <code>.lua</code> Lua module files to <code>.o</code> object files containing the exported bytecode data, and then link the <code>.o</code> files directly in your Nginx build.</p> <p>Below is a trivial example to demonstrate this. Consider that we have the following <code>.lua</code> file named <code>foo.lua</code>:</p> <pre><code> -- foo.lua\n local _M = {}\n\n function _M.go()\n     print(\"Hello from foo\")\n end\n\n return _M\n</code></pre> <p>And then we compile this <code>.lua</code> file to <code>foo.o</code> file:</p> <pre><code> /path/to/luajit/bin/luajit -bg foo.lua foo.o\n</code></pre> <p>What matters here is the name of the <code>.lua</code> file, which determines how you use this module later on the Lua land. The file name <code>foo.o</code> does not matter at all except the <code>.o</code> file extension (which tells <code>luajit</code> what output format is used). If you want to strip the Lua debug information from the resulting bytecode, you can just specify the <code>-b</code> option above instead of <code>-bg</code>.</p> <p>Then when building Nginx or OpenResty, pass the <code>--with-ld-opt=\"foo.o\"</code> option to the <code>./configure</code> script:</p> <pre><code> ./configure --with-ld-opt=\"/path/to/foo.o\" ...\n</code></pre> <p>Finally, you can just do the following in any Lua code run by ngx_lua:</p> <pre><code> local foo = require \"foo\"\n foo.go()\n</code></pre> <p>And this piece of code no longer depends on the external <code>foo.lua</code> file any more because it has already been compiled into the <code>nginx</code> executable.</p> <p>If you want to use dot in the Lua module name when calling <code>require</code>, as in</p> <pre><code> local foo = require \"resty.foo\"\n</code></pre> <p>then you need to rename the <code>foo.lua</code> file to <code>resty_foo.lua</code> before compiling it down to a <code>.o</code> file with the <code>luajit</code> command-line utility.</p> <p>It is important to use exactly the same version of LuaJIT when compiling <code>.lua</code> files to <code>.o</code> files as building nginx + ngx_lua. This is because the LuaJIT bytecode format may be incompatible between different LuaJIT versions. When the bytecode format is incompatible, you will see a Lua runtime error saying that the Lua module is not found.</p> <p>When you have multiple <code>.lua</code> files to compile and link, then just specify their <code>.o</code> files at the same time in the value of the <code>--with-ld-opt</code> option. For instance,</p> <pre><code> ./configure --with-ld-opt=\"/path/to/foo.o /path/to/bar.o\" ...\n</code></pre> <p>If you have too many <code>.o</code> files, then it might not be feasible to name them all in a single command. In this case, you can build a static library (or archive) for your <code>.o</code> files, as in</p> <pre><code> ar rcus libmyluafiles.a *.o\n</code></pre> <p>then you can link the <code>myluafiles</code> archive as a whole to your nginx executable:</p> <pre><code> ./configure \\\n     --with-ld-opt=\"-L/path/to/lib -Wl,--whole-archive -lmyluafiles -Wl,--no-whole-archive\"\n</code></pre> <p>where <code>/path/to/lib</code> is the path of the directory containing the <code>libmyluafiles.a</code> file. It should be noted that the linker option <code>--whole-archive</code> is required here because otherwise our archive will be skipped because no symbols in our archive are mentioned in the main parts of the nginx executable.</p>"},{"location":"modules/lua/#data-sharing-within-an-nginx-worker","title":"Data Sharing within an Nginx Worker","text":"<p>To globally share data among all the requests handled by the same Nginx worker process, encapsulate the shared data into a Lua module, use the Lua <code>require</code> builtin to import the module, and then manipulate the shared data in Lua. This works because required Lua modules are loaded only once and all coroutines will share the same copy of the module (both its code and data).</p> <p>Note that the use of global Lua variables is strongly discouraged, as it may lead to unexpected race conditions between concurrent requests.</p> <p>Here is a small example on sharing data within an Nginx worker via a Lua module:</p> <pre><code> -- mydata.lua\n local _M = {}\n\n local data = {\n     dog = 3,\n     cat = 4,\n     pig = 5,\n }\n\n function _M.get_age(name)\n     return data[name]\n end\n\n return _M\n</code></pre> <p>and then accessing it from <code>nginx.conf</code>:</p> <pre><code> location /lua {\n     content_by_lua_block {\n         local mydata = require \"mydata\"\n         ngx.say(mydata.get_age(\"dog\"))\n     }\n }\n</code></pre> <p>The <code>mydata</code> module in this example will only be loaded and run on the first request to the location <code>/lua</code>, and all subsequent requests to the same Nginx worker process will use the reloaded instance of the module as well as the same copy of the data in it, until a <code>HUP</code> signal is sent to the Nginx master process to force a reload. This data sharing technique is essential for high performance Lua applications based on this module.</p> <p>Note that this data sharing is on a per-worker basis and not on a per-server basis. That is, when there are multiple Nginx worker processes under an Nginx master, data sharing cannot cross the process boundary between these workers.</p> <p>It is usually recommended to share read-only data this way. You can also share changeable data among all the concurrent requests of each Nginx worker process as long as there is no nonblocking I/O operations (including ngx.sleep) in the middle of your calculations. As long as you do not give the control back to the Nginx event loop and ngx_lua's light thread scheduler (even implicitly), there can never be any race conditions in between. For this reason, always be very careful when you want to share changeable data on the worker level. Buggy optimizations can easily lead to hard-to-debug race conditions under load.</p> <p>If server-wide data sharing is required, then use one or more of the following approaches:</p> <ol> <li>Use the ngx.shared.DICT API provided by this module.</li> <li>Use only a single Nginx worker and a single server (this is however not recommended when there is a multi core CPU or multiple CPUs in a single machine).</li> <li>Use data storage mechanisms such as <code>memcached</code>, <code>redis</code>, <code>MySQL</code> or <code>PostgreSQL</code>. The OpenResty official releases come with a set of companion Nginx modules and Lua libraries that provide interfaces with these data storage mechanisms.</li> </ol>"},{"location":"modules/lua/#known-issues","title":"Known Issues","text":""},{"location":"modules/lua/#tcp-socket-connect-operation-issues","title":"TCP socket connect operation issues","text":"<p>The tcpsock:connect method may indicate <code>success</code> despite connection failures such as with <code>Connection Refused</code> errors.</p> <p>However, later attempts to manipulate the cosocket object will fail and return the actual error status message generated by the failed connect operation.</p> <p>This issue is due to limitations in the Nginx event model and only appears to affect Mac OS X.</p>"},{"location":"modules/lua/#lua-coroutine-yieldingresuming","title":"Lua Coroutine Yielding/Resuming","text":"<ul> <li>Because Lua's <code>dofile</code> and <code>require</code> builtins are currently implemented as C functions in LuaJIT 2.0/2.1, if the Lua file being loaded by <code>dofile</code> or <code>require</code> invokes ngx.location.capture*, ngx.exec, ngx.exit, or other API functions requiring yielding in the top-level scope of the Lua file, then the Lua error \"attempt to yield across C-call boundary\" will be raised. To avoid this, put these calls requiring yielding into your own Lua functions in the Lua file instead of the top-level scope of the file.</li> </ul>"},{"location":"modules/lua/#lua-variable-scope","title":"Lua Variable Scope","text":"<p>Care must be taken when importing modules, and this form should be used:</p> <pre><code> local xxx = require('xxx')\n</code></pre> <p>instead of the old deprecated form:</p> <pre><code> require('xxx')\n</code></pre> <p>Here is the reason: by design, the global environment has exactly the same lifetime as the Nginx request handler associated with it. Each request handler has its own set of Lua global variables and that is the idea of request isolation. The Lua module is actually loaded by the first Nginx request handler and is cached by the <code>require()</code> built-in in the <code>package.loaded</code> table for later reference, and the <code>module()</code> builtin used by some Lua modules has the side effect of setting a global variable to the loaded module table. But this global variable will be cleared at the end of the request handler,  and every subsequent request handler all has its own (clean) global environment. So one will get Lua exception for accessing the <code>nil</code> value.</p> <p>The use of Lua global variables is a generally inadvisable in the ngx_lua context as:</p> <ol> <li>the misuse of Lua globals has detrimental side effects on concurrent requests when such variables should instead be local in scope,</li> <li>Lua global variables require Lua table look-ups in the global environment which is computationally expensive, and</li> <li>some Lua global variable references may include typing errors which make such difficult to debug.</li> </ol> <p>It is therefore highly recommended to always declare such within an appropriate local scope instead.</p> <pre><code> -- Avoid\n foo = 123\n -- Recommended\n local foo = 123\n\n -- Avoid\n function foo() return 123 end\n -- Recommended\n local function foo() return 123 end\n</code></pre> <p>To find all instances of Lua global variables in your Lua code, run the lua-releng tool across all <code>.lua</code> source files:</p> <pre><code>$ lua-releng\nChecking use of Lua global variables in file lib/foo/bar.lua ...\n        1       [1489]  SETGLOBAL       7 -1    ; contains\n        55      [1506]  GETGLOBAL       7 -3    ; setvar\n        3       [1545]  GETGLOBAL       3 -4    ; varexpand\n</code></pre> <p>The output says that the line 1489 of file <code>lib/foo/bar.lua</code> writes to a global variable named <code>contains</code>, the line 1506 reads from the global variable <code>setvar</code>, and line 1545 reads the global <code>varexpand</code>.</p> <p>This tool will guarantee that local variables in the Lua module functions are all declared with the <code>local</code> keyword, otherwise a runtime exception will be thrown. It prevents undesirable race conditions while accessing such variables. See Data Sharing within an Nginx Worker for the reasons behind this.</p>"},{"location":"modules/lua/#locations-configured-by-subrequest-directives-of-other-modules","title":"Locations Configured by Subrequest Directives of Other Modules","text":"<p>The ngx.location.capture and ngx.location.capture_multi directives cannot capture locations that include the add_before_body, add_after_body, auth_request, echo_location, echo_location_async, echo_subrequest, or echo_subrequest_async directives.</p> <pre><code> location /foo {\n     content_by_lua_block {\n         res = ngx.location.capture(\"/bar\")\n     }\n }\n location /bar {\n     echo_location /blah;\n }\n location /blah {\n     echo \"Success!\";\n }\n</code></pre> <pre><code> $ curl -i http://example.com/foo\n</code></pre> <p>will not work as expected.</p>"},{"location":"modules/lua/#cosockets-not-available-everywhere","title":"Cosockets Not Available Everywhere","text":"<p>Due to internal limitations in the Nginx core, the cosocket API is disabled in the following contexts: set_by_lua*, log_by_lua*, header_filter_by_lua*, and body_filter_by_lua.</p> <p>The cosockets are currently also disabled in the init_by_lua* and init_worker_by_lua* directive contexts but we may add support for these contexts in the future because there is no limitation in the Nginx core (or the limitation might be worked around).</p> <p>There exists a workaround, however, when the original context does not need to wait for the cosocket results. That is, creating a zero-delay timer via the ngx.timer.at API and do the cosocket results in the timer handler, which runs asynchronously as to the original context creating the timer.</p>"},{"location":"modules/lua/#special-escaping-sequences","title":"Special Escaping Sequences","text":"<p>NOTE Following the <code>v0.9.17</code> release, this pitfall can be avoided by using the <code>*_by_lua_block {}</code> configuration directives.</p> <p>PCRE sequences such as <code>\\d</code>, <code>\\s</code>, or <code>\\w</code>, require special attention because in string literals, the backslash character, <code>\\</code>, is stripped out by both the Lua language parser and by the Nginx config file parser before processing if not within a <code>*_by_lua_block {}</code> directive. So the following snippet will not work as expected:</p> <pre><code> # nginx.conf\n ? location /test {\n ?     content_by_lua '\n ?         local regex = \"\\d+\"  -- THIS IS WRONG OUTSIDE OF A *_by_lua_block DIRECTIVE\n ?         local m = ngx.re.match(\"hello, 1234\", regex)\n ?         if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n ?     ';\n ? }\n # evaluates to \"not matched!\"\n</code></pre> <p>To avoid this, double escape the backslash:</p> <pre><code> # nginx.conf\n location /test {\n     content_by_lua '\n         local regex = \"\\\\\\\\d+\"\n         local m = ngx.re.match(\"hello, 1234\", regex)\n         if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n     ';\n }\n # evaluates to \"1234\"\n</code></pre> <p>Here, <code>\\\\\\\\d+</code> is stripped down to <code>\\\\d+</code> by the Nginx config file parser and this is further stripped down to <code>\\d+</code> by the Lua language parser before running.</p> <p>Alternatively, the regex pattern can be presented as a long-bracketed Lua string literal by encasing it in \"long brackets\", <code>[[...]]</code>, in which case backslashes have to only be escaped once for the Nginx config file parser.</p> <pre><code> # nginx.conf\n location /test {\n     content_by_lua '\n         local regex = [[\\\\d+]]\n         local m = ngx.re.match(\"hello, 1234\", regex)\n         if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n     ';\n }\n # evaluates to \"1234\"\n</code></pre> <p>Here, <code>[[\\\\d+]]</code> is stripped down to <code>[[\\d+]]</code> by the Nginx config file parser and this is processed correctly.</p> <p>Note that a longer from of the long bracket, <code>[=[...]=]</code>, may be required if the regex pattern contains <code>[...]</code> sequences. The <code>[=[...]=]</code> form may be used as the default form if desired.</p> <pre><code> # nginx.conf\n location /test {\n     content_by_lua '\n         local regex = [=[[0-9]+]=]\n         local m = ngx.re.match(\"hello, 1234\", regex)\n         if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n     ';\n }\n # evaluates to \"1234\"\n</code></pre> <p>An alternative approach to escaping PCRE sequences is to ensure that Lua code is placed in external script files and executed using the various <code>*_by_lua_file</code> directives. With this approach, the backslashes are only stripped by the Lua language parser and therefore only need to be escaped once each.</p> <pre><code> -- test.lua\n local regex = \"\\\\d+\"\n local m = ngx.re.match(\"hello, 1234\", regex)\n if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n -- evaluates to \"1234\"\n</code></pre> <p>Within external script files, PCRE sequences presented as long-bracketed Lua string literals do not require modification.</p> <pre><code> -- test.lua\n local regex = [[\\d+]]\n local m = ngx.re.match(\"hello, 1234\", regex)\n if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n -- evaluates to \"1234\"\n</code></pre> <p>As noted earlier, PCRE sequences presented within <code>*_by_lua_block {}</code> directives (available following the <code>v0.9.17</code> release) do not require modification.</p> <pre><code> # nginx.conf\n location /test {\n     content_by_lua_block {\n         local regex = [[\\d+]]\n         local m = ngx.re.match(\"hello, 1234\", regex)\n         if m then ngx.say(m[0]) else ngx.say(\"not matched!\") end\n     }\n }\n # evaluates to \"1234\"\n</code></pre> <p>NOTE You are recommended to use <code>by_lua_file</code> when the Lua code is very long.</p>"},{"location":"modules/lua/#mixing-with-ssi-not-supported","title":"Mixing with SSI Not Supported","text":"<p>Mixing SSI with ngx_lua in the same Nginx request is not supported at all. Just use ngx_lua exclusively. Everything you can do with SSI can be done atop ngx_lua anyway and it can be more efficient when using ngx_lua.</p>"},{"location":"modules/lua/#spdy-mode-not-fully-supported","title":"SPDY Mode Not Fully Supported","text":"<p>Certain Lua APIs provided by ngx_lua do not work in Nginx's SPDY mode yet: ngx.location.capture, ngx.location.capture_multi, and ngx.req.socket.</p>"},{"location":"modules/lua/#missing-data-on-short-circuited-requests","title":"Missing data on short circuited requests","text":"<p>Nginx may terminate a request early with (at least):</p> <ul> <li>400 (Bad Request)</li> <li>405 (Not Allowed)</li> <li>408 (Request Timeout)</li> <li>413 (Request Entity Too Large)</li> <li>414 (Request URI Too Large)</li> <li>494 (Request Headers Too Large)</li> <li>499 (Client Closed Request)</li> <li>500 (Internal Server Error)</li> <li>501 (Not Implemented)</li> </ul> <p>This means that phases that normally run are skipped, such as the rewrite or access phase. This also means that later phases that are run regardless, e.g. log_by_lua, will not have access to information that is normally set in those phases.</p>"},{"location":"modules/lua/#changes","title":"Changes","text":"<p>The changes made in every release of this module are listed in the change logs of the OpenResty bundle:</p> <p>https://openresty.org/#Changes</p>"},{"location":"modules/lua/#test-suite","title":"Test Suite","text":"<p>The following dependencies are required to run the test suite:</p> <ul> <li> <p>Nginx version &gt;= 1.4.2</p> </li> <li> <p>Perl modules:</p> <ul> <li>Test::Nginx: https://github.com/openresty/test-nginx</li> </ul> </li> <li> <p>Nginx modules:</p> <ul> <li>ngx_devel_kit</li> <li>ngx_set_misc</li> <li>ngx_auth_request (this is not needed if you're using Nginx 1.5.4+.</li> <li>ngx_echo</li> <li>ngx_memc</li> <li>ngx_srcache</li> <li>ngx_lua (i.e., this module)</li> <li>ngx_lua_upstream</li> <li>ngx_headers_more</li> <li>ngx_drizzle</li> <li>ngx_rds_json</li> <li>ngx_coolkit</li> <li>ngx_redis2</li> </ul> </li> </ul> <p>The order in which these modules are added during configuration is important because the position of any filter module in the filtering chain determines the final output, for example. The correct adding order is shown above.</p> <ul> <li> <p>3rd-party Lua libraries:</p> <ul> <li>lua-cjson</li> </ul> </li> <li> <p>Applications:</p> <ul> <li>mysql: create database 'ngx_test', grant all privileges to user 'ngx_test', password is 'ngx_test'</li> <li>memcached: listening on the default port, 11211.</li> <li>redis: listening on the default port, 6379.</li> </ul> </li> </ul> <p>See also the developer build script for more details on setting up the testing environment.</p> <p>To run the whole test suite in the default testing mode:</p> <pre><code>cd /path/to/lua-nginx-module\nexport PATH=/path/to/your/nginx/sbin:$PATH\nprove -I/path/to/test-nginx/lib -r t\n</code></pre> <p>To run specific test files:</p> <pre><code>cd /path/to/lua-nginx-module\nexport PATH=/path/to/your/nginx/sbin:$PATH\nprove -I/path/to/test-nginx/lib t/002-content.t t/003-errors.t\n</code></pre> <p>To run a specific test block in a particular test file, add the line <code>--- ONLY</code> to the test block you want to run, and then use the <code>prove</code> utility to run that <code>.t</code> file.</p> <p>There are also various testing modes based on mockeagain, valgrind, and etc. Refer to the Test::Nginx documentation for more details for various advanced testing modes. See also the test reports for the Nginx test cluster running on Amazon EC2: https://qa.openresty.org.</p>"},{"location":"modules/lua/#see-also","title":"See Also","text":"<p>Blog posts:</p> <ul> <li>Introduction to Lua-Land CPU Flame Graphs</li> <li>How OpenResty and Nginx Allocate and Manage Memory</li> <li>How OpenResty and Nginx Shared Memory Zones Consume RAM</li> <li>Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones</li> </ul> <p>Other related modules and libraries:</p> <ul> <li>ngx_stream_lua_module for an official port of this module for the Nginx \"stream\" subsystem (doing generic downstream TCP communications).</li> <li>lua-resty-memcached library based on ngx_lua cosocket.</li> <li>lua-resty-redis library based on ngx_lua cosocket.</li> <li>lua-resty-mysql library based on ngx_lua cosocket.</li> <li>lua-resty-upload library based on ngx_lua cosocket.</li> <li>lua-resty-dns library based on ngx_lua cosocket.</li> <li>lua-resty-websocket library for both WebSocket server and client, based on ngx_lua cosocket.</li> <li>lua-resty-string library based on LuaJIT FFI.</li> <li>lua-resty-lock library for a nonblocking simple lock API.</li> <li>lua-resty-cookie library for HTTP cookie manipulation.</li> <li>Routing requests to different MySQL queries based on URI arguments</li> <li>Dynamic Routing Based on Redis and Lua</li> <li>Using LuaRocks with ngx_lua</li> <li>Introduction to ngx_lua</li> <li>ngx_devel_kit</li> <li>echo-nginx-module</li> <li>drizzle-nginx-module</li> <li>postgres-nginx-module</li> <li>memc-nginx-module</li> <li>The OpenResty bundle</li> <li>Nginx Systemtap Toolkit</li> </ul>"},{"location":"modules/lua/#directives","title":"Directives","text":"<ul> <li>lua_load_resty_core</li> <li>lua_capture_error_log</li> <li>lua_use_default_type</li> <li>lua_malloc_trim</li> <li>lua_code_cache</li> <li>lua_thread_cache_max_entries</li> <li>lua_regex_cache_max_entries</li> <li>lua_regex_match_limit</li> <li>lua_package_path</li> <li>lua_package_cpath</li> <li>init_by_lua</li> <li>init_by_lua_block</li> <li>init_by_lua_file</li> <li>init_worker_by_lua</li> <li>init_worker_by_lua_block</li> <li>init_worker_by_lua_file</li> <li>exit_worker_by_lua_block</li> <li>exit_worker_by_lua_file</li> <li>set_by_lua</li> <li>set_by_lua_block</li> <li>set_by_lua_file</li> <li>content_by_lua</li> <li>content_by_lua_block</li> <li>content_by_lua_file</li> <li>server_rewrite_by_lua_block</li> <li>server_rewrite_by_lua_file</li> <li>rewrite_by_lua</li> <li>rewrite_by_lua_block</li> <li>rewrite_by_lua_file</li> <li>access_by_lua</li> <li>access_by_lua_block</li> <li>access_by_lua_file</li> <li>header_filter_by_lua</li> <li>header_filter_by_lua_block</li> <li>header_filter_by_lua_file</li> <li>body_filter_by_lua</li> <li>body_filter_by_lua_block</li> <li>body_filter_by_lua_file</li> <li>log_by_lua</li> <li>log_by_lua_block</li> <li>log_by_lua_file</li> <li>balancer_by_lua_block</li> <li>balancer_by_lua_file</li> <li>balancer_keepalive</li> <li>lua_need_request_body</li> <li>ssl_client_hello_by_lua_block</li> <li>ssl_client_hello_by_lua_file</li> <li>ssl_certificate_by_lua_block</li> <li>ssl_certificate_by_lua_file</li> <li>ssl_session_fetch_by_lua_block</li> <li>ssl_session_fetch_by_lua_file</li> <li>ssl_session_store_by_lua_block</li> <li>ssl_session_store_by_lua_file</li> <li>proxy_ssl_verify_by_lua_block</li> <li>proxy_ssl_verify_by_lua_file</li> <li>lua_shared_dict</li> <li>lua_socket_connect_timeout</li> <li>lua_socket_send_timeout</li> <li>lua_socket_send_lowat</li> <li>lua_socket_read_timeout</li> <li>lua_socket_buffer_size</li> <li>lua_socket_pool_size</li> <li>lua_socket_keepalive_timeout</li> <li>lua_socket_log_errors</li> <li>lua_ssl_ciphers</li> <li>lua_ssl_crl</li> <li>lua_ssl_protocols</li> <li>lua_ssl_certificate</li> <li>lua_ssl_certificate_key</li> <li>lua_ssl_trusted_certificate</li> <li>lua_ssl_verify_depth</li> <li>lua_ssl_key_log</li> <li>lua_ssl_conf_command</li> <li>lua_upstream_skip_openssl_default_verify</li> <li>lua_http10_buffering</li> <li>rewrite_by_lua_no_postpone</li> <li>access_by_lua_no_postpone</li> <li>lua_transform_underscores_in_response_headers</li> <li>lua_check_client_abort</li> <li>lua_max_pending_timers</li> <li>lua_max_running_timers</li> <li>lua_sa_restart</li> <li>lua_worker_thread_vm_pool_size</li> </ul> <p>The basic building blocks of scripting Nginx with Lua are directives. Directives are used to specify when the user Lua code is run and how the result will be used. Below is a diagram showing the order in which directives are executed.</p> <p></p>"},{"location":"modules/lua/#lua_load_resty_core","title":"lua_load_resty_core","text":"<p>syntax: lua_load_resty_core on|off</p> <p>default: lua_load_resty_core on</p> <p>context: http</p> <p>This directive is deprecated since the <code>v0.10.16</code> release of this module. The <code>resty.core</code> module from lua-resty-core is now mandatorily loaded during the Lua VM initialization. Specifying this directive will have no effect.</p> <p>This directive was first introduced in the <code>v0.10.15</code> release and used to optionally load the <code>resty.core</code> module.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_capture_error_log","title":"lua_capture_error_log","text":"<p>syntax: lua_capture_error_log size</p> <p>default: none</p> <p>context: http</p> <p>Enables a buffer of the specified <code>size</code> for capturing all the Nginx error log message data (not just those produced by this module or the Nginx http subsystem, but everything) without touching files or disks.</p> <p>You can use units like <code>k</code> and <code>m</code> in the <code>size</code> value, as in</p> <pre><code> lua_capture_error_log 100k;\n</code></pre> <p>As a rule of thumb, a 4KB buffer can usually hold about 20 typical error log messages. So do the maths!</p> <p>This buffer never grows. If it is full, new error log messages will replace the oldest ones in the buffer.</p> <p>The size of the buffer must be bigger than the maximum length of a single error log message (which is 4K in OpenResty and 2K in stock NGINX).</p> <p>You can read the messages in the buffer on the Lua land via the get_logs() function of the ngx.errlog module of the lua-resty-core library. This Lua API function will return the captured error log messages and also remove these already read from the global capturing buffer, making room for any new error log data. For this reason, the user should not configure this buffer to be too big if the user read the buffered error log data fast enough.</p> <p>Note that the log level specified in the standard error_log directive does have effect on this capturing facility. It only captures log messages of a level no lower than the specified log level in the error_log directive. The user can still choose to set an even higher filtering log level on the fly via the Lua API function errlog.set_filter_level. So it is more flexible than the static error_log directive.</p> <p>It is worth noting that there is no way to capture the debugging logs without building OpenResty or Nginx with the <code>./configure</code> option <code>--with-debug</code>. And enabling debugging logs is strongly discouraged in production builds due to high overhead.</p> <p>This directive was first introduced in the <code>v0.10.9</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_use_default_type","title":"lua_use_default_type","text":"<p>syntax: lua_use_default_type on | off</p> <p>default: lua_use_default_type on</p> <p>context: http, server, location, location if</p> <p>Specifies whether to use the MIME type specified by the default_type directive for the default value of the <code>Content-Type</code> response header. Deactivate this directive if a default <code>Content-Type</code> response header for Lua request handlers is not desired.</p> <p>This directive is turned on by default.</p> <p>This directive was first introduced in the <code>v0.9.1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_malloc_trim","title":"lua_malloc_trim","text":"<p>syntax: lua_malloc_trim &lt;request-count&gt;</p> <p>default: lua_malloc_trim 1000</p> <p>context: http</p> <p>Asks the underlying <code>libc</code> runtime library to release its cached free memory back to the operating system every <code>N</code> requests processed by the Nginx core. By default, <code>N</code> is 1000. You can configure the request count by using your own numbers. Smaller numbers mean more frequent releases, which may introduce higher CPU time consumption and smaller memory footprint while larger numbers usually lead to less CPU time overhead and relatively larger memory footprint. Just tune the number for your own use cases.</p> <p>Configuring the argument to <code>0</code> essentially turns off the periodical memory trimming altogether.</p> <pre><code> lua_malloc_trim 0;  # turn off trimming completely\n</code></pre> <p>The current implementation uses an Nginx log phase handler to do the request counting. So the appearance of the log_subrequest on directives in <code>nginx.conf</code> may make the counting faster when subrequests are involved. By default, only \"main requests\" count.</p> <p>Note that this directive does not affect the memory allocated by LuaJIT's own allocator based on the <code>mmap</code> system call.</p> <p>This directive was first introduced in the <code>v0.10.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_code_cache","title":"lua_code_cache","text":"<p>syntax: lua_code_cache on | off</p> <p>default: lua_code_cache on</p> <p>context: http, server, location, location if</p> <p>Enables or disables the Lua code cache for Lua code in <code>*_by_lua_file</code> directives (like set_by_lua_file and content_by_lua_file) and Lua modules.</p> <p>When turning off, every request served by ngx_lua will run in a separate Lua VM instance, starting from the <code>0.9.3</code> release. So the Lua files referenced in set_by_lua_file, content_by_lua_file, access_by_lua_file, and etc will not be cached and all Lua modules used will be loaded from scratch. With this in place, developers can adopt an edit-and-refresh approach.</p> <p>Please note however, that Lua code written inlined within nginx.conf such as those specified by set_by_lua, content_by_lua, access_by_lua, and rewrite_by_lua will not be updated when you edit the inlined Lua code in your <code>nginx.conf</code> file because only the Nginx config file parser can correctly parse the <code>nginx.conf</code> file and the only way is to reload the config file by sending a <code>HUP</code> signal or just to restart Nginx.</p> <p>Even when the code cache is enabled, Lua files which are loaded by <code>dofile</code> or <code>loadfile</code> in *_by_lua_file cannot be cached (unless you cache the results yourself). Usually you can either use the init_by_lua or init_by_lua_file directives to load all such files or just make these Lua files true Lua modules and load them via <code>require</code>.</p> <p>The ngx_lua module does not support the <code>stat</code> mode available with the Apache <code>mod_lua</code> module (yet).</p> <p>Disabling the Lua code cache is strongly discouraged for production use and should only be used during development as it has a significant negative impact on overall performance. For example, the performance of a \"hello world\" Lua example can drop by an order of magnitude after disabling the Lua code cache.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_thread_cache_max_entries","title":"lua_thread_cache_max_entries","text":"<p>syntax: lua_thread_cache_max_entries &lt;num&gt;</p> <p>default: lua_thread_cache_max_entries 1024</p> <p>context: http</p> <p>Specifies the maximum number of entries allowed in the worker process level lua thread object cache.</p> <p>This cache recycles the lua thread GC objects among all our \"light threads\".</p> <p>A zero value of <code>&lt;num&gt;</code> disables the cache.</p> <p>Note that this feature requires OpenResty's LuaJIT with the new C API <code>lua_resetthread</code>.</p> <p>This feature was first introduced in verson <code>v0.10.9</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_regex_cache_max_entries","title":"lua_regex_cache_max_entries","text":"<p>syntax: lua_regex_cache_max_entries &lt;num&gt;</p> <p>default: lua_regex_cache_max_entries 1024</p> <p>context: http</p> <p>Specifies the maximum number of entries allowed in the worker process level compiled regex cache.</p> <p>The regular expressions used in ngx.re.match, ngx.re.gmatch, ngx.re.sub, and ngx.re.gsub will be cached within this cache if the regex option <code>o</code> (i.e., compile-once flag) is specified.</p> <p>The default number of entries allowed is 1024 and when this limit is reached, new regular expressions will not be cached (as if the <code>o</code> option was not specified) and there will be one, and only one, warning in the <code>error.log</code> file:</p> <pre><code>2011/08/27 23:18:26 [warn] 31997#0: *1 lua exceeding regex cache max entries (1024), ...\n</code></pre> <p>If you are using the <code>ngx.re.*</code> implementation of lua-resty-core by loading the <code>resty.core.regex</code> module (or just the <code>resty.core</code> module), then an LRU cache is used for the regex cache being used here.</p> <p>Do not activate the <code>o</code> option for regular expressions (and/or <code>replace</code> string arguments for ngx.re.sub and ngx.re.gsub) that are generated on the fly and give rise to infinite variations to avoid hitting the specified limit.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_regex_match_limit","title":"lua_regex_match_limit","text":"<p>syntax: lua_regex_match_limit &lt;num&gt;</p> <p>default: lua_regex_match_limit 0</p> <p>context: http</p> <p>Specifies the \"match limit\" used by the PCRE library when executing the ngx.re API. To quote the PCRE manpage, \"the limit ... has the effect of limiting the amount of backtracking that can take place.\"</p> <p>When the limit is hit, the error string \"pcre_exec() failed: -8\" will be returned by the ngx.re API functions on the Lua land.</p> <p>When setting the limit to 0, the default \"match limit\" when compiling the PCRE library is used. And this is the default value of this directive.</p> <p>This directive was first introduced in the <code>v0.8.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_package_path","title":"lua_package_path","text":"<p>syntax: lua_package_path &lt;lua-style-path-str&gt;</p> <p>default: The content of LUA_PATH environment variable or Lua's compiled-in defaults.</p> <p>context: http</p> <p>Sets the Lua module search path used by scripts specified by set_by_lua, content_by_lua and others. The path string is in standard Lua path form, and <code>;;</code> can be used to stand for the original search paths.</p> <p>As from the <code>v0.5.0rc29</code> release, the special notation <code>$prefix</code> or <code>${prefix}</code> can be used in the search path string to indicate the path of the <code>server prefix</code> usually determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_package_cpath","title":"lua_package_cpath","text":"<p>syntax: lua_package_cpath &lt;lua-style-cpath-str&gt;</p> <p>default: The content of LUA_CPATH environment variable or Lua's compiled-in defaults.</p> <p>context: http</p> <p>Sets the Lua C-module search path used by scripts specified by set_by_lua, content_by_lua and others. The cpath string is in standard Lua cpath form, and <code>;;</code> can be used to stand for the original cpath.</p> <p>As from the <code>v0.5.0rc29</code> release, the special notation <code>$prefix</code> or <code>${prefix}</code> can be used in the search path string to indicate the path of the <code>server prefix</code> usually determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#init_by_lua","title":"init_by_lua","text":"<p>syntax: init_by_lua &lt;lua-script-str&gt;</p> <p>context: http</p> <p>phase: loading-config</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the init_by_lua_block directive instead.</p> <p>Similar to the init_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> init_by_lua '\n     print(\"I need no extra escaping here, for example: \\r\\nblah\")\n '\n</code></pre> <p>This directive was first introduced in the <code>v0.5.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#init_by_lua_block","title":"init_by_lua_block","text":"<p>syntax: init_by_lua_block { lua-script }</p> <p>context: http</p> <p>phase: loading-config</p> <p>When Nginx receives the <code>HUP</code> signal and starts reloading the config file, the Lua VM will also be re-created and <code>init_by_lua_block</code> will run again on the new Lua VM. In case that the lua_code_cache directive is turned off (default on), the <code>init_by_lua_block</code> handler will run upon every request because in this special mode a standalone Lua VM is always created for each request.</p> <p>Usually you can pre-load Lua modules at server start-up by means of this hook and take advantage of modern operating systems' copy-on-write (COW) optimization. Here is an example for pre-loading Lua modules:</p> <pre><code> # this runs before forking out nginx worker processes:\n init_by_lua_block { require \"cjson\" }\n\n server {\n     location = /api {\n         content_by_lua_block {\n             -- the following require() will just  return\n             -- the already loaded module from package.loaded:\n             ngx.say(require \"cjson\".encode{dog = 5, cat = 6})\n         }\n     }\n }\n</code></pre> <p>You can also initialize the lua_shared_dict shm storage at this phase. Here is an example for this:</p> <pre><code> lua_shared_dict dogs 1m;\n\n init_by_lua_block {\n     local dogs = ngx.shared.dogs\n     dogs:set(\"Tom\", 56)\n }\n\n server {\n     location = /api {\n         content_by_lua_block {\n             local dogs = ngx.shared.dogs\n             ngx.say(dogs:get(\"Tom\"))\n         }\n     }\n }\n</code></pre> <p>But note that, the lua_shared_dict's shm storage will not be cleared through a config reload (via the <code>HUP</code> signal, for example). So if you do not want to re-initialize the shm storage in your <code>init_by_lua_block</code> code in this case, then you just need to set a custom flag in the shm storage and always check the flag in your <code>init_by_lua_block</code> code.</p> <p>Because the Lua code in this context runs before Nginx forks its worker processes (if any), data or code loaded here will enjoy the Copy-on-write (COW) feature provided by many operating systems among all the worker processes, thus saving a lot of memory.</p> <p>Do not initialize your own Lua global variables in this context because use of Lua global variables have performance penalties and can lead to global namespace pollution (see the Lua Variable Scope section for more details). The recommended way is to use proper Lua module files (but do not use the standard Lua function module() to define Lua modules because it pollutes the global namespace as well) and call require() to load your own module files in <code>init_by_lua_block</code> or other contexts (require() does cache the loaded Lua modules in the global <code>package.loaded</code> table in the Lua registry so your modules will only loaded once for the whole Lua VM instance).</p> <p>Only a small set of the Nginx API for Lua is supported in this context:</p> <ul> <li>Logging APIs: ngx.log and print,</li> <li>Shared Dictionary API: ngx.shared.DICT.</li> </ul> <p>More Nginx APIs for Lua may be supported in this context upon future user requests.</p> <p>Basically you can safely use Lua libraries that do blocking I/O in this very context because blocking the master process during server start-up is completely okay. Even the Nginx core does blocking I/O (at least on resolving upstream's host names) at the configure-loading phase.</p> <p>You should be very careful about potential security vulnerabilities in your Lua code registered in this context because the Nginx master process is often run under the <code>root</code> account.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>See also the following blog posts for more details on OpenResty and Nginx's shared memory zones:</p> <ul> <li>How OpenResty and Nginx Shared Memory Zones Consume RAM</li> <li>Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones</li> </ul> <p>Back to TOC</p>"},{"location":"modules/lua/#init_by_lua_file","title":"init_by_lua_file","text":"<p>syntax: init_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http</p> <p>phase: loading-config</p> <p>Equivalent to init_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code or LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.5.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#init_worker_by_lua","title":"init_worker_by_lua","text":"<p>syntax: init_worker_by_lua &lt;lua-script-str&gt;</p> <p>context: http</p> <p>phase: starting-worker</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the init_worker_by_lua_block directive instead.</p> <p>Similar to the init_worker_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> init_worker_by_lua '\n     print(\"I need no extra escaping here, for example: \\r\\nblah\")\n ';\n</code></pre> <p>This directive was first introduced in the <code>v0.9.5</code> release.</p> <p>This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#init_worker_by_lua_block","title":"init_worker_by_lua_block","text":"<p>syntax: init_worker_by_lua_block { lua-script }</p> <p>context: http</p> <p>phase: starting-worker</p> <p>Runs the specified Lua code upon every Nginx worker process's startup when the master process is enabled. When the master process is disabled, this hook will just run after init_by_lua*.</p> <p>This hook is often used to create per-worker reoccurring timers (via the ngx.timer.at Lua API), either for backend health-check or other timed routine work. Below is an example,</p> <pre><code> init_worker_by_lua_block {\n     local delay = 3  -- in seconds\n     local new_timer = ngx.timer.at\n     local log = ngx.log\n     local ERR = ngx.ERR\n     local check\n\n     check = function(premature)\n         if not premature then\n             -- do the health check or other routine work\n             local ok, err = new_timer(delay, check)\n             if not ok then\n                 log(ERR, \"failed to create timer: \", err)\n                 return\n             end\n         end\n\n         -- do something in timer\n     end\n\n     local hdl, err = new_timer(delay, check)\n     if not hdl then\n         log(ERR, \"failed to create timer: \", err)\n         return\n     end\n\n     -- other job in init_worker_by_lua\n }\n</code></pre> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#init_worker_by_lua_file","title":"init_worker_by_lua_file","text":"<p>syntax: init_worker_by_lua_file &lt;lua-file-path&gt;</p> <p>context: http</p> <p>phase: starting-worker</p> <p>Similar to init_worker_by_lua_block, but accepts the file path to a Lua source file or Lua bytecode file.</p> <p>This directive was first introduced in the <code>v0.9.5</code> release.</p> <p>This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#exit_worker_by_lua_block","title":"exit_worker_by_lua_block","text":"<p>syntax: exit_worker_by_lua_block { lua-script }</p> <p>context: http</p> <p>phase: exiting-worker</p> <p>Runs the specified Lua code upon every Nginx worker process's exit when the master process is enabled. When the master process is disabled, this hook will run before the Nginx process exits.</p> <p>This hook is often used to release resources allocated by each worker (e.g. resources allocated by init_worker_by_lua*), or to prevent workers from exiting abnormally.</p> <p>For example,</p> <pre><code> exit_worker_by_lua_block {\n     print(\"log from exit_worker_by_lua_block\")\n }\n</code></pre> <p>It's not allowed to create a timer (even a 0-delay timer) here since it runs after all timers have been processed.</p> <p>This directive was first introduced in the <code>v0.10.18</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#exit_worker_by_lua_file","title":"exit_worker_by_lua_file","text":"<p>syntax: exit_worker_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http</p> <p>phase: exiting-worker</p> <p>Similar to exit_worker_by_lua_block, but accepts the file path to a Lua source file or Lua bytecode file.</p> <p>This directive was first introduced in the <code>v0.10.18</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#set_by_lua","title":"set_by_lua","text":"<p>syntax: set_by_lua $res &lt;lua-script-str&gt; [$arg1 $arg2 ...]</p> <p>context: server, server if, location, location if</p> <p>phase: rewrite</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the set_by_lua_block directive instead.</p> <p>Similar to the set_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping), and 1. this directive support extra arguments after the Lua script.</p> <p>For example,</p> <pre><code> set_by_lua $res ' return 32 + math.cos(32) ';\n # $res now has the value \"32.834223360507\" or alike.\n</code></pre> <p>As from the <code>v0.5.0rc29</code> release, Nginx variable interpolation is disabled in the <code>&lt;lua-script-str&gt;</code> argument of this directive and therefore, the dollar sign character (<code>$</code>) can be used directly.</p> <p>This directive requires the ngx_devel_kit module.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#set_by_lua_block","title":"set_by_lua_block","text":"<p>syntax: set_by_lua_block $res { lua-script }</p> <p>context: server, server if, location, location if</p> <p>phase: rewrite</p> <p>Executes code specified inside a pair of curly braces (<code>{}</code>), and returns string output to <code>$res</code>. The code inside a pair of curly braces (<code>{}</code>) can make API calls and can retrieve input arguments from the <code>ngx.arg</code> table (index starts from <code>1</code> and increases sequentially).</p> <p>This directive is designed to execute short, fast running code blocks as the Nginx event loop is blocked during code execution. Time consuming code sequences should therefore be avoided.</p> <p>This directive is implemented by injecting custom commands into the standard ngx_http_rewrite_module's command list. Because ngx_http_rewrite_module does not support nonblocking I/O in its commands, Lua APIs requiring yielding the current Lua \"light thread\" cannot work in this directive.</p> <p>At least the following API functions are currently disabled within the context of <code>set_by_lua_block</code>:</p> <ul> <li>Output API functions (e.g., ngx.say and ngx.send_headers)</li> <li>Control API functions (e.g., ngx.exit)</li> <li>Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi)</li> <li>Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).</li> <li>Sleeping API function ngx.sleep.</li> </ul> <p>In addition, note that this directive can only write out a value to a single Nginx variable at a time. However, a workaround is possible using the ngx.var.VARIABLE interface.</p> <pre><code> location /foo {\n     set $diff ''; # we have to predefine the $diff variable here\n\n     set_by_lua_block $sum {\n         local a = 32\n         local b = 56\n\n         ngx.var.diff = a - b  -- write to $diff directly\n         return a + b          -- return the $sum value normally\n     }\n\n     echo \"sum = $sum, diff = $diff\";\n }\n</code></pre> <p>This directive can be freely mixed with all directives of the ngx_http_rewrite_module, set-misc-nginx-module, and array-var-nginx-module modules. All of these directives will run in the same order as they appear in the config file.</p> <pre><code> set $foo 32;\n set_by_lua_block $bar { return tonumber(ngx.var.foo) + 1 }\n set $baz \"bar: $bar\";  # $baz == \"bar: 33\"\n</code></pre> <p>No special escaping is required in the Lua code block.</p> <p>This directive requires the ngx_devel_kit module.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#set_by_lua_file","title":"set_by_lua_file","text":"<p>syntax: set_by_lua_file $res &lt;path-to-lua-script-file&gt; [$arg1 $arg2 ...]</p> <p>context: server, server if, location, location if</p> <p>phase: rewrite</p> <p>Equivalent to set_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>Nginx variable interpolation is supported in the <code>&lt;path-to-lua-script-file&gt;</code> argument string of this directive. But special care must be taken for injection attacks.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.</p> <p>This directive requires the ngx_devel_kit module.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#content_by_lua","title":"content_by_lua","text":"<p>syntax: content_by_lua &lt;lua-script-str&gt;</p> <p>context: location, location if</p> <p>phase: content</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the content_by_lua_block directive instead.</p> <p>Similar to the content_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> content_by_lua '\n     ngx.say(\"I need no extra escaping here, for example: \\r\\nblah\")\n ';\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#content_by_lua_block","title":"content_by_lua_block","text":"<p>syntax: content_by_lua_block { lua-script }</p> <p>context: location, location if</p> <p>phase: content</p> <p>For instance,</p> <pre><code> content_by_lua_block {\n     ngx.say(\"I need no extra escaping here, for example: \\r\\nblah\")\n }\n</code></pre> <p>Acts as a \"content handler\" and executes Lua code string specified in <code>{ lua-script }</code> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).</p> <p>Do not use this directive and other content handler directives in the same location. For example, this directive and the proxy_pass directive should not be used in the same location.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#content_by_lua_file","title":"content_by_lua_file","text":"<p>syntax: content_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: location, location if</p> <p>phase: content</p> <p>Equivalent to content_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>If the file is not found, a <code>404 Not Found</code> status code will be returned, and a <code>503 Service Temporarily Unavailable</code> status code will be returned in case of errors in reading other files.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.</p> <p>Nginx variables are supported in the file path for dynamic dispatch, for example:</p> <pre><code> # CAUTION: contents in nginx var must be carefully filtered,\n # otherwise there'll be great security risk!\n location ~ ^/app/([-_a-zA-Z0-9/]+) {\n     set $path $1;\n     content_by_lua_file /path/to/lua/app/root/$path.lua;\n }\n</code></pre> <p>But be very careful about malicious user inputs and always carefully validate or filter out the user-supplied path components.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#server_rewrite_by_lua_block","title":"server_rewrite_by_lua_block","text":"<p>syntax: server_rewrite_by_lua_block { lua-script }</p> <p>context: http, server</p> <p>phase: server rewrite</p> <p>Acts as a server rewrite phase handler and executes Lua code string specified in <code>{ lua-script }</code> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).</p> <pre><code> server {\n     ...\n\n     server_rewrite_by_lua_block {\n         ngx.ctx.a = \"server_rewrite_by_lua_block in http\"\n     }\n\n     location /lua {\n         content_by_lua_block {\n             ngx.say(ngx.ctx.a)\n             ngx.log(ngx.INFO, ngx.ctx.a)\n            }\n     }\n }\n</code></pre> <p>Just as any other rewrite phase handlers, server_rewrite_by_lua_block also runs in subrequests.</p> <pre><code> server {\n     server_rewrite_by_lua_block {\n         ngx.log(ngx.INFO, \"is_subrequest:\", ngx.is_subrequest)\n     }\n\n     location /lua {\n         content_by_lua_block {\n             local res = ngx.location.capture(\"/sub\")\n             ngx.print(res.body)\n         }\n     }\n\n     location /sub {\n         content_by_lua_block {\n             ngx.say(\"OK\")\n         }\n     }\n }\n</code></pre> <p>Note that when calling <code>ngx.exit(ngx.OK)</code> within a server_rewrite_by_lua_block handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a server_rewrite_by_lua_block handler, call ngx.exit with status &gt;= 200 (<code>ngx.HTTP_OK</code>) and status &lt; 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.</p> <pre><code> server_rewrite_by_lua_block {\n     ngx.exit(503)\n }\n\n location /bar {\n     ...\n     # never exec\n }\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#server_rewrite_by_lua_file","title":"server_rewrite_by_lua_file","text":"<p>syntax: server_rewrite_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server</p> <p>phase: server rewrite</p> <p>Equivalent to server_rewrite_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.10.22</code> release, the LuaJIT bytecode to be executed.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#rewrite_by_lua","title":"rewrite_by_lua","text":"<p>syntax: rewrite_by_lua &lt;lua-script-str&gt;</p> <p>context: http, server, location, location if</p> <p>phase: rewrite tail</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the rewrite_by_lua_block directive instead.</p> <p>Similar to the rewrite_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> rewrite_by_lua '\n     do_something(\"hello, world!\\nhiya\\n\")\n ';\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#rewrite_by_lua_block","title":"rewrite_by_lua_block","text":"<p>syntax: rewrite_by_lua_block { lua-script }</p> <p>context: http, server, location, location if</p> <p>phase: rewrite tail</p> <p>Acts as a rewrite phase handler and executes Lua code string specified in <code>{ lua-script }</code> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).</p> <p>Note that this handler always runs after the standard ngx_http_rewrite_module. So the following will work as expected:</p> <pre><code> location /foo {\n     set $a 12; # create and initialize $a\n     set $b \"\"; # create and initialize $b\n     rewrite_by_lua_block {\n         ngx.var.b = tonumber(ngx.var.a) + 1\n     }\n     echo \"res = $b\";\n }\n</code></pre> <p>because <code>set $a 12</code> and <code>set $b \"\"</code> run before rewrite_by_lua_block.</p> <p>On the other hand, the following will not work as expected:</p> <pre><code> ?  location /foo {\n ?      set $a 12; # create and initialize $a\n ?      set $b ''; # create and initialize $b\n ?      rewrite_by_lua_block {\n ?          ngx.var.b = tonumber(ngx.var.a) + 1\n ?      }\n ?      if ($b = '13') {\n ?         rewrite ^ /bar redirect;\n ?         break;\n ?      }\n ?\n ?      echo \"res = $b\";\n ?  }\n</code></pre> <p>because <code>if</code> runs before rewrite_by_lua_block even if it is placed after rewrite_by_lua_block in the config.</p> <p>The right way of doing this is as follows:</p> <pre><code> location /foo {\n     set $a 12; # create and initialize $a\n     set $b ''; # create and initialize $b\n     rewrite_by_lua_block {\n         ngx.var.b = tonumber(ngx.var.a) + 1\n         if tonumber(ngx.var.b) == 13 then\n             return ngx.redirect(\"/bar\")\n         end\n     }\n\n     echo \"res = $b\";\n }\n</code></pre> <p>Note that the ngx_eval module can be approximated by using rewrite_by_lua_block. For example,</p> <pre><code> location / {\n     eval $res {\n         proxy_pass http://foo.com/check-spam;\n     }\n\n     if ($res = 'spam') {\n         rewrite ^ /terms-of-use.html redirect;\n     }\n\n     fastcgi_pass ...;\n }\n</code></pre> <p>can be implemented in ngx_lua as:</p> <pre><code> location = /check-spam {\n     internal;\n     proxy_pass http://foo.com/check-spam;\n }\n\n location / {\n     rewrite_by_lua_block {\n         local res = ngx.location.capture(\"/check-spam\")\n         if res.body == \"spam\" then\n             return ngx.redirect(\"/terms-of-use.html\")\n         end\n     }\n\n     fastcgi_pass ...;\n }\n</code></pre> <p>Just as any other rewrite phase handlers, rewrite_by_lua_block also runs in subrequests.</p> <p>Note that when calling <code>ngx.exit(ngx.OK)</code> within a rewrite_by_lua_block handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a rewrite_by_lua_block handler, call ngx.exit with status &gt;= 200 (<code>ngx.HTTP_OK</code>) and status &lt; 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.</p> <p>If the ngx_http_rewrite_module's rewrite directive is used to change the URI and initiate location re-lookups (internal redirections), then any rewrite_by_lua_block or rewrite_by_lua_file_block code sequences within the current location will not be executed. For example,</p> <pre><code> location /foo {\n     rewrite ^ /bar;\n     rewrite_by_lua_block {\n         ngx.exit(503)\n     }\n }\n location /bar {\n     ...\n }\n</code></pre> <p>Here the Lua code <code>ngx.exit(503)</code> will never run. This will be the case if <code>rewrite ^ /bar last</code> is used as this will similarly initiate an internal redirection. If the <code>break</code> modifier is used instead, there will be no internal redirection and the <code>rewrite_by_lua_block</code> code will be executed.</p> <p>The <code>rewrite_by_lua_block</code> code will always run at the end of the <code>rewrite</code> request-processing phase unless rewrite_by_lua_no_postpone is turned on.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#rewrite_by_lua_file","title":"rewrite_by_lua_file","text":"<p>syntax: rewrite_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server, location, location if</p> <p>phase: rewrite tail</p> <p>Equivalent to rewrite_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.</p> <p>The <code>rewrite_by_lua_file</code> code will always run at the end of the <code>rewrite</code> request-processing phase unless rewrite_by_lua_no_postpone is turned on.</p> <p>Nginx variables are supported in the file path for dynamic dispatch just as in content_by_lua_file.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#access_by_lua","title":"access_by_lua","text":"<p>syntax: access_by_lua &lt;lua-script-str&gt;</p> <p>context: http, server, location, location if</p> <p>phase: access tail</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the access_by_lua_block directive instead.</p> <p>Similar to the access_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> access_by_lua '\n     do_something(\"hello, world!\\nhiya\\n\")\n ';\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#access_by_lua_block","title":"access_by_lua_block","text":"<p>syntax: access_by_lua_block { lua-script }</p> <p>context: http, server, location, location if</p> <p>phase: access tail</p> <p>Acts as an access phase handler and executes Lua code string specified in <code>{ &lt;lua-script }</code> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).</p> <p>Note that this handler always runs after the standard ngx_http_access_module. So the following will work as expected:</p> <pre><code> location / {\n     deny    192.168.1.1;\n     allow   192.168.1.0/24;\n     allow   10.1.1.0/16;\n     deny    all;\n\n     access_by_lua_block {\n         local res = ngx.location.capture(\"/mysql\", { ... })\n         ...\n     }\n\n     # proxy_pass/fastcgi_pass/...\n }\n</code></pre> <p>That is, if a client IP address is in the blacklist, it will be denied before the MySQL query for more complex authentication is executed by access_by_lua_block.</p> <p>Note that the ngx_auth_request module can be approximated by using access_by_lua_block:</p> <pre><code> location / {\n     auth_request /auth;\n\n     # proxy_pass/fastcgi_pass/postgres_pass/...\n }\n</code></pre> <p>can be implemented in ngx_lua as:</p> <pre><code> location / {\n     access_by_lua_block {\n         local res = ngx.location.capture(\"/auth\")\n\n         if res.status == ngx.HTTP_OK then\n             return\n         end\n\n         if res.status == ngx.HTTP_FORBIDDEN then\n             ngx.exit(res.status)\n         end\n\n         ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\n     }\n\n     # proxy_pass/fastcgi_pass/postgres_pass/...\n }\n</code></pre> <p>As with other access phase handlers, access_by_lua_block will not run in subrequests.</p> <p>Note that when calling <code>ngx.exit(ngx.OK)</code> within a access_by_lua_block handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a access_by_lua_block handler, call ngx.exit with status &gt;= 200 (<code>ngx.HTTP_OK</code>) and status &lt; 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.</p> <p>Starting from the <code>v0.9.20</code> release, you can use the access_by_lua_no_postpone directive to control when to run this handler inside the \"access\" request-processing phase of Nginx.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#access_by_lua_file","title":"access_by_lua_file","text":"<p>syntax: access_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server, location, location if</p> <p>phase: access tail</p> <p>Equivalent to access_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid repeatedly reloading Nginx.</p> <p>Nginx variables are supported in the file path for dynamic dispatch just as in content_by_lua_file.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#header_filter_by_lua","title":"header_filter_by_lua","text":"<p>syntax: header_filter_by_lua &lt;lua-script-str&gt;</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the header_filter_by_lua_block directive instead.</p> <p>Similar to the header_filter_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> header_filter_by_lua '\n     ngx.header[\"content-length\"] = nil\n ';\n</code></pre> <p>This directive was first introduced in the <code>v0.2.1rc20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#header_filter_by_lua_block","title":"header_filter_by_lua_block","text":"<p>syntax: header_filter_by_lua_block { lua-script }</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>Uses Lua code specified in <code>{ lua-script }</code> to define an output header filter.</p> <p>Note that the following API functions are currently disabled within this context:</p> <ul> <li>Output API functions (e.g., ngx.say and ngx.send_headers)</li> <li>Control API functions (e.g., ngx.redirect and ngx.exec)</li> <li>Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi)</li> <li>Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).</li> </ul> <p>Here is an example of overriding a response header (or adding one if absent) in our Lua header filter:</p> <pre><code> location / {\n     proxy_pass http://mybackend;\n     header_filter_by_lua_block {\n         ngx.header.Foo = \"blah\"\n     }\n }\n</code></pre> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#header_filter_by_lua_file","title":"header_filter_by_lua_file","text":"<p>syntax: header_filter_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>Equivalent to header_filter_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.2.1rc20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#body_filter_by_lua","title":"body_filter_by_lua","text":"<p>syntax: body_filter_by_lua &lt;lua-script-str&gt;</p> <p>context: http, server, location, location if</p> <p>phase: output-body-filter</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the body_filter_by_lua_block directive instead.</p> <p>Similar to the body_filter_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> body_filter_by_lua '\n     local data, eof = ngx.arg[1], ngx.arg[2]\n ';\n</code></pre> <p>This directive was first introduced in the <code>v0.5.0rc32</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#body_filter_by_lua_block","title":"body_filter_by_lua_block","text":"<p>syntax: body_filter_by_lua_block { lua-script-str }</p> <p>context: http, server, location, location if</p> <p>phase: output-body-filter</p> <p>Uses Lua code specified in <code>{ lua-script }</code> to define an output body filter.</p> <p>The input data chunk is passed via ngx.arg[1] (as a Lua string value) and the \"eof\" flag indicating the end of the response body data stream is passed via ngx.arg[2] (as a Lua boolean value).</p> <p>Behind the scene, the \"eof\" flag is just the <code>last_buf</code> (for main requests) or <code>last_in_chain</code> (for subrequests) flag of the Nginx chain link buffers. (Before the <code>v0.7.14</code> release, the \"eof\" flag does not work at all in subrequests.)</p> <p>The output data stream can be aborted immediately by running the following Lua statement:</p> <pre><code> return ngx.ERROR\n</code></pre> <p>This will truncate the response body and usually result in incomplete and also invalid responses.</p> <p>The Lua code can pass its own modified version of the input data chunk to the downstream Nginx output body filters by overriding ngx.arg[1] with a Lua string or a Lua table of strings. For example, to transform all the lowercase letters in the response body, we can just write:</p> <pre><code> location / {\n     proxy_pass http://mybackend;\n     body_filter_by_lua_block {\n         ngx.arg[1] = string.upper(ngx.arg[1])\n     }\n }\n</code></pre> <p>When setting <code>nil</code> or an empty Lua string value to <code>ngx.arg[1]</code>, no data chunk will be passed to the downstream Nginx output filters at all.</p> <p>Likewise, new \"eof\" flag can also be specified by setting a boolean value to ngx.arg[2]. For example,</p> <pre><code> location /t {\n     echo hello world;\n     echo hiya globe;\n\n     body_filter_by_lua_block {\n         local chunk = ngx.arg[1]\n         if string.match(chunk, \"hello\") then\n             ngx.arg[2] = true  -- new eof\n             return\n         end\n\n         -- just throw away any remaining chunk data\n         ngx.arg[1] = nil\n     }\n }\n</code></pre> <p>Then <code>GET /t</code> will just return the output</p> <pre><code>hello world\n</code></pre> <p>That is, when the body filter sees a chunk containing the word \"hello\", then it will set the \"eof\" flag to true immediately, resulting in truncated but still valid responses.</p> <p>When the Lua code may change the length of the response body, then it is required to always clear out the <code>Content-Length</code> response header (if any) in a header filter to enforce streaming output, as in</p> <pre><code> location /foo {\n     # fastcgi_pass/proxy_pass/...\n\n     header_filter_by_lua_block {\n         ngx.header.content_length = nil\n     }\n     body_filter_by_lua_block {\n         ngx.arg[1] = string.len(ngx.arg[1]) .. \"\\n\"\n     }\n }\n</code></pre> <p>Note that the following API functions are currently disabled within this context due to the limitations in Nginx output filter's current implementation:</p> <ul> <li>Output API functions (e.g., ngx.say and ngx.send_headers)</li> <li>Control API functions (e.g., ngx.exit and ngx.exec)</li> <li>Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi)</li> <li>Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).</li> </ul> <p>Nginx output filters may be called multiple times for a single request because response body may be delivered in chunks. Thus, the Lua code specified by in this directive may also run multiple times in the lifetime of a single HTTP request.</p> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#body_filter_by_lua_file","title":"body_filter_by_lua_file","text":"<p>syntax: body_filter_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server, location, location if</p> <p>phase: output-body-filter</p> <p>Equivalent to body_filter_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.5.0rc32</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#log_by_lua","title":"log_by_lua","text":"<p>syntax: log_by_lua &lt;lua-script-str&gt;</p> <p>context: http, server, location, location if</p> <p>phase: log</p> <p>NOTE Use of this directive is discouraged following the <code>v0.9.17</code> release. Use the log_by_lua_block directive instead.</p> <p>Similar to the log_by_lua_block directive, but accepts the Lua source directly in an Nginx string literal (which requires special character escaping).</p> <p>For instance,</p> <pre><code> log_by_lua '\n     print(\"I need no extra escaping here, for example: \\r\\nblah\")\n ';\n</code></pre> <p>This directive was first introduced in the <code>v0.5.0rc31</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#log_by_lua_block","title":"log_by_lua_block","text":"<p>syntax: log_by_lua_block { lua-script }</p> <p>context: http, server, location, location if</p> <p>phase: log</p> <p>Runs the Lua source code inlined as the <code>{ lua-script }</code> at the <code>log</code> request processing phase. This does not replace the current access logs, but runs before.</p> <p>Note that the following API functions are currently disabled within this context:</p> <ul> <li>Output API functions (e.g., ngx.say and ngx.send_headers)</li> <li>Control API functions (e.g., ngx.exit)</li> <li>Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi)</li> <li>Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).</li> </ul> <p>Here is an example of gathering average data for $upstream_response_time:</p> <pre><code> lua_shared_dict log_dict 5M;\n\n server {\n     location / {\n         proxy_pass http://mybackend;\n\n         log_by_lua_block {\n             local log_dict = ngx.shared.log_dict\n             local upstream_time = tonumber(ngx.var.upstream_response_time)\n\n             local sum = log_dict:get(\"upstream_time-sum\") or 0\n             sum = sum + upstream_time\n             log_dict:set(\"upstream_time-sum\", sum)\n\n             local newval, err = log_dict:incr(\"upstream_time-nb\", 1)\n             if not newval and err == \"not found\" then\n                 log_dict:add(\"upstream_time-nb\", 0)\n                 log_dict:incr(\"upstream_time-nb\", 1)\n             end\n         }\n     }\n\n     location = /status {\n         content_by_lua_block {\n             local log_dict = ngx.shared.log_dict\n             local sum = log_dict:get(\"upstream_time-sum\")\n             local nb = log_dict:get(\"upstream_time-nb\")\n\n             if nb and sum then\n                 ngx.say(\"average upstream response time: \", sum / nb,\n                         \" (\", nb, \" reqs)\")\n             else\n                 ngx.say(\"no data yet\")\n             end\n         }\n     }\n }\n</code></pre> <p>This directive was first introduced in the <code>v0.9.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#log_by_lua_file","title":"log_by_lua_file","text":"<p>syntax: log_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server, location, location if</p> <p>phase: log</p> <p>Equivalent to log_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.5.0rc31</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#balancer_by_lua_block","title":"balancer_by_lua_block","text":"<p>syntax: balancer_by_lua_block { lua-script }</p> <p>context: upstream</p> <p>phase: content</p> <p>This directive runs Lua code as an upstream balancer for any upstream entities defined by the <code>upstream {}</code> configuration block.</p> <p>For instance,</p> <pre><code> upstream foo {\n     server 127.0.0.1;\n     balancer_by_lua_block {\n         -- use Lua to do something interesting here\n         -- as a dynamic balancer\n     }\n }\n\n server {\n     location / {\n         proxy_pass http://foo;\n     }\n }\n</code></pre> <p>The resulting Lua load balancer can work with any existing Nginx upstream modules like ngx_proxy and ngx_fastcgi.</p> <p>Also, the Lua load balancer can work with the standard upstream connection pool mechanism, i.e., the standard keepalive directive. Just ensure that the keepalive directive is used after this <code>balancer_by_lua_block</code> directive in a single <code>upstream {}</code> configuration block.</p> <p>The Lua load balancer can totally ignore the list of servers defined in the <code>upstream {}</code> block and select peer from a completely dynamic server list (even changing per request) via the ngx.balancer module from the lua-resty-core library.</p> <p>The Lua code handler registered by this directive might get called more than once in a single downstream request when the Nginx upstream mechanism retries the request on conditions specified by directives like the proxy_next_upstream directive.</p> <p>This Lua code execution context does not support yielding, so Lua APIs that may yield (like cosockets and \"light threads\") are disabled in this context. One can usually work around this limitation by doing such operations in an earlier phase handler (like access_by_lua*) and passing along the result into this context via the ngx.ctx table.</p> <p>This directive was first introduced in the <code>v0.10.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#balancer_by_lua_file","title":"balancer_by_lua_file","text":"<p>syntax: balancer_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: upstream</p> <p>phase: content</p> <p>Equivalent to balancer_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.10.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#balancer_keepalive","title":"balancer_keepalive","text":"<p>syntax: balancer_keepalive &lt;total-connections&gt;</p> <p>context: upstream</p> <p>phase: loading-config</p> <p>The <code>total-connections</code> parameter sets the maximum number of idle keepalive connections to upstream servers that are preserved in the cache of each worker process. When this number is exceeded, the least recently used connections are closed.</p> <p>It should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open. The connections parameter should be set to a number small enough to let upstream servers process new incoming connections as well.</p> <p>This directive was first introduced in the <code>v0.10.21</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_need_request_body","title":"lua_need_request_body","text":"<p>syntax: lua_need_request_body &lt;on|off&gt;</p> <p>default: off</p> <p>context: http, server, location, location if</p> <p>phase: depends on usage</p> <p>Determines whether to force the request body data to be read before running rewrite/access/content_by_lua* or not. The Nginx core does not read the client request body by default and if request body data is required, then this directive should be turned <code>on</code> or the ngx.req.read_body function should be called within the Lua code.</p> <p>To read the request body data within the $request_body variable, client_body_buffer_size must have the same value as client_max_body_size. Because when the content length exceeds client_body_buffer_size but less than client_max_body_size, Nginx will buffer the data into a temporary file on the disk, which will lead to empty value in the $request_body variable.</p> <p>If the current location includes rewrite_by_lua* directives, then the request body will be read just before the rewrite_by_lua* code is run (and also at the <code>rewrite</code> phase). Similarly, if only content_by_lua is specified, the request body will not be read until the content handler's Lua code is about to run (i.e., the request body will be read during the content phase).</p> <p>It is recommended however, to use the ngx.req.read_body and ngx.req.discard_body functions for finer control over the request body reading process instead.</p> <p>This also applies to access_by_lua*.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_client_hello_by_lua_block","title":"ssl_client_hello_by_lua_block","text":"<p>syntax: ssl_client_hello_by_lua_block { lua-script }</p> <p>context: http, server</p> <p>phase: right-after-client-hello-message-was-processed</p> <p>This directive runs user Lua code when Nginx is about to post-process the SSL client hello message for the downstream SSL (https) connections.</p> <p>It is particularly useful for dynamically setting the SSL protocols according to the SNI.</p> <p>It is also useful to do some custom operations according to the per-connection information in the client hello message.</p> <p>For example, one can parse custom client hello extension and do the corresponding handling in pure Lua.</p> <p>This Lua handler will always run whether the SSL session is resumed (via SSL session IDs or TLS session tickets) or not. While the <code>ssl_certificate_by_lua*</code> Lua handler will only runs when initiating a full SSL handshake.</p> <p>The ngx.ssl.clienthello Lua modules provided by the lua-resty-core library are particularly useful in this context.</p> <p>Note that this handler runs in extremely early stage of SSL handshake, before the SSL client hello extensions are parsed. So you can not use some Lua API like <code>ssl.server_name()</code> which is dependent on the later stage's processing.</p> <p>Also note that only the directive in default server is valid for several virtual servers with the same IP address and port.</p> <p>Below is a trivial example using the ngx.ssl.clienthello module at the same time:</p> <pre><code> server {\n     listen 443 ssl;\n     server_name   test.com;\n     ssl_certificate /path/to/cert.crt;\n     ssl_certificate_key /path/to/key.key;\n     ssl_client_hello_by_lua_block {\n         local ssl_clt = require \"ngx.ssl.clienthello\"\n         local host, err = ssl_clt.get_client_hello_server_name()\n         if host == \"test.com\" then\n             ssl_clt.set_protocols({\"TLSv1\", \"TLSv1.1\"})\n         elseif host == \"test2.com\" then\n             ssl_clt.set_protocols({\"TLSv1.2\", \"TLSv1.3\"})\n         elseif not host then\n             ngx.log(ngx.ERR, \"failed to get the SNI name: \", err)\n             ngx.exit(ngx.ERROR)\n         else\n             ngx.log(ngx.ERR, \"unknown SNI name: \", host)\n             ngx.exit(ngx.ERROR)\n         end\n     }\n     ...\n }\n server {\n     listen 443 ssl;\n     server_name   test2.com;\n     ssl_certificate /path/to/cert.crt;\n     ssl_certificate_key /path/to/key.key;\n     ...\n }\n</code></pre> <p>See more information in the ngx.ssl.clienthello Lua modules' official documentation.</p> <p>Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the ngx.exit call with an error code like <code>ngx.ERROR</code>.</p> <p>This Lua code execution context does support yielding, so Lua APIs that may yield (like cosockets, sleeping, and \"light threads\") are enabled in this context</p> <p>Note, you need to configure the ssl_certificate and ssl_certificate_key to avoid the following error while starting NGINX:</p> <pre><code>nginx: [emerg] no ssl configured for the server\n</code></pre> <p>This directive requires OpenSSL 1.1.1 or greater.</p> <p>If you are using the official pre-built packages for OpenResty 1.21.4.1 or later, then everything should work out of the box.</p> <p>If you are not using the Nginx core shipped with OpenResty 1.21.4.1 or later, you will need to apply patches to the standard Nginx core:</p> <p>https://openresty.org/en/nginx-ssl-patches.html</p> <p>Note for HTTP/3 (QUIC) users: When using this directive with HTTP/3 connections, certain yield operations may fail if the QUIC SSL Lua yield patch is not applied to your OpenSSL installation. OpenResty packages include this patch by default, but if you are building lua-nginx-module separately, you may need to apply the patch manually to ensure proper yield/resume functionality for HTTP/3 connections in SSL Lua phases. The patch can be found at: nginx-1.27.1-quic_ssl_lua_yield.patch</p> <p>This directive was first introduced in the <code>v0.10.21</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_client_hello_by_lua_file","title":"ssl_client_hello_by_lua_file","text":"<p>syntax: ssl_client_hello_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http, server</p> <p>phase: right-after-client-hello-message-was-processed</p> <p>Equivalent to ssl_client_hello_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>Note for HTTP/3 (QUIC) users: When using this directive with HTTP/3 connections, certain yield operations may fail if the QUIC SSL Lua yield patch is not applied to your OpenSSL installation. OpenResty packages include this patch by default, but if you are building lua-nginx-module separately, you may need to apply the patch manually to ensure proper yield/resume functionality for HTTP/3 connections in SSL Lua phases. The patch can be found at: nginx-1.27.1-quic_ssl_lua_yield.patch</p> <p>This directive was first introduced in the <code>v0.10.21</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_certificate_by_lua_block","title":"ssl_certificate_by_lua_block","text":"<p>syntax: ssl_certificate_by_lua_block { lua-script }</p> <p>context: server</p> <p>phase: right-before-SSL-handshake</p> <p>This directive runs user Lua code when Nginx is about to start the SSL handshake for the downstream SSL (https) connections.</p> <p>It is particularly useful for setting the SSL certificate chain and the corresponding private key on a per-request basis. It is also useful to load such handshake configurations nonblockingly from the remote (for example, with the cosocket API). And one can also do per-request OCSP stapling handling in pure Lua here as well.</p> <p>Another typical use case is to do SSL handshake traffic control nonblockingly in this context, with the help of the lua-resty-limit-traffic#readme library, for example.</p> <p>One can also do interesting things with the SSL handshake requests from the client side, like rejecting old SSL clients using the SSLv3 protocol or even below selectively.</p> <p>The ngx.ssl and ngx.ocsp Lua modules provided by the lua-resty-core library are particularly useful in this context. You can use the Lua API offered by these two Lua modules to manipulate the SSL certificate chain and private key for the current SSL connection being initiated.</p> <p>This Lua handler does not run at all, however, when Nginx/OpenSSL successfully resumes the SSL session via SSL session IDs or TLS session tickets for the current SSL connection. In other words, this Lua handler only runs when Nginx has to initiate a full SSL handshake.</p> <p>Below is a trivial example using the ngx.ssl module at the same time:</p> <pre><code> server {\n     listen 443 ssl;\n     server_name   test.com;\n\n     ssl_certificate_by_lua_block {\n         print(\"About to initiate a new SSL handshake!\")\n     }\n\n     location / {\n         root html;\n     }\n }\n</code></pre> <p>See more complicated examples in the ngx.ssl and ngx.ocsp Lua modules' official documentation.</p> <p>Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the ngx.exit call with an error code like <code>ngx.ERROR</code>.</p> <p>This Lua code execution context does support yielding, so Lua APIs that may yield (like cosockets, sleeping, and \"light threads\") are enabled in this context.</p> <p>Note, however, you still need to configure the ssl_certificate and ssl_certificate_key directives even though you will not use this static certificate and private key at all. This is because the NGINX core requires their appearance otherwise you are seeing the following error while starting NGINX:</p> <pre><code>nginx: [emerg] no ssl configured for the server\n</code></pre> <p>This directive requires OpenSSL 1.0.2e or greater.</p> <p>If you are using the official pre-built packages for OpenResty 1.9.7.2 or later, then everything should work out of the box.</p> <p>If you are not using the Nginx core shipped with OpenResty 1.9.7.2 or later, you will need to apply patches to the standard Nginx core:</p> <p>https://openresty.org/en/nginx-ssl-patches.html</p> <p>Note for HTTP/3 (QUIC) users: When using this directive with HTTP/3 connections, certain yield operations may fail if the QUIC SSL Lua yield patch is not applied to your OpenSSL installation. OpenResty packages include this patch by default, but if you are building lua-nginx-module separately, you may need to apply the patch manually to ensure proper yield/resume functionality for HTTP/3 connections in SSL Lua phases. The patch can be found at: nginx-1.27.1-quic_ssl_lua_yield.patch</p> <p>This directive was first introduced in the <code>v0.10.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_certificate_by_lua_file","title":"ssl_certificate_by_lua_file","text":"<p>syntax: ssl_certificate_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: server</p> <p>phase: right-before-SSL-handshake</p> <p>Equivalent to ssl_certificate_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>Note for HTTP/3 (QUIC) users: When using this directive with HTTP/3 connections, certain yield operations may fail if the QUIC SSL Lua yield patch is not applied to your OpenSSL installation. OpenResty packages include this patch by default, but if you are building lua-nginx-module separately, you may need to apply the patch manually to ensure proper yield/resume functionality for HTTP/3 connections in SSL Lua phases. The patch can be found at: nginx-1.27.1-quic_ssl_lua_yield.patch</p> <p>This directive was first introduced in the <code>v0.10.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_session_fetch_by_lua_block","title":"ssl_session_fetch_by_lua_block","text":"<p>syntax: ssl_session_fetch_by_lua_block { lua-script }</p> <p>context: http</p> <p>phase: right-before-SSL-handshake</p> <p>This directive runs Lua code to look up and load the SSL session (if any) according to the session ID provided by the current SSL handshake request for the downstream.</p> <p>The Lua API for obtaining the current session ID and loading a cached SSL session data is provided in the ngx.ssl.session Lua module shipped with the lua-resty-core library.</p> <p>Lua APIs that may yield, like ngx.sleep and cosockets, are enabled in this context.</p> <p>This hook, together with the ssl_session_store_by_lua* hook, can be used to implement distributed caching mechanisms in pure Lua (based on the cosocket API, for example). If a cached SSL session is found and loaded into the current SSL connection context, SSL session resumption can then get immediately initiated and bypass the full SSL handshake process which is very expensive in terms of CPU time.</p> <p>Please note that TLS session tickets are very different and it is the clients' responsibility to cache the SSL session state when session tickets are used. SSL session resumptions based on TLS session tickets would happen automatically without going through this hook (nor the ssl_session_store_by_lua* hook). This hook is mainly for older or less capable SSL clients that can only do SSL sessions by session IDs.</p> <p>When ssl_certificate_by_lua* is specified at the same time, this hook usually runs before ssl_certificate_by_lua*. When the SSL session is found and successfully loaded for the current SSL connection, SSL session resumption will happen and thus bypass the ssl_certificate_by_lua* hook completely. In this case, Nginx also bypasses the ssl_session_store_by_lua* hook, for obvious reasons.</p> <p>To easily test this hook locally with a modern web browser, you can temporarily put the following line in your https server block to disable the TLS session ticket support:</p> <pre><code>ssl_session_tickets off;\n</code></pre> <p>But do not forget to comment this line out before publishing your site to the world.</p> <p>If you are using the official pre-built packages for OpenResty 1.11.2.1 or later, then everything should work out of the box.</p> <p>If you are not using one of the OpenSSL packages provided by OpenResty, you will need to apply patches to OpenSSL in order to use this directive:</p> <p>https://openresty.org/en/openssl-patches.html</p> <p>Similarly, if you are not using the Nginx core shipped with OpenResty 1.11.2.1 or later, you will need to apply patches to the standard Nginx core:</p> <p>https://openresty.org/en/nginx-ssl-patches.html</p> <p>This directive was first introduced in the <code>v0.10.6</code> release.</p> <p>Note that this directive can only be used in the http context starting with the <code>v0.10.7</code> release since SSL session resumption happens before server name dispatch.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_session_fetch_by_lua_file","title":"ssl_session_fetch_by_lua_file","text":"<p>syntax: ssl_session_fetch_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http</p> <p>phase: right-before-SSL-handshake</p> <p>Equivalent to ssl_session_fetch_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or rather, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.10.6</code> release.</p> <p>Note that: this directive is only allowed to used in http context from the <code>v0.10.7</code> release (because SSL session resumption happens before server name dispatch).</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_session_store_by_lua_block","title":"ssl_session_store_by_lua_block","text":"<p>syntax: ssl_session_store_by_lua_block { lua-script }</p> <p>context: http</p> <p>phase: right-after-SSL-handshake</p> <p>This directive runs Lua code to fetch and save the SSL session (if any) according to the session ID provided by the current SSL handshake request for the downstream. The saved or cached SSL session data can be used for future SSL connections to resume SSL sessions without going through the full SSL handshake process (which is very expensive in terms of CPU time).</p> <p>Lua APIs that may yield, like ngx.sleep and cosockets, are disabled in this context. You can still, however, use the ngx.timer.at API to create 0-delay timers to save the SSL session data asynchronously to external services (like <code>redis</code> or <code>memcached</code>).</p> <p>The Lua API for obtaining the current session ID and the associated session state data is provided in the ngx.ssl.session Lua module shipped with the lua-resty-core library.</p> <p>To easily test this hook locally with a modern web browser, you can temporarily put the following line in your https server block to disable the TLS session ticket support:</p> <pre><code>ssl_session_tickets off;\n</code></pre> <p>But do not forget to comment this line out before publishing your site to the world.</p> <p>This directive was first introduced in the <code>v0.10.6</code> release.</p> <p>Note that: this directive is only allowed to used in http context from the <code>v0.10.7</code> release (because SSL session resumption happens before server name dispatch).</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ssl_session_store_by_lua_file","title":"ssl_session_store_by_lua_file","text":"<p>syntax: ssl_session_store_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: http</p> <p>phase: right-after-SSL-handshake</p> <p>Equivalent to ssl_session_store_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or rather, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>This directive was first introduced in the <code>v0.10.6</code> release.</p> <p>Note that: this directive is only allowed to used in http context from the <code>v0.10.7</code> release (because SSL session resumption happens before server name dispatch).</p> <p>Back to TOC</p>"},{"location":"modules/lua/#proxy_ssl_verify_by_lua_block","title":"proxy_ssl_verify_by_lua_block","text":"<p>syntax: proxy_ssl_verify_by_lua_block { lua-script }</p> <p>context: location</p> <p>phase: right-after-server-certificate-message-was-processed</p> <p>This directive runs user Lua code when Nginx is about to post-process the SSL server certificate message for the upstream SSL (https) connections.</p> <p>It is particularly useful to parse upstream server certificate and do some custom operations in pure lua.</p> <p>The ngx.ssl.proxysslverify Lua modules provided by the lua-resty-core library are particularly useful in this context.</p> <p>Below is a trivial example using the ngx.ssl.proxysslverify module at the same time:</p> <pre><code> server {\n     listen 443 ssl;\n     server_name   test.com;\n     ssl_certificate /path/to/cert.crt;\n     ssl_certificate_key /path/to/key.key;\n\n     location /t {\n         proxy_ssl_certificate /path/to/cert.crt;\n         proxy_ssl_certificate_key /path/to/key.key;\n         proxy_pass https://upstream;\n\n         proxy_ssl_verify_by_lua_block {\n             local proxy_ssl_vfy = require \"ngx.ssl.proxysslverify\"\n             local cert = proxy_ssl_vfy.get_verify_cert()\n\n             -- ocsp to verify cert\n             -- check crl\n             proxy_ssl_vfy.set_verify_result()\n             ...\n         }\n     }\n     ...\n }\n</code></pre> <p>See more information in the ngx.ssl.proxysslverify Lua modules' official documentation.</p> <p>Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the ngx.exit call with an error code like <code>ngx.ERROR</code>.</p> <p>This Lua code execution context does support yielding, so Lua APIs that may yield (like cosockets, sleeping, and \"light threads\") are enabled in this context</p> <p>Note, <code>ngx.ctx</code> in proxy_ssl_verify_by_lua_block is belonging to upstream connection, not downstream connection, so it's different from <code>ngx.ctx</code> in contexts like ssl_certificate_by_lua etc.</p> <p>This directive requires OpenSSL 3.0.2 or greater.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#proxy_ssl_verify_by_lua_file","title":"proxy_ssl_verify_by_lua_file","text":"<p>syntax: proxy_ssl_verify_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: location</p> <p>phase: right-after-server-certificate-message-was-processed</p> <p>Equivalent to proxy_ssl_verify_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the LuaJIT bytecode to be executed.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_shared_dict","title":"lua_shared_dict","text":"<p>syntax: lua_shared_dict &lt;name&gt; &lt;size&gt;</p> <p>default: no</p> <p>context: http</p> <p>phase: depends on usage</p> <p>Declares a shared memory zone, <code>&lt;name&gt;</code>, to serve as storage for the shm based Lua dictionary <code>ngx.shared.&lt;name&gt;</code>.</p> <p>Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance.</p> <p>The <code>&lt;size&gt;</code> argument accepts size units such as <code>k</code> and <code>m</code>:</p> <pre><code> http {\n     lua_shared_dict dogs 10m;\n     ...\n }\n</code></pre> <p>The hard-coded minimum size is 8KB while the practical minimum size depends on actual user data set (some people start with 12KB).</p> <p>See ngx.shared.DICT for details.</p> <p>This directive was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_connect_timeout","title":"lua_socket_connect_timeout","text":"<p>syntax: lua_socket_connect_timeout &lt;time&gt;</p> <p>default: lua_socket_connect_timeout 60s</p> <p>context: http, server, location</p> <p>This directive controls the default timeout value used in TCP/unix-domain socket object's connect method and can be overridden by the settimeout or settimeouts methods.</p> <p>The <code>&lt;time&gt;</code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., \"second\". The default setting is <code>60s</code>.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_send_timeout","title":"lua_socket_send_timeout","text":"<p>syntax: lua_socket_send_timeout &lt;time&gt;</p> <p>default: lua_socket_send_timeout 60s</p> <p>context: http, server, location</p> <p>Controls the default timeout value used in TCP/unix-domain socket object's send method and can be overridden by the settimeout or settimeouts methods.</p> <p>The <code>&lt;time&gt;</code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., \"second\". The default setting is <code>60s</code>.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_send_lowat","title":"lua_socket_send_lowat","text":"<p>syntax: lua_socket_send_lowat &lt;size&gt;</p> <p>default: lua_socket_send_lowat 0</p> <p>context: http, server, location</p> <p>Controls the <code>lowat</code> (low water) value for the cosocket send buffer.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_read_timeout","title":"lua_socket_read_timeout","text":"<p>syntax: lua_socket_read_timeout &lt;time&gt;</p> <p>default: lua_socket_read_timeout 60s</p> <p>context: http, server, location</p> <p>phase: depends on usage</p> <p>This directive controls the default timeout value used in TCP/unix-domain socket object's receive method and iterator functions returned by the receiveuntil method. This setting can be overridden by the settimeout or settimeouts methods.</p> <p>The <code>&lt;time&gt;</code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., \"second\". The default setting is <code>60s</code>.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_buffer_size","title":"lua_socket_buffer_size","text":"<p>syntax: lua_socket_buffer_size &lt;size&gt;</p> <p>default: lua_socket_buffer_size 4k/8k</p> <p>context: http, server, location</p> <p>Specifies the buffer size used by cosocket reading operations.</p> <p>This buffer does not have to be that big to hold everything at the same time because cosocket supports 100% non-buffered reading and parsing. So even <code>1</code> byte buffer size should still work everywhere but the performance could be terrible.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_pool_size","title":"lua_socket_pool_size","text":"<p>syntax: lua_socket_pool_size &lt;size&gt;</p> <p>default: lua_socket_pool_size 30</p> <p>context: http, server, location</p> <p>Specifies the size limit (in terms of connection count) for every cosocket connection pool associated with every remote server (i.e., identified by either the host-port pair or the unix domain socket file path).</p> <p>Default to 30 connections for every pool.</p> <p>When the connection pool exceeds the available size limit, the least recently used (idle) connection already in the pool will be closed to make room for the current connection.</p> <p>Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so size limit specified here also applies to every single Nginx worker process.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_keepalive_timeout","title":"lua_socket_keepalive_timeout","text":"<p>syntax: lua_socket_keepalive_timeout &lt;time&gt;</p> <p>default: lua_socket_keepalive_timeout 60s</p> <p>context: http, server, location</p> <p>This directive controls the default maximal idle time of the connections in the cosocket built-in connection pool. When this timeout reaches, idle connections will be closed and removed from the pool. This setting can be overridden by cosocket objects' setkeepalive method.</p> <p>The <code>&lt;time&gt;</code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., \"second\". The default setting is <code>60s</code>.</p> <p>This directive was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_socket_log_errors","title":"lua_socket_log_errors","text":"<p>syntax: lua_socket_log_errors on|off</p> <p>default: lua_socket_log_errors on</p> <p>context: http, server, location</p> <p>This directive can be used to toggle error logging when a failure occurs for the TCP or UDP cosockets. If you are already doing proper error handling and logging in your Lua code, then it is recommended to turn this directive off to prevent data flushing in your Nginx error log files (which is usually rather expensive).</p> <p>This directive was first introduced in the <code>v0.5.13</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_ciphers","title":"lua_ssl_ciphers","text":"<p>syntax: lua_ssl_ciphers &lt;ciphers&gt;</p> <p>default: lua_ssl_ciphers DEFAULT</p> <p>context: http, server, location</p> <p>Specifies the enabled ciphers for requests to a SSL/TLS server in the tcpsock:sslhandshake method. The ciphers are specified in the format understood by the OpenSSL library.</p> <p>The full list can be viewed using the \u201copenssl ciphers\u201d command.</p> <p>This directive was first introduced in the <code>v0.9.11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_crl","title":"lua_ssl_crl","text":"<p>syntax: lua_ssl_crl &lt;file&gt;</p> <p>default: no</p> <p>context: http, server, location</p> <p>Specifies a file with revoked certificates (CRL) in the PEM format used to verify the certificate of the SSL/TLS server in the tcpsock:sslhandshake method.</p> <p>This directive was first introduced in the <code>v0.9.11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_protocols","title":"lua_ssl_protocols","text":"<p>syntax: lua_ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3]</p> <p>default: lua_ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3</p> <p>context: http, server, location</p> <p>Enables the specified protocols for requests to a SSL/TLS server in the tcpsock:sslhandshake method.</p> <p>The support for the <code>TLSv1.3</code> parameter requires version <code>v0.10.12</code> and OpenSSL 1.1.1. From version v0.10.25, the default value change from <code>SSLV3 TLSv1 TLSv1.1 TLSv1.2</code> to <code>TLSv1 TLSv1.1 TLSv1.2 TLSv1.3</code>.</p> <p>This directive was first introduced in the <code>v0.9.11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_certificate","title":"lua_ssl_certificate","text":"<p>syntax: lua_ssl_certificate &lt;file&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Specifies the file path to the SSL/TLS certificate in PEM format used for the tcpsock:sslhandshake method.</p> <p>This directive allows you to specify the SSL/TLS certificate that will be presented to server during the SSL/TLS handshake process.</p> <p>This directive was first introduced in the <code>v0.10.26</code> release.</p> <p>See also lua_ssl_certificate_key and lua_ssl_verify_depth.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_certificate_key","title":"lua_ssl_certificate_key","text":"<p>syntax: lua_ssl_certificate_key &lt;file&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Specifies the file path to the private key associated with the SSL/TLS certificate used in the tcpsock:sslhandshake method.</p> <p>This directive allows you to specify the private key file corresponding to the SSL/TLS certificate specified by lua_ssl_certificate. The private key should be in PEM format and must match the certificate.</p> <p>This directive was first introduced in the <code>v0.10.26</code> release.</p> <p>See also lua_ssl_certificate and lua_ssl_verify_depth.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_trusted_certificate","title":"lua_ssl_trusted_certificate","text":"<p>syntax: lua_ssl_trusted_certificate &lt;file&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Specifies a file path with trusted CA certificates in the PEM format used to verify the certificate of the SSL/TLS server in the tcpsock:sslhandshake method.</p> <p>This directive was first introduced in the <code>v0.9.11</code> release.</p> <p>See also lua_ssl_verify_depth.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_verify_depth","title":"lua_ssl_verify_depth","text":"<p>syntax: lua_ssl_verify_depth &lt;number&gt;</p> <p>default: lua_ssl_verify_depth 1</p> <p>context: http, server, location</p> <p>Sets the verification depth in the server certificates chain.</p> <p>This directive was first introduced in the <code>v0.9.11</code> release.</p> <p>See also lua_ssl_certificate, lua_ssl_certificate_key and lua_ssl_trusted_certificate.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_key_log","title":"lua_ssl_key_log","text":"<p>syntax: lua_ssl_key_log &lt;file&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Enables logging of client connection SSL keys in the tcpsock:sslhandshake method and specifies the path to the key log file. Keys are logged in the SSLKEYLOGFILE format compatible with Wireshark.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_ssl_conf_command","title":"lua_ssl_conf_command","text":"<p>syntax: lua_ssl_conf_command &lt;command&gt;</p> <p>default: no</p> <p>context: http, server, location</p> <p>Sets arbitrary OpenSSL configuration commands.</p> <p>The directive is supported when using OpenSSL 1.0.2 or higher and nginx 1.19.4 or higher. According to the specify command, higher OpenSSL version may be needed.</p> <p>Several <code>lua_ssl_conf_command</code> directives can be specified on the same level:</p> <pre><code> lua_ssl_conf_command Options PrioritizeChaCha;\n lua_ssl_conf_command Ciphersuites TLS_CHACHA20_POLY1305_SHA256;\n</code></pre> <p>Configuration commands are applied after OpenResty own configuration for SSL, so they can be used to override anything set by OpenResty.</p> <p>Note though that configuring OpenSSL directly with <code>lua_ssl_conf_command</code> might result in a behaviour OpenResty does not expect, and should be done with care.</p> <p>This directive was first introduced in the <code>v0.10.21</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_upstream_skip_openssl_default_verify","title":"lua_upstream_skip_openssl_default_verify","text":"<p>syntax: lua_upstream_skip_openssl_default_verify on|off</p> <p>default: lua_upstream_skip_openssl_default_verify off</p> <p>context: location, location-if</p> <p>When using proxy_ssl_verify_by_lua directive, <code>lua_upstream_skip_openssl_default_verify</code> controls whether to skip default openssl's verify function, that means using pure Lua code to verify upstream server certificate.</p> <p>This directive is turned <code>off</code> by default.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_http10_buffering","title":"lua_http10_buffering","text":"<p>syntax: lua_http10_buffering on|off</p> <p>default: lua_http10_buffering on</p> <p>context: http, server, location, location-if</p> <p>Enables or disables automatic response buffering for HTTP 1.0 (or older) requests. This buffering mechanism is mainly used for HTTP 1.0 keep-alive which relies on a proper <code>Content-Length</code> response header.</p> <p>If the Lua code explicitly sets a <code>Content-Length</code> response header before sending the headers (either explicitly via ngx.send_headers or implicitly via the first ngx.say or ngx.print call), then the HTTP 1.0 response buffering will be disabled even when this directive is turned on.</p> <p>To output very large response data in a streaming fashion (via the ngx.flush call, for example), this directive MUST be turned off to minimize memory usage.</p> <p>This directive is turned <code>on</code> by default.</p> <p>This directive was first introduced in the <code>v0.5.0rc19</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#rewrite_by_lua_no_postpone","title":"rewrite_by_lua_no_postpone","text":"<p>syntax: rewrite_by_lua_no_postpone on|off</p> <p>default: rewrite_by_lua_no_postpone off</p> <p>context: http</p> <p>Controls whether or not to disable postponing rewrite_by_lua* directives to run at the end of the <code>rewrite</code> request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the <code>rewrite</code> phase.</p> <p>This directive was first introduced in the <code>v0.5.0rc29</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#access_by_lua_no_postpone","title":"access_by_lua_no_postpone","text":"<p>syntax: access_by_lua_no_postpone on|off</p> <p>default: access_by_lua_no_postpone off</p> <p>context: http</p> <p>Controls whether or not to disable postponing access_by_lua* directives to run at the end of the <code>access</code> request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the <code>access</code> phase.</p> <p>This directive was first introduced in the <code>v0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_transform_underscores_in_response_headers","title":"lua_transform_underscores_in_response_headers","text":"<p>syntax: lua_transform_underscores_in_response_headers on|off</p> <p>default: lua_transform_underscores_in_response_headers on</p> <p>context: http, server, location, location-if</p> <p>Controls whether to transform underscores (<code>_</code>) in the response header names specified in the ngx.header.HEADER API to hyphens (<code>-</code>).</p> <p>This directive was first introduced in the <code>v0.5.0rc32</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_check_client_abort","title":"lua_check_client_abort","text":"<p>syntax: lua_check_client_abort on|off</p> <p>default: lua_check_client_abort off</p> <p>context: http, server, location, location-if</p> <p>This directive controls whether to check for premature client connection abortion.</p> <p>When this directive is on, the ngx_lua module will monitor the premature connection close event on the downstream connections and when there is such an event, it will call the user Lua function callback (registered by ngx.on_abort) or just stop and clean up all the Lua \"light threads\" running in the current request's request handler when there is no user callback function registered.</p> <p>According to the current implementation, however, if the client closes the connection before the Lua code finishes reading the request body data via ngx.req.socket, then ngx_lua will neither stop all the running \"light threads\" nor call the user callback (if ngx.on_abort has been called). Instead, the reading operation on ngx.req.socket will just return the error message \"client aborted\" as the second return value (the first return value is surely <code>nil</code>).</p> <p>When TCP keepalive is disabled, it is relying on the client side to close the socket gracefully (by sending a <code>FIN</code> packet or something like that). For (soft) real-time web applications, it is highly recommended to configure the TCP keepalive support in your system's TCP stack implementation in order to detect \"half-open\" TCP connections in time.</p> <p>For example, on Linux, you can configure the standard listen directive in your <code>nginx.conf</code> file like this:</p> <pre><code> listen 80 so_keepalive=2s:2s:8;\n</code></pre> <p>On FreeBSD, you can only tune the system-wide configuration for TCP keepalive, for example:</p> <pre><code># sysctl net.inet.tcp.keepintvl=2000\n# sysctl net.inet.tcp.keepidle=2000\n</code></pre> <p>This directive was first introduced in the <code>v0.7.4</code> release.</p> <p>See also ngx.on_abort.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_max_pending_timers","title":"lua_max_pending_timers","text":"<p>syntax: lua_max_pending_timers &lt;count&gt;</p> <p>default: lua_max_pending_timers 1024</p> <p>context: http</p> <p>Controls the maximum number of pending timers allowed.</p> <p>Pending timers are those timers that have not expired yet.</p> <p>When exceeding this limit, the ngx.timer.at call will immediately return <code>nil</code> and the error string \"too many pending timers\".</p> <p>This directive was first introduced in the <code>v0.8.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_max_running_timers","title":"lua_max_running_timers","text":"<p>syntax: lua_max_running_timers &lt;count&gt;</p> <p>default: lua_max_running_timers 256</p> <p>context: http</p> <p>Controls the maximum number of \"running timers\" allowed.</p> <p>Running timers are those timers whose user callback functions are still running or <code>lightthreads</code> spawned in callback functions are still running.</p> <p>When exceeding this limit, Nginx will stop running the callbacks of newly expired timers and log an error message \"N lua_max_running_timers are not enough\" where \"N\" is the current value of this directive.</p> <p>This directive was first introduced in the <code>v0.8.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_sa_restart","title":"lua_sa_restart","text":"<p>syntax: lua_sa_restart on|off</p> <p>default: lua_sa_restart on</p> <p>context: http</p> <p>When enabled, this module will set the <code>SA_RESTART</code> flag on Nginx workers signal dispositions.</p> <p>This allows Lua I/O primitives to not be interrupted by Nginx's handling of various signals.</p> <p>This directive was first introduced in the <code>v0.10.14</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#lua_worker_thread_vm_pool_size","title":"lua_worker_thread_vm_pool_size","text":"<p>syntax: lua_worker_thread_vm_pool_size &lt;size&gt;</p> <p>default: lua_worker_thread_vm_pool_size 10</p> <p>context: http</p> <p>Specifies the size limit of the Lua VM pool (default 100) that will be used in the ngx.run_worker_thread API.</p> <p>Also, it is not allowed to create Lua VMs that exceeds the pool size limit.</p> <p>The Lua VM in the VM pool is used to execute Lua code in separate thread.</p> <p>The pool is global at Nginx worker level. And it is used to reuse Lua VMs between requests.</p> <p>Warning: Each worker thread uses a separate Lua VM and caches the Lua VM for reuse in subsequent operations. Configuring too many worker threads can result in consuming a lot of memory.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#nginx-api-for-lua","title":"Nginx API for Lua","text":"<ul> <li>Introduction</li> <li>ngx.arg</li> <li>ngx.var.VARIABLE</li> <li>Core constants</li> <li>HTTP method constants</li> <li>HTTP status constants</li> <li>Nginx log level constants</li> <li>print</li> <li>ngx.ctx</li> <li>ngx.location.capture</li> <li>ngx.location.capture_multi</li> <li>ngx.status</li> <li>ngx.header.HEADER</li> <li>ngx.resp.get_headers</li> <li>ngx.req.is_internal</li> <li>ngx.req.start_time</li> <li>ngx.req.http_version</li> <li>ngx.req.raw_header</li> <li>ngx.req.get_method</li> <li>ngx.req.set_method</li> <li>ngx.req.set_uri</li> <li>ngx.req.set_uri_args</li> <li>ngx.req.get_uri_args</li> <li>ngx.req.get_post_args</li> <li>ngx.req.get_headers</li> <li>ngx.req.set_header</li> <li>ngx.req.clear_header</li> <li>ngx.req.read_body</li> <li>ngx.req.discard_body</li> <li>ngx.req.get_body_data</li> <li>ngx.req.get_body_file</li> <li>ngx.req.set_body_data</li> <li>ngx.req.set_body_file</li> <li>ngx.req.init_body</li> <li>ngx.req.append_body</li> <li>ngx.req.finish_body</li> <li>ngx.req.socket</li> <li>ngx.exec</li> <li>ngx.redirect</li> <li>ngx.send_headers</li> <li>ngx.headers_sent</li> <li>ngx.print</li> <li>ngx.say</li> <li>ngx.log</li> <li>ngx.flush</li> <li>ngx.exit</li> <li>ngx.eof</li> <li>ngx.sleep</li> <li>ngx.escape_uri</li> <li>ngx.unescape_uri</li> <li>ngx.encode_args</li> <li>ngx.decode_args</li> <li>ngx.encode_base64</li> <li>ngx.decode_base64</li> <li>ngx.decode_base64mime</li> <li>ngx.crc32_short</li> <li>ngx.crc32_long</li> <li>ngx.hmac_sha1</li> <li>ngx.md5</li> <li>ngx.md5_bin</li> <li>ngx.sha1_bin</li> <li>ngx.quote_sql_str</li> <li>ngx.today</li> <li>ngx.time</li> <li>ngx.now</li> <li>ngx.update_time</li> <li>ngx.localtime</li> <li>ngx.utctime</li> <li>ngx.cookie_time</li> <li>ngx.http_time</li> <li>ngx.parse_http_time</li> <li>ngx.is_subrequest</li> <li>ngx.re.match</li> <li>ngx.re.find</li> <li>ngx.re.gmatch</li> <li>ngx.re.sub</li> <li>ngx.re.gsub</li> <li>ngx.shared.DICT</li> <li>ngx.shared.DICT.get</li> <li>ngx.shared.DICT.get_stale</li> <li>ngx.shared.DICT.set</li> <li>ngx.shared.DICT.safe_set</li> <li>ngx.shared.DICT.add</li> <li>ngx.shared.DICT.safe_add</li> <li>ngx.shared.DICT.replace</li> <li>ngx.shared.DICT.delete</li> <li>ngx.shared.DICT.incr</li> <li>ngx.shared.DICT.lpush</li> <li>ngx.shared.DICT.rpush</li> <li>ngx.shared.DICT.lpop</li> <li>ngx.shared.DICT.rpop</li> <li>ngx.shared.DICT.llen</li> <li>ngx.shared.DICT.ttl</li> <li>ngx.shared.DICT.expire</li> <li>ngx.shared.DICT.flush_all</li> <li>ngx.shared.DICT.flush_expired</li> <li>ngx.shared.DICT.get_keys</li> <li>ngx.shared.DICT.capacity</li> <li>ngx.shared.DICT.free_space</li> <li>ngx.socket.udp</li> <li>udpsock:bind</li> <li>udpsock:setpeername</li> <li>udpsock:send</li> <li>udpsock:receive</li> <li>udpsock:close</li> <li>udpsock:settimeout</li> <li>ngx.socket.stream</li> <li>ngx.socket.tcp</li> <li>tcpsock:bind</li> <li>tcpsock:connect</li> <li>tcpsock:getfd</li> <li>tcpsock:setclientcert</li> <li>tcpsock:sslhandshake</li> <li>tcpsock:send</li> <li>tcpsock:receive</li> <li>tcpsock:receiveany</li> <li>tcpsock:receiveuntil</li> <li>tcpsock:close</li> <li>tcpsock:settimeout</li> <li>tcpsock:settimeouts</li> <li>tcpsock:setoption</li> <li>tcpsock:setkeepalive</li> <li>tcpsock:getreusedtimes</li> <li>ngx.socket.connect</li> <li>ngx.get_phase</li> <li>ngx.thread.spawn</li> <li>ngx.thread.wait</li> <li>ngx.thread.kill</li> <li>ngx.on_abort</li> <li>ngx.timer.at</li> <li>ngx.timer.every</li> <li>ngx.timer.running_count</li> <li>ngx.timer.pending_count</li> <li>ngx.config.subsystem</li> <li>ngx.config.debug</li> <li>ngx.config.prefix</li> <li>ngx.config.nginx_version</li> <li>ngx.config.nginx_configure</li> <li>ngx.config.ngx_lua_version</li> <li>ngx.worker.exiting</li> <li>ngx.worker.pid</li> <li>ngx.worker.pids</li> <li>ngx.worker.count</li> <li>ngx.worker.id</li> <li>ngx.semaphore</li> <li>ngx.balancer</li> <li>ngx.ssl</li> <li>ngx.ocsp</li> <li>ndk.set_var.DIRECTIVE</li> <li>coroutine.create</li> <li>coroutine.resume</li> <li>coroutine.yield</li> <li>coroutine.wrap</li> <li>coroutine.running</li> <li>coroutine.status</li> <li>ngx.run_worker_thread</li> </ul>"},{"location":"modules/lua/#introduction","title":"Introduction","text":"<p>The various <code>*_by_lua</code>, <code>*_by_lua_block</code> and <code>*_by_lua_file</code> configuration directives serve as gateways to the Lua API within the <code>nginx.conf</code> file. The Nginx Lua API described below can only be called within the user Lua code run in the context of these configuration directives.</p> <p>The API is exposed to Lua in the form of two standard packages <code>ngx</code> and <code>ndk</code>. These packages are in the default global scope within ngx_lua and are always available within ngx_lua directives.</p> <p>The packages can be introduced into external Lua modules like this:</p> <pre><code> local say = ngx.say\n\n local _M = {}\n\n function _M.foo(a)\n     say(a)\n end\n\n return _M\n</code></pre> <p>Use of the package.seeall flag is strongly discouraged due to its various bad side-effects.</p> <p>It is also possible to directly require the packages in external Lua modules:</p> <pre><code> local ngx = require \"ngx\"\n local ndk = require \"ndk\"\n</code></pre> <p>The ability to require these packages was introduced in the <code>v0.2.1rc19</code> release.</p> <p>Network I/O operations in user code should only be done through the Nginx Lua API calls as the Nginx event loop may be blocked and performance drop off dramatically otherwise. Disk operations with relatively small amount of data can be done using the standard Lua <code>io</code> library but huge file reading and writing should be avoided wherever possible as they may block the Nginx process significantly. Delegating all network and disk I/O operations to Nginx's subrequests (via the ngx.location.capture method and similar) is strongly recommended for maximum performance.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxarg","title":"ngx.arg","text":"<p>syntax: val = ngx.arg[index]</p> <p>context: set_by_lua*, body_filter_by_lua*</p> <p>When this is used in the context of the set_by_lua* directives, this table is read-only and holds the input arguments to the config directives:</p> <pre><code> value = ngx.arg[n]\n</code></pre> <p>Here is an example</p> <pre><code> location /foo {\n     set $a 32;\n     set $b 56;\n\n     set_by_lua $sum\n         'return tonumber(ngx.arg[1]) + tonumber(ngx.arg[2])'\n         $a $b;\n\n     echo $sum;\n }\n</code></pre> <p>that writes out <code>88</code>, the sum of <code>32</code> and <code>56</code>.</p> <p>When this table is used in the context of body_filter_by_lua*, the first element holds the input data chunk to the output filter code and the second element holds the boolean flag for the \"eof\" flag indicating the end of the whole output data stream.</p> <p>The data chunk and \"eof\" flag passed to the downstream Nginx output filters can also be overridden by assigning values directly to the corresponding table elements. When setting <code>nil</code> or an empty Lua string value to <code>ngx.arg[1]</code>, no data chunk will be passed to the downstream Nginx output filters at all.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxvarvariable","title":"ngx.var.VARIABLE","text":"<p>syntax: ngx.var.VAR_NAME</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*</p> <p>Read and write Nginx variable values.</p> <pre><code> value = ngx.var.some_nginx_variable_name\n ngx.var.some_nginx_variable_name = value\n</code></pre> <p>Note that only already defined Nginx variables can be written to. For example:</p> <pre><code> location /foo {\n     set $my_var ''; # this line is required to create $my_var at config time\n     content_by_lua_block {\n         ngx.var.my_var = 123\n         ...\n     }\n }\n</code></pre> <p>That is, Nginx variables cannot be created on-the-fly. Here is a list of pre-defined Nginx variables.</p> <p>Some special Nginx variables like <code>$args</code> and <code>$limit_rate</code> can be assigned a value, many others are not, like <code>$query_string</code>, <code>$arg_PARAMETER</code>, and <code>$http_NAME</code>.</p> <p>Nginx regex group capturing variables <code>$1</code>, <code>$2</code>, <code>$3</code>, and etc, can be read by this interface as well, by writing <code>ngx.var[1]</code>, <code>ngx.var[2]</code>, <code>ngx.var[3]</code>, and etc.</p> <p>Setting <code>ngx.var.Foo</code> to a <code>nil</code> value will unset the <code>$Foo</code> Nginx variable.</p> <pre><code> ngx.var.args = nil\n</code></pre> <p>CAUTION When reading from an Nginx variable, Nginx will allocate memory in the per-request memory pool which is freed only at request termination. So when you need to read from an Nginx variable repeatedly in your Lua code, cache the Nginx variable value to your own Lua variable, for example,</p> <pre><code> local val = ngx.var.some_var\n --- use the val repeatedly later\n</code></pre> <p>to prevent (temporary) memory leaking within the current request's lifetime. Another way of caching the result is to use the ngx.ctx table.</p> <p>Undefined Nginx variables are evaluated to <code>nil</code> while uninitialized (but defined) Nginx variables are evaluated to an empty Lua string.</p> <p>This API requires a relatively expensive metamethod call and it is recommended to avoid using it on hot code paths.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#core-constants","title":"Core constants","text":"<p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, *log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <pre><code>   ngx.OK (0)\n   ngx.ERROR (-1)\n   ngx.AGAIN (-2)\n   ngx.DONE (-4)\n   ngx.DECLINED (-5)\n</code></pre> <p>Note that only three of these constants are utilized by the Nginx API for Lua (i.e., ngx.exit accepts <code>ngx.OK</code>, <code>ngx.ERROR</code>, and <code>ngx.DECLINED</code> as input).</p> <pre><code>   ngx.null\n</code></pre> <p>The <code>ngx.null</code> constant is a <code>NULL</code> light userdata usually used to represent nil values in Lua tables etc and is similar to the lua-cjson library's <code>cjson.null</code> constant. This constant was first introduced in the <code>v0.5.0rc5</code> release.</p> <p>The <code>ngx.DECLINED</code> constant was first introduced in the <code>v0.5.0rc19</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#http-method-constants","title":"HTTP method constants","text":"<p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <pre><code>  ngx.HTTP_GET\n  ngx.HTTP_HEAD\n  ngx.HTTP_PUT\n  ngx.HTTP_POST\n  ngx.HTTP_DELETE\n  ngx.HTTP_OPTIONS   (added in the v0.5.0rc24 release)\n  ngx.HTTP_MKCOL     (added in the v0.8.2 release)\n  ngx.HTTP_COPY      (added in the v0.8.2 release)\n  ngx.HTTP_MOVE      (added in the v0.8.2 release)\n  ngx.HTTP_PROPFIND  (added in the v0.8.2 release)\n  ngx.HTTP_PROPPATCH (added in the v0.8.2 release)\n  ngx.HTTP_LOCK      (added in the v0.8.2 release)\n  ngx.HTTP_UNLOCK    (added in the v0.8.2 release)\n  ngx.HTTP_PATCH     (added in the v0.8.2 release)\n  ngx.HTTP_TRACE     (added in the v0.8.2 release)\n</code></pre> <p>These constants are usually used in ngx.location.capture and ngx.location.capture_multi method calls.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#http-status-constants","title":"HTTP status constants","text":"<p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <pre><code>   value = ngx.HTTP_CONTINUE (100) (first added in the v0.9.20 release)\n   value = ngx.HTTP_SWITCHING_PROTOCOLS (101) (first added in the v0.9.20 release)\n   value = ngx.HTTP_OK (200)\n   value = ngx.HTTP_CREATED (201)\n   value = ngx.HTTP_ACCEPTED (202) (first added in the v0.9.20 release)\n   value = ngx.HTTP_NO_CONTENT (204) (first added in the v0.9.20 release)\n   value = ngx.HTTP_PARTIAL_CONTENT (206) (first added in the v0.9.20 release)\n   value = ngx.HTTP_SPECIAL_RESPONSE (300)\n   value = ngx.HTTP_MOVED_PERMANENTLY (301)\n   value = ngx.HTTP_MOVED_TEMPORARILY (302)\n   value = ngx.HTTP_SEE_OTHER (303)\n   value = ngx.HTTP_NOT_MODIFIED (304)\n   value = ngx.HTTP_TEMPORARY_REDIRECT (307) (first added in the v0.9.20 release)\n   value = ngx.HTTP_PERMANENT_REDIRECT (308)\n   value = ngx.HTTP_BAD_REQUEST (400)\n   value = ngx.HTTP_UNAUTHORIZED (401)\n   value = ngx.HTTP_PAYMENT_REQUIRED (402) (first added in the v0.9.20 release)\n   value = ngx.HTTP_FORBIDDEN (403)\n   value = ngx.HTTP_NOT_FOUND (404)\n   value = ngx.HTTP_NOT_ALLOWED (405)\n   value = ngx.HTTP_NOT_ACCEPTABLE (406) (first added in the v0.9.20 release)\n   value = ngx.HTTP_REQUEST_TIMEOUT (408) (first added in the v0.9.20 release)\n   value = ngx.HTTP_CONFLICT (409) (first added in the v0.9.20 release)\n   value = ngx.HTTP_GONE (410)\n   value = ngx.HTTP_UPGRADE_REQUIRED (426) (first added in the v0.9.20 release)\n   value = ngx.HTTP_TOO_MANY_REQUESTS (429) (first added in the v0.9.20 release)\n   value = ngx.HTTP_CLOSE (444) (first added in the v0.9.20 release)\n   value = ngx.HTTP_ILLEGAL (451) (first added in the v0.9.20 release)\n   value = ngx.HTTP_INTERNAL_SERVER_ERROR (500)\n   value = ngx.HTTP_NOT_IMPLEMENTED (501)\n   value = ngx.HTTP_METHOD_NOT_IMPLEMENTED (501) (kept for compatibility)\n   value = ngx.HTTP_BAD_GATEWAY (502) (first added in the v0.9.20 release)\n   value = ngx.HTTP_SERVICE_UNAVAILABLE (503)\n   value = ngx.HTTP_GATEWAY_TIMEOUT (504) (first added in the v0.3.1rc38 release)\n   value = ngx.HTTP_VERSION_NOT_SUPPORTED (505) (first added in the v0.9.20 release)\n   value = ngx.HTTP_INSUFFICIENT_STORAGE (507) (first added in the v0.9.20 release)\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#nginx-log-level-constants","title":"Nginx log level constants","text":"<p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <pre><code>   ngx.STDERR\n   ngx.EMERG\n   ngx.ALERT\n   ngx.CRIT\n   ngx.ERR\n   ngx.WARN\n   ngx.NOTICE\n   ngx.INFO\n   ngx.DEBUG\n</code></pre> <p>These constants are usually used by the ngx.log method.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#print","title":"print","text":"<p>syntax: print(...)</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Writes argument values into the Nginx <code>error.log</code> file with the <code>ngx.NOTICE</code> log level.</p> <p>It is equivalent to</p> <pre><code> ngx.log(ngx.NOTICE, ...)\n</code></pre> <p>Lua <code>nil</code> arguments are accepted and result in literal <code>\"nil\"</code> strings while Lua booleans result in literal <code>\"true\"</code> or <code>\"false\"</code> strings. And the <code>ngx.null</code> constant will yield the <code>\"null\"</code> string output.</p> <p>There is a hard coded <code>2048</code> byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the <code>NGX_MAX_ERROR_STR</code> macro definition in the <code>src/core/ngx_log.h</code> file in the Nginx source tree.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxctx","title":"ngx.ctx","text":"<p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, exit_worker_by_lua*</p> <p>This table can be used to store per-request Lua context data and has a life time identical to the current request (as with the Nginx variables).</p> <p>Consider the following example,</p> <pre><code> location /test {\n     rewrite_by_lua_block {\n         ngx.ctx.foo = 76\n     }\n     access_by_lua_block {\n         ngx.ctx.foo = ngx.ctx.foo + 3\n     }\n     content_by_lua_block {\n         ngx.say(ngx.ctx.foo)\n     }\n }\n</code></pre> <p>Then <code>GET /test</code> will yield the output</p> <pre><code> 79\n</code></pre> <p>That is, the <code>ngx.ctx.foo</code> entry persists across the rewrite, access, and content phases of a request.</p> <p>Every request, including subrequests, has its own copy of the table. For example:</p> <pre><code> location /sub {\n     content_by_lua_block {\n         ngx.say(\"sub pre: \", ngx.ctx.blah)\n         ngx.ctx.blah = 32\n         ngx.say(\"sub post: \", ngx.ctx.blah)\n     }\n }\n\n location /main {\n     content_by_lua_block {\n         ngx.ctx.blah = 73\n         ngx.say(\"main pre: \", ngx.ctx.blah)\n         local res = ngx.location.capture(\"/sub\")\n         ngx.print(res.body)\n         ngx.say(\"main post: \", ngx.ctx.blah)\n     }\n }\n</code></pre> <p>Then <code>GET /main</code> will give the output</p> <pre><code> main pre: 73\n sub pre: nil\n sub post: 32\n main post: 73\n</code></pre> <p>Here, modification of the <code>ngx.ctx.blah</code> entry in the subrequest does not affect the one in the parent request. This is because they have two separate versions of <code>ngx.ctx.blah</code>.</p> <p>Internal redirects (triggered by nginx configuration directives like <code>error_page</code>, <code>try_files</code>, <code>index</code>, etc.) will destroy the original request <code>ngx.ctx</code> data (if any) and the new request will have an empty <code>ngx.ctx</code> table. For instance,</p> <pre><code> location /new {\n     content_by_lua_block {\n         ngx.say(ngx.ctx.foo)\n     }\n }\n\n location /orig {\n     content_by_lua_block {\n         ngx.ctx.foo = \"hello\"\n         ngx.exec(\"/new\")\n     }\n }\n</code></pre> <p>Then <code>GET /orig</code> will give</p> <pre><code> nil\n</code></pre> <p>rather than the original <code>\"hello\"</code> value.</p> <p>Because HTTP request is created after SSL handshake, the <code>ngx.ctx</code> created in ssl_certificate_by_lua*, ssl_session_store_by_lua*, ssl_session_fetch_by_lua* and ssl_client_hello_by_lua* is not available in the following phases like rewrite_by_lua*.</p> <p>Since <code>v0.10.18</code>, the <code>ngx.ctx</code> created during a SSL handshake will be inherited by the requests which share the same TCP connection established by the handshake. Note that overwrite values in <code>ngx.ctx</code> in the http request phases (like <code>rewrite_by_lua*</code>) will only take affect in the current http request.</p> <p>Arbitrary data values, including Lua closures and nested tables, can be inserted into this \"magic\" table. It also allows the registration of custom meta methods.</p> <p>Overriding <code>ngx.ctx</code> with a new Lua table is also supported, for example,</p> <pre><code> ngx.ctx = { foo = 32, bar = 54 }\n</code></pre> <p>When being used in the context of init_worker_by_lua*, this table just has the same lifetime of the current Lua handler.</p> <p>The <code>ngx.ctx</code> lookup requires relatively expensive metamethod calls and it is much slower than explicitly passing per-request data along by your own function arguments. So do not abuse this API for saving your own function arguments because it usually has quite some performance impact.</p> <p>Because of the metamethod magic, never \"local\" the <code>ngx.ctx</code> table outside your Lua function scope on the Lua module level due to worker-level data sharing. For example, the following is bad:</p> <pre><code> -- mymodule.lua\n local _M = {}\n\n -- the following line is bad since ngx.ctx is a per-request\n -- data while this &lt;code&gt;ctx&lt;/code&gt; variable is on the Lua module level\n -- and thus is per-nginx-worker.\n local ctx = ngx.ctx\n\n function _M.main()\n     ctx.foo = \"bar\"\n end\n\n return _M\n</code></pre> <p>Use the following instead:</p> <pre><code> -- mymodule.lua\n local _M = {}\n\n function _M.main(ctx)\n     ctx.foo = \"bar\"\n end\n\n return _M\n</code></pre> <p>That is, let the caller pass the <code>ctx</code> table explicitly via a function argument.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxlocationcapture","title":"ngx.location.capture","text":"<p>syntax: res = ngx.location.capture(uri, options?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Issues a synchronous but still non-blocking Nginx Subrequest using <code>uri</code>.</p> <p>Nginx's subrequests provide a powerful way to make non-blocking internal requests to other locations configured with disk file directory or any other Nginx C modules like <code>ngx_proxy</code>, <code>ngx_fastcgi</code>, <code>ngx_memc</code>, <code>ngx_postgres</code>, <code>ngx_drizzle</code>, and even ngx_lua itself and etc etc etc.</p> <p>Also note that subrequests just mimic the HTTP interface but there is no extra HTTP/TCP traffic nor IPC involved. Everything works internally, efficiently, on the C level.</p> <p>Subrequests are completely different from HTTP 301/302 redirection (via ngx.redirect) and internal redirection (via ngx.exec).</p> <p>You should always read the request body (by either calling ngx.req.read_body or configuring lua_need_request_body on) before initiating a subrequest.</p> <p>This API function (as well as ngx.location.capture_multi) always buffers the whole response body of the subrequest in memory. Thus, you should use cosockets and streaming processing instead if you have to handle large subrequest responses.</p> <p>Here is a basic example:</p> <pre><code> res = ngx.location.capture(uri)\n</code></pre> <p>Returns a Lua table with 4 slots: <code>res.status</code>, <code>res.header</code>, <code>res.body</code>, and <code>res.truncated</code>.</p> <p><code>res.status</code> holds the response status code for the subrequest response.</p> <p><code>res.header</code> holds all the response headers of the subrequest and it is a normal Lua table. For multi-value response headers, the value is a Lua (array) table that holds all the values in the order that they appear. For instance, if the subrequest response headers contain the following lines:</p> <pre><code> Set-Cookie: a=3\n Set-Cookie: foo=bar\n Set-Cookie: baz=blah\n</code></pre> <p>Then <code>res.header[\"Set-Cookie\"]</code> will be evaluated to the table value <code>{\"a=3\", \"foo=bar\", \"baz=blah\"}</code>.</p> <p><code>res.body</code> holds the subrequest's response body data, which might be truncated. You always need to check the <code>res.truncated</code> boolean flag to see if <code>res.body</code> contains truncated data. The data truncation here can only be caused by those unrecoverable errors in your subrequests like the cases that the remote end aborts the connection prematurely in the middle of the response body data stream or a read timeout happens when your subrequest is receiving the response body data from the remote.</p> <p>URI query strings can be concatenated to URI itself, for instance,</p> <pre><code> res = ngx.location.capture('/foo/bar?a=3&amp;b=4')\n</code></pre> <p>Named locations like <code>@foo</code> are not allowed due to a limitation in the Nginx core. Use normal locations combined with the <code>internal</code> directive to prepare internal-only locations.</p> <p>An optional option table can be fed as the second argument, which supports the options:</p> <ul> <li><code>method</code>     specify the subrequest's request method, which only accepts constants like <code>ngx.HTTP_POST</code>.</li> <li><code>body</code>     specify the subrequest's request body (string value only).</li> <li><code>args</code>     specify the subrequest's URI query arguments (both string value and Lua tables are accepted)</li> <li><code>headers</code>     specify the subrequest's request headers (Lua table only). this headers will override the original headers of the subrequest.</li> <li><code>ctx</code>     specify a Lua table to be the ngx.ctx table for the subrequest. It can be the current request's ngx.ctx table, which effectively makes the parent and its subrequest to share exactly the same context table. This option was first introduced in the <code>v0.3.1rc25</code> release.</li> <li><code>vars</code>     take a Lua table which holds the values to set the specified Nginx variables in the subrequest as this option's value. This option was first introduced in the <code>v0.3.1rc31</code> release.</li> <li><code>copy_all_vars</code>     specify whether to copy over all the Nginx variable values of the current request to the subrequest in question. modifications of the Nginx variables in the subrequest will not affect the current (parent) request. This option was first introduced in the <code>v0.3.1rc31</code> release.</li> <li><code>share_all_vars</code>     specify whether to share all the Nginx variables of the subrequest with the current (parent) request. modifications of the Nginx variables in the subrequest will affect the current (parent) request. Enabling this option may lead to hard-to-debug issues due to bad side-effects and is considered bad and harmful. Only enable this option when you completely know what you are doing.</li> <li><code>always_forward_body</code>     when set to true, the current (parent) request's request body will always be forwarded to the subrequest being created if the <code>body</code> option is not specified. The request body read by either ngx.req.read_body() or lua_need_request_body on will be directly forwarded to the subrequest without copying the whole request body data when creating the subrequest (no matter the request body data is buffered in memory buffers or temporary files). By default, this option is <code>false</code> and when the <code>body</code> option is not specified, the request body of the current (parent) request is only forwarded when the subrequest takes the <code>PUT</code> or <code>POST</code> request method.</li> </ul> <p>Issuing a POST subrequest, for example, can be done as follows</p> <pre><code> res = ngx.location.capture(\n     '/foo/bar',\n     { method = ngx.HTTP_POST, body = 'hello, world' }\n )\n</code></pre> <p>See HTTP method constants methods other than POST. The <code>method</code> option is <code>ngx.HTTP_GET</code> by default.</p> <p>The <code>args</code> option can specify extra URI arguments, for instance,</p> <pre><code> ngx.location.capture('/foo?a=1',\n     { args = { b = 3, c = ':' } }\n )\n</code></pre> <p>is equivalent to</p> <pre><code> ngx.location.capture('/foo?a=1&amp;b=3&amp;c=%3a')\n</code></pre> <p>that is, this method will escape argument keys and values according to URI rules and concatenate them together into a complete query string. The format for the Lua table passed as the <code>args</code> argument is identical to the format used in the ngx.encode_args method.</p> <p>The <code>args</code> option can also take plain query strings:</p> <pre><code> ngx.location.capture('/foo?a=1',\n     { args = 'b=3&amp;c=%3a' }\n )\n</code></pre> <p>This is functionally identical to the previous examples.</p> <p>The <code>share_all_vars</code> option controls whether to share Nginx variables among the current request and its subrequests. If this option is set to <code>true</code>, then the current request and associated subrequests will share the same Nginx variable scope. Hence, changes to Nginx variables made by a subrequest will affect the current request.</p> <p>Care should be taken in using this option as variable scope sharing can have unexpected side effects. The <code>args</code>, <code>vars</code>, or <code>copy_all_vars</code> options are generally preferable instead.</p> <p>This option is set to <code>false</code> by default</p> <pre><code> location /other {\n     set $dog \"$dog world\";\n     echo \"$uri dog: $dog\";\n }\n\n location /lua {\n     set $dog 'hello';\n     content_by_lua_block {\n         res = ngx.location.capture(\"/other\",\n             { share_all_vars = true })\n\n         ngx.print(res.body)\n         ngx.say(ngx.var.uri, \": \", ngx.var.dog)\n     }\n }\n</code></pre> <p>Accessing location <code>/lua</code> gives</p> <pre><code>/other dog: hello world\n/lua: hello world\n</code></pre> <p>The <code>copy_all_vars</code> option provides a copy of the parent request's Nginx variables to subrequests when such subrequests are issued. Changes made to these variables by such subrequests will not affect the parent request or any other subrequests sharing the parent request's variables.</p> <pre><code> location /other {\n     set $dog \"$dog world\";\n     echo \"$uri dog: $dog\";\n }\n\n location /lua {\n     set $dog 'hello';\n     content_by_lua_block {\n         res = ngx.location.capture(\"/other\",\n             { copy_all_vars = true })\n\n         ngx.print(res.body)\n         ngx.say(ngx.var.uri, \": \", ngx.var.dog)\n     }\n }\n</code></pre> <p>Request <code>GET /lua</code> will give the output</p> <pre><code>/other dog: hello world\n/lua: hello\n</code></pre> <p>Note that if both <code>share_all_vars</code> and <code>copy_all_vars</code> are set to true, then <code>share_all_vars</code> takes precedence.</p> <p>In addition to the two settings above, it is possible to specify values for variables in the subrequest using the <code>vars</code> option. These variables are set after the sharing or copying of variables has been evaluated, and provides a more efficient method of passing specific values to a subrequest over encoding them as URL arguments and unescaping them in the Nginx config file.</p> <pre><code> location /other {\n     content_by_lua_block {\n         ngx.say(\"dog = \", ngx.var.dog)\n         ngx.say(\"cat = \", ngx.var.cat)\n     }\n }\n\n location /lua {\n     set $dog '';\n     set $cat '';\n     content_by_lua_block {\n         res = ngx.location.capture(\"/other\",\n             { vars = { dog = \"hello\", cat = 32 }})\n\n         ngx.print(res.body)\n     }\n }\n</code></pre> <p>Accessing <code>/lua</code> will yield the output</p> <pre><code>dog = hello\ncat = 32\n</code></pre> <p>The <code>headers</code> option can be used to specify the request headers for the subrequest. The value of this option should be a Lua table where the keys are the header names and the values are the header values. For example,</p> <pre><code>location /foo {\n    content_by_lua_block {\n        ngx.print(ngx.var.http_x_test)\n    }\n}\n\nlocation /lua {\n    content_by_lua_block {\n        local res = ngx.location.capture(\"/foo\", {\n            headers = {\n                [\"X-Test\"] = \"aa\",\n            }\n        })\n        ngx.print(res.body)\n    }\n}\n</code></pre> <p>Accessing <code>/lua</code> will yield the output</p> <pre><code>aa\n</code></pre> <p>The <code>ctx</code> option can be used to specify a custom Lua table to serve as the ngx.ctx table for the subrequest.</p> <pre><code> location /sub {\n     content_by_lua_block {\n         ngx.ctx.foo = \"bar\";\n     }\n }\n location /lua {\n     content_by_lua_block {\n         local ctx = {}\n         res = ngx.location.capture(\"/sub\", { ctx = ctx })\n\n         ngx.say(ctx.foo)\n         ngx.say(ngx.ctx.foo)\n     }\n }\n</code></pre> <p>Then request <code>GET /lua</code> gives</p> <pre><code>bar\nnil\n</code></pre> <p>It is also possible to use this <code>ctx</code> option to share the same ngx.ctx table between the current (parent) request and the subrequest:</p> <pre><code> location /sub {\n     content_by_lua_block {\n         ngx.ctx.foo = \"bar\"\n     }\n }\n location /lua {\n     content_by_lua_block {\n         res = ngx.location.capture(\"/sub\", { ctx = ngx.ctx })\n         ngx.say(ngx.ctx.foo)\n     }\n }\n</code></pre> <p>Request <code>GET /lua</code> yields the output</p> <pre><code>bar\n</code></pre> <p>Note that subrequests issued by ngx.location.capture inherit all the request headers of the current request by default and that this may have unexpected side effects on the subrequest responses. For example, when using the standard <code>ngx_proxy</code> module to serve subrequests, an \"Accept-Encoding: gzip\" header in the main request may result in gzipped responses that cannot be handled properly in Lua code. Original request headers should be ignored by setting proxy_pass_request_headers to <code>off</code> in subrequest locations.</p> <p>When the <code>body</code> option is not specified and the <code>always_forward_body</code> option is false (the default value), the <code>POST</code> and <code>PUT</code> subrequests will inherit the request bodies of the parent request (if any).</p> <p>There is a hard-coded upper limit on the number of subrequests possible for every main request. In older versions of Nginx, the limit was <code>50</code> concurrent subrequests and in more recent versions, Nginx <code>1.9.5</code> onwards, the same limit is changed to limit the depth of recursive subrequests. When this limit is exceeded, the following error message is added to the <code>error.log</code> file:</p> <pre><code>[error] 13983#0: *1 subrequests cycle while processing \"/uri\"\n</code></pre> <p>The limit can be manually modified if required by editing the definition of the <code>NGX_HTTP_MAX_SUBREQUESTS</code> macro in the <code>nginx/src/http/ngx_http_request.h</code> file in the Nginx source tree.</p> <p>Please also refer to restrictions on capturing locations configured by subrequest directives of other modules.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxlocationcapture_multi","title":"ngx.location.capture_multi","text":"<p>syntax: res1, res2, ... = ngx.location.capture_multi({ {uri, options?}, {uri, options?}, ... })</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Just like ngx.location.capture, but supports multiple subrequests running in parallel.</p> <p>This function issues several parallel subrequests specified by the input table and returns their results in the same order. For example,</p> <pre><code> res1, res2, res3 = ngx.location.capture_multi{\n     { \"/foo\", { args = \"a=3&amp;b=4\" } },\n     { \"/bar\" },\n     { \"/baz\", { method = ngx.HTTP_POST, body = \"hello\" } },\n }\n\n if res1.status == ngx.HTTP_OK then\n     ...\n end\n\n if res2.body == \"BLAH\" then\n     ...\n end\n</code></pre> <p>This function will not return until all the subrequests terminate. The total latency is the longest latency of the individual subrequests rather than the sum.</p> <p>Lua tables can be used for both requests and responses when the number of subrequests to be issued is not known in advance:</p> <pre><code> -- construct the requests table\n local reqs = {}\n table.insert(reqs, { \"/mysql\" })\n table.insert(reqs, { \"/postgres\" })\n table.insert(reqs, { \"/redis\" })\n table.insert(reqs, { \"/memcached\" })\n\n -- issue all the requests at once and wait until they all return\n local resps = {\n     ngx.location.capture_multi(reqs)\n }\n\n -- loop over the responses table\n for i, resp in ipairs(resps) do\n     -- process the response table \"resp\"\n end\n</code></pre> <p>The ngx.location.capture function is just a special form of this function. Logically speaking, the ngx.location.capture can be implemented like this</p> <pre><code> ngx.location.capture =\n     function (uri, args)\n         return ngx.location.capture_multi({ {uri, args} })\n     end\n</code></pre> <p>Please also refer to restrictions on capturing locations configured by subrequest directives of other modules.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxstatus","title":"ngx.status","text":"<p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Read and write the current request's response status. This should be called before sending out the response headers.</p> <pre><code> ngx.status = ngx.HTTP_CREATED\n status = ngx.status\n</code></pre> <p>Setting <code>ngx.status</code> after the response header is sent out has no effect but leaving an error message in your Nginx's error log file:</p> <pre><code>attempt to set ngx.status after sending out response headers\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxheaderheader","title":"ngx.header.HEADER","text":"<p>syntax: ngx.header.HEADER = VALUE</p> <p>syntax: value = ngx.header.HEADER</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Set, add to, or clear the current request's <code>HEADER</code> response header that is to be sent.</p> <p>Underscores (<code>_</code>) in the header names will be replaced by hyphens (<code>-</code>) by default. This transformation can be turned off via the lua_transform_underscores_in_response_headers directive.</p> <p>The header names are matched case-insensitively.</p> <pre><code> -- equivalent to ngx.header[\"Content-Type\"] = 'text/plain'\n ngx.header.content_type = 'text/plain'\n\n ngx.header[\"X-My-Header\"] = 'blah blah'\n</code></pre> <p>Multi-value headers can be set this way:</p> <pre><code> ngx.header['Set-Cookie'] = {'a=32; path=/', 'b=4; path=/'}\n</code></pre> <p>will yield</p> <pre><code> Set-Cookie: a=32; path=/\n Set-Cookie: b=4; path=/\n</code></pre> <p>in the response headers.</p> <p>Only Lua tables are accepted (Only the last element in the table will take effect for standard headers such as <code>Content-Type</code> that only accept a single value).</p> <pre><code> ngx.header.content_type = {'a', 'b'}\n</code></pre> <p>is equivalent to</p> <pre><code> ngx.header.content_type = 'b'\n</code></pre> <p>Setting a slot to <code>nil</code> effectively removes it from the response headers:</p> <pre><code> ngx.header[\"X-My-Header\"] = nil\n</code></pre> <p>The same applies to assigning an empty table:</p> <pre><code> ngx.header[\"X-My-Header\"] = {}\n</code></pre> <p>Setting <code>ngx.header.HEADER</code> after sending out response headers (either explicitly with ngx.send_headers or implicitly with ngx.print and similar) will log an error message.</p> <p>Reading <code>ngx.header.HEADER</code> will return the value of the response header named <code>HEADER</code>.</p> <p>Underscores (<code>_</code>) in the header names will also be replaced by dashes (<code>-</code>) and the header names will be matched case-insensitively. If the response header is not present at all, <code>nil</code> will be returned.</p> <p>This is particularly useful in the context of header_filter_by_lua*, for example,</p> <pre><code> location /test {\n     set $footer '';\n\n     proxy_pass http://some-backend;\n\n     header_filter_by_lua_block {\n         if ngx.header[\"X-My-Header\"] == \"blah\" then\n             ngx.var.footer = \"some value\"\n         end\n     }\n\n     echo_after_body $footer;\n }\n</code></pre> <p>For multi-value headers, all of the values of header will be collected in order and returned as a Lua table. For example, response headers</p> <pre><code>Foo: bar\nFoo: baz\n</code></pre> <p>will result in</p> <pre><code> {\"bar\", \"baz\"}\n</code></pre> <p>to be returned when reading <code>ngx.header.Foo</code>.</p> <p>Note that <code>ngx.header</code> is not a normal Lua table and as such, it is not possible to iterate through it using the Lua <code>ipairs</code> function.</p> <p>Note: this function throws a Lua error if <code>HEADER</code> or <code>VALUE</code> contain unsafe characters (control characters).</p> <p>For reading request headers, use the ngx.req.get_headers function instead.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxrespget_headers","title":"ngx.resp.get_headers","text":"<p>syntax: headers, err = ngx.resp.get_headers(max_headers?, raw?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*</p> <p>Returns a Lua table holding all the current response headers for the current request.</p> <pre><code> local h, err = ngx.resp.get_headers()\n\n if err == \"truncated\" then\n     -- one can choose to ignore or reject the current response here\n end\n\n for k, v in pairs(h) do\n     ...\n end\n</code></pre> <p>This function has the same signature as ngx.req.get_headers except getting response headers instead of request headers.</p> <p>Note that a maximum of 100 response headers are parsed by default (including those with the same name) and that additional response headers are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string <code>\"truncated\"</code>.</p> <p>This API was first introduced in the <code>v0.9.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqis_internal","title":"ngx.req.is_internal","text":"<p>syntax: is_internal = ngx.req.is_internal()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Returns a boolean indicating whether the current request is an \"internal request\", i.e., a request initiated from inside the current Nginx server instead of from the client side.</p> <p>Subrequests are all internal requests and so are requests after internal redirects.</p> <p>This API was first introduced in the <code>v0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqstart_time","title":"ngx.req.start_time","text":"<p>syntax: secs = ngx.req.start_time()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Returns a floating-point number representing the timestamp (including milliseconds as the decimal part) when the current request was created.</p> <p>The following example emulates the <code>$request_time</code> variable value (provided by ngx_http_log_module) in pure Lua:</p> <pre><code> local request_time = ngx.now() - ngx.req.start_time()\n</code></pre> <p>This function was first introduced in the <code>v0.7.7</code> release.</p> <p>See also ngx.now and ngx.update_time.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqhttp_version","title":"ngx.req.http_version","text":"<p>syntax: num = ngx.req.http_version()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*</p> <p>Returns the HTTP version number for the current request as a Lua number.</p> <p>Current possible values are 3.0, 2.0, 1.0, 1.1, and 0.9. Returns <code>nil</code> for unrecognized values.</p> <p>This method was first introduced in the <code>v0.7.17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqraw_header","title":"ngx.req.raw_header","text":"<p>syntax: str = ngx.req.raw_header(no_request_line?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*</p> <p>Returns the original raw HTTP protocol header received by the Nginx server.</p> <p>By default, the request line and trailing <code>CR LF</code> terminator will also be included. For example,</p> <pre><code> ngx.print(ngx.req.raw_header())\n</code></pre> <p>gives something like this:</p> <pre><code>GET /t HTTP/1.1\nHost: localhost\nConnection: close\nFoo: bar\n</code></pre> <p>You can specify the optional <code>no_request_line</code> argument as a <code>true</code> value to exclude the request line from the result. For example,</p> <pre><code> ngx.print(ngx.req.raw_header(true))\n</code></pre> <p>outputs something like this:</p> <pre><code>Host: localhost\nConnection: close\nFoo: bar\n</code></pre> <p>This method was first introduced in the <code>v0.7.17</code> release.</p> <p>This method does not work in HTTP/2 requests yet.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_method","title":"ngx.req.get_method","text":"<p>syntax: method_name = ngx.req.get_method()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, balancer_by_lua*, log_by_lua*</p> <p>Retrieves the current request's request method name. Strings like <code>\"GET\"</code> and <code>\"POST\"</code> are returned instead of numerical method constants.</p> <p>If the current request is an Nginx subrequest, then the subrequest's method name will be returned.</p> <p>This method was first introduced in the <code>v0.5.6</code> release.</p> <p>See also ngx.req.set_method.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_method","title":"ngx.req.set_method","text":"<p>syntax: ngx.req.set_method(method_id)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*</p> <p>Overrides the current request's request method with the <code>method_id</code> argument. Currently only numerical method constants are supported, like <code>ngx.HTTP_POST</code> and <code>ngx.HTTP_GET</code>.</p> <p>If the current request is an Nginx subrequest, then the subrequest's method will be overridden.</p> <p>This method was first introduced in the <code>v0.5.6</code> release.</p> <p>See also ngx.req.get_method.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_uri","title":"ngx.req.set_uri","text":"<p>syntax: ngx.req.set_uri(uri, jump?, binary?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*</p> <p>Rewrite the current request's (parsed) URI by the <code>uri</code> argument. The <code>uri</code> argument must be a Lua string and cannot be of zero length, or a Lua exception will be thrown.</p> <p>The optional boolean <code>jump</code> argument can trigger location rematch (or location jump) as ngx_http_rewrite_module's rewrite directive, that is, when <code>jump</code> is <code>true</code> (default to <code>false</code>), this function will never return and it will tell Nginx to try re-searching locations with the new URI value at the later <code>post-rewrite</code> phase and jumping to the new location.</p> <p>Location jump will not be triggered otherwise, and only the current request's URI will be modified, which is also the default behavior. This function will return but with no returned values when the <code>jump</code> argument is <code>false</code> or absent altogether.</p> <p>For example, the following Nginx config snippet</p> <pre><code> rewrite ^ /foo last;\n</code></pre> <p>can be coded in Lua like this:</p> <pre><code> ngx.req.set_uri(\"/foo\", true)\n</code></pre> <p>Similarly, Nginx config</p> <pre><code> rewrite ^ /foo break;\n</code></pre> <p>can be coded in Lua as</p> <pre><code> ngx.req.set_uri(\"/foo\", false)\n</code></pre> <p>or equivalently,</p> <pre><code> ngx.req.set_uri(\"/foo\")\n</code></pre> <p>The <code>jump</code> argument can only be set to <code>true</code> in rewrite_by_lua*. Use of jump in other contexts is prohibited and will throw out a Lua exception.</p> <p>A more sophisticated example involving regex substitutions is as follows</p> <pre><code> location /test {\n     rewrite_by_lua_block {\n         local uri = ngx.re.sub(ngx.var.uri, \"^/test/(.*)\", \"/$1\", \"o\")\n         ngx.req.set_uri(uri)\n     }\n     proxy_pass http://my_backend;\n }\n</code></pre> <p>which is functionally equivalent to</p> <pre><code> location /test {\n     rewrite ^/test/(.*) /$1 break;\n     proxy_pass http://my_backend;\n }\n</code></pre> <p>Note: this function throws a Lua error if the <code>uri</code> argument contains unsafe characters (control characters).</p> <p>Note that it is not possible to use this interface to rewrite URI arguments and that ngx.req.set_uri_args should be used for this instead. For instance, Nginx config</p> <pre><code> rewrite ^ /foo?a=3? last;\n</code></pre> <p>can be coded as</p> <pre><code> ngx.req.set_uri_args(\"a=3\")\n ngx.req.set_uri(\"/foo\", true)\n</code></pre> <p>or</p> <pre><code> ngx.req.set_uri_args({a = 3})\n ngx.req.set_uri(\"/foo\", true)\n</code></pre> <p>Starting from <code>0.10.16</code> of this module, this function accepts an optional boolean <code>binary</code> argument to allow arbitrary binary URI data. By default, this <code>binary</code> argument is false and this function will throw out a Lua error such as the one below when the <code>uri</code> argument contains any control characters (ASCII Code 0 ~ 0x08, 0x0A ~ 0x1F and 0x7F).</p> <pre><code>[error] 23430#23430: *1 lua entry thread aborted: runtime error:\ncontent_by_lua(nginx.conf:44):3: ngx.req.set_uri unsafe byte \"0x00\"\nin \"\\x00foo\" (maybe you want to set the 'binary' argument?)\n</code></pre> <p>This interface was first introduced in the <code>v0.3.1rc14</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_uri_args","title":"ngx.req.set_uri_args","text":"<p>syntax: ngx.req.set_uri_args(args)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*</p> <p>Rewrite the current request's URI query arguments by the <code>args</code> argument. The <code>args</code> argument can be either a Lua string, as in</p> <pre><code> ngx.req.set_uri_args(\"a=3&amp;b=hello%20world\")\n</code></pre> <p>or a Lua table holding the query arguments' key-value pairs, as in</p> <pre><code> ngx.req.set_uri_args({ a = 3, b = \"hello world\" })\n</code></pre> <p>In the former case, i.e., when the whole query-string is provided directly, the input Lua string should already be well-formed with the URI encoding. For security considerations, this method will automatically escape any control and whitespace characters (ASCII code 0x00 ~ 0x20 and 0x7F) in the Lua string.</p> <p>In the latter case, this method will escape argument keys and values according to the URI escaping rule.</p> <p>Multi-value arguments are also supported:</p> <pre><code> ngx.req.set_uri_args({ a = 3, b = {5, 6} })\n</code></pre> <p>which will result in a query string like <code>a=3&amp;b=5&amp;b=6</code> or <code>b=5&amp;b=6&amp;a=3</code>.</p> <p>Note that when using Lua table as the <code>arg</code> argument, the order of the arguments in the result query string which change from time to time. If you would like to get an ordered result, you need to use Lua string as the <code>arg</code> argument.</p> <p>This interface was first introduced in the <code>v0.3.1rc13</code> release.</p> <p>See also ngx.req.set_uri.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_uri_args","title":"ngx.req.get_uri_args","text":"<p>syntax: args, err = ngx.req.get_uri_args(max_args?, tab?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*</p> <p>Returns a Lua table holding all the current request URL query arguments. An optional <code>tab</code> argument can be used to reuse the table returned by this method.</p> <pre><code> location = /test {\n     content_by_lua_block {\n         local args, err = ngx.req.get_uri_args()\n\n         if err == \"truncated\" then\n             -- one can choose to ignore or reject the current request here\n         end\n\n         for key, val in pairs(args) do\n             if type(val) == \"table\" then\n                 ngx.say(key, \": \", table.concat(val, \", \"))\n             else\n                 ngx.say(key, \": \", val)\n             end\n         end\n     }\n }\n</code></pre> <p>Then <code>GET /test?foo=bar&amp;bar=baz&amp;bar=blah</code> will yield the response body</p> <pre><code> foo: bar\n bar: baz, blah\n</code></pre> <p>Multiple occurrences of an argument key will result in a table value holding all the values for that key in order.</p> <p>Keys and values are unescaped according to URI escaping rules. In the settings above, <code>GET /test?a%20b=1%61+2</code> will yield:</p> <pre><code> a b: 1a 2\n</code></pre> <p>Arguments without the <code>=&lt;value&gt;</code> parts are treated as boolean arguments. <code>GET /test?foo&amp;bar</code> will yield:</p> <pre><code> foo: true\n bar: true\n</code></pre> <p>That is, they will take Lua boolean values <code>true</code>. However, they are different from arguments taking empty string values. <code>GET /test?foo=&amp;bar=</code> will give something like</p> <pre><code> foo:\n bar:\n</code></pre> <p>Empty key arguments are discarded. <code>GET /test?=hello&amp;=world</code> will yield an empty output for instance.</p> <p>Updating query arguments via the Nginx variable <code>$args</code> (or <code>ngx.var.args</code> in Lua) at runtime is also supported:</p> <pre><code> ngx.var.args = \"a=3&amp;b=42\"\n local args, err = ngx.req.get_uri_args()\n</code></pre> <p>Here the <code>args</code> table will always look like</p> <pre><code> {a = 3, b = 42}\n</code></pre> <p>regardless of the actual request query string.</p> <p>Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string <code>\"truncated\"</code>.</p> <p>However, the optional <code>max_args</code> function argument can be used to override this limit:</p> <pre><code> local args, err = ngx.req.get_uri_args(10)\n if err == \"truncated\" then\n     -- one can choose to ignore or reject the current request here\n end\n</code></pre> <p>This argument can be set to zero to remove the limit and to process all request arguments received:</p> <pre><code> local args, err = ngx.req.get_uri_args(0)\n</code></pre> <p>Removing the <code>max_args</code> cap is strongly discouraged.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_post_args","title":"ngx.req.get_post_args","text":"<p>syntax: args, err = ngx.req.get_post_args(max_args?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Returns a Lua table holding all the current request POST query arguments (of the MIME type <code>application/x-www-form-urlencoded</code>). Call ngx.req.read_body to read the request body first or turn on the lua_need_request_body directive to avoid errors.</p> <pre><code> location = /test {\n     content_by_lua_block {\n         ngx.req.read_body()\n         local args, err = ngx.req.get_post_args()\n\n         if err == \"truncated\" then\n             -- one can choose to ignore or reject the current request here\n         end\n\n         if not args then\n             ngx.say(\"failed to get post args: \", err)\n             return\n         end\n         for key, val in pairs(args) do\n             if type(val) == \"table\" then\n                 ngx.say(key, \": \", table.concat(val, \", \"))\n             else\n                 ngx.say(key, \": \", val)\n             end\n         end\n     }\n }\n</code></pre> <p>Then</p> <pre><code> # Post request with the body 'foo=bar&amp;bar=baz&amp;bar=blah'\n $ curl --data 'foo=bar&amp;bar=baz&amp;bar=blah' localhost/test\n</code></pre> <p>will yield the response body like</p> <pre><code> foo: bar\n bar: baz, blah\n</code></pre> <p>Multiple occurrences of an argument key will result in a table value holding all of the values for that key in order.</p> <p>Keys and values will be unescaped according to URI escaping rules.</p> <p>With the settings above,</p> <pre><code> # POST request with body 'a%20b=1%61+2'\n $ curl -d 'a%20b=1%61+2' localhost/test\n</code></pre> <p>will yield:</p> <pre><code> a b: 1a 2\n</code></pre> <p>Arguments without the <code>=&lt;value&gt;</code> parts are treated as boolean arguments. <code>POST /test</code> with the request body <code>foo&amp;bar</code> will yield:</p> <pre><code> foo: true\n bar: true\n</code></pre> <p>That is, they will take Lua boolean values <code>true</code>. However, they are different from arguments taking empty string values. <code>POST /test</code> with request body <code>foo=&amp;bar=</code> will return something like</p> <pre><code> foo:\n bar:\n</code></pre> <p>Empty key arguments are discarded. <code>POST /test</code> with body <code>=hello&amp;=world</code> will yield empty outputs for instance.</p> <p>Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string <code>\"truncated\"</code>.</p> <p>However, the optional <code>max_args</code> function argument can be used to override this limit:</p> <pre><code> local args, err = ngx.req.get_post_args(10)\n if err == \"truncated\" then\n     -- one can choose to ignore or reject the current request here\n end\n</code></pre> <p>This argument can be set to zero to remove the limit and to process all request arguments received:</p> <pre><code> local args, err = ngx.req.get_post_args(0)\n</code></pre> <p>Removing the <code>max_args</code> cap is strongly discouraged.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_headers","title":"ngx.req.get_headers","text":"<p>syntax: headers, err = ngx.req.get_headers(max_headers?, raw?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Returns a Lua table holding all the current request headers.</p> <pre><code> local h, err = ngx.req.get_headers()\n\n if err == \"truncated\" then\n     -- one can choose to ignore or reject the current request here\n end\n\n for k, v in pairs(h) do\n     ...\n end\n</code></pre> <p>To read an individual header:</p> <pre><code> ngx.say(\"Host: \", ngx.req.get_headers()[\"Host\"])\n</code></pre> <p>Note that the ngx.var.HEADER API call, which uses core $http_HEADER variables, may be more preferable for reading individual request headers.</p> <p>For multiple instances of request headers such as:</p> <pre><code> Foo: foo\n Foo: bar\n Foo: baz\n</code></pre> <p>the value of <code>ngx.req.get_headers()[\"Foo\"]</code> will be a Lua (array) table such as:</p> <pre><code> {\"foo\", \"bar\", \"baz\"}\n</code></pre> <p>Note that a maximum of 100 request headers are parsed by default (including those with the same name) and that additional request headers are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string <code>\"truncated\"</code>.</p> <p>However, the optional <code>max_headers</code> function argument can be used to override this limit:</p> <pre><code> local headers, err = ngx.req.get_headers(10)\n\n if err == \"truncated\" then\n     -- one can choose to ignore or reject the current request here\n end\n</code></pre> <p>This argument can be set to zero to remove the limit and to process all request headers received:</p> <pre><code> local headers, err = ngx.req.get_headers(0)\n</code></pre> <p>Removing the <code>max_headers</code> cap is strongly discouraged.</p> <p>Since the <code>0.6.9</code> release, all the header names in the Lua table returned are converted to the pure lower-case form by default, unless the <code>raw</code> argument is set to <code>true</code> (default to <code>false</code>).</p> <p>Also, by default, an <code>__index</code> metamethod is added to the resulting Lua table and will normalize the keys to a pure lowercase form with all underscores converted to dashes in case of a lookup miss. For example, if a request header <code>My-Foo-Header</code> is present, then the following invocations will all pick up the value of this header correctly:</p> <pre><code> ngx.say(headers.my_foo_header)\n ngx.say(headers[\"My-Foo-Header\"])\n ngx.say(headers[\"my-foo-header\"])\n</code></pre> <p>The <code>__index</code> metamethod will not be added when the <code>raw</code> argument is set to <code>true</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_header","title":"ngx.req.set_header","text":"<p>syntax: ngx.req.set_header(header_name, header_value)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*</p> <p>Set the current request's request header named <code>header_name</code> to value <code>header_value</code>, overriding any existing ones.</p> <p>The input Lua string <code>header_name</code> and <code>header_value</code> should already be well-formed with the URI encoding. For security considerations, this method will automatically escape \" \", \"\"\", \"(\", \")\", \",\", \"/\", \":\", \";\", \"?\", \"&lt;\", \"=\", \"&gt;\", \"?\", \"@\", \"[\", \"]\", \"\\\", \"{\", \"}\", 0x00-0x1F, 0x7F-0xFF in <code>header_name</code> and automatically escape \"0x00-0x08, 0x0A-0x0F, 0x7F in <code>header_value</code>.</p> <p>By default, all the subrequests subsequently initiated by ngx.location.capture and ngx.location.capture_multi will inherit the new header.</p> <p>It is not a Lua's equivalent of nginx <code>proxy_set_header</code> directive (same is true about ngx.req.clear_header). <code>proxy_set_header</code> only affects the upstream request while <code>ngx.req.set_header</code> change the incoming request. Record the http headers in the access log file will show the difference. But you still can use it as an alternative of nginx <code>proxy_set_header</code> directive as long as you know the difference.</p> <p>Here is an example of setting the <code>Content-Type</code> header:</p> <pre><code> ngx.req.set_header(\"Content-Type\", \"text/css\")\n</code></pre> <p>The <code>header_value</code> can take an array list of values, for example,</p> <pre><code> ngx.req.set_header(\"Foo\", {\"a\", \"abc\"})\n</code></pre> <p>will produce two new request headers:</p> <pre><code> Foo: a\n Foo: abc\n</code></pre> <p>and old <code>Foo</code> headers will be overridden if there is any.</p> <p>When the <code>header_value</code> argument is <code>nil</code>, the request header will be removed. So</p> <pre><code> ngx.req.set_header(\"X-Foo\", nil)\n</code></pre> <p>is equivalent to</p> <pre><code> ngx.req.clear_header(\"X-Foo\")\n</code></pre> <p>Note: this function throws a Lua error if <code>header_name</code> or <code>header_value</code> contain unsafe characters (control characters).</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqclear_header","title":"ngx.req.clear_header","text":"<p>syntax: ngx.req.clear_header(header_name)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*</p> <p>Clears the current request's request header named <code>header_name</code>. None of the current request's existing subrequests will be affected but subsequently initiated subrequests will inherit the change by default.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqread_body","title":"ngx.req.read_body","text":"<p>syntax: ngx.req.read_body()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Reads the client request body synchronously without blocking the Nginx event loop.</p> <pre><code> ngx.req.read_body()\n local args = ngx.req.get_post_args()\n</code></pre> <p>If the request body is already read previously by turning on lua_need_request_body or by using other modules, then this function does not run and returns immediately.</p> <p>If the request body has already been explicitly discarded, either by the ngx.req.discard_body function or other modules, this function does not run and returns immediately.</p> <p>In case of errors, such as connection errors while reading the data, this method will throw out a Lua exception or terminate the current request with a 500 status code immediately.</p> <p>The request body data read using this function can be retrieved later via ngx.req.get_body_data or, alternatively, the temporary file name for the body data cached to disk using ngx.req.get_body_file. This depends on</p> <ol> <li>whether the current request body is already larger than the client_body_buffer_size,</li> <li>and whether client_body_in_file_only has been switched on.</li> </ol> <p>In cases where current request may have a request body and the request body data is not required, The ngx.req.discard_body function must be used to explicitly discard the request body to avoid breaking things under HTTP 1.1 keepalive or HTTP 1.1 pipelining.</p> <p>This function was first introduced in the <code>v0.3.1rc17</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqdiscard_body","title":"ngx.req.discard_body","text":"<p>syntax: ngx.req.discard_body()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Explicitly discard the request body, i.e., read the data on the connection and throw it away immediately (without using the request body by any means).</p> <p>This function is an asynchronous call and returns immediately.</p> <p>If the request body has already been read, this function does nothing and returns immediately.</p> <p>This function was first introduced in the <code>v0.3.1rc17</code> release.</p> <p>See also ngx.req.read_body.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_body_data","title":"ngx.req.get_body_data","text":"<p>syntax: data = ngx.req.get_body_data(max_bytes?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, log_by_lua*</p> <p>Retrieves in-memory request body data. It returns a Lua string rather than a Lua table holding all the parsed query arguments. Use the ngx.req.get_post_args function instead if a Lua table is required.</p> <p>The optional <code>max_bytes</code> argument can be used when you don't need the entire body.</p> <p>This function returns <code>nil</code> if</p> <ol> <li>the request body has not been read,</li> <li>the request body has been read into disk temporary files,</li> <li>or the request body has zero size.</li> </ol> <p>If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however).</p> <p>If the request body has been read into disk files, try calling the ngx.req.get_body_file function instead.</p> <p>To force in-memory request bodies, try setting client_body_buffer_size to the same size value in client_max_body_size.</p> <p>Note that calling this function instead of using <code>ngx.var.request_body</code> or <code>ngx.var.echo_request_body</code> is more efficient because it can save one dynamic memory allocation and one data copy.</p> <p>This function was first introduced in the <code>v0.3.1rc17</code> release.</p> <p>See also ngx.req.get_body_file.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqget_body_file","title":"ngx.req.get_body_file","text":"<p>syntax: file_name = ngx.req.get_body_file()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Retrieves the file name for the in-file request body data. Returns <code>nil</code> if the request body has not been read or has been read into memory.</p> <p>The returned file is read only and is usually cleaned up by Nginx's memory pool. It should not be manually modified, renamed, or removed in Lua code.</p> <p>If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however).</p> <p>If the request body has been read into memory, try calling the ngx.req.get_body_data function instead.</p> <p>To force in-file request bodies, try turning on client_body_in_file_only.</p> <p>Note that this function is also work for balancer phase but it needs to call balancer.recreate_request to make the change take effect after set the request body data or headers.</p> <p>This function was first introduced in the <code>v0.3.1rc17</code> release.</p> <p>See also ngx.req.get_body_data.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_body_data","title":"ngx.req.set_body_data","text":"<p>syntax: ngx.req.set_body_data(data)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, balancer_by_lua*,</p> <p>Set the current request's request body using the in-memory data specified by the <code>data</code> argument.</p> <p>If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by ngx.req.discard_body.</p> <p>Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively.</p> <p>Note that this function is also work for balancer phase but it needs to call balancer.recreate_request to make the change take effect after set the request body data or headers.</p> <p>This function was first introduced in the <code>v0.3.1rc18</code> release.</p> <p>See also ngx.req.set_body_file.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqset_body_file","title":"ngx.req.set_body_file","text":"<p>syntax: ngx.req.set_body_file(file_name, auto_clean?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, balancer_by_lua*,</p> <p>Set the current request's request body using the in-file data specified by the <code>file_name</code> argument.</p> <p>If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by ngx.req.discard_body.</p> <p>If the optional <code>auto_clean</code> argument is given a <code>true</code> value, then this file will be removed at request completion or the next time this function or ngx.req.set_body_data are called in the same request. The <code>auto_clean</code> is default to <code>false</code>.</p> <p>Please ensure that the file specified by the <code>file_name</code> argument exists and is readable by an Nginx worker process by setting its permission properly to avoid Lua exception errors.</p> <p>Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively.</p> <p>This function was first introduced in the <code>v0.3.1rc18</code> release.</p> <p>See also ngx.req.set_body_data.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqinit_body","title":"ngx.req.init_body","text":"<p>syntax: ngx.req.init_body(buffer_size?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Creates a new blank request body for the current request and initializes the buffer for later request body data writing via the ngx.req.append_body and ngx.req.finish_body APIs.</p> <p>If the <code>buffer_size</code> argument is specified, then its value will be used for the size of the memory buffer for body writing with ngx.req.append_body. If the argument is omitted, then the value specified by the standard client_body_buffer_size directive will be used instead.</p> <p>When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core.</p> <p>It is important to always call the ngx.req.finish_body after all the data has been appended onto the current request body. Also, when this function is used together with ngx.req.socket, it is required to call ngx.req.socket before this function, or you will get the \"request body already exists\" error message.</p> <p>The usage of this function is often like this:</p> <pre><code> ngx.req.init_body(128 * 1024)  -- buffer is 128KB\n for chunk in next_data_chunk() do\n     ngx.req.append_body(chunk) -- each chunk can be 4KB\n end\n ngx.req.finish_body()\n</code></pre> <p>This function can be used with ngx.req.append_body, ngx.req.finish_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module.</p> <p>This function was first introduced in the <code>v0.5.11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqappend_body","title":"ngx.req.append_body","text":"<p>syntax: ngx.req.append_body(data_chunk)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Append new data chunk specified by the <code>data_chunk</code> argument onto the existing request body created by the ngx.req.init_body call.</p> <p>When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core.</p> <p>It is important to always call the ngx.req.finish_body after all the data has been appended onto the current request body.</p> <p>This function can be used with ngx.req.init_body, ngx.req.finish_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module.</p> <p>This function was first introduced in the <code>v0.5.11</code> release.</p> <p>See also ngx.req.init_body.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqfinish_body","title":"ngx.req.finish_body","text":"<p>syntax: ngx.req.finish_body()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Completes the construction process of the new request body created by the ngx.req.init_body and ngx.req.append_body calls.</p> <p>This function can be used with ngx.req.init_body, ngx.req.append_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module.</p> <p>This function was first introduced in the <code>v0.5.11</code> release.</p> <p>See also ngx.req.init_body.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxreqsocket","title":"ngx.req.socket","text":"<p>syntax: tcpsock, err = ngx.req.socket()</p> <p>syntax: tcpsock, err = ngx.req.socket(raw)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Returns a read-only cosocket object that wraps the downstream connection. Only receive, receiveany and receiveuntil methods are supported on this object.</p> <p>In case of error, <code>nil</code> will be returned as well as a string describing the error.</p> <p>Note: This method will block while waiting for client request body to be fully received. Block time depends on the client_body_timeout directive and maximum body size specified by the client_max_body_size directive. If read timeout occurs or client body size exceeds the defined limit, this function will not return and <code>408 Request Time-out</code> or <code>413 Request Entity Too Large</code> response will be returned to the client instead.</p> <p>The socket object returned by this method is usually used to read the current request's body in a streaming fashion. Do not turn on the lua_need_request_body directive, and do not mix this call with ngx.req.read_body and ngx.req.discard_body.</p> <p>If any request body data has been pre-read into the Nginx core request header buffer, the resulting cosocket object will take care of this to avoid potential data loss resulting from such pre-reading. Chunked request bodies are not yet supported in this API.</p> <p>Since the <code>v0.9.0</code> release, this function accepts an optional boolean <code>raw</code> argument. When this argument is <code>true</code>, this function returns a full-duplex cosocket object wrapping around the raw downstream connection socket, upon which you can call the receive, receiveany, receiveuntil, and send methods.</p> <p>When the <code>raw</code> argument is <code>true</code>, it is required that no pending data from any previous ngx.say, ngx.print, or ngx.send_headers calls exists. So if you have these downstream output calls previously, you should call ngx.flush(true) before calling <code>ngx.req.socket(true)</code> to ensure that there is no pending output data. If the request body has not been read yet, then this \"raw socket\" can also be used to read the request body.</p> <p>You can use the \"raw request socket\" returned by <code>ngx.req.socket(true)</code> to implement fancy protocols like WebSocket, or just emit your own raw HTTP response header or body data. You can refer to the lua-resty-websocket library for a real world example.</p> <p>This function was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxexec","title":"ngx.exec","text":"<p>syntax: ngx.exec(uri, args?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Does an internal redirect to <code>uri</code> with <code>args</code> and is similar to the echo_exec directive of the echo-nginx-module.</p> <pre><code> ngx.exec('/some-location')\n ngx.exec('/some-location', 'a=3&amp;b=5&amp;c=6')\n ngx.exec('/some-location?a=3&amp;b=5', 'c=6')\n</code></pre> <p>The optional second <code>args</code> can be used to specify extra URI query arguments, for example:</p> <pre><code> ngx.exec(\"/foo\", \"a=3&amp;b=hello%20world\")\n</code></pre> <p>Alternatively, a Lua table can be passed for the <code>args</code> argument for ngx_lua to carry out URI escaping and string concatenation.</p> <pre><code> ngx.exec(\"/foo\", { a = 3, b = \"hello world\" })\n</code></pre> <p>The result is exactly the same as the previous example.</p> <p>The format for the Lua table passed as the <code>args</code> argument is identical to the format used in the ngx.encode_args method.</p> <p>Named locations are also supported but the second <code>args</code> argument will be ignored if present and the querystring for the new target is inherited from the referring location (if any).</p> <p><code>GET /foo/file.php?a=hello</code> will return \"hello\" and not \"goodbye\" in the example below</p> <pre><code> location /foo {\n     content_by_lua_block {\n         ngx.exec(\"@bar\", \"a=goodbye\")\n     }\n }\n\n location @bar {\n     content_by_lua_block {\n         local args = ngx.req.get_uri_args()\n         for key, val in pairs(args) do\n             if key == \"a\" then\n                 ngx.say(val)\n             end\n         end\n     }\n }\n</code></pre> <p>Note that the <code>ngx.exec</code> method is different from ngx.redirect in that it is purely an internal redirect and that no new external HTTP traffic is involved.</p> <p>Also note that this method call terminates the processing of the current request and that it must be called before ngx.send_headers or explicit response body outputs by either ngx.print or ngx.say.</p> <p>It is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.exec(...)</code> be adopted when this method call is used in contexts other than header_filter_by_lua* to reinforce the fact that the request processing is being terminated.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxredirect","title":"ngx.redirect","text":"<p>syntax: ngx.redirect(uri, status?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Issue an <code>HTTP 301</code> or <code>302</code> redirection to <code>uri</code>.</p> <p>Note: this function throws a Lua error if the <code>uri</code> argument contains unsafe characters (control characters).</p> <p>The optional <code>status</code> parameter specifies the HTTP status code to be used. The following status codes are supported right now:</p> <ul> <li><code>301</code></li> <li><code>302</code> (default)</li> <li><code>303</code></li> <li><code>307</code></li> <li><code>308</code></li> </ul> <p>It is <code>302</code> (<code>ngx.HTTP_MOVED_TEMPORARILY</code>) by default.</p> <p>Here is an example assuming the current server name is <code>localhost</code> and that it is listening on port 1984:</p> <pre><code> return ngx.redirect(\"/foo\")\n</code></pre> <p>which is equivalent to</p> <pre><code> return ngx.redirect(\"/foo\", ngx.HTTP_MOVED_TEMPORARILY)\n</code></pre> <p>Redirecting arbitrary external URLs is also supported, for example:</p> <pre><code> return ngx.redirect(\"http://www.google.com\")\n</code></pre> <p>We can also use the numerical code directly as the second <code>status</code> argument:</p> <pre><code> return ngx.redirect(\"/foo\", 301)\n</code></pre> <p>This method is similar to the rewrite directive with the <code>redirect</code> modifier in the standard ngx_http_rewrite_module, for example, this <code>nginx.conf</code> snippet</p> <pre><code> rewrite ^ /foo? redirect;  # nginx config\n</code></pre> <p>is equivalent to the following Lua code</p> <pre><code> return ngx.redirect('/foo')  -- Lua code\n</code></pre> <p>while</p> <pre><code> rewrite ^ /foo? permanent;  # nginx config\n</code></pre> <p>is equivalent to</p> <pre><code> return ngx.redirect('/foo', ngx.HTTP_MOVED_PERMANENTLY)  -- Lua code\n</code></pre> <p>URI arguments can be specified as well, for example:</p> <pre><code> return ngx.redirect('/foo?a=3&amp;b=4')\n</code></pre> <p>Note that this method call terminates the processing of the current request and that it must be called before ngx.send_headers or explicit response body outputs by either ngx.print or ngx.say.</p> <p>It is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.redirect(...)</code> be adopted when this method call is used in contexts other than header_filter_by_lua* to reinforce the fact that the request processing is being terminated.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsend_headers","title":"ngx.send_headers","text":"<p>syntax: ok, err = ngx.send_headers()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Explicitly send out the response headers.</p> <p>Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.</p> <p>Note that there is normally no need to manually send out response headers as ngx_lua will automatically send headers out before content is output with ngx.say or ngx.print or when content_by_lua* exits normally.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxheaders_sent","title":"ngx.headers_sent","text":"<p>syntax: value = ngx.headers_sent</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Returns <code>true</code> if the response headers have been sent (by ngx_lua), and <code>false</code> otherwise.</p> <p>This API was first introduced in ngx_lua v0.3.1rc6.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxprint","title":"ngx.print","text":"<p>syntax: ok, err = ngx.print(...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Emits arguments concatenated to the HTTP client (as response body). If response headers have not been sent, this function will send headers out first and then output body data.</p> <p>Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.</p> <p>Lua <code>nil</code> values will output <code>\"nil\"</code> strings and Lua boolean values will output <code>\"true\"</code> and <code>\"false\"</code> literal strings respectively.</p> <p>Nested arrays of strings are permitted and the elements in the arrays will be sent one by one:</p> <pre><code> local table = {\n     \"hello, \",\n     {\"world: \", true, \" or \", false,\n         {\": \", nil}}\n }\n ngx.print(table)\n</code></pre> <p>will yield the output</p> <pre><code> hello, world: true or false: nil\n</code></pre> <p>Non-array table arguments will cause a Lua exception to be thrown.</p> <p>The <code>ngx.null</code> constant will yield the <code>\"null\"</code> string output.</p> <p>This is an asynchronous call and will return immediately without waiting for all the data to be written into the system send buffer. To run in synchronous mode, call <code>ngx.flush(true)</code> after calling <code>ngx.print</code>. This can be particularly useful for streaming output. See ngx.flush for more details.</p> <p>Please note that both <code>ngx.print</code> and ngx.say will always invoke the whole Nginx output body filter chain, which is an expensive operation. So be careful when calling either of these two in a tight loop; buffer the data yourself in Lua and save the calls.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsay","title":"ngx.say","text":"<p>syntax: ok, err = ngx.say(...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Just as ngx.print but also emit a trailing newline.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxlog","title":"ngx.log","text":"<p>syntax: ngx.log(log_level, ...)</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Log arguments concatenated to error.log with the given logging level.</p> <p>Lua <code>nil</code> arguments are accepted and result in literal <code>\"nil\"</code> string while Lua booleans result in literal <code>\"true\"</code> or <code>\"false\"</code> string outputs. And the <code>ngx.null</code> constant will yield the <code>\"null\"</code> string output.</p> <p>The <code>log_level</code> argument can take constants like <code>ngx.ERR</code> and <code>ngx.WARN</code>. Check out Nginx log level constants for details.</p> <p>There is a hard coded <code>2048</code> byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the <code>NGX_MAX_ERROR_STR</code> macro definition in the <code>src/core/ngx_log.h</code> file in the Nginx source tree.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxflush","title":"ngx.flush","text":"<p>syntax: ok, err = ngx.flush(wait?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Flushes response output to the client.</p> <p><code>ngx.flush</code> accepts an optional boolean <code>wait</code> argument (Default: <code>false</code>) first introduced in the <code>v0.3.1rc34</code> release. When called with the default argument, it issues an asynchronous call (Returns immediately without waiting for output data to be written into the system send buffer). Calling the function with the <code>wait</code> argument set to <code>true</code> switches to synchronous mode.</p> <p>In synchronous mode, the function will not return until all output data has been written into the system send buffer or until the send_timeout setting has expired. Note that using the Lua coroutine mechanism means that this function does not block the Nginx event loop even in the synchronous mode.</p> <p>When <code>ngx.flush(true)</code> is called immediately after ngx.print or ngx.say, it causes the latter functions to run in synchronous mode. This can be particularly useful for streaming output.</p> <p>Note that <code>ngx.flush</code> is not functional when in the HTTP 1.0 output buffering mode. See HTTP 1.0 support.</p> <p>Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxexit","title":"ngx.exit","text":"<p>syntax: ngx.exit(status)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>When <code>status &gt;= 200</code> (i.e., <code>ngx.HTTP_OK</code> and above), it will interrupt the execution of the current request and return status code to Nginx.</p> <p>When <code>status == 0</code> (i.e., <code>ngx.OK</code>), it will only quit the current phase handler (or the content handler if the content_by_lua* directive is used) and continue to run later phases (if any) for the current request.</p> <p>The <code>status</code> argument can be <code>ngx.OK</code>, <code>ngx.ERROR</code>, <code>ngx.HTTP_NOT_FOUND</code>, <code>ngx.HTTP_MOVED_TEMPORARILY</code>, or other HTTP status constants.</p> <p>To return an error page with custom contents, use code snippets like this:</p> <pre><code> ngx.status = ngx.HTTP_GONE\n ngx.say(\"This is our own content\")\n -- to cause quit the whole request rather than the current phase handler\n ngx.exit(ngx.HTTP_OK)\n</code></pre> <p>The effect in action:</p> <pre><code> $ curl -i http://localhost/test\n HTTP/1.1 410 Gone\n Server: nginx/1.0.6\n Date: Thu, 15 Sep 2011 00:51:48 GMT\n Content-Type: text/plain\n Transfer-Encoding: chunked\n Connection: keep-alive\n\n This is our own content\n</code></pre> <p>Number literals can be used directly as the argument, for instance,</p> <pre><code> ngx.exit(501)\n</code></pre> <p>Note that while this method accepts all HTTP status constants as input, it only accepts <code>ngx.OK</code> and <code>ngx.ERROR</code> of the core constants.</p> <p>Also note that this method call terminates the processing of the current request and that it is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.exit(...)</code> be used to reinforce the fact that the request processing is being terminated.</p> <p>When being used in the contexts of header_filter_by_lua*, balancer_by_lua*, and ssl_session_store_by_lua*, <code>ngx.exit()</code> is an asynchronous operation and will return immediately. This behavior may change in future and it is recommended that users always use <code>return</code> in combination as suggested above.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxeof","title":"ngx.eof","text":"<p>syntax: ok, err = ngx.eof()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Explicitly specify the end of the response output stream. In the case of HTTP 1.1 chunked encoded output, it will just trigger the Nginx core to send out the \"last chunk\".</p> <p>When you disable the HTTP 1.1 keep-alive feature for your downstream connections, you can rely on well written HTTP clients to close the connection actively for you when you call this method. This trick can be used do back-ground jobs without letting the HTTP clients to wait on the connection, as in the following example:</p> <pre><code> location = /async {\n     keepalive_timeout 0;\n     content_by_lua_block {\n         ngx.say(\"got the task!\")\n         ngx.eof()  -- well written HTTP clients will close the connection at this point\n         -- access MySQL, PostgreSQL, Redis, Memcached, and etc here...\n     }\n }\n</code></pre> <p>But if you create subrequests to access other locations configured by Nginx upstream modules, then you should configure those upstream modules to ignore client connection abortions if they are not by default. For example, by default the standard ngx_http_proxy_module will terminate both the subrequest and the main request as soon as the client closes the connection, so it is important to turn on the proxy_ignore_client_abort directive in your location block configured by ngx_http_proxy_module:</p> <pre><code> proxy_ignore_client_abort on;\n</code></pre> <p>A better way to do background jobs is to use the ngx.timer.at API.</p> <p>Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsleep","title":"ngx.sleep","text":"<p>syntax: ngx.sleep(seconds)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Sleeps for the specified seconds without blocking. One can specify time resolution up to 0.001 seconds (i.e., one millisecond).</p> <p>Behind the scene, this method makes use of the Nginx timers.</p> <p>Since the <code>0.7.20</code> release, The <code>0</code> time argument can also be specified.</p> <p>This method was introduced in the <code>0.5.0rc30</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxescape_uri","title":"ngx.escape_uri","text":"<p>syntax: newstr = ngx.escape_uri(str, type?)</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Since <code>v0.10.16</code>, this function accepts an optional <code>type</code> argument. It accepts the following values (defaults to <code>2</code>):</p> <ul> <li><code>0</code>: escapes <code>str</code> as a full URI. And the characters <code></code> (space), <code>#</code>, <code>%</code>, <code>?</code>, 0x00 ~ 0x1F, 0x7F ~ 0xFF will be escaped.</li> <li><code>2</code>: escape <code>str</code> as a URI component. All characters except alphabetic characters, digits, <code>-</code>, <code>.</code>, <code>_</code>, <code>~</code> will be encoded as <code>%XX</code>.</li> </ul> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxunescape_uri","title":"ngx.unescape_uri","text":"<p>syntax: newstr = ngx.unescape_uri(str)</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Unescape <code>str</code> as an escaped URI component.</p> <p>For example,</p> <pre><code> ngx.say(ngx.unescape_uri(\"b%20r56+7\"))\n</code></pre> <p>gives the output</p> <pre><code>b r56 7\n</code></pre> <p>Invalid escaping sequences are handled in a conventional way: <code>%</code>s are left unchanged. Also, characters that should not appear in escaped string are simply left unchanged.</p> <p>For example,</p> <pre><code> ngx.say(ngx.unescape_uri(\"try %search%%20%again%\"))\n</code></pre> <p>gives the output</p> <pre><code>try %search% %again%\n</code></pre> <p>(Note that <code>%20</code> following <code>%</code> got unescaped, even it can be considered a part of invalid sequence.)</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxencode_args","title":"ngx.encode_args","text":"<p>syntax: str = ngx.encode_args(table)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_client_hello_by_lua*</p> <p>Encode the Lua table to a query args string according to the URI encoded rules.</p> <p>For example,</p> <pre><code> ngx.encode_args({foo = 3, [\"b r\"] = \"hello world\"})\n</code></pre> <p>yields</p> <pre><code>foo=3&amp;b%20r=hello%20world\n</code></pre> <p>The table keys must be Lua strings.</p> <p>Multi-value query args are also supported. Just use a Lua table for the argument's value, for example:</p> <pre><code> ngx.encode_args({baz = {32, \"hello\"}})\n</code></pre> <p>gives</p> <pre><code>baz=32&amp;baz=hello\n</code></pre> <p>If the value table is empty and the effect is equivalent to the <code>nil</code> value.</p> <p>Boolean argument values are also supported, for instance,</p> <pre><code> ngx.encode_args({a = true, b = 1})\n</code></pre> <p>yields</p> <pre><code>a&amp;b=1\n</code></pre> <p>If the argument value is <code>false</code>, then the effect is equivalent to the <code>nil</code> value.</p> <p>This method was first introduced in the <code>v0.3.1rc27</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxdecode_args","title":"ngx.decode_args","text":"<p>syntax: table, err = ngx.decode_args(str, max_args?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Decodes a URI encoded query-string into a Lua table. This is the inverse function of ngx.encode_args.</p> <p>The optional <code>max_args</code> argument can be used to specify the maximum number of arguments parsed from the <code>str</code> argument. By default, a maximum of 100 request arguments are parsed (including those with the same name) and that additional URI arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string <code>\"truncated\"</code>.</p> <p>This argument can be set to zero to remove the limit and to process all request arguments received:</p> <pre><code> local args = ngx.decode_args(str, 0)\n</code></pre> <p>Removing the <code>max_args</code> cap is strongly discouraged.</p> <p>This method was introduced in the <code>v0.5.0rc29</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxencode_base64","title":"ngx.encode_base64","text":"<p>syntax: newstr = ngx.encode_base64(str, no_padding?)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Encodes <code>str</code> to a base64 digest. For base64url encoding use <code>base64.encode_base64url</code>.</p> <p>Since the <code>0.9.16</code> release, an optional boolean-typed <code>no_padding</code> argument can be specified to control whether the base64 padding should be appended to the resulting digest (default to <code>false</code>, i.e., with padding enabled).</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxdecode_base64","title":"ngx.decode_base64","text":"<p>syntax: newstr = ngx.decode_base64(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Decodes the <code>str</code> argument as a base64 digest to the raw form. For base64url decoding use <code>base64.decode_base64url</code>.</p> <p>The <code>str</code> should be standard 'base64' encoding for RFC 3548 or RFC 4648, and will returns <code>nil</code> if is not well formed or any characters not in the base encoding alphabet. Padding may be omitted from the input.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxdecode_base64mime","title":"ngx.decode_base64mime","text":"<p>syntax: newstr = ngx.decode_base64mime(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*</p> <p>requires: <code>resty.core.base64</code> or <code>resty.core</code></p> <p>Decodes the <code>str</code> argument as a base64 digest to the raw form. The <code>str</code> follows base64 transfer encoding for MIME (RFC 2045), and will discard characters outside the base encoding alphabet. Returns <code>nil</code> if <code>str</code> is not well formed.</p> <p>'''Note:''' This method requires the <code>resty.core.base64</code> or <code>resty.core</code> modules from the lua-resty-core library.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxcrc32_short","title":"ngx.crc32_short","text":"<p>syntax: intval = ngx.crc32_short(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Calculates the CRC-32 (Cyclic Redundancy Code) digest for the <code>str</code> argument.</p> <p>This method performs better on relatively short <code>str</code> inputs (i.e., less than 30 ~ 60 bytes), as compared to ngx.crc32_long. The result is exactly the same as ngx.crc32_long.</p> <p>Behind the scene, it is just a thin wrapper around the <code>ngx_crc32_short</code> function defined in the Nginx core.</p> <p>This API was first introduced in the <code>v0.3.1rc8</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxcrc32_long","title":"ngx.crc32_long","text":"<p>syntax: intval = ngx.crc32_long(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Calculates the CRC-32 (Cyclic Redundancy Code) digest for the <code>str</code> argument.</p> <p>This method performs better on relatively long <code>str</code> inputs (i.e., longer than 30 ~ 60 bytes), as compared to ngx.crc32_short.  The result is exactly the same as ngx.crc32_short.</p> <p>Behind the scene, it is just a thin wrapper around the <code>ngx_crc32_long</code> function defined in the Nginx core.</p> <p>This API was first introduced in the <code>v0.3.1rc8</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxhmac_sha1","title":"ngx.hmac_sha1","text":"<p>syntax: digest = ngx.hmac_sha1(secret_key, str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Computes the HMAC-SHA1 digest of the argument <code>str</code> and turns the result using the secret key <code>&lt;secret_key&gt;</code>.</p> <p>The raw binary form of the <code>HMAC-SHA1</code> digest will be generated, use ngx.encode_base64, for example, to encode the result to a textual representation if desired.</p> <p>For example,</p> <pre><code> local key = \"thisisverysecretstuff\"\n local src = \"some string we want to sign\"\n local digest = ngx.hmac_sha1(key, src)\n ngx.say(ngx.encode_base64(digest))\n</code></pre> <p>yields the output</p> <pre><code>R/pvxzHC4NLtj7S+kXFg/NePTmk=\n</code></pre> <p>This API requires the OpenSSL library enabled in the Nginx build (usually by passing the <code>--with-http_ssl_module</code> option to the <code>./configure</code> script).</p> <p>This function was first introduced in the <code>v0.3.1rc29</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxmd5","title":"ngx.md5","text":"<p>syntax: digest = ngx.md5(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the hexadecimal representation of the MD5 digest of the <code>str</code> argument.</p> <p>For example,</p> <pre><code> location = /md5 {\n     content_by_lua_block {\n         ngx.say(ngx.md5(\"hello\"))\n     }\n }\n</code></pre> <p>yields the output</p> <pre><code>5d41402abc4b2a76b9719d911017c592\n</code></pre> <p>See ngx.md5_bin if the raw binary MD5 digest is required.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxmd5_bin","title":"ngx.md5_bin","text":"<p>syntax: digest = ngx.md5_bin(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the binary form of the MD5 digest of the <code>str</code> argument.</p> <p>See ngx.md5 if the hexadecimal form of the MD5 digest is required.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsha1_bin","title":"ngx.sha1_bin","text":"<p>syntax: digest = ngx.sha1_bin(str)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the binary form of the SHA-1 digest of the <code>str</code> argument.</p> <p>This function requires SHA-1 support in the Nginx build. (This usually just means OpenSSL should be installed while building Nginx).</p> <p>This function was first introduced in the <code>v0.5.0rc6</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxquote_sql_str","title":"ngx.quote_sql_str","text":"<p>syntax: quoted_value = ngx.quote_sql_str(raw_value)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns a quoted SQL string literal according to the MySQL quoting rules.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtoday","title":"ngx.today","text":"<p>syntax: str = ngx.today()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns current date (in the format <code>yyyy-mm-dd</code>) from the Nginx cached time (no syscall involved unlike Lua's date library).</p> <p>This is the local time.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtime","title":"ngx.time","text":"<p>syntax: secs = ngx.time()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the elapsed seconds from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library).</p> <p>Updates of the Nginx time cache can be forced by calling ngx.update_time first.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxnow","title":"ngx.now","text":"<p>syntax: secs = ngx.now()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns a floating-point number for the elapsed time in seconds (including milliseconds as the decimal part) from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library).</p> <p>You can forcibly update the Nginx time cache by calling ngx.update_time first.</p> <p>This API was first introduced in <code>v0.3.1rc32</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxupdate_time","title":"ngx.update_time","text":"<p>syntax: ngx.update_time()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Forcibly updates the Nginx current time cache. This call involves a syscall and thus has some overhead, so do not abuse it.</p> <p>This API was first introduced in <code>v0.3.1rc32</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxlocaltime","title":"ngx.localtime","text":"<p>syntax: str = ngx.localtime()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the current time stamp (in the format <code>yyyy-mm-dd hh:mm:ss</code>) of the Nginx cached time (no syscall involved unlike Lua's os.date function).</p> <p>This is the local time.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxutctime","title":"ngx.utctime","text":"<p>syntax: str = ngx.utctime()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the current time stamp (in the format <code>yyyy-mm-dd hh:mm:ss</code>) of the Nginx cached time (no syscall involved unlike Lua's os.date function).</p> <p>This is the UTC time.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxcookie_time","title":"ngx.cookie_time","text":"<p>syntax: str = ngx.cookie_time(sec)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns a formatted string can be used as the cookie expiration time. The parameter <code>sec</code> is the time stamp in seconds (like those returned from ngx.time).</p> <pre><code> ngx.say(ngx.cookie_time(1290079655))\n     -- yields \"Thu, 18-Nov-10 11:27:35 GMT\"\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxhttp_time","title":"ngx.http_time","text":"<p>syntax: str = ngx.http_time(sec)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns a formated string can be used as the http header time (for example, being used in <code>Last-Modified</code> header). The parameter <code>sec</code> is the time stamp in seconds (like those returned from ngx.time).</p> <pre><code> ngx.say(ngx.http_time(1290079655))\n     -- yields \"Thu, 18 Nov 2010 11:27:35 GMT\"\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxparse_http_time","title":"ngx.parse_http_time","text":"<p>syntax: sec = ngx.parse_http_time(str)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Parse the http time string (as returned by ngx.http_time) into seconds. Returns the seconds or <code>nil</code> if the input string is in bad forms.</p> <pre><code> local time = ngx.parse_http_time(\"Thu, 18 Nov 2010 11:27:35 GMT\")\n if time == nil then\n     ...\n end\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxis_subrequest","title":"ngx.is_subrequest","text":"<p>syntax: value = ngx.is_subrequest</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*</p> <p>Returns <code>true</code> if the current request is an Nginx subrequest, or <code>false</code> otherwise.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxrematch","title":"ngx.re.match","text":"<p>syntax: captures, err = ngx.re.match(subject, regex, options?, ctx?, res_table?)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Matches the <code>subject</code> string using the Perl compatible regular expression <code>regex</code> with the optional <code>options</code>.</p> <p>Only the first occurrence of the match is returned, or <code>nil</code> if no match is found. In case of errors, like seeing a bad regular expression or exceeding the PCRE stack limit, <code>nil</code> and a string describing the error will be returned.</p> <p>When a match is found, a Lua table <code>captures</code> is returned, where <code>captures[0]</code> holds the whole substring being matched, and <code>captures[1]</code> holds the first parenthesized sub-pattern's capturing, <code>captures[2]</code> the second, and so on.</p> <pre><code> local m, err = ngx.re.match(\"hello, 1234\", \"[0-9]+\")\n if m then\n     -- m[0] == \"1234\"\n\n else\n     if err then\n         ngx.log(ngx.ERR, \"error: \", err)\n         return\n     end\n\n     ngx.say(\"match not found\")\n end\n</code></pre> <pre><code> local m, err = ngx.re.match(\"hello, 1234\", \"([0-9])[0-9]+\")\n -- m[0] == \"1234\"\n -- m[1] == \"1\"\n</code></pre> <p>Named captures are also supported since the <code>v0.7.14</code> release and are returned in the same Lua table as key-value pairs as the numbered captures.</p> <pre><code> local m, err = ngx.re.match(\"hello, 1234\", \"([0-9])(?&lt;remaining&gt;[0-9]+)\")\n -- m[0] == \"1234\"\n -- m[1] == \"1\"\n -- m[2] == \"234\"\n -- m[\"remaining\"] == \"234\"\n</code></pre> <p>Unmatched subpatterns will have <code>false</code> values in their <code>captures</code> table fields.</p> <pre><code> local m, err = ngx.re.match(\"hello, world\", \"(world)|(hello)|(?&lt;named&gt;howdy)\")\n -- m[0] == \"hello\"\n -- m[1] == false\n -- m[2] == \"hello\"\n -- m[3] == false\n -- m[\"named\"] == false\n</code></pre> <p>Specify <code>options</code> to control how the match operation will be performed. The following option characters are supported:</p> <pre><code>a             anchored mode (only match from the beginning)\n\nd             enable the DFA mode (or the longest token match semantics).\n              this requires PCRE 6.0+ or else a Lua exception will be thrown.\n              first introduced in ngx_lua v0.3.1rc30.\n\nD             enable duplicate named pattern support. This allows named\n              subpattern names to be repeated, returning the captures in\n              an array-like Lua table. for example,\n                local m = ngx.re.match(\"hello, world\",\n                                       \"(?&lt;named&gt;\\w+), (?&lt;named&gt;\\w+)\",\n                                       \"D\")\n                -- m[\"named\"] == {\"hello\", \"world\"}\n              this option was first introduced in the v0.7.14 release.\n              this option requires at least PCRE 8.12.\n\ni             case insensitive mode (similar to Perl's /i modifier)\n\nj             enable PCRE JIT compilation, this requires PCRE 8.21+ which\n              must be built with the --enable-jit option. for optimum performance,\n              this option should always be used together with the 'o' option.\n              first introduced in ngx_lua v0.3.1rc30.\n\nJ             enable the PCRE Javascript compatible mode. this option was\n              first introduced in the v0.7.14 release. this option requires\n              at least PCRE 8.12.\n\nm             multi-line mode (similar to Perl's /m modifier)\n\no             compile-once mode (similar to Perl's /o modifier),\n              to enable the worker-process-level compiled-regex cache\n\ns             single-line mode (similar to Perl's /s modifier)\n\nu             UTF-8 mode. this requires PCRE to be built with\n              the --enable-utf8 option or else a Lua exception will be thrown.\n\nU             similar to \"u\" but disables PCRE's UTF-8 validity check on\n              the subject string. first introduced in ngx_lua v0.8.1.\n\nx             extended mode (similar to Perl's /x modifier)\n</code></pre> <p>These options can be combined:</p> <pre><code> local m, err = ngx.re.match(\"hello, world\", \"HEL LO\", \"ix\")\n -- m[0] == \"hello\"\n</code></pre> <pre><code> local m, err = ngx.re.match(\"hello, \u7f8e\u597d\u751f\u6d3b\", \"HELLO, (.{2})\", \"iu\")\n -- m[0] == \"hello, \u7f8e\u597d\"\n -- m[1] == \"\u7f8e\u597d\"\n</code></pre> <p>The <code>o</code> option is useful for performance tuning, because the regex pattern in question will only be compiled once, cached in the worker-process level, and shared among all requests in the current Nginx worker process. The upper limit of the regex cache can be tuned via the lua_regex_cache_max_entries directive.</p> <p>The optional fourth argument, <code>ctx</code>, can be a Lua table holding an optional <code>pos</code> field. When the <code>pos</code> field in the <code>ctx</code> table argument is specified, <code>ngx.re.match</code> will start matching from that offset (starting from 1). Regardless of the presence of the <code>pos</code> field in the <code>ctx</code> table, <code>ngx.re.match</code> will always set this <code>pos</code> field to the position after the substring matched by the whole pattern in case of a successful match. When match fails, the <code>ctx</code> table will be left intact.</p> <pre><code> local ctx = {}\n local m, err = ngx.re.match(\"1234, hello\", \"[0-9]+\", \"\", ctx)\n      -- m[0] = \"1234\"\n      -- ctx.pos == 5\n</code></pre> <pre><code> local ctx = { pos = 2 }\n local m, err = ngx.re.match(\"1234, hello\", \"[0-9]+\", \"\", ctx)\n      -- m[0] = \"234\"\n      -- ctx.pos == 5\n</code></pre> <p>The <code>ctx</code> table argument combined with the <code>a</code> regex modifier can be used to construct a lexer atop <code>ngx.re.match</code>.</p> <p>Note that, the <code>options</code> argument is not optional when the <code>ctx</code> argument is specified and that the empty Lua string (<code>\"\"</code>) must be used as placeholder for <code>options</code> if no meaningful regex options are required.</p> <p>This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences).</p> <p>To confirm that PCRE JIT is enabled, activate the Nginx debug log by adding the <code>--with-debug</code> option to Nginx or OpenResty's <code>./configure</code> script. Then, enable the \"debug\" error log level in <code>error_log</code> directive. The following message will be generated if PCRE JIT is enabled:</p> <pre><code>pcre JIT compiling result: 1\n</code></pre> <p>Starting from the <code>0.9.4</code> release, this function also accepts a 5th argument, <code>res_table</code>, for letting the caller supply the Lua table used to hold all the capturing results. Starting from <code>0.9.6</code>, it is the caller's responsibility to ensure this table is empty. This is very useful for recycling Lua tables and saving GC and table allocation overhead.</p> <p>This feature was introduced in the <code>v0.2.1rc11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxrefind","title":"ngx.re.find","text":"<p>syntax: from, to, err = ngx.re.find(subject, regex, options?, ctx?, nth?)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to ngx.re.match but only returns the beginning index (<code>from</code>) and end index (<code>to</code>) of the matched substring. The returned indexes are 1-based and can be fed directly into the string.sub API function to obtain the matched substring.</p> <p>In case of errors (like bad regexes or any PCRE runtime errors), this API function returns two <code>nil</code> values followed by a string describing the error.</p> <p>If no match is found, this function just returns a <code>nil</code> value.</p> <p>Below is an example:</p> <pre><code> local s = \"hello, 1234\"\n local from, to, err = ngx.re.find(s, \"([0-9]+)\", \"jo\")\n if from then\n     ngx.say(\"from: \", from)\n     ngx.say(\"to: \", to)\n     ngx.say(\"matched: \", string.sub(s, from, to))\n else\n     if err then\n         ngx.say(\"error: \", err)\n         return\n     end\n     ngx.say(\"not matched!\")\n end\n</code></pre> <p>This example produces the output</p> <pre><code>from: 8\nto: 11\nmatched: 1234\n</code></pre> <p>Because this API function does not create new Lua strings nor new Lua tables, it is much faster than ngx.re.match. It should be used wherever possible.</p> <p>Since the <code>0.9.3</code> release, an optional 5th argument, <code>nth</code>, is supported to specify which (submatch) capture's indexes to return. When <code>nth</code> is 0 (which is the default), the indexes for the whole matched substring is returned; when <code>nth</code> is 1, then the 1st submatch capture's indexes are returned; when <code>nth</code> is 2, then the 2nd submatch capture is returned, and so on. When the specified submatch does not have a match, then two <code>nil</code> values will be returned. Below is an example for this:</p> <pre><code> local str = \"hello, 1234\"\n local from, to = ngx.re.find(str, \"([0-9])([0-9]+)\", \"jo\", nil, 2)\n if from then\n     ngx.say(\"matched 2nd submatch: \", string.sub(str, from, to))  -- yields \"234\"\n end\n</code></pre> <p>This API function was first introduced in the <code>v0.9.2</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxregmatch","title":"ngx.re.gmatch","text":"<p>syntax: iterator, err = ngx.re.gmatch(subject, regex, options?)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to ngx.re.match, but returns a Lua iterator instead, so as to let the user programmer iterate all the matches over the <code>&lt;subject&gt;</code> string argument with the PCRE <code>regex</code>.</p> <p>In case of errors, like seeing an ill-formed regular expression, <code>nil</code> and a string describing the error will be returned.</p> <p>Here is a small example to demonstrate its basic usage:</p> <pre><code> local iterator, err = ngx.re.gmatch(\"hello, world!\", \"([a-z]+)\", \"i\")\n if not iterator then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n local m\n m, err = iterator()    -- m[0] == m[1] == \"hello\"\n if err then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n m, err = iterator()    -- m[0] == m[1] == \"world\"\n if err then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n m, err = iterator()    -- m == nil\n if err then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n</code></pre> <p>More often we just put it into a Lua loop:</p> <pre><code> local it, err = ngx.re.gmatch(\"hello, world!\", \"([a-z]+)\", \"i\")\n if not it then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n while true do\n     local m, err = it()\n     if err then\n         ngx.log(ngx.ERR, \"error: \", err)\n         return\n     end\n\n     if not m then\n         -- no match found (any more)\n         break\n     end\n\n     -- found a match\n     ngx.say(m[0])\n     ngx.say(m[1])\n end\n</code></pre> <p>The optional <code>options</code> argument takes exactly the same semantics as the ngx.re.match method.</p> <p>The current implementation requires that the iterator returned should only be used in a single request. That is, one should not assign it to a variable belonging to persistent namespace like a Lua package.</p> <p>This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences).</p> <p>This feature was first introduced in the <code>v0.2.1rc12</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxresub","title":"ngx.re.sub","text":"<p>syntax: newstr, n, err = ngx.re.sub(subject, regex, replace, options?)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Substitutes the first match of the Perl compatible regular expression <code>regex</code> on the <code>subject</code> argument string with the string or function argument <code>replace</code>. The optional <code>options</code> argument has exactly the same meaning as in ngx.re.match.</p> <p>This method returns the resulting new string as well as the number of successful substitutions. In case of failures, like syntax errors in the regular expressions or the <code>&lt;replace&gt;</code> string argument, it will return <code>nil</code> and a string describing the error.</p> <p>When the <code>replace</code> is a string, then it is treated as a special template for string replacement. For example,</p> <pre><code> local newstr, n, err = ngx.re.sub(\"hello, 1234\", \"([0-9])[0-9]\", \"[$0][$1]\")\n if not newstr then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n -- newstr == \"hello, [12][1]34\"\n -- n == 1\n</code></pre> <p>where <code>$0</code> referring to the whole substring matched by the pattern and <code>$1</code> referring to the first parenthesized capturing substring.</p> <p>Curly braces can also be used to disambiguate variable names from the background string literals:</p> <pre><code> local newstr, n, err = ngx.re.sub(\"hello, 1234\", \"[0-9]\", \"${0}00\")\n -- newstr == \"hello, 100234\"\n -- n == 1\n</code></pre> <p>Literal dollar sign characters (<code>$</code>) in the <code>replace</code> string argument can be escaped by another dollar sign, for instance,</p> <pre><code> local newstr, n, err = ngx.re.sub(\"hello, 1234\", \"[0-9]\", \"$$\")\n -- newstr == \"hello, $234\"\n -- n == 1\n</code></pre> <p>Do not use backlashes to escape dollar signs; it will not work as expected.</p> <p>When the <code>replace</code> argument is of type \"function\", then it will be invoked with the \"match table\" as the argument to generate the replace string literal for substitution. The \"match table\" fed into the <code>replace</code> function is exactly the same as the return value of ngx.re.match. Here is an example:</p> <pre><code> local func = function (m)\n     return \"[\" .. m[0] .. \"][\" .. m[1] .. \"]\"\n end\n\n local newstr, n, err = ngx.re.sub(\"hello, 1234\", \"( [0-9] ) [0-9]\", func, \"x\")\n -- newstr == \"hello, [12][1]34\"\n -- n == 1\n</code></pre> <p>The dollar sign characters in the return value of the <code>replace</code> function argument are not special at all.</p> <p>This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences).</p> <p>This feature was first introduced in the <code>v0.2.1rc13</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxregsub","title":"ngx.re.gsub","text":"<p>syntax: newstr, n, err = ngx.re.gsub(subject, regex, replace, options?)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Just like ngx.re.sub, but does global substitution.</p> <p>Here is some examples:</p> <pre><code> local newstr, n, err = ngx.re.gsub(\"hello, world\", \"([a-z])[a-z]+\", \"[$0,$1]\", \"i\")\n if not newstr then\n     ngx.log(ngx.ERR, \"error: \", err)\n     return\n end\n\n -- newstr == \"[hello,h], [world,w]\"\n -- n == 2\n</code></pre> <pre><code> local func = function (m)\n     return \"[\" .. m[0] .. \",\" .. m[1] .. \"]\"\n end\n local newstr, n, err = ngx.re.gsub(\"hello, world\", \"([a-z])[a-z]+\", func, \"i\")\n -- newstr == \"[hello,h], [world,w]\"\n -- n == 2\n</code></pre> <p>This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences).</p> <p>This feature was first introduced in the <code>v0.2.1rc15</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddict","title":"ngx.shared.DICT","text":"<p>syntax: dict = ngx.shared.DICT</p> <p>syntax: dict = ngx.shared[name_var]</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Fetching the shm-based Lua dictionary object for the shared memory zone named <code>DICT</code> defined by the lua_shared_dict directive.</p> <p>Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance.</p> <p>The resulting object <code>dict</code> has the following methods:</p> <ul> <li>get</li> <li>get_stale</li> <li>set</li> <li>safe_set</li> <li>add</li> <li>safe_add</li> <li>replace</li> <li>delete</li> <li>incr</li> <li>lpush</li> <li>rpush</li> <li>lpop</li> <li>rpop</li> <li>llen</li> <li>ttl</li> <li>expire</li> <li>flush_all</li> <li>flush_expired</li> <li>get_keys</li> <li>capacity</li> <li>free_space</li> </ul> <p>All these methods are atomic operations, that is, safe from concurrent accesses from multiple Nginx worker processes for the same <code>lua_shared_dict</code> zone.</p> <p>Here is an example:</p> <pre><code> http {\n     lua_shared_dict dogs 10m;\n     server {\n         location /set {\n             content_by_lua_block {\n                 local dogs = ngx.shared.dogs\n                 dogs:set(\"Jim\", 8)\n                 ngx.say(\"STORED\")\n             }\n         }\n         location /get {\n             content_by_lua_block {\n                 local dogs = ngx.shared.dogs\n                 ngx.say(dogs:get(\"Jim\"))\n             }\n         }\n     }\n }\n</code></pre> <p>Let us test it:</p> <pre><code> $ curl localhost/set\n STORED\n\n $ curl localhost/get\n 8\n\n $ curl localhost/get\n 8\n</code></pre> <p>The number <code>8</code> will be consistently output when accessing <code>/get</code> regardless of how many Nginx workers there are because the <code>dogs</code> dictionary resides in the shared memory and visible to all of the worker processes.</p> <p>The shared dictionary will retain its contents through a server config reload (either by sending the <code>HUP</code> signal to the Nginx process or by using the <code>-s reload</code> command-line option).</p> <p>The contents in the dictionary storage will be lost, however, when the Nginx server quits.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictget","title":"ngx.shared.DICT.get","text":"<p>syntax: value, flags = ngx.shared.DICT:get(key)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Retrieving the value in the dictionary ngx.shared.DICT for the key <code>key</code>. If the key does not exist or has expired, then <code>nil</code> will be returned.</p> <p>In case of errors, <code>nil</code> and a string describing the error will be returned.</p> <p>The value returned will have the original data type when they were inserted into the dictionary, for example, Lua booleans, numbers, or strings.</p> <p>The first argument to this method must be the dictionary object itself, for example,</p> <pre><code> local cats = ngx.shared.cats\n local value, flags = cats.get(cats, \"Marry\")\n</code></pre> <p>or use Lua's syntactic sugar for method calls:</p> <pre><code> local cats = ngx.shared.cats\n local value, flags = cats:get(\"Marry\")\n</code></pre> <p>These two forms are fundamentally equivalent.</p> <p>If the user flags is <code>0</code> (the default), then no flags value will be returned.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictget_stale","title":"ngx.shared.DICT.get_stale","text":"<p>syntax: value, flags, stale = ngx.shared.DICT:get_stale(key)</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the get method but returns the value even if the key has already expired.</p> <p>Returns a 3rd value, <code>stale</code>, indicating whether the key has expired or not.</p> <p>Note that the value of an expired key is not guaranteed to be available so one should never rely on the availability of expired items.</p> <p>This method was first introduced in the <code>0.8.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictset","title":"ngx.shared.DICT.set","text":"<p>syntax: success, err, forcible = ngx.shared.DICT:set(key, value, exptime?, flags?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Unconditionally sets a key-value pair into the shm-based dictionary ngx.shared.DICT. Returns three values:</p> <ul> <li><code>success</code>: boolean value to indicate whether the key-value pair is stored or not.</li> <li><code>err</code>: textual error message, can be <code>\"no memory\"</code>.</li> <li><code>forcible</code>: a boolean value to indicate whether other valid items have been removed forcibly when out of storage in the shared memory zone.</li> </ul> <p>The <code>value</code> argument inserted can be Lua booleans, numbers, strings, or <code>nil</code>. Their value type will also be stored into the dictionary and the same data type can be retrieved later via the get method.</p> <p>The optional <code>exptime</code> argument specifies expiration time (in seconds) for the inserted key-value pair. The time resolution is <code>0.001</code> seconds. If the <code>exptime</code> takes the value <code>0</code> (which is the default), then the item will never expire.</p> <p>The optional <code>flags</code> argument specifies a user flags value associated with the entry to be stored. It can also be retrieved later with the value. The user flags is stored as an unsigned 32-bit integer internally. Defaults to <code>0</code>. The user flags argument was first introduced in the <code>v0.5.0rc2</code> release.</p> <p>When it fails to allocate memory for the current key-value item, then <code>set</code> will try removing existing items in the storage according to the Least-Recently Used (LRU) algorithm. Note that, LRU takes priority over expiration time here. If up to tens of existing items have been removed and the storage left is still insufficient (either due to the total capacity limit specified by lua_shared_dict or memory segmentation), then the <code>err</code> return value will be <code>no memory</code> and <code>success</code> will be <code>false</code>.</p> <p>If the sizes of items in the dictionary are not multiples or even powers of a certain value (like 2), it is easier to encounter <code>no memory</code> error because of memory fragmentation. It is recommended to use different dictionaries for different sizes of items.</p> <p>When you encounter <code>no memory</code> error, you can also evict more least-recently-used items by retrying this method call more times to to make room for the current item.</p> <p>If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the <code>forcible</code> return value will be <code>true</code>. If it stores the item without forcibly removing other valid items, then the return value <code>forcible</code> will be <code>false</code>.</p> <p>The first argument to this method must be the dictionary object itself, for example,</p> <pre><code> local cats = ngx.shared.cats\n local succ, err, forcible = cats.set(cats, \"Marry\", \"it is a nice cat!\")\n</code></pre> <p>or use Lua's syntactic sugar for method calls:</p> <pre><code> local cats = ngx.shared.cats\n local succ, err, forcible = cats:set(\"Marry\", \"it is a nice cat!\")\n</code></pre> <p>These two forms are fundamentally equivalent.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>Please note that while internally the key-value pair is set atomically, the atomicity does not go across the method call boundary.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictsafe_set","title":"ngx.shared.DICT.safe_set","text":"<p>syntax: ok, err = ngx.shared.DICT:safe_set(key, value, exptime?, flags?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the set method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string \"no memory\".</p> <p>This feature was first introduced in the <code>v0.7.18</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictadd","title":"ngx.shared.DICT.add","text":"<p>syntax: success, err, forcible = ngx.shared.DICT:add(key, value, exptime?, flags?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Just like the set method, but only stores the key-value pair into the dictionary ngx.shared.DICT if the key does not exist.</p> <p>If the <code>key</code> argument already exists in the dictionary (and not expired for sure), the <code>success</code> return value will be <code>false</code> and the <code>err</code> return value will be <code>\"exists\"</code>.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictsafe_add","title":"ngx.shared.DICT.safe_add","text":"<p>syntax: ok, err = ngx.shared.DICT:safe_add(key, value, exptime?, flags?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the add method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string \"no memory\".</p> <p>This feature was first introduced in the <code>v0.7.18</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictreplace","title":"ngx.shared.DICT.replace","text":"<p>syntax: success, err, forcible = ngx.shared.DICT:replace(key, value, exptime?, flags?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Just like the set method, but only stores the key-value pair into the dictionary ngx.shared.DICT if the key does exist.</p> <p>If the <code>key</code> argument does not exist in the dictionary (or expired already), the <code>success</code> return value will be <code>false</code> and the <code>err</code> return value will be <code>\"not found\"</code>.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictdelete","title":"ngx.shared.DICT.delete","text":"<p>syntax: ngx.shared.DICT:delete(key)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Unconditionally removes the key-value pair from the shm-based dictionary ngx.shared.DICT.</p> <p>It is equivalent to <code>ngx.shared.DICT:set(key, nil)</code>.</p> <p>This feature was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictincr","title":"ngx.shared.DICT.incr","text":"<p>syntax: newval, err, forcible? = ngx.shared.DICT:incr(key, value, init?, init_ttl?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>optional requirement: <code>resty.core.shdict</code> or <code>resty.core</code></p> <p>Increments the (numerical) value for <code>key</code> in the shm-based dictionary ngx.shared.DICT by the step value <code>value</code>. Returns the new resulting number if the operation is successfully completed or <code>nil</code> and an error message otherwise.</p> <p>When the key does not exist or has already expired in the shared dictionary,</p> <ol> <li>if the <code>init</code> argument is not specified or takes the value <code>nil</code>, this method will return <code>nil</code> and the error string <code>\"not found\"</code>, or</li> <li>if the <code>init</code> argument takes a number value, this method will create a new <code>key</code> with the value <code>init + value</code>.</li> </ol> <p>Like the add method, it also overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone.</p> <p>The optional <code>init_ttl</code> argument specifies expiration time (in seconds) of the value when it is initialized via the <code>init</code> argument. The time resolution is <code>0.001</code> seconds. If <code>init_ttl</code> takes the value <code>0</code> (which is the default), then the item will never expire. This argument cannot be provided without providing the <code>init</code> argument as well, and has no effect if the value already exists (e.g., if it was previously inserted via set or the likes).</p> <p>Note: Usage of the <code>init_ttl</code> argument requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the lua-resty-core library. Example:</p> <pre><code> require \"resty.core\"\n\n local cats = ngx.shared.cats\n local newval, err = cats:incr(\"black_cats\", 1, 0, 0.1)\n\n print(newval) -- 1\n\n ngx.sleep(0.2)\n\n local val, err = cats:get(\"black_cats\")\n print(val) -- nil\n</code></pre> <p>The <code>forcible</code> return value will always be <code>nil</code> when the <code>init</code> argument is not specified.</p> <p>If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the <code>forcible</code> return value will be <code>true</code>. If it stores the item without forcibly removing other valid items, then the return value <code>forcible</code> will be <code>false</code>.</p> <p>If the original value is not a valid Lua number in the dictionary, it will return <code>nil</code> and <code>\"not a number\"</code>.</p> <p>The <code>value</code> argument and <code>init</code> argument can be any valid Lua numbers, like negative numbers or floating-point numbers.</p> <p>This method was first introduced in the <code>v0.3.1rc22</code> release.</p> <p>The optional <code>init</code> parameter was first added in the <code>v0.10.6</code> release.</p> <p>The optional <code>init_ttl</code> parameter was introduced in the <code>v0.10.12rc2</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictlpush","title":"ngx.shared.DICT.lpush","text":"<p>syntax: length, err = ngx.shared.DICT:lpush(key, value)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Inserts the specified (numerical or string) <code>value</code> at the head of the list named <code>key</code> in the shm-based dictionary ngx.shared.DICT. Returns the number of elements in the list after the push operation.</p> <p>If <code>key</code> does not exist, it is created as an empty list before performing the push operation. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>\"value not a list\"</code>.</p> <p>It never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string \"no memory\".</p> <p>This feature was first introduced in the <code>v0.10.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictrpush","title":"ngx.shared.DICT.rpush","text":"<p>syntax: length, err = ngx.shared.DICT:rpush(key, value)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the lpush method, but inserts the specified (numerical or string) <code>value</code> at the tail of the list named <code>key</code>.</p> <p>This feature was first introduced in the <code>v0.10.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictlpop","title":"ngx.shared.DICT.lpop","text":"<p>syntax: val, err = ngx.shared.DICT:lpop(key)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Removes and returns the first element of the list named <code>key</code> in the shm-based dictionary ngx.shared.DICT.</p> <p>If <code>key</code> does not exist, it will return <code>nil</code>. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>\"value not a list\"</code>.</p> <p>This feature was first introduced in the <code>v0.10.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictrpop","title":"ngx.shared.DICT.rpop","text":"<p>syntax: val, err = ngx.shared.DICT:rpop(key)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Removes and returns the last element of the list named <code>key</code> in the shm-based dictionary ngx.shared.DICT.</p> <p>If <code>key</code> does not exist, it will return <code>nil</code>. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>\"value not a list\"</code>.</p> <p>This feature was first introduced in the <code>v0.10.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictllen","title":"ngx.shared.DICT.llen","text":"<p>syntax: len, err = ngx.shared.DICT:llen(key)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the number of elements in the list named <code>key</code> in the shm-based dictionary ngx.shared.DICT.</p> <p>If key does not exist, it is interpreted as an empty list and 0 is returned. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>\"value not a list\"</code>.</p> <p>This feature was first introduced in the <code>v0.10.6</code> release.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictttl","title":"ngx.shared.DICT.ttl","text":"<p>syntax: ttl, err = ngx.shared.DICT:ttl(key)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>requires: <code>resty.core.shdict</code> or <code>resty.core</code></p> <p>Retrieves the remaining TTL (time-to-live in seconds) of a key-value pair in the shm-based dictionary ngx.shared.DICT. Returns the TTL as a number if the operation is successfully completed or <code>nil</code> and an error message otherwise.</p> <p>If the key does not exist (or has already expired), this method will return <code>nil</code> and the error string <code>\"not found\"</code>.</p> <p>The TTL is originally determined by the <code>exptime</code> argument of the set, add, replace (and the likes) methods. It has a time resolution of <code>0.001</code> seconds. A value of <code>0</code> means that the item will never expire.</p> <p>Example:</p> <pre><code> require \"resty.core\"\n\n local cats = ngx.shared.cats\n local succ, err = cats:set(\"Marry\", \"a nice cat\", 0.5)\n\n ngx.sleep(0.2)\n\n local ttl, err = cats:ttl(\"Marry\")\n ngx.say(ttl) -- 0.3\n</code></pre> <p>This feature was first introduced in the <code>v0.10.11</code> release.</p> <p>Note: This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the lua-resty-core library.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictexpire","title":"ngx.shared.DICT.expire","text":"<p>syntax: success, err = ngx.shared.DICT:expire(key, exptime)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>requires: <code>resty.core.shdict</code> or <code>resty.core</code></p> <p>Updates the <code>exptime</code> (in second) of a key-value pair in the shm-based dictionary ngx.shared.DICT. Returns a boolean indicating success if the operation completes or <code>nil</code> and an error message otherwise.</p> <p>If the key does not exist, this method will return <code>nil</code> and the error string <code>\"not found\"</code>.</p> <p>The <code>exptime</code> argument has a resolution of <code>0.001</code> seconds. If <code>exptime</code> is <code>0</code>, then the item will never expire.</p> <p>Example:</p> <pre><code> require \"resty.core\"\n\n local cats = ngx.shared.cats\n local succ, err = cats:set(\"Marry\", \"a nice cat\", 0.1)\n\n succ, err = cats:expire(\"Marry\", 0.5)\n\n ngx.sleep(0.2)\n\n local val, err = cats:get(\"Marry\")\n ngx.say(val) -- \"a nice cat\"\n</code></pre> <p>This feature was first introduced in the <code>v0.10.11</code> release.</p> <p>Note: This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the lua-resty-core library.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictflush_all","title":"ngx.shared.DICT.flush_all","text":"<p>syntax: ngx.shared.DICT:flush_all()</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Flushes out all the items in the dictionary. This method does not actually free up all the memory blocks in the dictionary but just marks all the existing items as expired.</p> <p>This feature was first introduced in the <code>v0.5.0rc17</code> release.</p> <p>See also ngx.shared.DICT.flush_expired and ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictflush_expired","title":"ngx.shared.DICT.flush_expired","text":"<p>syntax: flushed = ngx.shared.DICT:flush_expired(max_count?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Flushes out the expired items in the dictionary, up to the maximal number specified by the optional <code>max_count</code> argument. When the <code>max_count</code> argument is given <code>0</code> or not given at all, then it means unlimited. Returns the number of items that have actually been flushed.</p> <p>Unlike the flush_all method, this method actually frees up the memory used by the expired items.</p> <p>This feature was first introduced in the <code>v0.6.3</code> release.</p> <p>See also ngx.shared.DICT.flush_all and ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictget_keys","title":"ngx.shared.DICT.get_keys","text":"<p>syntax: keys = ngx.shared.DICT:get_keys(max_count?)</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Fetch a list of the keys from the dictionary, up to <code>&lt;max_count&gt;</code>.</p> <p>By default, only the first 1024 keys (if any) are returned. When the <code>&lt;max_count&gt;</code> argument is given the value <code>0</code>, then all the keys will be returned even there is more than 1024 keys in the dictionary.</p> <p>CAUTION Avoid calling this method on dictionaries with a very large number of keys as it may lock the dictionary for significant amount of time and block Nginx worker processes trying to access the dictionary.</p> <p>This feature was first introduced in the <code>v0.7.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictcapacity","title":"ngx.shared.DICT.capacity","text":"<p>syntax: capacity_bytes = ngx.shared.DICT:capacity()</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>requires: <code>resty.core.shdict</code> or <code>resty.core</code></p> <p>Retrieves the capacity in bytes for the shm-based dictionary ngx.shared.DICT declared with the lua_shared_dict directive.</p> <p>Example:</p> <pre><code> require \"resty.core.shdict\"\n\n local cats = ngx.shared.cats\n local capacity_bytes = cats:capacity()\n</code></pre> <p>This feature was first introduced in the <code>v0.10.11</code> release.</p> <p>Note: This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the lua-resty-core library.</p> <p>This feature requires at least Nginx core version <code>0.7.3</code>.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxshareddictfree_space","title":"ngx.shared.DICT.free_space","text":"<p>syntax: free_page_bytes = ngx.shared.DICT:free_space()</p> <p>context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>requires: <code>resty.core.shdict</code> or <code>resty.core</code></p> <p>Retrieves the free page size in bytes for the shm-based dictionary ngx.shared.DICT.</p> <p>Note: The memory for ngx.shared.DICT is allocated via the Nginx slab allocator which has each slot for data size ranges like \\~8, 9\\~16, 17\\~32, ..., 1025\\~2048, 2048\\~ bytes. And pages are assigned to a slot if there is no room in already assigned pages for the slot.</p> <p>So even if the return value of the <code>free_space</code> method is zero, there may be room in already assigned pages, so you may successfully set a new key value pair to the shared dict without getting <code>true</code> for <code>forcible</code> or non nil <code>err</code> from the <code>ngx.shared.DICT.set</code>.</p> <p>On the other hand, if already assigned pages for a slot are full and a new key value pair is added to the slot and there is no free page, you may get <code>true</code> for <code>forcible</code> or non nil <code>err</code> from the <code>ngx.shared.DICT.set</code> method.</p> <p>Example:</p> <pre><code> require \"resty.core.shdict\"\n\n local cats = ngx.shared.cats\n local free_page_bytes = cats:free_space()\n</code></pre> <p>This feature was first introduced in the <code>v0.10.11</code> release.</p> <p>Note: This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the lua-resty-core library.</p> <p>This feature requires at least Nginx core version <code>1.11.7</code>.</p> <p>See also ngx.shared.DICT.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsocketudp","title":"ngx.socket.udp","text":"<p>syntax: udpsock = ngx.socket.udp()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Creates and returns a UDP or datagram-oriented unix domain socket object (also known as one type of the \"cosocket\" objects). The following methods are supported on this object:</p> <ul> <li>bind</li> <li>setpeername</li> <li>send</li> <li>receive</li> <li>close</li> <li>settimeout</li> </ul> <p>It is intended to be compatible with the UDP API of the LuaSocket library but is 100% nonblocking out of the box.</p> <p>This feature was first introduced in the <code>v0.5.7</code> release.</p> <p>See also ngx.socket.tcp.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsockbind","title":"udpsock:bind","text":"<p>syntax: ok, err = udpsock:bind(address)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*,ssl_session_fetch_by_lua*,ssl_client_hello_by_lua*</p> <p>Just like the standard proxy_bind directive, this api makes the outgoing connection to a upstream server originate from the specified local IP address.</p> <p>Only IP addresses can be specified as the <code>address</code> argument.</p> <p>Here is an example for connecting to a TCP server from the specified local IP address:</p> <pre><code> location /test {\n     content_by_lua_block {\n         local sock = ngx.socket.udp()\n         -- assume \"192.168.1.10\" is the local ip address\n         local ok, err = sock:bind(\"192.168.1.10\")\n         if not ok then\n             ngx.say(\"failed to bind: \", err)\n             return\n         end\n         sock:close()\n     }\n }\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsocksetpeername","title":"udpsock:setpeername","text":"<p>syntax: ok, err = udpsock:setpeername(host, port)</p> <p>syntax: ok, err = udpsock:setpeername(\"unix:/path/to/unix-domain.socket\")</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Attempts to connect a UDP socket object to a remote server or to a datagram unix domain socket file. Because the datagram protocol is actually connection-less, this method does not really establish a \"connection\", but only just set the name of the remote peer for subsequent read/write operations.</p> <p>Both IP addresses and domain names can be specified as the <code>host</code> argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the resolver directive in the <code>nginx.conf</code> file like this:</p> <pre><code> resolver 8.8.8.8;  # use Google's public DNS nameserver\n</code></pre> <p>If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly.</p> <p>In case of error, the method returns <code>nil</code> followed by a string describing the error. In case of success, the method returns <code>1</code>.</p> <p>Here is an example for connecting to a UDP (memcached) server:</p> <pre><code> location /test {\n     resolver 8.8.8.8;\n\n     content_by_lua_block {\n         local sock = ngx.socket.udp()\n         local ok, err = sock:setpeername(\"my.memcached.server.domain\", 11211)\n         if not ok then\n             ngx.say(\"failed to connect to memcached: \", err)\n             return\n         end\n         ngx.say(\"successfully connected to memcached!\")\n         sock:close()\n     }\n }\n</code></pre> <p>Since the <code>v0.7.18</code> release, connecting to a datagram unix domain socket file is also possible on Linux:</p> <pre><code> local sock = ngx.socket.udp()\n local ok, err = sock:setpeername(\"unix:/tmp/some-datagram-service.sock\")\n if not ok then\n     ngx.say(\"failed to connect to the datagram unix domain socket: \", err)\n     return\n end\n\n -- do something after connect\n -- such as sock:send or sock:receive\n</code></pre> <p>assuming the datagram service is listening on the unix domain socket file <code>/tmp/some-datagram-service.sock</code> and the client socket will use the \"autobind\" feature on Linux.</p> <p>Calling this method on an already connected socket object will cause the original connection to be closed first.</p> <p>This method was first introduced in the <code>v0.5.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsocksend","title":"udpsock:send","text":"<p>syntax: ok, err = udpsock:send(data)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Sends data on the current UDP or datagram unix domain socket object.</p> <p>In case of success, it returns <code>1</code>. Otherwise, it returns <code>nil</code> and a string describing the error.</p> <p>The input argument <code>data</code> can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land.</p> <p>This feature was first introduced in the <code>v0.5.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsockreceive","title":"udpsock:receive","text":"<p>syntax: data, err = udpsock:receive(size?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Receives data from the UDP or datagram unix domain socket object with an optional receive buffer size argument, <code>size</code>.</p> <p>This method is a synchronous operation and is 100% nonblocking.</p> <p>In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error.</p> <p>If the <code>size</code> argument is specified, then this method will use this size as the receive buffer size. But when this size is greater than <code>8192</code>, then <code>8192</code> will be used instead.</p> <p>If no argument is specified, then the maximal buffer size, <code>8192</code> is assumed.</p> <p>Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example:</p> <pre><code> sock:settimeout(1000)  -- one second timeout\n local data, err = sock:receive()\n if not data then\n     ngx.say(\"failed to read a packet: \", err)\n     return\n end\n ngx.say(\"successfully read a packet: \", data)\n</code></pre> <p>It is important here to call the settimeout method before calling this method.</p> <p>This feature was first introduced in the <code>v0.5.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsockclose","title":"udpsock:close","text":"<p>syntax: ok, err = udpsock:close()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Closes the current UDP or datagram unix domain socket. It returns the <code>1</code> in case of success and returns <code>nil</code> with a string describing the error otherwise.</p> <p>Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing.</p> <p>This feature was first introduced in the <code>v0.5.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#udpsocksettimeout","title":"udpsock:settimeout","text":"<p>syntax: udpsock:settimeout(time)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Set the timeout value in milliseconds for subsequent socket operations (like receive).</p> <p>Settings done by this method takes priority over those config directives, like lua_socket_read_timeout.</p> <p>This feature was first introduced in the <code>v0.5.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsocketstream","title":"ngx.socket.stream","text":"<p>Just an alias to ngx.socket.tcp. If the stream-typed cosocket may also connect to a unix domain socket, then this API name is preferred.</p> <p>This API function was first added to the <code>v0.10.1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsockettcp","title":"ngx.socket.tcp","text":"<p>syntax: tcpsock = ngx.socket.tcp()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Creates and returns a TCP or stream-oriented unix domain socket object (also known as one type of the \"cosocket\" objects). The following methods are supported on this object:</p> <ul> <li>bind</li> <li>connect</li> <li>setclientcert</li> <li>sslhandshake</li> <li>send</li> <li>receive</li> <li>close</li> <li>settimeout</li> <li>settimeouts</li> <li>setoption</li> <li>receiveany</li> <li>receiveuntil</li> <li>setkeepalive</li> <li>getreusedtimes</li> </ul> <p>It is intended to be compatible with the TCP API of the LuaSocket library but is 100% nonblocking out of the box. Also, we introduce some new APIs to provide more functionalities.</p> <p>The cosocket object created by this API function has exactly the same lifetime as the Lua handler creating it. So never pass the cosocket object to any other Lua handler (including ngx.timer callback functions) and never share the cosocket object between different Nginx requests.</p> <p>For every cosocket object's underlying connection, if you do not explicitly close it (via close) or put it back to the connection pool (via setkeepalive), then it is automatically closed when one of the following two events happens:</p> <ul> <li>the current request handler completes, or</li> <li>the Lua cosocket object value gets collected by the Lua GC.</li> </ul> <p>Fatal errors in cosocket operations always automatically close the current connection (note that, read timeout error is the only error that is not fatal), and if you call close on a closed connection, you will get the \"closed\" error.</p> <p>Starting from the <code>0.9.9</code> release, the cosocket object here is full-duplex, that is, a reader \"light thread\" and a writer \"light thread\" can operate on a single cosocket object simultaneously (both \"light threads\" must belong to the same Lua handler though, see reasons above). But you cannot have two \"light threads\" both reading (or writing or connecting) the same cosocket, otherwise you might get an error like \"socket busy reading\" when calling the methods of the cosocket object.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>See also ngx.socket.udp.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockbind","title":"tcpsock:bind","text":"<p>syntax: ok, err = tcpsock:bind(address, port?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*,ssl_session_fetch_by_lua*,ssl_client_hello_by_lua*</p> <p>Just like the standard proxy_bind directive, this api makes the outgoing connection to a upstream server originate from the specified local IP address.</p> <p>IP addresses can be specified as the <code>address</code> argument. The optional <code>port</code> argument is usually used in the transparent proxy.</p> <p>Here is an example for connecting to a TCP server from the specified local IP address:</p> <pre><code> location /test {\n     content_by_lua_block {\n         local sock = ngx.socket.tcp()\n         -- assume \"192.168.1.10\" is the local ip address\n         local ok, err = sock:bind(\"192.168.1.10\")\n         if not ok then\n             ngx.say(\"failed to bind\")\n             return\n         end\n         local ok, err = sock:connect(\"192.168.1.67\", 80)\n         if not ok then\n             ngx.say(\"failed to connect server: \", err)\n             return\n         end\n         ngx.say(\"successfully connected!\")\n         sock:close()\n     }\n }\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockconnect","title":"tcpsock:connect","text":"<p>syntax: ok, err = tcpsock:connect(host, port, options_table?)</p> <p>syntax: ok, err = tcpsock:connect(\"unix:/path/to/unix-domain.socket\", options_table?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Attempts to connect a TCP socket object to a remote server or to a stream unix domain socket file without blocking.</p> <p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method (or the ngx.socket.connect function).</p> <p>Both IP addresses and domain names can be specified as the <code>host</code> argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the resolver directive in the <code>nginx.conf</code> file like this:</p> <pre><code> resolver 8.8.8.8;  # use Google's public DNS nameserver\n</code></pre> <p>If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly.</p> <p>In case of error, the method returns <code>nil</code> followed by a string describing the error. In case of success, the method returns <code>1</code>.</p> <p>Here is an example for connecting to a TCP server:</p> <pre><code> location /test {\n     resolver 8.8.8.8;\n\n     content_by_lua_block {\n         local sock = ngx.socket.tcp()\n         local ok, err = sock:connect(\"www.google.com\", 80)\n         if not ok then\n             ngx.say(\"failed to connect to google: \", err)\n             return\n         end\n         ngx.say(\"successfully connected to google!\")\n         sock:close()\n     }\n }\n</code></pre> <p>Connecting to a Unix Domain Socket file is also possible:</p> <pre><code> local sock = ngx.socket.tcp()\n local ok, err = sock:connect(\"unix:/tmp/memcached.sock\")\n if not ok then\n     ngx.say(\"failed to connect to the memcached unix domain socket: \", err)\n     return\n end\n\n -- do something after connect\n -- such as sock:send or sock:receive\n</code></pre> <p>assuming memcached (or something else) is listening on the unix domain socket file <code>/tmp/memcached.sock</code>.</p> <p>Timeout for the connecting operation is controlled by the lua_socket_connect_timeout config directive and the settimeout method. And the latter takes priority. For example:</p> <pre><code> local sock = ngx.socket.tcp()\n sock:settimeout(1000)  -- one second timeout\n local ok, err = sock:connect(host, port)\n</code></pre> <p>It is important here to call the settimeout method before calling this method.</p> <p>Calling this method on an already connected socket object will cause the original connection to be closed first.</p> <p>An optional Lua table can be specified as the last argument to this method to specify various connect options:</p> <ul> <li> <p><code>pool</code>     specify a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template <code>\"&lt;host&gt;:&lt;port&gt;\"</code> or <code>\"&lt;unix-socket-path&gt;\"</code>.</p> </li> <li> <p><code>pool_size</code>     specify the size of the connection pool. If omitted and no     <code>backlog</code> option was provided, no pool will be created. If omitted     but <code>backlog</code> was provided, the pool will be created with a default     size equal to the value of the lua_socket_pool_size     directive.     The connection pool holds up to <code>pool_size</code> alive connections     ready to be reused by subsequent calls to connect, but     note that there is no upper limit to the total number of opened connections     outside of the pool. If you need to restrict the total number of opened     connections, specify the <code>backlog</code> option.     When the connection pool would exceed its size limit, the least recently used     (kept-alive) connection already in the pool will be closed to make room for     the current connection.     Note that the cosocket connection pool is per Nginx worker process rather     than per Nginx server instance, so the size limit specified here also applies     to every single Nginx worker process. Also note that the size of the connection     pool cannot be changed once it has been created.     This option was first introduced in the <code>v0.10.14</code> release.</p> </li> <li> <p><code>backlog</code>     if specified, this module will limit the total number of opened connections     for this pool. No more connections than <code>pool_size</code> can be opened     for this pool at any time. If <code>pool_size</code> number of connections are in use,     subsequent connect operations will be queued into a queue equal to this     option's value (the \"backlog\" queue).     If the number of queued connect operations is equal to <code>backlog</code>,     subsequent connect operations will fail and return <code>nil</code> plus the     error string <code>\"too many waiting connect operations\"</code>.     The queued connect operations will be resumed once the number of active     connections becomes less than <code>pool_size</code>.     The queued connect operation will abort once they have been queued for more     than <code>connect_timeout</code>, controlled by     settimeouts, and will return <code>nil</code> plus     the error string <code>\"timeout\"</code>.     This option was first introduced in the <code>v0.10.14</code> release.</p> </li> </ul> <p>The support for the options table argument was first introduced in the <code>v0.5.7</code> release.</p> <p>This method was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockgetfd","title":"tcpsock:getfd","text":"<p>syntax: fd, err = tcpsock:getfd()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Get the file descriptor of the current tcp socket.</p> <p>This method was first introduced in the <code>v0.10.29</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksetclientcert","title":"tcpsock:setclientcert","text":"<p>syntax: ok, err = tcpsock:setclientcert(cert, pkey)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Set client certificate chain and corresponding private key to the TCP socket object. The certificate chain and private key provided will be used later by the tcpsock:sslhandshake method.</p> <ul> <li><code>cert</code> specify a client certificate chain cdata object that will be used while handshaking with remote server. These objects can be created using ngx.ssl.parse_pem_cert or ngx.ssl.parse_der_cert function provided by lua-resty-core. Note that specifying the <code>cert</code> option requires corresponding <code>pkey</code> be provided too. See below.</li> <li><code>pkey</code> specify a private key corresponds to the <code>cert</code> option above. These objects can be created using ngx.ssl.parse_pem_priv_key or ngx.ssl.parse_der_priv_key function provided by lua-resty-core.</li> </ul> <p>If both of <code>cert</code> and <code>pkey</code> are <code>nil</code>, this method will clear any existing client certificate and private key that was previously set on the cosocket object.</p> <p>This method was first introduced in the <code>v0.10.22</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksslhandshake","title":"tcpsock:sslhandshake","text":"<p>syntax: session, err = tcpsock:sslhandshake(reused_session?, server_name?, ssl_verify?, send_status_req?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Does SSL/TLS handshake on the currently established connection.</p> <p>The optional <code>reused_session</code> argument can take a former SSL session userdata returned by a previous <code>sslhandshake</code> call for exactly the same target. For short-lived connections, reusing SSL sessions can usually speed up the handshake by one order by magnitude but it is not so useful if the connection pool is enabled. This argument defaults to <code>nil</code>. If this argument takes the boolean <code>false</code> value, no SSL session userdata would return by this call and only a Lua boolean will be returned as the first return value; otherwise the current SSL session will always be returned as the first argument in case of successes.</p> <p>The optional <code>server_name</code> argument is used to specify the server name for the new TLS extension Server Name Indication (SNI). Use of SNI can make different servers share the same IP address on the server side. Also, when SSL verification is enabled, this <code>server_name</code> argument is also used to validate the server name specified in the server certificate sent from the remote.</p> <p>The optional <code>ssl_verify</code> argument takes a Lua boolean value to control whether to perform SSL verification. When set to <code>true</code>, the server certificate will be verified according to the CA certificates specified by the lua_ssl_trusted_certificate directive. You may also need to adjust the lua_ssl_verify_depth directive to control how deep we should follow along the certificate chain. Also, when the <code>ssl_verify</code> argument is true and the <code>server_name</code> argument is also specified, the latter will be used to validate the server name in the server certificate.</p> <p>The optional <code>send_status_req</code> argument takes a boolean that controls whether to send the OCSP status request in the SSL handshake request (which is for requesting OCSP stapling).</p> <p>For connections that have already done SSL/TLS handshake, this method returns immediately.</p> <p>This method was first introduced in the <code>v0.9.11</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksend","title":"tcpsock:send","text":"<p>syntax: bytes, err = tcpsock:send(data)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Sends data without blocking on the current TCP or Unix Domain Socket connection.</p> <p>This method is a synchronous operation that will not return until all the data has been flushed into the system socket send buffer or an error occurs.</p> <p>In case of success, it returns the total number of bytes that have been sent. Otherwise, it returns <code>nil</code> and a string describing the error.</p> <p>The input argument <code>data</code> can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land.</p> <p>Timeout for the sending operation is controlled by the lua_socket_send_timeout config directive and the settimeout method. And the latter takes priority. For example:</p> <pre><code> sock:settimeout(1000)  -- one second timeout\n local bytes, err = sock:send(request)\n</code></pre> <p>It is important here to call the settimeout method before calling this method.</p> <p>In case of any connection errors, this method always automatically closes the current connection.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockreceive","title":"tcpsock:receive","text":"<p>syntax: data, err, partial = tcpsock:receive(size)</p> <p>syntax: data, err, partial = tcpsock:receive(pattern?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Receives data from the connected socket according to the reading pattern or size.</p> <p>This method is a synchronous operation just like the send method and is 100% nonblocking.</p> <p>In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error and the partial data received so far.</p> <p>If a number-like argument is specified (including strings that look like numbers), then it is interpreted as a size. This method will not return until it reads exactly this size of data or an error occurs.</p> <p>If a non-number-like string argument is specified, then it is interpreted as a \"pattern\". The following patterns are supported:</p> <ul> <li><code>'*a'</code>: reads from the socket until the connection is closed. No end-of-line translation is performed;</li> <li><code>'*l'</code>: reads a line of text from the socket. The line is terminated by a <code>Line Feed</code> (LF) character (ASCII 10), optionally preceded by a <code>Carriage Return</code> (CR) character (ASCII 13). The CR and LF characters are not included in the returned line. In fact, all CR characters are ignored by the pattern.</li> </ul> <p>If no argument is specified, then it is assumed to be the pattern <code>'*l'</code>, that is, the line reading pattern.</p> <p>Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example:</p> <pre><code> sock:settimeout(1000)  -- one second timeout\n local line, err, partial = sock:receive()\n if not line then\n     ngx.say(\"failed to read a line: \", err)\n     return\n end\n ngx.say(\"successfully read a line: \", line)\n</code></pre> <p>It is important here to call the settimeout method before calling this method.</p> <p>Since the <code>v0.8.8</code> release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockreceiveany","title":"tcpsock:receiveany","text":"<p>syntax: data, err = tcpsock:receiveany(max)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns any data received by the connected socket, at most <code>max</code> bytes.</p> <p>This method is a synchronous operation just like the send method and is 100% nonblocking.</p> <p>In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error.</p> <p>If the received data is more than this size, this method will return with exactly this size of data. The remaining data in the underlying receive buffer could be returned in the next reading operation.</p> <p>Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeouts method. And the latter takes priority. For example:</p> <pre><code> sock:settimeouts(1000, 1000, 1000)  -- one second timeout for connect/read/write\n local data, err = sock:receiveany(10 * 1024) -- read any data, at most 10K\n if not data then\n     ngx.say(\"failed to read any data: \", err)\n     return\n end\n ngx.say(\"successfully read: \", data)\n</code></pre> <p>This method doesn't automatically close the current connection when the read timeout error occurs. For other connection errors, this method always automatically closes the connection.</p> <p>This feature was first introduced in the <code>v0.10.14</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockreceiveuntil","title":"tcpsock:receiveuntil","text":"<p>syntax: iterator = tcpsock:receiveuntil(pattern, options?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>This method returns an iterator Lua function that can be called to read the data stream until it sees the specified pattern or an error occurs.</p> <p>Here is an example for using this method to read a data stream with the boundary sequence <code>--abcedhb</code>:</p> <pre><code> local reader = sock:receiveuntil(\"\\r\\n--abcedhb\")\n local data, err, partial = reader()\n if not data then\n     ngx.say(\"failed to read the data stream: \", err)\n end\n ngx.say(\"read the data stream: \", data)\n</code></pre> <p>When called without any argument, the iterator function returns the received data right before the specified pattern string in the incoming data stream. So for the example above, if the incoming data stream is <code>'hello, world! -agentzh\\r\\n--abcedhb blah blah'</code>, then the string <code>'hello, world! -agentzh'</code> will be returned.</p> <p>In case of error, the iterator function will return <code>nil</code> along with a string describing the error and the partial data bytes that have been read so far.</p> <p>The iterator function can be called multiple times and can be mixed safely with other cosocket method calls or other iterator function calls.</p> <p>The iterator function behaves differently (i.e., like a real iterator) when it is called with a <code>size</code> argument. That is, it will read that <code>size</code> of data on each invocation and will return <code>nil</code> at the last invocation (either sees the boundary pattern or meets an error). For the last successful invocation of the iterator function, the <code>err</code> return value will be <code>nil</code> too. The iterator function will be reset after the last successful invocation that returns <code>nil</code> data and <code>nil</code> error. Consider the following example:</p> <pre><code> local reader = sock:receiveuntil(\"\\r\\n--abcedhb\")\n\n while true do\n     local data, err, partial = reader(4)\n     if not data then\n         if err then\n             ngx.say(\"failed to read the data stream: \", err)\n             break\n         end\n\n         ngx.say(\"read done\")\n         break\n     end\n     ngx.say(\"read chunk: [\", data, \"]\")\n end\n</code></pre> <p>Then for the incoming data stream <code>'hello, world! -agentzh\\r\\n--abcedhb blah blah'</code>, we shall get the following output from the sample code above:</p> <pre><code>read chunk: [hell]\nread chunk: [o, w]\nread chunk: [orld]\nread chunk: [! -a]\nread chunk: [gent]\nread chunk: [zh]\nread done\n</code></pre> <p>Note that, the actual data returned might be a little longer than the size limit specified by the <code>size</code> argument when the boundary pattern has ambiguity for streaming parsing. Near the boundary of the data stream, the data string actually returned could also be shorter than the size limit.</p> <p>Timeout for the iterator function's reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example:</p> <pre><code> local readline = sock:receiveuntil(\"\\r\\n\")\n\n sock:settimeout(1000)  -- one second timeout\n line, err, partial = readline()\n if not line then\n     ngx.say(\"failed to read a line: \", err)\n     return\n end\n ngx.say(\"successfully read a line: \", line)\n</code></pre> <p>It is important here to call the settimeout method before calling the iterator function (note that the <code>receiveuntil</code> call is irrelevant here).</p> <p>As from the <code>v0.5.1</code> release, this method also takes an optional <code>options</code> table argument to control the behavior. The following options are supported:</p> <ul> <li><code>inclusive</code></li> </ul> <p>The <code>inclusive</code> takes a boolean value to control whether to include the pattern string in the returned data string. Default to <code>false</code>. For example,</p> <pre><code> local reader = tcpsock:receiveuntil(\"_END_\", { inclusive = true })\n local data = reader()\n ngx.say(data)\n</code></pre> <p>Then for the input data stream <code>\"hello world _END_ blah blah blah\"</code>, then the example above will output <code>hello world _END_</code>, including the pattern string <code>_END_</code> itself.</p> <p>Since the <code>v0.8.8</code> release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection.</p> <p>This method was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockclose","title":"tcpsock:close","text":"<p>syntax: ok, err = tcpsock:close()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Closes the current TCP or stream unix domain socket. It returns the <code>1</code> in case of success and returns <code>nil</code> with a string describing the error otherwise.</p> <p>Note that there is no need to call this method on socket objects that have invoked the setkeepalive method because the socket object is already closed (and the current connection is saved into the built-in connection pool).</p> <p>Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksettimeout","title":"tcpsock:settimeout","text":"<p>syntax: tcpsock:settimeout(time)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Set the timeout value in milliseconds for subsequent socket operations (connect, receive, and iterators returned from receiveuntil).</p> <p>Settings done by this method take priority over those specified via config directives (i.e. lua_socket_connect_timeout, lua_socket_send_timeout, and lua_socket_read_timeout).</p> <p>Note that this method does not affect the lua_socket_keepalive_timeout setting; the <code>timeout</code> argument to the setkeepalive method should be used for this purpose instead.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksettimeouts","title":"tcpsock:settimeouts","text":"<p>syntax: tcpsock:settimeouts(connect_timeout, send_timeout, read_timeout)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Respectively sets the connect, send, and read timeout thresholds (in milliseconds) for subsequent socket operations (connect, send, receive, and iterators returned from receiveuntil).</p> <p>Settings done by this method take priority over those specified via config directives (i.e. lua_socket_connect_timeout, lua_socket_send_timeout, and lua_socket_read_timeout).</p> <p>It is recommended to use settimeouts instead of settimeout.</p> <p>Note that this method does not affect the lua_socket_keepalive_timeout setting; the <code>timeout</code> argument to the setkeepalive method should be used for this purpose instead.</p> <p>This feature was first introduced in the <code>v0.10.7</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksetoption","title":"tcpsock:setoption","text":"<p>syntax: ok, err = tcpsock:setoption(option, value?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>This function is added for LuaSocket API compatibility, its functionality is implemented <code>v0.10.18</code>.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>In case of success, it returns <code>true</code>. Otherwise, it returns nil and a string describing the error.</p> <p>The <code>option</code> is a string with the option name, and the value depends on the option being set:</p> <ul> <li> <p><code>keepalive</code></p> <p>Setting this option to true enables sending of keep-alive messages on connection-oriented sockets. Make sure the <code>connect</code> function had been called before, for example,</p> <p><pre><code>local ok, err = tcpsock:setoption(\"keepalive\", true)\nif not ok then\n    ngx.say(\"setoption keepalive failed: \", err)\nend\n</code></pre> * <code>reuseaddr</code></p> <p>Enabling this option indicates that the rules used in validating addresses supplied in a call to bind should allow reuse of local addresses. Make sure the <code>connect</code> function had been called before, for example,</p> <p><pre><code>local ok, err = tcpsock:setoption(\"reuseaddr\", 0)\nif not ok then\n    ngx.say(\"setoption reuseaddr failed: \", err)\nend\n</code></pre> * <code>tcp-nodelay</code></p> <p>Setting this option to true disables the Nagle's algorithm for the connection. Make sure the <code>connect</code> function had been called before, for example,</p> <p><pre><code>local ok, err = tcpsock:setoption(\"tcp-nodelay\", true)\nif not ok then\n    ngx.say(\"setoption tcp-nodelay failed: \", err)\nend\n</code></pre> * <code>sndbuf</code></p> <p>Sets the maximum socket send buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt(). Make sure the <code>connect</code> function had been called before, for example,</p> <p><pre><code>local ok, err = tcpsock:setoption(\"sndbuf\", 1024 * 10)\nif not ok then\n    ngx.say(\"setoption sndbuf failed: \", err)\nend\n</code></pre> * <code>rcvbuf</code></p> <p>Sets the maximum socket receive buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt. Make sure the <code>connect</code> function had been called before, for example,</p> <pre><code>local ok, err = tcpsock:setoption(\"rcvbuf\", 1024 * 10)\nif not ok then\n    ngx.say(\"setoption rcvbuf failed: \", err)\nend\n</code></pre> </li> </ul> <p>NOTE: Once the option is set, it will become effective until the connection is closed. If you know the connection is from the connection pool and all the in-pool connections already have called the setoption() method with the desired socket option state, then you can just skip calling setoption() again to avoid the overhead of repeated calls, for example,</p> <pre><code> local count, err = tcpsock:getreusedtimes()\n if not count then\n     ngx.say(\"getreusedtimes failed: \", err)\n     return\n end\n\n if count == 0 then\n     local ok, err = tcpsock:setoption(\"rcvbuf\", 1024 * 10)\n     if not ok then\n         ngx.say(\"setoption rcvbuf failed: \", err)\n         return\n     end\n end\n</code></pre> <p>These options described above are supported in <code>v0.10.18</code>, and more options will be implemented in future.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsocksetkeepalive","title":"tcpsock:setkeepalive","text":"<p>syntax: ok, err = tcpsock:setkeepalive(timeout?, size?)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Puts the current socket's connection immediately into the cosocket built-in connection pool and keep it alive until other connect method calls request it or the associated maximal idle timeout is expired.</p> <p>The first optional argument, <code>timeout</code>, can be used to specify the maximal idle timeout (in milliseconds) for the current connection. If omitted, the default setting in the lua_socket_keepalive_timeout config directive will be used. If the <code>0</code> value is given, then the timeout interval is unlimited.</p> <p>The second optional argument <code>size</code> is considered deprecated since the <code>v0.10.14</code> release of this module, in favor of the <code>pool_size</code> option of the connect method. Since the <code>v0.10.14</code> release, this option will only take effect if the call to connect did not already create a connection pool. When this option takes effect (no connection pool was previously created by connect), it will specify the size of the connection pool, and create it. If omitted (and no pool was previously created), the default size is the value of the lua_socket_pool_size directive. The connection pool holds up to <code>size</code> alive connections ready to be reused by subsequent calls to connect, but note that there is no upper limit to the total number of opened connections outside of the pool. When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so the size limit specified here also applies to every single Nginx worker process. Also note that the size of the connection pool cannot be changed once it has been created. If you need to restrict the total number of opened connections, specify both the <code>pool_size</code> and <code>backlog</code> option in the call to connect.</p> <p>In case of success, this method returns <code>1</code>; otherwise, it returns <code>nil</code> and a string describing the error.</p> <p>When the system receive buffer for the current connection has unread data, then this method will return the \"connection in dubious state\" error message (as the second return value) because the previous session has unread data left behind for the next session and the connection is not safe to be reused.</p> <p>This method also makes the current cosocket object enter the \"closed\" state, so there is no need to manually call the close method on it afterwards.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#tcpsockgetreusedtimes","title":"tcpsock:getreusedtimes","text":"<p>syntax: count, err = tcpsock:getreusedtimes()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.</p> <p>If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsocketconnect","title":"ngx.socket.connect","text":"<p>syntax: tcpsock, err = ngx.socket.connect(host, port)</p> <p>syntax: tcpsock, err = ngx.socket.connect(\"unix:/path/to/unix-domain.socket\")</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*</p> <p>This function is a shortcut for combining ngx.socket.tcp() and the connect() method call in a single operation. It is actually implemented like this:</p> <pre><code> local sock = ngx.socket.tcp()\n local ok, err = sock:connect(...)\n if not ok then\n     return nil, err\n end\n return sock\n</code></pre> <p>There is no way to use the settimeout method to specify connecting timeout for this method and the lua_socket_connect_timeout directive must be set at configure time instead.</p> <p>This feature was first introduced in the <code>v0.5.0rc1</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxget_phase","title":"ngx.get_phase","text":"<p>syntax: str = ngx.get_phase()</p> <p>context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Retrieves the current running phase name. Possible return values are</p> <ul> <li><code>init</code>     for the context of init_by_lua*.</li> <li><code>init_worker</code>     for the context of init_worker_by_lua*.</li> <li><code>ssl_cert</code>     for the context of ssl_certificate_by_lua*.</li> <li><code>ssl_session_fetch</code>     for the context of ssl_session_fetch_by_lua*.</li> <li><code>ssl_session_store</code>     for the context of ssl_session_store_by_lua*.</li> <li><code>ssl_client_hello</code>     for the context of ssl_client_hello_by_lua*.</li> <li><code>set</code>     for the context of set_by_lua*.</li> <li><code>rewrite</code>     for the context of rewrite_by_lua*.</li> <li><code>balancer</code>     for the context of balancer_by_lua*.</li> <li><code>access</code>     for the context of access_by_lua*.</li> <li><code>content</code>     for the context of content_by_lua*.</li> <li><code>header_filter</code>     for the context of header_filter_by_lua*.</li> <li><code>body_filter</code>     for the context of body_filter_by_lua*.</li> <li><code>log</code>     for the context of log_by_lua*.</li> <li><code>timer</code>     for the context of user callback functions for ngx.timer.*.</li> <li><code>exit_worker</code>     for the context of exit_worker_by_lua*.</li> </ul> <p>This API was first introduced in the <code>v0.5.10</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxthreadspawn","title":"ngx.thread.spawn","text":"<p>syntax: co = ngx.thread.spawn(func, arg1, arg2, ...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Spawns a new user \"light thread\" with the Lua function <code>func</code> as well as those optional arguments <code>arg1</code>, <code>arg2</code>, and etc. Returns a Lua thread (or Lua coroutine) object represents this \"light thread\".</p> <p>\"Light threads\" are just a special kind of Lua coroutines that are scheduled by the ngx_lua module.</p> <p>Before <code>ngx.thread.spawn</code> returns, the <code>func</code> will be called with those optional arguments until it returns, aborts with an error, or gets yielded due to I/O operations via the Nginx API for Lua (like tcpsock:receive).</p> <p>After <code>ngx.thread.spawn</code> returns, the newly-created \"light thread\" will keep running asynchronously usually at various I/O events.</p> <p>All the Lua code chunks running by rewrite_by_lua, access_by_lua, and content_by_lua are in a boilerplate \"light thread\" created automatically by ngx_lua. Such boilerplate \"light thread\" are also called \"entry threads\".</p> <p>By default, the corresponding Nginx handler (e.g., rewrite_by_lua handler) will not terminate until</p> <ol> <li>both the \"entry thread\" and all the user \"light threads\" terminates,</li> <li>a \"light thread\" (either the \"entry thread\" or a user \"light thread\") aborts by calling ngx.exit, ngx.exec, ngx.redirect, or ngx.req.set_uri(uri, true), or</li> <li>the \"entry thread\" terminates with a Lua error.</li> </ol> <p>When the user \"light thread\" terminates with a Lua error, however, it will not abort other running \"light threads\" like the \"entry thread\" does.</p> <p>Due to the limitation in the Nginx subrequest model, it is not allowed to abort a running Nginx subrequest in general. So it is also prohibited to abort a running \"light thread\" that is pending on one ore more Nginx subrequests. You must call ngx.thread.wait to wait for those \"light thread\" to terminate before quitting the \"world\". A notable exception here is that you can abort pending subrequests by calling ngx.exit with and only with the status code <code>ngx.ERROR</code> (-1), <code>408</code>, <code>444</code>, or <code>499</code>.</p> <p>The \"light threads\" are not scheduled in a pre-emptive way. In other words, no time-slicing is performed automatically. A \"light thread\" will keep running exclusively on the CPU until</p> <ol> <li>a (nonblocking) I/O operation cannot be completed in a single run,</li> <li>it calls coroutine.yield to actively give up execution, or</li> <li>it is aborted by a Lua error or an invocation of ngx.exit, ngx.exec, ngx.redirect, or ngx.req.set_uri(uri, true).</li> </ol> <p>For the first two cases, the \"light thread\" will usually be resumed later by the ngx_lua scheduler unless a \"stop-the-world\" event happens.</p> <p>User \"light threads\" can create \"light threads\" themselves. And normal user coroutines created by coroutine.create can also create \"light threads\". The coroutine (be it a normal Lua coroutine or a \"light thread\") that directly spawns the \"light thread\" is called the \"parent coroutine\" for the \"light thread\" newly spawned.</p> <p>The \"parent coroutine\" can call ngx.thread.wait to wait on the termination of its child \"light thread\".</p> <p>You can call coroutine.status() and coroutine.yield() on the \"light thread\" coroutines.</p> <p>The status of the \"light thread\" coroutine can be \"zombie\" if</p> <ol> <li>the current \"light thread\" already terminates (either successfully or with an error),</li> <li>its parent coroutine is still alive, and</li> <li>its parent coroutine is not waiting on it with ngx.thread.wait.</li> </ol> <p>The following example demonstrates the use of coroutine.yield() in the \"light thread\" coroutines to do manual time-slicing:</p> <pre><code> local yield = coroutine.yield\n\n function f()\n     local self = coroutine.running()\n     ngx.say(\"f 1\")\n     yield(self)\n     ngx.say(\"f 2\")\n     yield(self)\n     ngx.say(\"f 3\")\n end\n\n local self = coroutine.running()\n ngx.say(\"0\")\n yield(self)\n\n ngx.say(\"1\")\n ngx.thread.spawn(f)\n\n ngx.say(\"2\")\n yield(self)\n\n ngx.say(\"3\")\n yield(self)\n\n ngx.say(\"4\")\n</code></pre> <p>Then it will generate the output</p> <pre><code>0\n1\nf 1\n2\nf 2\n3\nf 3\n4\n</code></pre> <p>\"Light threads\" are mostly useful for making concurrent upstream requests in a single Nginx request handler, much like a generalized version of ngx.location.capture_multi that can work with all the Nginx API for Lua. The following example demonstrates parallel requests to MySQL, Memcached, and upstream HTTP services in a single Lua handler, and outputting the results in the order that they actually return (similar to Facebook's BigPipe model):</p> <pre><code> -- query mysql, memcached, and a remote http service at the same time,\n -- output the results in the order that they\n -- actually return the results.\n\n local mysql = require \"resty.mysql\"\n local memcached = require \"resty.memcached\"\n\n local function query_mysql()\n     local db = mysql:new()\n     db:connect{\n                 host = \"127.0.0.1\",\n                 port = 3306,\n                 database = \"test\",\n                 user = \"monty\",\n                 password = \"mypass\"\n               }\n     local res, err, errno, sqlstate =\n             db:query(\"select * from cats order by id asc\")\n     db:set_keepalive(0, 100)\n     ngx.say(\"mysql done: \", cjson.encode(res))\n end\n\n local function query_memcached()\n     local memc = memcached:new()\n     memc:connect(\"127.0.0.1\", 11211)\n     local res, err = memc:get(\"some_key\")\n     ngx.say(\"memcached done: \", res)\n end\n\n local function query_http()\n     local res = ngx.location.capture(\"/my-http-proxy\")\n     ngx.say(\"http done: \", res.body)\n end\n\n ngx.thread.spawn(query_mysql)      -- create thread 1\n ngx.thread.spawn(query_memcached)  -- create thread 2\n ngx.thread.spawn(query_http)       -- create thread 3\n</code></pre> <p>This API was first enabled in the <code>v0.7.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxthreadwait","title":"ngx.thread.wait","text":"<p>syntax: ok, res1, res2, ... = ngx.thread.wait(thread1, thread2, ...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Waits on one or more child \"light threads\" and returns the results of the first \"light thread\" that terminates (either successfully or with an error).</p> <p>The arguments <code>thread1</code>, <code>thread2</code>, and etc are the Lua thread objects returned by earlier calls of ngx.thread.spawn.</p> <p>The return values have exactly the same meaning as coroutine.resume, that is, the first value returned is a boolean value indicating whether the \"light thread\" terminates successfully or not, and subsequent values returned are the return values of the user Lua function that was used to spawn the \"light thread\" (in case of success) or the error object (in case of failure).</p> <p>Only the direct \"parent coroutine\" can wait on its child \"light thread\", otherwise a Lua exception will be raised.</p> <p>The following example demonstrates the use of <code>ngx.thread.wait</code> and ngx.location.capture to emulate ngx.location.capture_multi:</p> <pre><code> local capture = ngx.location.capture\n local spawn = ngx.thread.spawn\n local wait = ngx.thread.wait\n local say = ngx.say\n\n local function fetch(uri)\n     return capture(uri)\n end\n\n local threads = {\n     spawn(fetch, \"/foo\"),\n     spawn(fetch, \"/bar\"),\n     spawn(fetch, \"/baz\")\n }\n\n for i = 1, #threads do\n     local ok, res = wait(threads[i])\n     if not ok then\n         say(i, \": failed to run: \", res)\n     else\n         say(i, \": status: \", res.status)\n         say(i, \": body: \", res.body)\n     end\n end\n</code></pre> <p>Here it essentially implements the \"wait all\" model.</p> <p>And below is an example demonstrating the \"wait any\" model:</p> <pre><code> function f()\n     ngx.sleep(0.2)\n     ngx.say(\"f: hello\")\n     return \"f done\"\n end\n\n function g()\n     ngx.sleep(0.1)\n     ngx.say(\"g: hello\")\n     return \"g done\"\n end\n\n local tf, err = ngx.thread.spawn(f)\n if not tf then\n     ngx.say(\"failed to spawn thread f: \", err)\n     return\n end\n\n ngx.say(\"f thread created: \", coroutine.status(tf))\n\n local tg, err = ngx.thread.spawn(g)\n if not tg then\n     ngx.say(\"failed to spawn thread g: \", err)\n     return\n end\n\n ngx.say(\"g thread created: \", coroutine.status(tg))\n\n ok, res = ngx.thread.wait(tf, tg)\n if not ok then\n     ngx.say(\"failed to wait: \", res)\n     return\n end\n\n ngx.say(\"res: \", res)\n\n -- stop the \"world\", aborting other running threads\n ngx.exit(ngx.OK)\n</code></pre> <p>And it will generate the following output:</p> <pre><code>f thread created: running\ng thread created: running\ng: hello\nres: g done\n</code></pre> <p>This API was first enabled in the <code>v0.7.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxthreadkill","title":"ngx.thread.kill","text":"<p>syntax: ok, err = ngx.thread.kill(thread)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*</p> <p>Kills a running \"light thread\" created by ngx.thread.spawn. Returns a true value when successful or <code>nil</code> and a string describing the error otherwise.</p> <p>According to the current implementation, only the parent coroutine (or \"light thread\") can kill a thread. Also, a running \"light thread\" with pending Nginx subrequests (initiated by ngx.location.capture for example) cannot be killed due to a limitation in the Nginx core.</p> <p>This API was first enabled in the <code>v0.9.9</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxon_abort","title":"ngx.on_abort","text":"<p>syntax: ok, err = ngx.on_abort(callback)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>Registers a user Lua function as the callback which gets called automatically when the client closes the (downstream) connection prematurely.</p> <p>Returns <code>1</code> if the callback is registered successfully or returns <code>nil</code> and a string describing the error otherwise.</p> <p>All the Nginx API for Lua can be used in the callback function because the function is run in a special \"light thread\", just as those \"light threads\" created by ngx.thread.spawn.</p> <p>The callback function can decide what to do with the client abortion event all by itself. For example, it can simply ignore the event by doing nothing and the current Lua request handler will continue executing without interruptions. And the callback function can also decide to terminate everything by calling ngx.exit, for example,</p> <pre><code> local function my_cleanup()\n     -- custom cleanup work goes here, like cancelling a pending DB transaction\n\n     -- now abort all the \"light threads\" running in the current request handler\n     ngx.exit(499)\n end\n\n local ok, err = ngx.on_abort(my_cleanup)\n if not ok then\n     ngx.log(ngx.ERR, \"failed to register the on_abort callback: \", err)\n     ngx.exit(500)\n end\n</code></pre> <p>When lua_check_client_abort is set to <code>off</code> (which is the default), then this function call will always return the error message \"lua_check_client_abort is off\".</p> <p>According to the current implementation, this function can only be called once in a single request handler; subsequent calls will return the error message \"duplicate call\".</p> <p>This API was first introduced in the <code>v0.7.4</code> release.</p> <p>See also lua_check_client_abort.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtimerat","title":"ngx.timer.at","text":"<p>syntax: hdl, err = ngx.timer.at(delay, callback, user_arg1, user_arg2, ...)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Creates an Nginx timer with a user callback function as well as optional user arguments.</p> <p>The first argument, <code>delay</code>, specifies the delay for the timer, in seconds. One can specify fractional seconds like <code>0.001</code> to mean 1 millisecond here. <code>0</code> delay can also be specified, in which case the timer will immediately expire when the current handler yields execution.</p> <p>The second argument, <code>callback</code>, can be any Lua function, which will be invoked later in a background \"light thread\" after the delay specified. The user callback will be called automatically by the Nginx core with the arguments <code>premature</code>, <code>user_arg1</code>, <code>user_arg2</code>, and etc, where the <code>premature</code> argument takes a boolean value indicating whether it is a premature timer expiration or not(for the <code>0</code> delay timer it is always <code>false</code>), and <code>user_arg1</code>, <code>user_arg2</code>, and etc, are those (extra) user arguments specified when calling <code>ngx.timer.at</code> as the remaining arguments.</p> <p>Premature timer expiration happens when the Nginx worker process is trying to shut down, as in an Nginx configuration reload triggered by the <code>HUP</code> signal or in an Nginx server shutdown. When the Nginx worker is trying to shut down, one can no longer call <code>ngx.timer.at</code> to create new timers with nonzero delays and in that case <code>ngx.timer.at</code> will return a \"conditional false\" value and a string describing the error, that is, \"process exiting\".</p> <p>Starting from the <code>v0.9.3</code> release, it is allowed to create zero-delay timers even when the Nginx worker process starts shutting down.</p> <p>When a timer expires, the user Lua code in the timer callback is running in a \"light thread\" detached completely from the original request creating the timer. So objects with the same lifetime as the request creating them, like cosockets, cannot be shared between the original request and the timer user callback function.</p> <p>Here is a simple example:</p> <pre><code> location / {\n     ...\n     log_by_lua_block {\n         local function push_data(premature, uri, args, status)\n             -- push the data uri, args, and status to the remote\n             -- via ngx.socket.tcp or ngx.socket.udp\n             -- (one may want to buffer the data in Lua a bit to\n             -- save I/O operations)\n         end\n         local ok, err = ngx.timer.at(0, push_data,\n                                      ngx.var.uri, ngx.var.args, ngx.header.status)\n         if not ok then\n             ngx.log(ngx.ERR, \"failed to create timer: \", err)\n             return\n         end\n\n         -- other job in log_by_lua_block\n     }\n }\n</code></pre> <p>One can also create infinite re-occurring timers, for instance, a timer getting triggered every <code>5</code> seconds, by calling <code>ngx.timer.at</code> recursively in the timer callback function. Here is such an example,</p> <pre><code> local delay = 5\n local handler\n handler = function (premature)\n     -- do some routine job in Lua just like a cron job\n     if premature then\n         return\n     end\n     local ok, err = ngx.timer.at(delay, handler)\n     if not ok then\n         ngx.log(ngx.ERR, \"failed to create the timer: \", err)\n         return\n     end\n\n     -- do something in timer\n end\n\n local ok, err = ngx.timer.at(delay, handler)\n if not ok then\n     ngx.log(ngx.ERR, \"failed to create the timer: \", err)\n     return\n end\n\n -- do other jobs\n</code></pre> <p>It is recommended, however, to use the ngx.timer.every API function instead for creating recurring timers since it is more robust.</p> <p>Because timer callbacks run in the background and their running time will not add to any client request's response time, they can easily accumulate in the server and exhaust system resources due to either Lua programming mistakes or just too much client traffic. To prevent extreme consequences like crashing the Nginx server, there are built-in limitations on both the number of \"pending timers\" and the number of \"running timers\" in an Nginx worker process. The \"pending timers\" here mean timers that have not yet been expired and \"running timers\" are those whose user callbacks are currently running.</p> <p>The maximal number of pending timers allowed in an Nginx worker is controlled by the lua_max_pending_timers directive. The maximal number of running timers is controlled by the lua_max_running_timers directive.</p> <p>According to the current implementation, each \"running timer\" will take one (fake) connection record from the global connection record list configured by the standard worker_connections directive in <code>nginx.conf</code>. So ensure that the worker_connections directive is set to a large enough value that takes into account both the real connections and fake connections required by timer callbacks (as limited by the lua_max_running_timers directive).</p> <p>A lot of the Lua APIs for Nginx are enabled in the context of the timer callbacks, like stream/datagram cosockets (ngx.socket.tcp and ngx.socket.udp), shared memory dictionaries (ngx.shared.DICT), user coroutines (coroutine.*), user \"light threads\" (ngx.thread.*), ngx.exit, ngx.now/ngx.time, ngx.md5/ngx.sha1_bin, are all allowed. But the subrequest API (like ngx.location.capture), the ngx.req.* API, the downstream output API (like ngx.say, ngx.print, and ngx.flush) are explicitly disabled in this context.</p> <p>You must notice that each timer will be based on a fake request (this fake request is also based on a fake connection). Because Nginx's memory release is based on the connection closure, if you run a lot of APIs that apply for memory resources in a timer, such as tcpsock:connect, will cause the accumulation of memory resources. So it is recommended to create a new timer after running several times to release memory resources.</p> <p>You can pass most of the standard Lua values (nils, booleans, numbers, strings, tables, closures, file handles, etc.) into the timer callback, either explicitly as user arguments or implicitly as upvalues for the callback closure. There are several exceptions, however: you cannot pass any thread objects returned by coroutine.create and ngx.thread.spawn or any cosocket objects returned by ngx.socket.tcp, ngx.socket.udp, and ngx.req.socket because these objects' lifetime is bound to the request context creating them while the timer callback is detached from the creating request's context (by design) and runs in its own (fake) request context. If you try to share the thread or cosocket objects across the boundary of the creating request, then you will get the \"no co ctx found\" error (for threads) or \"bad request\" (for cosockets). It is fine, however, to create all these objects inside your timer callback.</p> <p>Please note that the timer Lua handler has its own copy of the <code>ngx.ctx</code> magic table. It won't share the same <code>ngx.ctx</code> with the Lua handler creating the timer. If you need to pass data from the timer creator to the timer handler, please use the extra parameters of <code>ngx.timer.at()</code>.</p> <p>This API was first introduced in the <code>v0.8.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtimerevery","title":"ngx.timer.every","text":"<p>syntax: hdl, err = ngx.timer.every(delay, callback, user_arg1, user_arg2, ...)</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the ngx.timer.at API function, but</p> <ol> <li><code>delay</code> cannot be zero,</li> <li>timer will be created every <code>delay</code> seconds until the current Nginx worker process starts exiting.</li> </ol> <p>Like ngx.timer.at, the <code>callback</code> argument will be called automatically with the arguments <code>premature</code>, <code>user_arg1</code>, <code>user_arg2</code>, etc.</p> <p>When success, returns a \"conditional true\" value (but not a <code>true</code>). Otherwise, returns a \"conditional false\" value and a string describing the error.</p> <p>This API also respect the lua_max_pending_timers and lua_max_running_timers.</p> <p>This API was first introduced in the <code>v0.10.9</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtimerrunning_count","title":"ngx.timer.running_count","text":"<p>syntax: count = ngx.timer.running_count()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the number of timers currently running.</p> <p>This directive was first introduced in the <code>v0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxtimerpending_count","title":"ngx.timer.pending_count","text":"<p>syntax: count = ngx.timer.pending_count()</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>Returns the number of pending timers.</p> <p>This directive was first introduced in the <code>v0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfigsubsystem","title":"ngx.config.subsystem","text":"<p>syntax: subsystem = ngx.config.subsystem</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>This string field indicates the Nginx subsystem the current Lua environment is based on. For this module, this field always takes the string value <code>\"http\"</code>. For ngx_stream_lua_module, however, this field takes the value <code>\"stream\"</code>.</p> <p>This field was first introduced in the <code>0.10.1</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfigdebug","title":"ngx.config.debug","text":"<p>syntax: debug = ngx.config.debug</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>This boolean field indicates whether the current Nginx is a debug build, i.e., being built by the <code>./configure</code> option <code>--with-debug</code>.</p> <p>This field was first introduced in the <code>0.8.7</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfigprefix","title":"ngx.config.prefix","text":"<p>syntax: prefix = ngx.config.prefix()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>Returns the Nginx server \"prefix\" path, as determined by the <code>-p</code> command-line option when running the Nginx executable, or the path specified by the <code>--prefix</code> command-line option when building Nginx with the <code>./configure</code> script.</p> <p>This function was first introduced in the <code>0.9.2</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfignginx_version","title":"ngx.config.nginx_version","text":"<p>syntax: ver = ngx.config.nginx_version</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>This field take an integral value indicating the version number of the current Nginx core being used. For example, the version number <code>1.4.3</code> results in the Lua number 1004003.</p> <p>This API was first introduced in the <code>0.9.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfignginx_configure","title":"ngx.config.nginx_configure","text":"<p>syntax: str = ngx.config.nginx_configure()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*</p> <p>This function returns a string for the Nginx <code>./configure</code> command's arguments string.</p> <p>This API was first introduced in the <code>0.9.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxconfigngx_lua_version","title":"ngx.config.ngx_lua_version","text":"<p>syntax: ver = ngx.config.ngx_lua_version</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*</p> <p>This field take an integral value indicating the version number of the current <code>ngx_lua</code> module being used. For example, the version number <code>0.9.3</code> results in the Lua number 9003.</p> <p>This API was first introduced in the <code>0.9.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxworkerexiting","title":"ngx.worker.exiting","text":"<p>syntax: exiting = ngx.worker.exiting()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>This function returns a boolean value indicating whether the current Nginx worker process already starts exiting. Nginx worker process exiting happens on Nginx server quit or configuration reload (aka HUP reload).</p> <p>This API was first introduced in the <code>0.9.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxworkerpid","title":"ngx.worker.pid","text":"<p>syntax: pid = ngx.worker.pid()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>This function returns a Lua number for the process ID (PID) of the current Nginx worker process. This API is more efficient than <code>ngx.var.pid</code> and can be used in contexts where the ngx.var.VARIABLE API cannot be used (like init_worker_by_lua).</p> <p>This API was first introduced in the <code>0.9.5</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxworkerpids","title":"ngx.worker.pids","text":"<p>syntax: pids = ngx.worker.pids()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, exit_worker_by_lua*</p> <p>This function returns a Lua table for all Nginx worker process IDs (PIDs). Nginx uses channel to send the current worker PID to another worker in the worker process start or restart. So this API can get all current worker PIDs. Windows does not have this API.</p> <p>This API was first introduced in the <code>0.10.23</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxworkercount","title":"ngx.worker.count","text":"<p>syntax: count = ngx.worker.count()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>Returns the total number of the Nginx worker processes (i.e., the value configured by the worker_processes directive in <code>nginx.conf</code>).</p> <p>This API was first introduced in the <code>0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxworkerid","title":"ngx.worker.id","text":"<p>syntax: id = ngx.worker.id()</p> <p>context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_worker_by_lua*, exit_worker_by_lua*</p> <p>Returns the ordinal number of the current Nginx worker processes (starting from number 0).</p> <p>So if the total number of workers is <code>N</code>, then this method may return a number between 0 and <code>N - 1</code> (inclusive).</p> <p>This function returns meaningful values only for Nginx 1.9.1+. With earlier versions of Nginx, it always returns <code>nil</code>.</p> <p>See also ngx.worker.count.</p> <p>This API was first introduced in the <code>0.9.20</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxsemaphore","title":"ngx.semaphore","text":"<p>syntax: local semaphore = require \"ngx.semaphore\"</p> <p>This is a Lua module that implements a classic-style semaphore API for efficient synchronizations among different \"light threads\". Sharing the same semaphore among different \"light threads\" created in different (request) contexts are also supported as long as the \"light threads\" reside in the same Nginx worker process and the lua_code_cache directive is turned on (which is the default).</p> <p>This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library.</p> <p>Please refer to the documentation for this <code>ngx.semaphore</code> Lua module in lua-resty-core for more details.</p> <p>This feature requires at least ngx_lua <code>v0.10.0</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxbalancer","title":"ngx.balancer","text":"<p>syntax: local balancer = require \"ngx.balancer\"</p> <p>This is a Lua module that provides a Lua API to allow defining completely dynamic load balancers in pure Lua.</p> <p>This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library.</p> <p>Please refer to the documentation for this <code>ngx.balancer</code> Lua module in lua-resty-core for more details.</p> <p>This feature requires at least ngx_lua <code>v0.10.0</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxssl","title":"ngx.ssl","text":"<p>syntax: local ssl = require \"ngx.ssl\"</p> <p>This Lua module provides API functions to control the SSL handshake process in contexts like ssl_certificate_by_lua*.</p> <p>This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library.</p> <p>Please refer to the documentation for this <code>ngx.ssl</code> Lua module for more details.</p> <p>This feature requires at least ngx_lua <code>v0.10.0</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxocsp","title":"ngx.ocsp","text":"<p>syntax: local ocsp = require \"ngx.ocsp\"</p> <p>This Lua module provides API to perform OCSP queries, OCSP response validations, and OCSP stapling planting.</p> <p>Usually, this module is used together with the ngx.ssl module in the context of ssl_certificate_by_lua*.</p> <p>This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library.</p> <p>Please refer to the documentation for this <code>ngx.ocsp</code> Lua module for more details.</p> <p>This feature requires at least ngx_lua <code>v0.10.0</code>.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ndkset_vardirective","title":"ndk.set_var.DIRECTIVE","text":"<p>syntax: res = ndk.set_var.DIRECTIVE_NAME</p> <p>context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*</p> <p>This mechanism allows calling other Nginx C modules' directives that are implemented by Nginx Devel Kit (NDK)'s set_var submodule's <code>ndk_set_var_value</code>.</p> <p>For example, the following set-misc-nginx-module directives can be invoked this way:</p> <ul> <li>set_quote_sql_str</li> <li>set_quote_pgsql_str</li> <li>set_quote_json_str</li> <li>set_unescape_uri</li> <li>set_escape_uri</li> <li>set_encode_base32</li> <li>set_decode_base32</li> <li>set_encode_base64</li> <li>set_decode_base64</li> <li>set_encode_hex</li> <li>set_decode_hex</li> <li>set_sha1</li> <li>set_md5</li> </ul> <p>For instance,</p> <pre><code> local res = ndk.set_var.set_escape_uri('a/b')\n -- now res == 'a%2fb'\n</code></pre> <p>Similarly, the following directives provided by encrypted-session-nginx-module can be invoked from within Lua too:</p> <ul> <li>set_encrypt_session</li> <li>set_decrypt_session</li> </ul> <p>This feature requires the ngx_devel_kit module.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutinecreate","title":"coroutine.create","text":"<p>syntax: co = coroutine.create(f)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Creates a user Lua coroutines with a Lua function, and returns a coroutine object.</p> <p>Similar to the standard Lua coroutine.create API, but works in the context of the Lua coroutines created by ngx_lua.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first introduced in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutineresume","title":"coroutine.resume","text":"<p>syntax: ok, ... = coroutine.resume(co, ...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Resumes the execution of a user Lua coroutine object previously yielded or just created.</p> <p>Similar to the standard Lua coroutine.resume API, but works in the context of the Lua coroutines created by ngx_lua.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first introduced in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutineyield","title":"coroutine.yield","text":"<p>syntax: ... = coroutine.yield(...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Yields the execution of the current user Lua coroutine.</p> <p>Similar to the standard Lua coroutine.yield API, but works in the context of the Lua coroutines created by ngx_lua.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first introduced in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutinewrap","title":"coroutine.wrap","text":"<p>syntax: co = coroutine.wrap(f)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Similar to the standard Lua coroutine.wrap API, but works in the context of the Lua coroutines created by ngx_lua.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first introduced in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutinerunning","title":"coroutine.running","text":"<p>syntax: co = coroutine.running()</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Identical to the standard Lua coroutine.running API.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first enabled in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#coroutinestatus","title":"coroutine.status","text":"<p>syntax: status = coroutine.status(co)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*</p> <p>Identical to the standard Lua coroutine.status API.</p> <p>This API was first usable in the context of init_by_lua* since the <code>0.9.2</code>.</p> <p>This API was first enabled in the <code>v0.6.0</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/lua/#ngxrun_worker_thread","title":"ngx.run_worker_thread","text":"<p>syntax: ok, res1, res2, ... = ngx.run_worker_thread(threadpool, module_name, func_name, arg1, arg2, ...)</p> <p>context: rewrite_by_lua*, access_by_lua*, content_by_lua*</p> <p>This API is still experimental and may change in the future without notice.</p> <p>This API is available only for Linux.</p> <p>Wrap the nginx worker thread to execute lua function. The caller coroutine would yield until the function returns.</p> <p>Only the following ngx_lua APIs could be used in <code>function_name</code> function of the <code>module</code> module:</p> <ul> <li><code>ngx.encode_base64</code></li> <li> <p><code>ngx.decode_base64</code></p> </li> <li> <p><code>ngx.hmac_sha1</code></p> </li> <li><code>ngx.encode_args</code></li> <li><code>ngx.decode_args</code></li> <li> <p><code>ngx.quote_sql_str</code></p> </li> <li> <p><code>ngx.crc32_short</code></p> </li> <li><code>ngx.crc32_long</code></li> <li><code>ngx.hmac_sha1</code></li> <li><code>ngx.md5_bin</code></li> <li> <p><code>ngx.md5</code></p> </li> <li> <p><code>ngx.config.subsystem</code></p> </li> <li><code>ngx.config.debug</code></li> <li><code>ngx.config.prefix</code></li> <li><code>ngx.config.nginx_version</code></li> <li><code>ngx.config.nginx_configure</code></li> <li> <p><code>ngx.config.ngx_lua_version</code></p> </li> <li> <p><code>ngx.shared.DICT</code></p> </li> </ul> <p>The first argument <code>threadpool</code> specifies the Nginx thread pool name defined by thread_pool.</p> <p>The second argument <code>module_name</code> specifies the lua module name to execute in the worker thread, which would return a lua table. The module must be inside the package path, e.g.</p> <pre><code>\n</code></pre> <p>The third argument <code>func_name</code> specifies the function field in the module table as the second argument.</p> <p>The type of <code>args</code> must be one of type below:</p> <ul> <li>boolean</li> <li>number</li> <li>string</li> <li>nil</li> <li>table (the table may be recursive, and contains members of types above.)</li> </ul> <p>The <code>ok</code> is in boolean type, which indicate the C land error (failed to get thread from thread pool, pcall the module function failed, etc.). If <code>ok</code> is <code>false</code>, the <code>res1</code> is the error string.</p> <p>The return values (res1, ...) are returned by invocation of the module function. Normally, the <code>res1</code> should be in boolean type, so that the caller could inspect the error.</p> <p>This API is useful when you need to execute the below types of tasks:</p> <ul> <li>CPU bound task, e.g. do md5 calculation</li> <li>File I/O task</li> <li>Call <code>os.execute()</code> or blocking C API via <code>ffi</code></li> <li>Call external Lua library not based on cosocket or nginx</li> </ul> <p>Example1: do md5 calculation.</p> <pre><code> location /calc_md5 {\n     default_type 'text/plain';\n\n     content_by_lua_block {\n         local ok, md5_or_err = ngx.run_worker_thread(\"testpool\", \"md5\", \"md5\")\n         ngx.say(ok, \" : \", md5_or_err)\n     }\n }\n</code></pre> <p><code>md5.lua</code></p> <pre><code>local function md5()\n    return ngx.md5(\"hello\")\nend\n\nreturn { md5=md5, }\n</code></pre> <p>Example2: write logs into the log file.</p> <pre><code> location /write_log_file {\n     default_type 'text/plain';\n\n     content_by_lua_block {\n         local ok, err = ngx.run_worker_thread(\"testpool\", \"write_log_file\", \"log\", ngx.var.arg_str)\n         if not ok then\n             ngx.say(ok, \" : \", err)\n             return\n         end\n         ngx.say(ok)\n     }\n }\n</code></pre> <p><code>write_log_file.lua</code></p> <pre><code> local function log(str)\n     local file, err = io.open(\"/tmp/tmp.log\", \"a\")\n     if not file then\n         return false, err\n     end\n     file:write(str)\n     file:flush()\n     file:close()\n     return true\n end\n return {log=log}\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/lua/#obsolete-sections","title":"Obsolete Sections","text":"<p>This section is just holding obsolete documentation sections that have been either renamed or removed so that existing links over the web are still valid.</p>"},{"location":"modules/lua/#special-pcre-sequences","title":"Special PCRE Sequences","text":"<p>This section has been renamed to Special Escaping Sequences.</p>"},{"location":"modules/lua/#lualuajit-bytecode-support","title":"Lua/LuaJIT bytecode support","text":"<p>This section has been renamed to LuaJIT bytecode support. As of version <code>v0.10.16</code> of this module, the standard Lua interpreter (also known as \"PUC-Rio Lua\") is not supported anymore.</p>"},{"location":"modules/lua/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-lua.</p>"},{"location":"modules/markdown/","title":"markdown: Markdown-to-html NGINX module","text":""},{"location":"modules/markdown/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-markdown\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-markdown\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_markdown_filter_module.so;\n</code></pre> <p>This document describes nginx-module-markdown v0.1.6  released on Sep 23 2025.</p> <p>The <code>ngx_markdown_filter_module</code> module is a filter that transforms markdown files to html format.</p> <p>This module utilizes the cmark library.</p>"},{"location":"modules/markdown/#example-configuration","title":"Example configuration","text":"<pre><code>location ~ \\.md {\n    markdown_filter on;\n    markdown_template html/template.html;\n}\n</code></pre> <p>This works on proxy locations as well.</p>"},{"location":"modules/markdown/#directives","title":"Directives","text":"<pre><code>Syntax:  markdown_filter on|off;\nContext: location\n</code></pre> <pre><code>Syntax:  markdown_template html/template.html;\nContext: location\n</code></pre> <pre><code>## enable `unsafe` mode for cmark\nSyntax:  markdown_unsafe on|off;\nContext: location;\n</code></pre> <pre><code>## enable `tagfilter` extension for cmark-gfm\nSyntax:  markdown_gfm_tagfilter on|off;\nContext: location;\n</code></pre> <pre><code>## enable `tasklist` extension for cmark-gfm\nSyntax:  markdown_gfm_tasklist on|off;\nContext: location;\n</code></pre> <pre><code>## enable `strikethrough` extension for cmark-gfm\nSyntax:  markdown_gfm_strikethrough on|off;\nContext: location;\n</code></pre> <pre><code>## enable `autolink` extension for cmark-gfm\nSyntax: markdown_gfm_autolink on|off;\nContext: location;\n</code></pre>"},{"location":"modules/markdown/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-markdown.</p>"},{"location":"modules/memc/","title":"memc: Extended version of the standard NGINX memcached module","text":""},{"location":"modules/memc/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-memc\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-memc\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_memc_module.so;\n</code></pre> <p>This document describes nginx-module-memc v0.20  released on Dec 27 2023.</p> <p>ngx_memc - An extended version of the standard memcached module that supports set, add, delete, and many more memcached commands.</p>"},{"location":"modules/memc/#synopsis","title":"Synopsis","text":"<pre><code> # GET /foo?key=dog\n #\n # POST /foo?key=cat\n # Cat's value...\n #\n # PUT /foo?key=bird\n # Bird's value...\n #\n # DELETE /foo?key=Tiger\n location /foo {\n     set $memc_key $arg_key;\n\n     # $memc_cmd defaults to get for GET,\n     #   add for POST, set for PUT, and\n     #   delete for the DELETE request method.\n\n     memc_pass 127.0.0.1:11211;\n }\n</code></pre> <pre><code> # GET /bar?cmd=get&amp;key=cat\n #\n # POST /bar?cmd=set&amp;key=dog\n # My value for the \"dog\" key...\n #\n # DELETE /bar?cmd=delete&amp;key=dog\n # GET /bar?cmd=delete&amp;key=dog\n location /bar {\n     set $memc_cmd $arg_cmd;\n     set $memc_key $arg_key;\n     set $memc_flags $arg_flags; # defaults to 0\n     set $memc_exptime $arg_exptime; # defaults to 0\n\n     memc_pass 127.0.0.1:11211;\n }\n</code></pre> <pre><code> # GET /bar?cmd=get&amp;key=cat\n # GET /bar?cmd=set&amp;key=dog&amp;val=animal&amp;flags=1234&amp;exptime=2\n # GET /bar?cmd=delete&amp;key=dog\n # GET /bar?cmd=flush_all\n location /bar {\n     set $memc_cmd $arg_cmd;\n     set $memc_key $arg_key;\n     set $memc_value $arg_val;\n     set $memc_flags $arg_flags; # defaults to 0\n     set $memc_exptime $arg_exptime; # defaults to 0\n\n     memc_cmds_allowed get set add delete flush_all;\n\n     memc_pass 127.0.0.1:11211;\n }\n</code></pre> <pre><code>   http {\n     ...\n     upstream backend {\n        server 127.0.0.1:11984;\n        server 127.0.0.1:11985;\n     }\n     server {\n         location /stats {\n             set $memc_cmd stats;\n             memc_pass backend;\n         }\n         ...\n     }\n   }\n   ...\n</code></pre> <pre><code> # read the memcached flags into the Last-Modified header\n # to respond 304 to conditional GET\n location /memc {\n     set $memc_key $arg_key;\n\n     memc_pass 127.0.0.1:11984;\n\n     memc_flags_to_last_modified on;\n }\n</code></pre> <pre><code> location /memc {\n     set $memc_key foo;\n     set $memc_cmd get;\n\n     # access the unix domain socket listend by memcached\n     memc_pass unix:/tmp/memcached.sock;\n }\n</code></pre>"},{"location":"modules/memc/#description","title":"Description","text":"<p>This module extends the standard memcached module to support almost the whole memcached ascii protocol.</p> <p>It allows you to define a custom REST interface to your memcached servers or access memcached in a very efficient way from within the nginx server by means of subrequests or independent fake requests.</p> <p>This module is not supposed to be merged into the Nginx core because I've used Ragel to generate the memcached response parsers (in C) for joy :)</p> <p>If you are going to use this module to cache location responses out of the box, try srcache-nginx-module with this module to achieve that.</p> <p>When used in conjunction with lua-nginx-module, it is recommended to use the lua-resty-memcached library instead of this module though, because the former is much more flexible and memory-efficient.</p>"},{"location":"modules/memc/#keep-alive-connections-to-memcached-servers","title":"Keep-alive connections to memcached servers","text":"<p>You need HttpUpstreamKeepaliveModule together with this module for keep-alive TCP connections to your backend memcached servers.</p> <p>Here's a sample configuration:</p> <pre><code>   http {\n     upstream backend {\n       server 127.0.0.1:11211;\n\n       # a pool with at most 1024 connections\n       # and do not distinguish the servers:\n       keepalive 1024;\n     }\n\n     server {\n         ...\n         location /memc {\n             set $memc_cmd get;\n             set $memc_key $arg_key;\n             memc_pass backend;\n         }\n     }\n   }\n</code></pre>"},{"location":"modules/memc/#how-it-works","title":"How it works","text":"<p>It implements the memcached TCP protocol all by itself, based upon the <code>upstream</code> mechanism. Everything involving I/O is non-blocking.</p> <p>The module itself does not keep TCP connections to the upstream memcached servers across requests, just like other upstream modules. For a working solution, see section Keep-alive connections to memcached servers.</p>"},{"location":"modules/memc/#memcached-commands-supported","title":"Memcached commands supported","text":"<p>The memcached storage commands set, add, replace, prepend, and append uses the <code>$memc_key</code> as the key, <code>$memc_exptime</code> as the expiration time (or delay) (defaults to 0), <code>$memc_flags</code> as the flags (defaults to 0), to build the corresponding memcached queries.</p> <p>If <code>$memc_value</code> is not defined at all, then the request body will be used as the value of the <code>$memc_value</code> except for the incr and decr commands. Note that if <code>$memc_value</code> is defined as an empty string (<code>\"\"</code>), that empty string will still be used as the value as is.</p> <p>The following memcached commands have been implemented and tested (with their parameters marked by corresponding nginx variables defined by this module):</p>"},{"location":"modules/memc/#get-memc_key","title":"get $memc_key","text":"<p>Retrieves the value using a key.</p> <pre><code>   location /foo {\n       set $memc_cmd 'get';\n       set $memc_key 'my_key';\n\n       memc_pass 127.0.0.1:11211;\n\n       add_header X-Memc-Flags $memc_flags;\n   }\n</code></pre> <p>Returns <code>200 OK</code> with the value put into the response body if the key is found, or <code>404 Not Found</code> otherwise. The <code>flags</code> number will be set into the <code>$memc_flags</code> variable so it's often desired to put that info into the response headers by means of the standard add_header directive.</p> <p>It returns <code>502</code> for <code>ERROR</code>, <code>CLIENT_ERROR</code>, or <code>SERVER_ERROR</code>.</p>"},{"location":"modules/memc/#set-memc_key-memc_flags-memc_exptime-memc_value","title":"set $memc_key $memc_flags $memc_exptime $memc_value","text":"<p>To use the request body as the memcached value, just avoid setting the <code>$memc_value</code> variable:</p> <pre><code>   # POST /foo\n   # my value...\n   location /foo {\n       set $memc_cmd 'set';\n       set $memc_key 'my_key';\n       set $memc_flags 12345;\n       set $memc_exptime 24;\n\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre> <p>Or let the <code>$memc_value</code> hold the value:</p> <pre><code>   location /foo {\n       set $memc_cmd 'set';\n       set $memc_key 'my_key';\n       set $memc_flags 12345;\n       set $memc_exptime 24;\n       set $memc_value 'my_value';\n\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre> <p>Returns <code>201 Created</code> if the upstream memcached server replies <code>STORED</code>, <code>200</code> for <code>NOT_STORED</code>, <code>404</code> for <code>NOT_FOUND</code>, <code>502</code> for <code>ERROR</code>, <code>CLIENT_ERROR</code>, or <code>SERVER_ERROR</code>.</p> <p>The original memcached responses are returned as the response body except for <code>404 NOT FOUND</code>.</p>"},{"location":"modules/memc/#add-memc_key-memc_flags-memc_exptime-memc_value","title":"add $memc_key $memc_flags $memc_exptime $memc_value","text":"<p>Similar to the set command.</p>"},{"location":"modules/memc/#replace-memc_key-memc_flags-memc_exptime-memc_value","title":"replace $memc_key $memc_flags $memc_exptime $memc_value","text":"<p>Similar to the set command.</p>"},{"location":"modules/memc/#append-memc_key-memc_flags-memc_exptime-memc_value","title":"append $memc_key $memc_flags $memc_exptime $memc_value","text":"<p>Similar to the set command.</p> <p>Note that at least memcached version 1.2.2 does not support the \"append\" and \"prepend\" commands. At least 1.2.4 and later versions seem to supports these two commands.</p>"},{"location":"modules/memc/#prepend-memc_key-memc_flags-memc_exptime-memc_value","title":"prepend $memc_key $memc_flags $memc_exptime $memc_value","text":"<p>Similar to the append command.</p>"},{"location":"modules/memc/#delete-memc_key","title":"delete $memc_key","text":"<p>Deletes the memcached entry using a key.</p> <pre><code>   location /foo\n       set $memc_cmd delete;\n       set $memc_key my_key;\n\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre> <p>Returns <code>200 OK</code> if deleted successfully, <code>404 Not Found</code> for <code>NOT_FOUND</code>, or <code>502</code> for <code>ERROR</code>, <code>CLIENT_ERROR</code>, or <code>SERVER_ERROR</code>.</p> <p>The original memcached responses are returned as the response body except for <code>404 NOT FOUND</code>.</p>"},{"location":"modules/memc/#delete-memc_key-memc_exptime","title":"delete $memc_key $memc_exptime","text":"<p>Similar to the delete $memc_key command except it accepts an optional <code>expiration</code> time specified by the <code>$memc_exptime</code> variable.</p> <p>This command is no longer available in the latest memcached version 1.4.4.</p>"},{"location":"modules/memc/#incr-memc_key-memc_value","title":"incr $memc_key $memc_value","text":"<p>Increments the existing value of <code>$memc_key</code> by the amount specified by <code>$memc_value</code>:</p> <pre><code>   location /foo {\n       set $memc_cmd incr;\n       set $memc_key my_key;\n       set $memc_value 2;\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre> <p>In the preceding example, every time we access <code>/foo</code> will cause the value of <code>my_key</code> increments by <code>2</code>.</p> <p>Returns <code>200 OK</code> with the new value associated with that key as the response body if successful, or <code>404 Not Found</code> if the key is not found.</p> <p>It returns <code>502</code> for <code>ERROR</code>, <code>CLIENT_ERROR</code>, or <code>SERVER_ERROR</code>.</p>"},{"location":"modules/memc/#decr-memc_key-memc_value","title":"decr $memc_key $memc_value","text":"<p>Similar to incr $memc_key $memc_value.</p>"},{"location":"modules/memc/#flush_all","title":"flush_all","text":"<p>Mark all the keys on the memcached server as expired:</p> <pre><code>   location /foo {\n       set $memc_cmd flush_all;\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre>"},{"location":"modules/memc/#flush_all-memc_exptime","title":"flush_all $memc_exptime","text":"<p>Just like flush_all but also accepts an expiration time specified by the <code>$memc_exptime</code> variable.</p>"},{"location":"modules/memc/#stats","title":"stats","text":"<p>Causes the memcached server to output general-purpose statistics and settings</p> <pre><code>   location /foo {\n       set $memc_cmd stats;\n       memc_pass 127.0.0.1:11211;\n   }\n</code></pre> <p>Returns <code>200 OK</code> if the request succeeds, or 502 for <code>ERROR</code>, <code>CLIENT_ERROR</code>, or <code>SERVER_ERROR</code>.</p> <p>The raw <code>stats</code> command output from the upstream memcached server will be put into the response body. </p>"},{"location":"modules/memc/#directives","title":"Directives","text":"<p>All the standard memcached module directives in nginx 0.8.28 are directly inherited, with the <code>memcached_</code> prefixes replaced by <code>memc_</code>. For example, the <code>memcached_pass</code> directive is spelled <code>memc_pass</code>.</p> <p>Here we only document the most important two directives (the latter is a new directive introduced by this module).</p>"},{"location":"modules/memc/#memc_pass","title":"memc_pass","text":"<p>syntax: memc_pass &lt;memcached server IP address&gt;:&lt;memcached server port&gt;</p> <p>syntax: memc_pass &lt;memcached server hostname&gt;:&lt;memcached server port&gt;</p> <p>syntax: memc_pass &lt;upstream_backend_name&gt;</p> <p>syntax: memc_pass unix:&lt;path_to_unix_domain_socket&gt;</p> <p>default: none</p> <p>context: http, server, location, if</p> <p>phase: content</p> <p>Specify the memcached server backend.</p>"},{"location":"modules/memc/#memc_cmds_allowed","title":"memc_cmds_allowed","text":"<p>syntax: memc_cmds_allowed &lt;cmd&gt;...</p> <p>default: none</p> <p>context: http, server, location, if</p> <p>Lists memcached commands that are allowed to access. By default, all the memcached commands supported by this module are accessible. An example is</p> <pre><code>    location /foo {\n        set $memc_cmd $arg_cmd;\n        set $memc_key $arg_key;\n        set $memc_value $arg_val;\n\n        memc_pass 127.0.0.1:11211;\n\n        memc_cmds_allowed get;\n    }\n</code></pre>"},{"location":"modules/memc/#memc_flags_to_last_modified","title":"memc_flags_to_last_modified","text":"<p>syntax: memc_flags_to_last_modified on|off</p> <p>default: off</p> <p>context: http, server, location, if</p> <p>Read the memcached flags as epoch seconds and set it as the value of the <code>Last-Modified</code> header. For conditional GET, it will signal nginx to return <code>304 Not Modified</code> response to save bandwidth.</p>"},{"location":"modules/memc/#memc_connect_timeout","title":"memc_connect_timeout","text":"<p>syntax: memc_connect_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for connecting to the memcached server, in seconds by default.</p> <p>It's wise to always explicitly specify the time unit to avoid confusion. Time units supported are \"s\"(seconds), \"ms\"(milliseconds), \"y\"(years), \"M\"(months), \"w\"(weeks), \"d\"(days), \"h\"(hours), and \"m\"(minutes).</p> <p>This time must be less than 597 hours.</p>"},{"location":"modules/memc/#memc_send_timeout","title":"memc_send_timeout","text":"<p>syntax: memc_send_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for sending TCP requests to the memcached server, in seconds by default.</p> <p>It is wise to always explicitly specify the time unit to avoid confusion. Time units supported are \"s\"(seconds), \"ms\"(milliseconds), \"y\"(years), \"M\"(months), \"w\"(weeks), \"d\"(days), \"h\"(hours), and \"m\"(minutes).</p> <p>This time must be less than 597 hours.</p>"},{"location":"modules/memc/#memc_read_timeout","title":"memc_read_timeout","text":"<p>syntax: memc_read_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for reading TCP responses from the memcached server, in seconds by default.</p> <p>It's wise to always explicitly specify the time unit to avoid confusion. Time units supported are \"s\"(seconds), \"ms\"(milliseconds), \"y\"(years), \"M\"(months), \"w\"(weeks), \"d\"(days), \"h\"(hours), and \"m\"(minutes).</p> <p>This time must be less than 597 hours.</p>"},{"location":"modules/memc/#memc_buffer_size","title":"memc_buffer_size","text":"<p>syntax: memc_buffer_size &lt;size&gt;</p> <p>default: 4k/8k</p> <p>context: http, server, location</p> <p>This buffer size is used for the memory buffer to hold</p> <ul> <li>the complete response for memcached commands other than <code>get</code>,</li> <li>the complete response header (i.e., the first line of the response) for the <code>get</code> memcached command.</li> </ul> <p>This default size is the page size, may be <code>4k</code> or <code>8k</code>.</p>"},{"location":"modules/memc/#memc_ignore_client_abort","title":"memc_ignore_client_abort","text":"<p>syntax: memc_ignore_client_abort on|off</p> <p>default: off</p> <p>context: location</p> <p>Determines whether the connection with a memcache server should be closed when a client closes a connection without waiting for a response.</p> <p>This directive was first added in the <code>v0.14</code> release.</p>"},{"location":"modules/memc/#changes","title":"Changes","text":"<p>The changes of every release of this module can be obtained from the OpenResty bundle's change logs:</p> <p>http://openresty.org/#Changes</p>"},{"location":"modules/memc/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too. Thanks to the Test::Base module in the Perl world.</p> <p>To run it on your side:</p> <pre><code> $ PATH=/path/to/your/nginx-with-memc-module:$PATH prove -r t\n</code></pre> <p>You need to terminate any Nginx processes before running the test suite if you have changed the Nginx server binary.</p> <p>Either LWP::UserAgent or IO::Socket is used by the test scaffold.</p> <p>Because a single nginx server (by default, <code>localhost:1984</code>) is used across all the test scripts (<code>.t</code> files), it's meaningless to run the test suite in parallel by specifying <code>-jN</code> when invoking the <code>prove</code> utility.</p> <p>You should also keep a memcached server listening on the <code>11211</code> port at localhost before running the test suite.</p> <p>Some parts of the test suite requires modules rewrite and echo to be enabled as well when building Nginx.</p>"},{"location":"modules/memc/#see-also","title":"See Also","text":"<ul> <li>The original announcement email on the nginx mailing list: ngx_memc: \"an extended version of ngx_memcached that supports set, add, delete, and many more commands\"</li> <li>My slides demonstrating various ngx_memc usage: http://agentzh.org/misc/slides/nginx-conf-scripting/nginx-conf-scripting.html#34 (use the arrow or pageup/pagedown keys on the keyboard to swith pages)</li> <li>The latest memcached TCP protocol.</li> <li>The ngx_srcache module</li> <li>The lua-resty-memcached library based on the lua-nginx-module cosocket API.</li> <li>The standard memcached module.</li> <li>The echo module for Nginx module's automated testing.</li> <li>The standard headers module and the 3rd-parth headers-more module.</li> </ul>"},{"location":"modules/memc/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-memc.</p>"},{"location":"modules/naxsi/","title":"naxsi: NGINX Anti XSS &amp; SQL Injection module","text":""},{"location":"modules/naxsi/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-naxsi\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-naxsi\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_naxsi_module.so;\n</code></pre> <p>This document describes nginx-module-naxsi v1.6  released on Nov 28 2023.</p> <p></p>"},{"location":"modules/naxsi/#what-is-naxsi","title":"What is Naxsi?","text":"<p>NAXSI means Nginx Anti XSS &amp; SQL Injection. </p> <p>Technically, it is a third party nginx module, available as a package for many UNIX-like platforms. This module, by default, reads a small subset of simple (and readable) rules containing 99% of known patterns involved in website vulnerabilities. For example, <code>&lt;</code>, <code>|</code> or <code>drop</code> are not supposed to be part of a URI.</p> <p>Being very simple, those patterns may match legitimate queries, it is the Naxsi's administrator duty to add specific rules that will whitelist legitimate behaviours. The administrator can either add whitelists manually by analyzing nginx's error log, or (recommended) start the project with an intensive auto-learning phase that will automatically generate whitelisting rules regarding a website's behaviour.</p> <p>In short, Naxsi behaves like a DROP-by-default firewall, the only task is to add required ACCEPT rules for the target website to work properly.</p>"},{"location":"modules/naxsi/#why-is-it-different","title":"Why is it different?","text":"<p>Contrary to most Web Application Firewalls, Naxsi doesn't rely on a signature base like an antivirus, and thus cannot be circumvented by an \"unknown\" attack pattern. Naxsi is Free software (as in freedom) and free (as in free beer) to use.</p>"},{"location":"modules/naxsi/#what-does-it-run-on","title":"What does it run on?","text":"<p>Naxsi should be compatible with any nginx version.</p> <p>It depends on <code>libpcre</code> for its regexp support, and is reported to work great on NetBSD, FreeBSD, OpenBSD, Debian, Ubuntu and CentOS.</p>"},{"location":"modules/naxsi/#why-using-this-repository","title":"Why using this repository","text":"<p>The original project is (unofficially) abandoned, but you can fully ask for support here as i'm willing to keep the project working as last remaining developer.</p>"},{"location":"modules/naxsi/#documentation","title":"Documentation","text":"<p>docs</p>"},{"location":"modules/naxsi/#support","title":"Support","text":"<p>You can ask for support regarding NAXSI here or on the original repository https://github.com/nbs-system/naxsi</p>"},{"location":"modules/naxsi/#future-plans","title":"Future plans","text":"<ul> <li>Bring back nxapi via py3</li> <li>Creation of a simple tool to create rules and test them</li> </ul>"},{"location":"modules/naxsi/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-naxsi.</p>"},{"location":"modules/nchan/","title":"nchan: Scalable, flexible pub/sub server for the modern web","text":""},{"location":"modules/nchan/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-nchan\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-nchan\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_nchan_module.so;\n</code></pre> <p>This document describes nginx-module-nchan v1.3.7  released on Sep 20 2024.</p> <p></p> <p>https://nchan.io</p> <p>Nchan is a scalable, flexible pub/sub server for the modern web, built as a module for the Nginx web server. It can be configured as a standalone server, or as a shim between your application and hundreds, thousands, or millions of live subscribers. It can buffer messages in memory, on-disk, or via Redis. All connections are handled asynchronously and distributed among any number of worker processes. It can also scale to many Nginx servers with Redis.</p> <p>Messages are published to channels with HTTP <code>POST</code> requests or Websocket, and subscribed also through Websocket, long-polling, EventSource (SSE), old-fashioned interval polling, and more.</p> <p>In a web browser, you can use Websocket or EventSource natively, or the NchanSubscriber.js wrapper library. It supports Long-Polling, EventSource, and resumable Websockets, and has a few other added convenience options. It's also available on NPM.</p>"},{"location":"modules/nchan/#features","title":"Features","text":"<ul> <li>RESTful, HTTP-native API.</li> <li>Supports Websocket, EventSource (Server-Sent Events), Long-Polling and other HTTP-based subscribers.</li> <li>Per-channel configurable message buffers with no-repeat, no-loss message delivery guarantees.</li> <li>Subscribe to hundreds of channels over a single subscriber connection.</li> <li>HTTP request callbacks and hooks for easy integration.</li> <li>Introspection with channel events and url for monitoring performance statistics.</li> <li>Channel group usage accounting and limits.</li> <li>Fast, nonblocking shared-memory local message storage and optional, slower, persistent storage with Redis.</li> <li>Horizontally scalable (using Redis).</li> <li>Auto-failover and high availability with no single point of failure using Redis Cluster.</li> </ul>"},{"location":"modules/nchan/#status-and-history","title":"Status and History","text":"<p>The latest Nchan release is 1.3.7 (September 19, 2024) (changelog).</p> <p>The first iteration of Nchan was written in 2009-2010 as the Nginx HTTP Push Module, and was vastly refactored into its present state in 2014-2016.</p>"},{"location":"modules/nchan/#upgrade-from-nginx-http-push-module","title":"Upgrade from Nginx HTTP Push Module","text":"<p>Although Nchan is backwards-compatible with all Push Module configuration directives, some of the more unusual and rarely used settings have been disabled and will be ignored (with a warning). See the upgrade page for a detailed list of changes and improvements, as well as a full list of incompatibilities.</p>"},{"location":"modules/nchan/#does-it-scale","title":"Does it scale?","text":"<p>Yes it does. Like Nginx, Nchan can easily handle as much traffic as you can throw at it. I've tried to benchmark it, but my benchmarking tools are much slower than Nchan. The data I've gathered is on how long Nchan itself takes to respond to every subscriber after publishing a message -- this excludes TCP handshake times and internal HTTP request parsing. Basically, it measures how Nchan scales assuming all other components are already tuned for scalability. The graphed data are averages of 5 runs with 50-byte messages.</p> <p>With a well-tuned OS and network stack on commodity server hardware, expect to handle upwards of 300K concurrent subscribers per second at minimal CPU load. Nchan can also be scaled out to multiple Nginx instances using the Redis storage engine, and that too can be scaled up beyond a single-point-of-failure by using Redis Cluster.</p>"},{"location":"modules/nchan/#getting-started","title":"Getting Started","text":"<p>Once you've built and installed Nchan, it's very easy to start using. Add two locations to your nginx config:</p> <pre><code>#...\nhttp {  \n  server {\n    #...\n\n    location = /sub {\n      nchan_subscriber;\n      nchan_channel_id $arg_id;\n    }\n\n    location = /pub {\n      nchan_publisher;\n      nchan_channel_id $arg_id;\n    }\n  }\n}\n</code></pre> <p>You can now publish messages to channels by <code>POST</code>ing data to <code>/pub?id=channel_id</code> , and subscribe by pointing Websocket, EventSource, or NchanSubscriber.js to <code>sub/?id=channel_id</code>. It's that simple.</p> <p>But Nchan is very flexible and highly configurable. So, of course, it can get a lot more complicated...</p>"},{"location":"modules/nchan/#conceptual-overview","title":"Conceptual Overview","text":"<p>The basic unit of most pub/sub solutions is the messaging channel. Nchan is no different. Publishers send messages to channels with a certain channel id, and subscribers subscribed to those channels receive them. Some number of messages may be buffered for a time in a channel's message buffer before they are deleted. Pretty simple, right? </p> <p>Well... the trouble is that nginx configuration does not deal with channels, publishers, and subscribers. Rather, it has several sections for incoming requests to match against server and location sections. Nchan configuration directives map servers and locations onto channel publishing and subscribing endpoints:</p> <pre><code>#very basic nchan config\nworker_processes 5;\n\nhttp {  \n  server {\n    listen       80;\n\n    location = /sub {\n      nchan_subscriber;\n      nchan_channel_id foobar;\n    }\n\n    location = /pub {\n      nchan_publisher;\n      nchan_channel_id foobar;\n    }\n  }\n}\n</code></pre> <p>The above maps requests to the URI <code>/sub</code> onto the channel <code>foobar</code>'s subscriber endpoint , and similarly <code>/pub</code> onto channel <code>foobar</code>'s publisher endpoint.</p>"},{"location":"modules/nchan/#publisher-endpoints","title":"Publisher Endpoints","text":"<p>Publisher endpoints are Nginx config locations with the <code>nchan_publisher</code> directive.</p> <p>Messages can be published to a channel by sending HTTP POST requests with the message contents to the publisher endpoint locations. You can also publish messages through a Websocket connection to the same location.</p> <pre><code>  location /pub {\n    #example publisher location\n    nchan_publisher;\n    nchan_channel_id foo;\n    nchan_channel_group test;\n    nchan_message_buffer_length 50;\n    nchan_message_timeout 5m;\n  }\n</code></pre>"},{"location":"modules/nchan/#publishing-messages","title":"Publishing Messages","text":"<p>Requests and websocket messages are responded to with information about the channel at time of message publication. Here's an example from publishing with <code>curl</code>:</p> <pre><code>&gt;  curl --request POST --data \"test message\" http://127.0.0.1:80/pub\n\n queued messages: 5\n last requested: 18 sec. ago\n active subscribers: 0\n last message id: 1450755280:0\n</code></pre> <p>The response can be in plaintext (as above), JSON, or XML, based on the request's <code>Accept</code> header:</p> <pre><code>&gt; curl --request POST --data \"test message\" -H \"Accept: text/json\" http://127.0.0.2:80/pub\n\n {\"messages\": 5, \"requested\": 18, \"subscribers\": 0, \"last_message_id\": \"1450755280:0\" }\n</code></pre> <p>Websocket publishers also receive the same responses when publishing, with the encoding determined by the <code>Accept</code> header present during the handshake.</p> <p>The response code for an HTTP request is <code>202</code> Accepted if no subscribers are present at time of publication, or <code>201</code> Created if at least 1 subscriber was present.</p> <p>Metadata can be added to a message when using an HTTP POST request for publishing. A <code>Content-Type</code> header will be associated as the message's content type (and output to Long-Poll, Interval-Poll, and multipart/mixed subscribers). A <code>X-EventSource-Event</code> header can also be used to associate an EventSource <code>event:</code> line value with a message.</p>"},{"location":"modules/nchan/#other-publisher-endpoint-actions","title":"Other Publisher Endpoint Actions","text":"<p>HTTP <code>GET</code> requests return channel information without publishing a message. The response code is <code>200</code> if the channel exists, and <code>404</code> otherwise: <pre><code>&gt; curl --request POST --data \"test message\" http://127.0.0.2:80/pub\n  ...\n\n&gt; curl -v --request GET -H \"Accept: text/json\" http://127.0.0.2:80/pub\n\n {\"messages\": 1, \"requested\": 7, \"subscribers\": 0, \"last_message_id\": \"1450755421:0\" }\n</code></pre></p> <p>HTTP <code>DELETE</code> requests delete a channel and end all subscriber connections. Like the <code>GET</code> requests, this returns a <code>200</code> status response with channel info if the channel existed, and a <code>404</code> otherwise.</p>"},{"location":"modules/nchan/#how-channel-settings-work","title":"How Channel Settings Work","text":"<p>A channel's configuration is set to the that of its last-used publishing location. So, if you want a channel to behave consistently, and want to publish to it from multiple locations, make sure those locations have the same configuration.</p> <p>You can also can use differently-configured publisher locations to dynamically update a channel's message buffer settings. This can be used to erase messages or to scale an existing channel's message buffer as desired.</p>"},{"location":"modules/nchan/#subscriber-endpoints","title":"Subscriber Endpoints","text":"<p>Subscriber endpoints are Nginx config locations with the <code>nchan_subscriber</code> directive.</p> <p>Nchan supports several different kinds of subscribers for receiving messages: Websocket, EventSource (Server Sent Events),  Long-Poll, Interval-Poll. HTTP chunked transfer, and HTTP multipart/mixed.</p> <pre><code>  location /sub {\n    #example subscriber location\n    nchan_subscriber;\n    nchan_channel_id foo;\n    nchan_channel_group test;\n    nchan_subscriber_first_message oldest;\n  }\n</code></pre> <p>The <code>content-type:</code> line may be omitted.      #### Websocket Publisher   Messages published through a websocket connection can be forwarded to an upstream application with the <code>nchan_publisher_upstream_request</code> config directive.    Messages published in a binary frame are automatically given the <code>content-type</code> \"<code>application/octet-stream</code>\".   #### Permessage-deflate   Nchan version 1.1.8 and above supports the permessage-deflate protocol extension. Messages are deflated once when they are published, and then can be broadcast to any number of compatible websocket subscribers. Message deflation is enabled by setting the <code>nchan_deflate_message_for_websocket on;</code> directive in a publisher location.      The deflated data is stored alongside the original message in memory, or, if large enough, on disk. This means more shared memory is necessary when using <code>nchan_deflate_message_for_websocket</code>.      Deflation parameters (speed, memory use, strategy, etc.), can be tweaked using the <code>nchan_permessage_deflate_compression_window</code>, <code>nchan_permessage_deflate_compression_level</code>,   <code>nchan_permessage_deflate_compression_strategy</code>, and    <code>nchan_permessage_deflate_compression_window</code> settings.      Nchan also supports the (deprecated) perframe-deflate extension still in use by Safari as <code>x-webkit-perframe-deflate</code>.    </p>"},{"location":"modules/nchan/#long-polling","title":"Long-Polling","text":"<p>The tried-and-true server-push method supported by every browser out there.   Initiated by sending an HTTP <code>GET</code> request to a channel subscriber endpoint.   The long-polling subscriber walks through a channel's message queue via the built-in cache mechanism of HTTP clients, namely with the \"<code>Last-Modified</code>\" and \"<code>Etag</code>\" headers. Explicitly, to receive the next message for given a long-poll subscriber response, send a request with the \"<code>If-Modified-Since</code>\" header set to the previous response's \"<code>Last-Modified</code>\" header, and \"<code>If-None-Match</code>\" likewise set to the previous response's \"<code>Etag</code>\" header.   Sending a request without a \"<code>If-Modified-Since</code>\" or \"<code>If-None-Match</code>\" headers returns the oldest message in a channel's message queue, or waits until the next published message, depending on the value of the <code>nchan_subscriber_first_message</code> config directive.   A message's associated content type, if present, will be sent to this subscriber with the <code>Content-Type</code> header.    </p>"},{"location":"modules/nchan/#interval-polling","title":"Interval-Polling","text":"<p>Works just like long-polling, except if the requested message is not yet available, immediately responds with a <code>304 Not Modified</code>.   Nchan cannot automatically distinguish between long-poll and interval-poll subscriber requests, so long-polling must be disabled for a subscriber location if you wish to use interval-polling.</p>"},{"location":"modules/nchan/#websocket","title":"Websocket","text":"<p>Bidirectional communication for web browsers. Part of the HTML5 spec. Nchan supports the latest protocol version 13 (RFC 6455).   Initiated by sending a websocket handshake to the desired subscriber endpoint location.   If the websocket connection is closed by the server, the <code>close</code> frame will contain the HTTP response code and status line describing the reason for closing the connection. Server-initiated keep-alive pings can be configured with the <code>nchan_websocket_ping_interval</code> config directive.   Messages are delivered to subscribers in <code>text</code> websocket frames, except if a message's <code>content-type</code> is \"<code>application/octet-stream</code>\" -- then it is delivered in a <code>binary</code> frame.      Websocket subscribers can use the custom <code>ws+meta.nchan</code> subprotocol to receive message metadata with messages, making websocket connections resumable. Messages received with this subprotocol are of the form  <pre>\n  id: message_id\n  content-type: message_content_type\n  \\n\n  message_data\n  </pre></p>"},{"location":"modules/nchan/#eventsource","title":"EventSource","text":"<p>Also known as Server-Sent Events or SSE, it predates Websockets in the HTML5 spec, and is a very simple protocol.   Initiated by sending an HTTP <code>GET</code> request to a channel subscriber endpoint with the \"<code>Accept: text/event-stream</code>\" header.     Each message <code>data:</code> segment will be prefaced by the message <code>id:</code>.   To resume a closed EventSource connection from the last-received message, one should start the connection with the \"<code>Last-Event-ID</code>\" header set to the last message's <code>id</code>.   Unfortunately, browsers don't support setting this header for an <code>EventSource</code> object, so by default the last message id is set either from the \"<code>Last-Event-Id</code>\" header or the <code>last_event_id</code> url query string argument.   This behavior can be configured via the <code>nchan_subscriber_last_message_id</code> config.   A message's <code>content-type</code> will not be received by an EventSource subscriber, as the protocol makes no provisions for this metadata.   A message's associated <code>event</code> type, if present, will be sent to this subscriber with the <code>event:</code> line. </p>"},{"location":"modules/nchan/#http-multipartmixed","title":"HTTP multipart/mixed","text":"<p>The <code>multipart/mixed</code> MIMEtype was conceived for emails, but hey, why not use it for HTTP? It's easy to parse and includes metadata with each message.   Initiated by including an <code>Accept: multipart/mixed</code> header.   The response headers and the unused \"preamble\" portion of the response body are sent right away, with the boundary string generated randomly for each subscriber.  Each subsequent message will be sent as one part of the multipart message, and will include the message time and tag (<code>Last-Modified</code> and <code>Etag</code>) as well as the optional <code>Content-Type</code> headers.   Each message is terminated with the next multipart message's boundary without a trailing newline. While this conforms to the multipart spec, it is unusual as multipart messages are defined as starting, rather than ending with a boundary.   A message's associated content type, if present, will be sent to this subscriber with the <code>Content-Type</code> header.    </p>"},{"location":"modules/nchan/#http-raw-stream","title":"HTTP Raw Stream","text":"<p>A simple subscription method similar to the streaming subscriber of the Nginx HTTP Push Stream Module. Messages are appended to the response body, separated by a newline or configurable by <code>nchan_subscriber_http_raw_stream_separator</code>.    </p>"},{"location":"modules/nchan/#http-chunked-transfer","title":"HTTP Chunked Transfer","text":"<p>This subscription method uses the <code>chunked</code> <code>Transfer-Encoding</code> to receive messages.    Initiated by explicitly including <code>chunked</code> in the <code>TE</code> header: <code>TE: chunked</code> (or <code>TE: chunked;q=??</code> where the qval &gt; 0)   The response headers are sent right away, and each message will be sent as an individual chunk. Note that because a zero-length chunk terminates the transfer, zero-length messages will not be sent to the subscriber.   Unlike the other subscriber types, the <code>chunked</code> subscriber cannot be used with http/2 because it disallows chunked encoding.    </p>"},{"location":"modules/nchan/#pubsub-endpoint","title":"PubSub Endpoint","text":"<p>PubSub endpoints are Nginx config locations with the <code>nchan_pubsub</code> directive.</p> <p>A combination of publisher and subscriber endpoints, this location treats all HTTP <code>GET</code> requests as subscribers, and all HTTP <code>POST</code> as publishers. Channels cannot be deleted through a pubsub endpoing with an HTTP <code>DELETE</code> request.</p> <p>One simple use case is an echo server:</p> <pre><code>  location = /pubsub {\n    nchan_pubsub;\n    nchan_channel_id foo;\n    nchan_channel_group test;\n  }\n</code></pre> <p>A more interesting setup may set different publisher and subscriber channel ids:</p> <pre><code>  location = /pubsub {\n    nchan_pubsub;\n    nchan_publisher_channel_id foo;\n    nchan_subscriber_channel_id bar;\n    nchan_channel_group test;\n  }\n</code></pre> <p>Here, subscribers will listen for messages on channel <code>foo</code>, and publishers will publish messages to channel <code>bar</code>. This can be useful when setting up websocket proxying between web clients and your application.</p>"},{"location":"modules/nchan/#the-channel-id","title":"The Channel ID","text":"<p>So far the examples have used static channel ids, which is not very useful. In practice, the channel id can be set to any nginx variable, such as a querystring argument, a header value, or a part of the location url:</p> <pre><code>  location = /sub_by_ip {\n    #channel id is the subscriber's IP address\n    nchan_subscriber;\n    nchan_channel_id $remote_addr;\n  }\n\n  location /sub_by_querystring {\n    #channel id is the query string parameter chanid\n    # GET /sub/sub_by_querystring?foo=bar&amp;chanid=baz will have the channel id set to 'baz'\n    nchan_subscriber;\n    nchan_channel_id $arg_chanid;\n  }\n\n  location ~ /sub/(\\w+)$ {\n    #channel id is the word after /sub/\n    # GET /sub/foobar_baz will have the channel id set to 'foobar_baz'\n    # I hope you know your regular expressions...\n    nchan_subscriber;\n    nchan_channel_id $1; #first capture of the location match\n  }\n</code></pre> <p>I recommend using the last option, a channel id derived from the request URL via a regular expression. It makes things nice and RESTful.</p>"},{"location":"modules/nchan/#channel-multiplexing","title":"Channel Multiplexing","text":"<p>With channel multiplexing, subscribers can subscribe to up to 255 channels per connection. Messages published to all the specified channels will be delivered in-order to the subscriber. There are two ways to enable multiplexing:</p> <p>Up to 7 channel ids can be specified for the <code>nchan_channel_id</code> or <code>nchan_channel_subscriber_id</code> config directive:</p> <pre><code>  location ~ /multisub/(\\w+)/(\\w+)$ {\n    nchan_subscriber;\n    nchan_channel_id \"$1\" \"$2\" \"common_channel\";\n    #GET /multisub/foo/bar will be subscribed to:\n    # channels 'foo', 'bar', and 'common_channel',\n    #and will receive messages from all of the above.\n  }\n</code></pre> <p>For more than 7 channels, <code>nchan_channel_id_split_delimiter</code> can be used to split the <code>nchan_channel_id</code> or <code>nchan_channel_subscriber_id</code> into up to 255 individual channel ids:</p> <pre><code>  location ~ /multisub-split/(.*)$ {\n    nchan_subscriber;\n    nchan_channel_id \"$1\";\n    nchan_channel_id_split_delimiter \",\";\n    #GET /multisub-split/foo,bar,baz,a will be subscribed to:\n    # channels 'foo', 'bar', 'baz', and 'a'\n    #and will receive messages from all of the above.\n  }\n</code></pre> <p>It is also possible to publish to multiple channels with a single request as well as delete multiple channels with a single request, with similar configuration:</p> <pre><code>  location ~ /multipub/(\\w+)/(\\w+)$ {\n    nchan_publisher;\n    nchan_channel_id \"$1\" \"$2\" \"another_channel\";\n    #POST /multipub/foo/bar will publish to:\n    # channels 'foo', 'bar', 'another_channel'\n    #DELETE /multipub/foo/bar will delete:\n    # channels 'foo', 'bar', 'another_channel'\n  }\n</code></pre> <p>When a channel is deleted, all of its messages are deleted, and all of its subscribers' connection are closed -- including ones subscribing through a multiplexed location. For example, suppose a subscriber is subscribed to channels \"foo\" and \"bar\" via a single multiplexed connection. If \"foo\" is deleted, the connection is closed, and the subscriber therefore loses the \"bar\" subscription as well.</p> <p>See the Channel Security section about using good IDs and keeping private channels secure.</p>"},{"location":"modules/nchan/#channel-groups","title":"Channel Groups","text":"<p>Channels can be associated with groups to avoid channel ID conflicts:</p> <pre><code>  location /test_pubsub {\n    nchan_pubsub;\n    nchan_channel_group \"test\";\n    nchan_channel_id \"foo\";\n  }\n\n  location /pubsub {\n    nchan_pubsub;\n    nchan_channel_group \"production\";\n    nchan_channel_id \"foo\";\n    #same channel id, different channel group. Thus, different channel.\n  }\n\n  location /flexgroup_pubsub {\n    nchan_pubsub;\n    nchan_channel_group $arg_group;\n    nchan_channel_id \"foo\";\n    #group can be set with request variables too\n  }\n</code></pre>"},{"location":"modules/nchan/#limits-and-accounting","title":"Limits and Accounting","text":"<p>Groups can be used to track aggregate channel usage, as well as set limits on the number of channels, subscribers, stored messages, memory use, etc:</p> <pre><code>  #enable group accounting\n  nchan_channel_group_accounting on;\n\n  location ~ /pubsub/(\\w+)$ {\n    nchan_pubsub;\n    nchan_channel_group \"limited\";\n    nchan_channel_id $1;\n  }\n\n  location ~ /prelimited_pubsub/(\\w+)$ {\n    nchan_pubsub;\n    nchan_channel_group \"limited\";\n    nchan_channel_id $1;\n    nchan_group_max_subscribers 100;\n    nchan_group_max_messages_memory 50M;\n  }\n\n  location /group {\n    nchan_channel_group limited;\n    nchan_group_location;\n    nchan_group_max_channels $arg_max_channels;\n    nchan_group_max_messages $arg_max_messages;\n    nchan_group_max_messages_memory $arg_max_messages_mem;\n    nchan_group_max_messages_disk $arg_max_messages_disk;\n    nchan_group_max_subscribers $arg_max_subs;\n  }\n</code></pre> <p>Here, <code>/group</code> is an <code>nchan_group_location</code>, which is used for accessing and modifying group data. To get group data, send a <code>GET</code> request to a <code>nchan_group_location</code>:</p> <pre><code>&gt;  curl http://localhost/group\n\nchannels: 10\nsubscribers: 0\nmessages: 219\nshared memory used by messages: 42362 bytes\ndisk space used by messages: 0 bytes\nlimits:\n  max channels: 0\n  max subscribers: 0\n  max messages: 0\n  max messages shared memory: 0\n  max messages disk space: 0  \n</code></pre> <p>By default, the data is returned in human-readable plaintext, but can also be formatted as JSON, XML, or YAML:</p> <pre><code>&gt;  curl -H \"Accept: text/json\" http://localhost/group\n\n{\n  \"channels\": 21,\n  \"subscribers\": 40,\n  \"messages\": 53,\n  \"messages_memory\": 19941,\n  \"messages_disk\": 0,\n  \"limits\": {\n    \"channels\": 0,\n    \"subscribers\": 0,\n    \"messages\": 0,\n    \"messages_memory\": 0,\n    \"messages_disk\": 0\n  }\n}\n</code></pre> <p>The data in the response are for the single Nchan instance only, regardless of whether Redis is used. A limit of 0 means 'unlimited'.</p> <p>Limits can be set per-location, as with the above <code>/prelimited_pubsub/...</code> location, or with a POST request to the <code>nchan_group_location</code>: <pre><code>&gt;  curl -X POST \"http://localhost/group?max_channels=15&amp;max_subs=1000&amp;max_messages_disk=0.5G\"\n\nchannels: 0\nsubscribers: 0\nmessages: 0\nshared memory used by messages: 0 bytes\ndisk space used by messages: 0 bytes\nlimits:\n  max channels: 15\n  max subscribers: 1000\n  max messages: 0\n  max messages shared memory: 0\n  max messages disk space: 536870912\n</code></pre></p> <p>Limits are only applied locally, regardless of whether Redis is enabled.  If a publisher or subscriber request exceeds a group limit, Nchan will respond to it with a <code>403 Forbidden</code> response.</p>"},{"location":"modules/nchan/#hooks-and-callbacks","title":"Hooks and Callbacks","text":""},{"location":"modules/nchan/#request-authorization","title":"Request Authorization","text":"<p>This feature, configured with <code>nchan_authorize_request</code>, behaves just like the Nginx http_auth_request module.</p> <p>Consider the configuration: <pre><code>  upstream my_app {\n    server 127.0.0.1:8080;\n  }\n  location = /auth {\n    proxy_pass http://my_app/pubsub_authorize;\n    proxy_pass_request_body off;\n    proxy_set_header Content-Length \"\";\n    proxy_set_header X-Subscriber-Type $nchan_subscriber_type;\n    proxy_set_header X-Publisher-Type $nchan_publisher_type;\n    proxy_set_header X-Prev-Message-Id $nchan_prev_message_id;\n    proxy_set_header X-Channel-Id $nchan_channel_id;\n    proxy_set_header X-Original-URI $request_uri;\n    proxy_set_header X-Forwarded-For $remote_addr;\n  }\n\n  location ~ /pubsub/auth/(\\w+)$ {\n    nchan_channel_id $1;\n    nchan_authorize_request /auth;\n    nchan_pubsub;\n    nchan_channel_group test;\n  }\n</code></pre></p> <p>Here, any request to the location <code>/pubsub/auth/&lt;...&gt;</code> will need to be authorized by your application (<code>my_app</code>). Nginx will generate a <code>GET /pubsub_authorize</code> request to the application, with additional headers set by the <code>proxy_set_header</code> directives. Note that Nchan-specific variables are available for this authorization request. Once your application receives this request, it should decide whether or not to authorize the subscriber. This can be done based on a forwarded session cookie, IP address, or any set of parameters of your choosing. If authorized, it should respond with an empty <code>200 OK</code> response. All non-<code>2xx</code> response codes (such as <code>403 Forbidden</code>) are interpreted as authorization failures. In this case, the failing response is proxied to the client. </p> <p>Note that Websocket and EventSource clients will only try to authorize during the initial handshake request, whereas Long-Poll and Interval-Poll subscribers will need to be authorized each time they request the next message, which may flood your application with too many authorization requests.</p>"},{"location":"modules/nchan/#subscriber-presence","title":"Subscriber Presence","text":"<p>Subscribers can notify an application when they have subscribed and unsubscribed to a channel using the <code>nchan_subscribe_request</code> and <code>nchan_unsubscribe_request</code> settings.  These should point to Nginx locations configured to forward requests to an upstream proxy (your application):</p> <pre><code>  location ~ /sub/(\\w+)$ {\n    nchan_channel_id $1;\n    nchan_subscribe_request /upstream/sub;\n    nchan_unsubscribe_request /upstream/unsub;\n    nchan_subscriber;\n    nchan_channel_group test;\n  }\n\n  location = /upstream/unsub {\n    proxy_pass http://127.0.0.1:9292/unsub;\n    proxy_ignore_client_abort on;  #!!!important!!!!\n    proxy_set_header X-Subscriber-Type $nchan_subscriber_type;\n    proxy_set_header X-Channel-Id $nchan_channel_id;\n    proxy_set_header X-Original-URI $request_uri;\n  } \n  location = /upstream/sub {\n    proxy_pass http://127.0.0.1:9292/sub;\n    proxy_set_header X-Subscriber-Type $nchan_subscriber_type;\n    proxy_set_header X-Message-Id $nchan_message_id;\n    proxy_set_header X-Channel-Id $nchan_channel_id;\n    proxy_set_header X-Original-URI $request_uri;\n  } \n</code></pre> <p>In order for <code>nchan_unsubscribe_request</code> to work correctly, the location it points to must have <code>proxy_ignore_client_abort on;</code>. Otherwise, suddenly aborted subscribers may not trigger an unsubscribe request.</p> <p>Note that the subscribe/unsubscribe hooks are disabled for long-poll and interval-poll clients, because they would trigger these hooks each time they receive a message.</p>"},{"location":"modules/nchan/#message-forwarding","title":"Message Forwarding","text":"<p>Messages can be forwarded to an upstream application before being published using the <code>nchan_publisher_upstream_request</code> setting:</p> <p><pre><code>  location ~ /pub/(\\w+)$ {\n    #publisher endpoint\n    nchan_channel_id $1;\n    nchan_pubsub;\n    nchan_publisher_upstream_request /upstream_pub;\n  }\n\n  location = /upstream_pub {\n    proxy_pass http://127.0.0.1:9292/pub;\n    proxy_set_header X-Publisher-Type $nchan_publisher_type;\n    proxy_set_header X-Prev-Message-Id $nchan_prev_message_id;\n    proxy_set_header X-Channel-Id $nchan_channel_id;\n    proxy_set_header X-Original-URI $request_uri;\n  } \n</code></pre> With this configuration, incoming messages are first <code>POST</code>ed to <code>http://127.0.0.1:9292/pub</code>. The upstream response code determines how publishing will proceed:   - <code>304 Not Modified</code> publishes the message as received, without modifification.   - <code>204 No Content</code> discards the message   - <code>200 OK</code> is used for modifying the message. Instead of the original incoming message, the message contained in this HTTP response is published.</p> <p>There are two main use cases for <code>nchan_publisher_upstream_request</code>: forwarding incoming data from Websocket publishers to an application, and mutating incoming messages.</p>"},{"location":"modules/nchan/#storage","title":"Storage","text":"<p>Nchan can stores messages in memory, on disk, or via Redis. Memory storage is much faster, whereas Redis has additional overhead as is considerably slower for publishing messages, but offers near unlimited scalability for broadcast use cases with far more subscribers than publishers.</p>"},{"location":"modules/nchan/#memory-storage","title":"Memory Storage","text":"<p>This default storage method uses a segment of shared memory to store messages and channel data. Large messages as determined by Nginx's caching layer are stored on-disk. The size of the memory segment is configured with <code>nchan_shared_memory_size</code>. Data stored here is not persistent, and is lost if Nginx is restarted or reloaded.</p>"},{"location":"modules/nchan/#redis","title":"Redis","text":"<p>Redis can be used to add data persistence and horizontal scalability, failover and high availability to your Nchan setup. </p>"},{"location":"modules/nchan/#connecting-to-a-redis-server","title":"Connecting to a Redis Server","text":"<p>To connect to a single Redis master server, use an <code>upstream</code> with <code>nchan_redis_server</code> and <code>nchan_redis_pass</code> settings:</p> <pre><code>http {\n  upstream my_redis_server {\n    nchan_redis_server 127.0.0.1;\n  }\n  server {\n    listen 80;\n\n    location ~ /redis_sub/(\\w+)$ {\n      nchan_subscriber;\n      nchan_channel_id $1;\n      nchan_redis_pass my_redis_server;\n    }\n    location ~ /redis_pub/(\\w+)$ {\n      nchan_redis_pass my_redis_server;\n      nchan_publisher;\n      nchan_channel_id $1;\n    }\n  }\n} \n</code></pre> <p>All servers with the above configuration connecting to the same redis server share channel and message data.</p> <p>Channels that don't use Redis can be configured side-by-side with Redis-backed channels, provided the endpoints never overlap. (This can be ensured, as above, by setting separate <code>nchan_channel_group</code>s.). Different locations can also connect to different Redis servers.</p> <p>Nchan can work with a single Redis master. It can also auto-discover and use Redis slaves to balance PUBSUB traffic.</p>"},{"location":"modules/nchan/#redis-cluster","title":"Redis Cluster","text":"<p>Nchan also supports using Redis Cluster, which adds scalability via sharding channels among cluster nodes. Redis cluster also provides automatic failover, high availability, and eliminates the single point of failure of one shared Redis server. It is configured and used like so:</p> <pre><code>http {\n  upstream redis_cluster {\n    nchan_redis_server redis://127.0.0.1:7000;\n    nchan_redis_server redis://127.0.0.1:7001;\n    nchan_redis_server redis://127.0.0.1:7002;\n    # you don't need to specify all the nodes, they will be autodiscovered\n    # however, it's recommended that you do specify at least a few master nodes.\n  }\n  server {\n    listen 80;\n\n    location ~ /sub/(\\w+)$ {\n      nchan_subscriber;\n      nchan_channel_id $1;\n      nchan_redis_pass redis_cluster;\n    }\n    location ~ /pub/(\\w+)$ {\n      nchan_publisher;\n      nchan_channel_id $1;\n      nchan_redis_pass redis_cluster;\n    }\n  }\n} \n</code></pre>"},{"location":"modules/nchan/#high-availability","title":"High Availability","text":"<p>Redis Cluster connections are designed to be resilient and try to recover from errors. Interrupted connections will have their commands queued until reconnection, and Nchan will publish any messages it successfully received while disconnected. Nchan is also adaptive to cluster modifications. It will add new nodes and remove them as needed.</p> <p>All Nchan servers sharing a Redis server or cluster should have their times synchronized (via ntpd or your favorite ntp daemon). Failure to do so may result in missed or duplicate messages.</p>"},{"location":"modules/nchan/#failover-recovery","title":"Failover Recovery","text":"<p>Starting with version 1.3.0, Nchan will attempt to recover from cluster node failures, keyslot errors, and cluster epoch changes without disconnecting from the entire cluster. It will attempt to do this until <code>nchan_redis_cluster_max_failing_time</code> is exceeded. Additionally, recovery attempt delays have configurable jitter, exponential backoff, and maximum values.</p>"},{"location":"modules/nchan/#using-redis-securely","title":"Using Redis securely","text":"<p>Redis servers can be connected to via TLS by using the <code>nchan_redis_ssl</code> config setting in an <code>upstream</code> block, or by using the <code>rediss://</code>  schema for the server URLs.</p> <p>A password and optional username for the <code>AUTH</code> command can be set by the <code>nchan_redis_username</code> and <code>nchan_redis_password</code> config settings in an <code>upstream</code> block, or by using the <code>redis://&lt;username&gt;:&lt;password&gt;@hostname</code> server URL schema.</p> <p>Note that autodiscovered Redis nodes inherit their parent's SSL, username, and password settings.</p>"},{"location":"modules/nchan/#tweaks-and-optimizations","title":"Tweaks and Optimizations","text":"<p>As of version 1.2.0, Nchan uses Redis slaves to load-balance PUBSUB traffic. By default, there is an equal chance that a channel's PUBSUB subscription will go to any master or slave. The <code>nchan_redis_subscribe_weights</code> setting is available to fine-tune this load-balancing.</p> <p>Also from 1.2.0 onward, <code>nchan_redis_optimize_target</code> can be used to prefer optimizing Redis slaves for CPU or bandwidth. For heavy publishing loads, the tradeoff is very roughly 35% replication bandwidth per slave to 30% CPU load on slaves.</p>"},{"location":"modules/nchan/#performance-statistics","title":"Performance Statistics","text":"<p>Redis command statistics were added in version 1.3.5. These provide total number of times different Redis commands were run on, and the total amount of time they took. The stats are for a given Nchan server, not all servers connected to a Redis upstream. They are grouped by each upstream, and totaled per node.</p> <pre><code>http {\n  upstream my_redis_cluster {\n    nchan_redis_server 127.0.0.1;\n  }\n\n  server {\n    #[...]\n\n    location ~ /nchan_redis_cluster_stats$ {\n      nchan_redis_upstream_stats my_redis_cluster;\n    }\n  }\n</code></pre> <p>To get the stats, send a GET request to the stats location.</p> <pre><code>  curl http://localhost/nchan_redis_cluster_stats\n</code></pre> <p>The response is JSON of the form:</p> <pre><code>{\n  \"upstream\": \"redis_cluster\",\n  \"nodes\": [\n    {\n      \"address\"        : \"127.0.0.1:7000\",\n      \"id\"             : \"f13d71b1d14d8bf92b72cebee61421294e95dc72\",\n      \"command_totals\" : {\n        \"connect\"    : {\n          \"msec\"     : 357,\n          \"times\"    : 5\n        },\n        \"pubsub_subscribe\": {\n          \"msec\"     : 749,\n          \"times\"    : 37\n        },\n        \"pubsub_unsubsribe\": {\n          \"msec\"     : 332,\n          \"times\"    : 37\n        }\n        /*[...]*/\n      }\n    },\n    {\n      \"address\"        : \"127.0.0.1:7001\",\n      \"id\"             : \"b768ecb4152912bed6dc927e8f70284191a79ed7\",\n      \"command_totals\" : {\n        \"connect\"    : {\n          \"msec\"     : 4281,\n          \"times\"    : 5\n        },\n        \"pubsub_subscribe\": {\n          \"msec\"     : 309,\n          \"times\"    : 33\n        },\n        \"pubsub_unsubsribe\": {\n          \"msec\"     : 307,\n          \"times\"    : 30\n        },\n        /*[...]*/\n      },\n    }\n    /*[...]*/\n  ]\n}\n</code></pre> <p>For brevity, the entire <code>command_totals</code> hash is omitted in this documentation.</p>"},{"location":"modules/nchan/#introspection","title":"Introspection","text":"<p>There are several ways to see what's happening inside Nchan. These are useful for debugging application integration and for measuring performance.</p>"},{"location":"modules/nchan/#channel-events","title":"Channel Events","text":"<p>Channel events are messages automatically published by Nchan when certain events occur in a channel. These are very useful for debugging the use of channels. However, they carry a significant performance overhead and should be used during development, and not in production.</p> <p>Channel events are published to special 'meta' channels associated with normal channels. Here's how to configure them:</p> <pre><code>location ~ /pubsub/(.+)$ {\n  nchan_pubsub;\n  nchan_channel_id $1;\n  nchan_channel_events_channel_id $1; #enables channel events for this location\n}\n\nlocation ~ /channel_events/(.+) {\n  #channel events subscriber location\n  nchan_subscriber;\n  nchan_channel_group meta; #\"meta\" is a SPECIAL channel group\n  nchan_channel_id $1;\n}\n</code></pre> <p>Note the <code>/channel_events/...</code> location has a special <code>nchan_channel_group</code>, <code>meta</code>. This group is reserved for accessing \"channel events channels\", or\"metachannels\".</p> <p>Now, say I subscribe to <code>/channel_events/foo</code> I will refer to this as the channel events subscriber.</p> <p>Let's see what this channel events subscriber receives when I publish messages to </p> <p>Subscribing to <code>/pubsub/foo</code> produces the channel event <pre><code>subscriber_enqueue foo\n</code></pre></p> <p>Publishing a message to <code>/pubsub/foo</code>: <pre><code>channel_publish foo\n</code></pre></p> <p>Unsubscribing from <code>/pubsub/foo</code>: <pre><code>subscriber_dequeue foo\n</code></pre></p> <p>Deleting <code>/pubsub/foo</code> (with HTTP <code>DELETE /pubsub/foo</code>): <pre><code>channel_delete foo\n</code></pre></p> <p>The event string itself is configirable with nchan_channel_event_string. By default, it is set to <code>$nchan_channel_event $nchan_channel_id</code>.  This string can use any Nginx and Nchan variables.</p>"},{"location":"modules/nchan/#nchan_stub_status-stats","title":"nchan_stub_status Stats","text":"<p>Like Nginx's stub_status, <code>nchan_stub_status</code> is used to get performance metrics.</p> <pre><code>  location /nchan_stub_status {\n    nchan_stub_status;\n  }\n</code></pre> <p>Sending a GET request to this location produces the response:</p> <pre><code>total published messages: 1906\nstored messages: 1249\nshared memory used: 1824K\nchannels: 80\nsubscribers: 90\nredis pending commands: 0\nredis connected servers: 0\nredis unhealthy upstreams: 0\ntotal redis commands sent: 0\ntotal interprocess alerts received: 1059634\ninterprocess alerts in transit: 0\ninterprocess queued alerts: 0\ntotal interprocess send delay: 0\ntotal interprocess receive delay: 0\nnchan version: 1.1.5\n</code></pre> <p>Here's what each line means, and how to interpret it:   - <code>total published messages</code>: Number of messages published to all channels through this Nchan server.   - <code>stored messages</code>: Number of messages currently buffered in memory   - <code>shared memory used</code>: Total shared memory used for buffering messages, storing channel information, and other purposes. This value should be comfortably below <code>nchan_shared_memory_size</code>.   - <code>channels</code>: Number of channels present on this Nchan server.   - <code>subscribers</code>: Number of subscribers to all channels on this Nchan server.   - <code>redis pending commands</code>: Number of commands sent to Redis that are awaiting a reply. May spike during high load, especially if the Redis server is overloaded. Should tend towards 0.   - <code>redis connected servers</code>: Number of redis servers to which Nchan is currently connected.   - <code>redis unhealthy upstreams</code>: Number of redis upstreams (individual server or cluster mode) that are currently not usable for publishing and subscribing.   - <code>total redis commands sent</code>: Total number of commands this Nchan instance sent to Redis.   - <code>total interprocess alerts received</code>: Number of interprocess communication packets transmitted between Nginx workers processes for Nchan. Can grow at 100-10000 per second at high load.   - <code>interprocess alerts in transit</code>: Number of interprocess communication packets in transit between Nginx workers. May be nonzero during high load, but should always tend toward 0 over time.   - <code>interprocess queued alerts</code>: Number of interprocess communication packets waiting to be sent. May be nonzero during high load, but should always tend toward 0 over time.   - <code>total interprocess send delay</code>: Total amount of time interprocess communication packets spend being queued if delayed. May increase during high load.   - <code>total interprocess receive delay</code>: Total amount of time interprocess communication packets spend in transit if delayed. May increase during high load.   - <code>nchan_version</code>: current version of Nchan. Available for version 1.1.5 and above.</p> <p>Additionally, when there is at least one <code>nchan_stub_status</code> location, this data is also available through variables.</p>"},{"location":"modules/nchan/#securing-channels","title":"Securing Channels","text":""},{"location":"modules/nchan/#securing-publisher-endpoints","title":"Securing Publisher Endpoints","text":"<p>Consider the use case of an application where authenticated users each use a private, dedicated channel for live updates. The configuration might look like this:</p> <pre><code>http {\n  server {\n    #available only on localhost\n    listen  127.0.0.1:8080;\n    location ~ /pub/(\\w+)$ {\n      nchan_publisher;\n      nchan_channel_group my_app_group;\n      nchan_channel_id $1;\n    }\n  }\n\n  server {\n    #available to the world\n    listen 80;\n\n    location ~ /sub/(\\w+)$ {\n      nchan_subscriber;\n      nchan_channel_group my_app_group;\n      nchan_channel_id $1;\n    }\n  }\n}\n</code></pre> <p>Here, the subscriber endpoint is available on a public-facing port 80, and the publisher endpoint is only available on localhost, so can be accessed only by applications residing on that machine. Another way to limit access to the publisher endpoint is by using the allow/deny settings:</p> <pre><code>  server {\n    #available to the world\n    listen 80; \n    location ~ /pub/(\\w+)$ {\n      allow 127.0.0.1;\n      deny all;\n      nchan_publisher;\n      nchan_channel_group my_app_group;\n      nchan_channel_id $1;\n    }\n</code></pre> <p>Here, only the local IP 127.0.0.1 is allowed to use the publisher location, even though it is defined in a non-localhost server block.</p>"},{"location":"modules/nchan/#keeping-a-channel-private","title":"Keeping a Channel Private","text":"<p>A Channel ID that is meant to be private should be treated with the same care as a session ID token. Considering the above use case of one-channel-per-user, how can we ensure that only the authenticated user, and no one else, is able to access his channel? </p> <p>First, if you intend on securing the channel contents, you must use TLS/SSL:</p> <pre><code>http {\n  server {\n    #available only on localhost\n    listen  127.0.0.1:8080;\n    #...publisher endpoint config\n  }\n  server {\n    #available to the world\n    listen 443 ssl;\n    #SSL config goes here\n    location ~ /sub/(\\w+)$ {\n      nchan_subscriber;\n      nchan_channel_group my_app_group;\n      nchan_channel_id $1;\n    }\n  }\n}\n</code></pre> <p>Now that you have a secure connection between the subscriber client and the server, you don't need to worry about the channel ID or messages being passively intercepted. This is a minimum requirement for secure message delivery, but it is not sufficient. </p> <p>You must also take care to do at least one of the following:   - Generate good, high-entropy Channel IDs.   - Authorize all subscribers with the <code>nchan_authorize_request</code> config directive.   - Authorize subscribers and hide channel IDs with the \"<code>X-Accel-Redirect</code>\" mechanism.</p>"},{"location":"modules/nchan/#good-ids","title":"Good IDs","text":"<p>An ID that can be guessed is an ID that can be hijacked. If you are not authenticating subscribers (as described below), a channel ID should be impossible to guess. Use at least 128 bits of entropy to generate a random token, associate it with the authenticated user, and share it only with the user's client. Do not reuse tokens, just as you would not reuse session IDs.</p>"},{"location":"modules/nchan/#x-accel-redirect","title":"X-Accel-Redirect","text":"<p>This feature uses the X-Accel feature of Nginx upstream proxies to perform an internal request to a subscriber endpoint. It allows a subscriber client to be authenticated by your application, and then redirected by nginx internally to a location chosen by your application (such as a publisher or subscriber endpoint). This makes it possible to have securely authenticated clients that are unaware of the channel id they are subscribed to.</p> <p>Consider the following configuration: <pre><code>upstream upstream_app {\n  server 127.0.0.1:8080;\n}\n\nserver {\n  listen 80; \n\n  location = /sub_upstream {\n    proxy_pass http://upstream_app/subscriber_x_accel_redirect;\n    proxy_set_header X-Forwarded-For $remote_addr;\n  }\n\n  location ~ /sub/internal/(\\w+)$ {\n    internal; #this location only accessible for internal nginx redirects\n    nchan_subscriber;\n    nchan_channel_id $1;\n    nchan_channel_group test;\n  }\n}\n</code></pre></p> <p>As commented, <code>/sub/internal/</code> is inaccessible from the outside: <pre><code>&gt; curl  -v  http://127.0.0.1/sub/internal/foo\n\n  &lt; HTTP/1.1 404 Not Found\n  &lt; Server: nginx/1.9.5\n  &lt;\n  &lt;html&gt;\n  &lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;\n  &lt;body bgcolor=\"white\"&gt;\n  &lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;\n  &lt;hr&gt;&lt;center&gt;nginx/1.9.5&lt;/center&gt;\n  &lt;/body&gt;\n  &lt;/html&gt;\n</code></pre></p> <p>But if a request is made to <code>/sub_upstream</code>, it gets forwarded to your application (<code>my_app</code>) on port 8080 with the url <code>/subscriber_x_accel_redirect</code>. Note that you can set any forwarded headers here like any <code>proxy_pass</code> Nginx location,  but unlike the case with <code>nchan_authorize_request</code>, Nchan-specific variables are not available.</p> <p>Now, your application must be set up to handle the request to <code>/subscriber_x_accel_redirect</code>. You should make sure the client is properly authenticated (maybe using a session cookie), and generate an associated channel id. If authentication fails, respond with a normal <code>403 Forbidden</code> response. You can also pass extra information about the failure in the response body and headers.</p> <p>If your application successfully authenticates the subscriber request, you now need to instruct Nginx to issue an internal redirect to <code>/sub/internal/my_channel_id</code>. This is accomplished by responding with an empty <code>200 OK</code> response that includes two headers: - <code>X-Accel-Redirect: /sub/internal/my_channel_id</code> - <code>X-Accel-Buffering: no</code></p> <p>In the presence of these headers, Nginx will not forward your app's response to the client, and instead will internally redirect to <code>/sub/internal/my_channel_id</code>.  This will behave as if the client had requested the subscriber endpoint location directly.</p> <p>Thus using X-Accel-Redirect it is possible to both authenticate all subscribers and keep channel IDs completely hidden from subscribers.</p> <p>This method is especially useful for EventSource and Websocket subscribers. Long-Polling subscribers will need to be re-authenticated for every new message, which may flood your application with too many authentication requests.</p>"},{"location":"modules/nchan/#revoking-channel-authorization","title":"Revoking Channel Authorization","text":"<p>In some cases, you may want to revoke a particular subscriber's authorization for a given channel (e.g., if the user's permissions are changed). If the channel is unique to the subscriber, this is simply accomplished by deleting the channel. The same can be achieved for shared channels by subscribing each subscriber to both the shared channel and a subscriber-specific channel via a multiplexed connection. Deleting the subscriber-specific channel will terminate the subscriber''s connection, thereby also terminating their subscription to the shared channel. Consider the following configuration:</p> <pre><code>location ~ /sub/(\\w+) {\n  nchan_subscriber;\n  nchan_channel_id shared_$1 user_$arg_userid;\n  nchan_authorize_request /authorize;\n}\n\nlocation /pub/user {\n  nchan_publisher;\n  nchan_channel_id user_$arg_userid;\n}\n</code></pre> <p>A request to <code>/sub/foo?userid=1234</code> will subscribe to channels \"shared_foo\" and \"user_1234\" via a multiplexed connection. If you later send a <code>DELETE</code> request to <code>/pub/user?userid=1234</code>, this subscriber will be disconnected and therefore unsubscribed from both \"user_1234\" and \"shared_foo\".</p>"},{"location":"modules/nchan/#variables","title":"Variables","text":"<p>Nchan makes several variables usabled in the config file:</p> <ul> <li> <p><code>$nchan_channel_id</code>   The channel id extracted from a publisher or subscriber location request. For multiplexed locations, this is the first channel id in the list.</p> </li> <li> <p><code>$nchan_channel_id1</code>, <code>$nchan_channel_id2</code>, <code>$nchan_channel_id3</code>, <code>$nchan_channel_id4</code>   As above, but for the nth channel id in multiplexed channels.</p> </li> <li> <p><code>$nchan_subscriber_type</code>   For subscriber locations, this variable is set to the subscriber type (websocket, longpoll, etc.).</p> </li> <li> <p><code>$nchan_channel_subscriber_last_seen</code>   For publisher locations, this variable is set to the timestamp for the last connected subscriber.</p> </li> <li> <p><code>$nchan_channel_subscriber_count</code>   For publisher locations, this variable is set to the number of subscribers in the published channel.</p> </li> <li> <p><code>$nchan_channel_message_count</code>   For publisher locations, this variable is set to the number of messages buffered in the published channel.</p> </li> <li> <p><code>$nchan_publisher_type</code>   For publisher locations, this variable is set to the subscriber type (http or websocket).</p> </li> <li> <p><code>$nchan_prev_message_id</code>, <code>$nchan_message_id</code>   The current and previous (if applicable) message id for publisher request or subscriber response.</p> </li> <li> <p><code>$nchan_channel_event</code>   For channel events, this is the event name. Useful when configuring <code>nchan_channel_event_string</code>.</p> </li> <li> <p><code>$nchan_version</code>   Current Nchan version. Available since 1.1.5.</p> </li> </ul> <p>Additionally, <code>nchan_stub_status</code> data is also exposed as variables. These are available only when <code>nchan_stub_status</code> is enabled on at least one location:</p> <ul> <li><code>$nchan_stub_status_total_published_messages</code> </li> <li><code>$nchan_stub_status_stored_messages</code> </li> <li><code>$nchan_stub_status_shared_memory_used</code> </li> <li><code>$nchan_stub_status_channels</code> </li> <li><code>$nchan_stub_status_subscribers</code> </li> <li><code>$nchan_stub_status_redis_pending_commands</code> </li> <li><code>$nchan_stub_status_redis_connected_servers</code> </li> <li><code>$nchan_stub_status_redis_unhealthy_upstreams</code> </li> <li><code>$nchan_stub_status_total_ipc_alerts_received</code> </li> <li><code>$nchan_stub_status_ipc_queued_alerts</code> </li> <li><code>$nchan_stub_status_total_ipc_send_delay</code> </li> <li><code>$nchan_stub_status_total_ipc_receive_delay</code> </li> </ul>"},{"location":"modules/nchan/#configuration-directives","title":"Configuration Directives","text":"<ul> <li> <p>nchan_channel_id   arguments: 1 - 7   default: <code>(none)</code>   context: server, location, if  </p> <p>Channel id for a publisher or subscriber location. Can have up to 4 values to subscribe to up to 4 channels.   more details </p> </li> <li> <p>nchan_channel_id_split_delimiter   arguments: 1   default: <code>(none)</code>   context: server, location, if  </p> <p>Split the channel id into several ids for multiplexing using the delimiter string provided.   more details </p> </li> <li> <p>nchan_deflate_message_for_websocket <code>[ on | off ]</code>   arguments: 1   default: <code>off</code>   context: server, location  </p> <p>Store a compressed (deflated) copy of the message along with the original to be sent to websocket clients supporting the permessage-deflate protocol extension    </p> </li> <li> <p>nchan_eventsource_event   arguments: 1   default: <code>(none)</code>   context: server, location, if  </p> <p>Set the EventSource <code>event:</code> line to this value. When used in a publisher location, overrides the published message's <code>X-EventSource-Event</code> header and associates the message with the given value. When used in a subscriber location, overrides all messages' associated <code>event:</code> string with the given value.    </p> </li> <li> <p>nchan_eventsource_ping_comment   arguments: 1   default: <code>(empty)</code>   context: server, location, if  </p> <p>Set the EventSource comment <code>: ...</code> line for periodic pings from server to client. Newlines are not allowed. If empty, no comment is sent with the ping.    </p> </li> <li> <p>nchan_eventsource_ping_data   arguments: 1   default: <code>(empty)</code>   context: server, location, if  </p> <p>Set the EventSource <code>data:</code> line for periodic pings from server to client. Newlines are not allowed. If empty, no data is sent with the ping.    </p> </li> <li> <p>nchan_eventsource_ping_event   arguments: 1   default: <code>ping</code>   context: server, location, if  </p> <p>Set the EventSource <code>event:</code> line for periodic pings from server to client. Newlines are not allowed. If empty, no event type is sent with the ping.    </p> </li> <li> <p>nchan_eventsource_ping_interval <code>&lt;number&gt; (seconds)</code>   arguments: 1   default: <code>0 (none)</code>   context: server, location, if  </p> <p>Interval for sending ping messages to EventSource subscribers. Disabled by default.    </p> </li> <li> <p>nchan_longpoll_multipart_response <code>[ off | on | raw ]</code>   arguments: 1   default: <code>off</code>   context: server, location, if  </p> <p>when set to 'on', enable sending multiple messages in a single longpoll response, separated using the multipart/mixed content-type scheme. If there is only one available message in response to a long-poll request, it is sent unmodified. This is useful for high-latency long-polling connections as a way to minimize round-trips to the server. When set to 'raw', sends multiple messages using the http-raw-stream message separator.    </p> </li> <li> <p>nchan_permessage_deflate_compression_level <code>[ 0-9 ]</code>   arguments: 1   default: <code>6</code>   context: http  </p> <p>Compression level for the <code>deflate</code> algorithm used in websocket's permessage-deflate extension. 0: no compression, 1: fastest, worst, 9: slowest, best    </p> </li> <li> <p>nchan_permessage_deflate_compression_memlevel <code>[ 1-9 ]</code>   arguments: 1   default: <code>8</code>   context: http  </p> <p>Memory level for the <code>deflate</code> algorithm used in websocket's permessage-deflate extension. How much memory should be allocated for the internal compression state. 1 - minimum memory, slow and reduces compression ratio; 9 - maximum memory for optimal speed    </p> </li> <li> <p>nchan_permessage_deflate_compression_strategy <code>[ default | filtered | huffman-only | rle | fixed ]</code>   arguments: 1   default: <code>default</code>   context: http  </p> <p>Compression strategy for the <code>deflate</code> algorithm used in websocket's permessage-deflate extension. Use 'default' for normal data, For details see zlib's section on copression strategies </p> </li> <li> <p>nchan_permessage_deflate_compression_window <code>[ 9-15 ]</code>   arguments: 1   default: <code>10</code>   context: http  </p> <p>Compression window for the <code>deflate</code> algorithm used in websocket's permessage-deflate extension. The base two logarithm of the window size (the size of the history buffer). The bigger the window, the better the compression, but the more memory used by the compressor.    </p> </li> <li> <p>nchan_publisher <code>[ http | websocket ]</code>   arguments: 0 - 2   default: <code>http websocket</code>   context: server, location, if   legacy name: push_publisher  </p> <p>Defines a server or location as a publisher endpoint. Requests to a publisher location are treated as messages to be sent to subscribers. See the protocol documentation for a detailed description.   more details </p> </li> <li> <p>nchan_publisher_channel_id   arguments: 1 - 7   default: <code>(none)</code>   context: server, location, if  </p> <p>Channel id for publisher location.    </p> </li> <li> <p>nchan_publisher_upstream_request <code>&lt;url&gt;</code>   arguments: 1   context: server, location, if  </p> <p>Send POST request to internal location (which may proxy to an upstream server) with published message in the request body. Useful for bridging websocket publishers with HTTP applications, or for transforming message via upstream application before publishing to a channel.   The upstream response code determines how publishing will proceed. A <code>200 OK</code> will publish the message from the upstream response's body. A <code>304 Not Modified</code> will publish the message as it was received from the publisher. A <code>204 No Content</code> will result in the message not being published.   more details </p> </li> <li> <p>nchan_pubsub <code>[ http | websocket | eventsource | longpoll | intervalpoll | chunked | multipart-mixed | http-raw-stream ]</code>   arguments: 0 - 6   default: <code>http websocket eventsource longpoll chunked multipart-mixed</code>   context: server, location, if  </p> <p>Defines a server or location as a pubsub endpoint. For long-polling, GETs subscribe. and POSTs publish. For Websockets, publishing data on a connection does not yield a channel metadata response. Without additional configuration, this turns a location into an echo server.   more details </p> </li> <li> <p>nchan_subscribe_request <code>&lt;url&gt;</code>   arguments: 1   context: server, location, if  </p> <p>Send GET request to internal location (which may proxy to an upstream server) after subscribing. Disabled for longpoll and interval-polling subscribers.   more details </p> </li> <li> <p>nchan_subscriber <code>[ websocket | eventsource | longpoll | intervalpoll | chunked | multipart-mixed | http-raw-stream ]</code>   arguments: 0 - 5   default: <code>websocket eventsource longpoll chunked multipart-mixed</code>   context: server, location, if   legacy name: push_subscriber  </p> <p>Defines a server or location as a channel subscriber endpoint. This location represents a subscriber's interface to a channel's message queue. The queue is traversed automatically, starting at the position defined by the <code>nchan_subscriber_first_message</code> setting.    The value is a list of permitted subscriber types.   more details </p> </li> <li> <p>nchan_subscriber_channel_id   arguments: 1 - 7   default: <code>(none)</code>   context: server, location, if  </p> <p>Channel id for subscriber location. Can have up to 4 values to subscribe to up to 4 channels.    </p> </li> <li> <p>nchan_subscriber_compound_etag_message_id   arguments: 1   default: <code>off</code>   context: server, location, if  </p> <p>Override the default behavior of using both <code>Last-Modified</code> and <code>Etag</code> headers for the message id.   Enabling this option packs the entire message id into the <code>Etag</code> header, and discards <code>Last-Modified</code> and <code>If-Modified-Since</code> headers.   more details </p> </li> <li> <p>nchan_subscriber_first_message <code>[ oldest | newest | &lt;number&gt; ]</code>   arguments: 1   default: <code>oldest</code>   context: server, location, if  </p> <p>Controls the first message received by a new subscriber. 'oldest' starts at the oldest available message in a channel's message queue, 'newest' waits until a message arrives. If a number <code>n</code> is specified, starts at <code>n</code>th message from the oldest. (<code>-n</code> starts at <code>n</code>th from now). 0 is equivalent to 'newest'.    </p> </li> <li> <p>nchan_subscriber_http_raw_stream_separator <code>&lt;string&gt;</code>   arguments: 1   default: <code>\\n</code>   context: server, location, if  </p> <p>Message separator string for the http-raw-stream subscriber. Automatically terminated with a newline character if not explicitly set to an empty string.    </p> </li> <li> <p>nchan_subscriber_info   arguments: 0   context: location  </p> <p>A subscriber location for debugging the state of subscribers on a given channel. The subscribers of the channel specified by <code>nchan_channel_id</code> evaluate <code>nchan_subscriber_info_string</code> and send it back to the requested on this location. This is useful to see where subscribers are in an Nchan cluster, as well as debugging subscriber connection issues.    </p> </li> <li> <p>nchan_subscriber_info_string   arguments: 1   default: <code>$nchan_subscriber_type $remote_addr:$remote_port $http_user_agent $server_name $request_uri $pid</code>   context: server, location  </p> <p>this string is evaluated by each subscriber on a given channel and sent to the requester of a <code>nchan_subscriber_info</code> location    </p> </li> <li> <p>nchan_subscriber_last_message_id   arguments: 1 - 5   default: <code>$http_last_event_id $arg_last_event_id</code>   context: server, location, if  </p> <p>If <code>If-Modified-Since</code> and <code>If-None-Match</code> headers are absent, set the message id to the first non-empty of these values. Used primarily as a workaround for the inability to set the first <code>Last-Message-Id</code> of a web browser's EventSource object.     </p> </li> <li> <p>nchan_subscriber_message_id_custom_etag_header   arguments: 1   default: <code>(none)</code>   context: server, location, if  </p> <p>Use a custom header instead of the Etag header for message ID in subscriber responses. This setting is a hack, useful when behind a caching proxy such as Cloudflare that under some conditions (like using gzip encoding) swallow the Etag header.    </p> </li> <li> <p>nchan_subscriber_timeout <code>&lt;number&gt; (seconds)</code>   arguments: 1   default: <code>0 (none)</code>   context: http, server, location, if   legacy name: push_subscriber_timeout  </p> <p>Maximum time a subscriber may wait for a message before being disconnected. If you don't want a subscriber's connection to timeout, set this to 0. When possible, the subscriber will get a response with a <code>408 Request Timeout</code> status; otherwise the subscriber will simply be disconnected.    </p> </li> <li> <p>nchan_unsubscribe_request <code>&lt;url&gt;</code>   arguments: 1   context: server, location, if  </p> <p>Send GET request to internal location (which may proxy to an upstream server) after unsubscribing. Disabled for longpoll and interval-polling subscribers.   more details </p> </li> <li> <p>nchan_websocket_client_heartbeat <code>&lt;heartbeat_in&gt; &lt;heartbeat_out&gt;</code>   arguments: 2   default: <code>none (disabled)</code>   context: server, location, if  </p> <p>Most browser Websocket clients do not allow manually sending PINGs to the server. To overcome this limitation, this setting can be used to set up a PING/PONG message/response connection heartbeat. When the client sends the server message heartbeat_in (PING), the server automatically responds with heartbeat_out (PONG).    </p> </li> <li> <p>nchan_websocket_ping_interval <code>&lt;number&gt; (seconds)</code>   arguments: 1   default: <code>0 (none)</code>   context: server, location, if  </p> <p>Interval for sending websocket ping frames. Disabled by default.    </p> </li> <li> <p>nchan_access_control_allow_credentials   arguments: 1   default: <code>on</code>   context: http, server, location, if  </p> <p>When enabled, sets the Cross-Origin Resource Sharing (CORS) <code>Access-Control-Allow-Credentials</code> header to <code>true</code>.    </p> </li> <li> <p>nchan_access_control_allow_origin <code>&lt;string&gt;</code>   arguments: 1   default: <code>$http_origin</code>   context: http, server, location, if  </p> <p>Set the Cross-Origin Resource Sharing (CORS) <code>Access-Control-Allow-Origin</code> header to this value. If the incoming request's <code>Origin</code> header does not match this value, respond with a <code>403 Forbidden</code>. Multiple origins can be provided in a single argument separated with a space.    </p> </li> <li> <p>nchan_authorize_request <code>&lt;url&gt;</code>   arguments: 1   context: server, location, if  </p> <p>Send GET request to internal location (which may proxy to an upstream server) for authorization of a publisher or subscriber request. A 200 response authorizes the request, a 403 response forbids it.   more details </p> </li> <li> <p>nchan_channel_group <code>&lt;string&gt;</code>   arguments: 1   default: <code>(none)</code>   context: server, location, if   legacy name: push_channel_group  </p> <p>The accounting and security group a channel belongs to. Works like a prefix string to the channel id. Can be set with nginx variables.    </p> </li> <li> <p>nchan_channel_group_accounting   arguments: 1   default: <code>off</code>   context: server, location  </p> <p>Enable tracking channel, subscriber, and message information on a per-channel-group basis. Can be used to place upper limits on channel groups.    </p> </li> <li> <p>nchan_group_location <code>[ get | set | delete | off ]</code>   arguments: 0 - 3   default: <code>get set delete</code>   context: location  </p> <p>Group information and configuration location. GET request for group info, POST to set limits, DELETE to delete all channels in group.    </p> </li> <li> <p>nchan_group_max_channels <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: location  </p> <p>Maximum number of channels allowed in the group.    </p> </li> <li> <p>nchan_group_max_messages <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: location  </p> <p>Maximum number of messages allowed for all the channels in the group.    </p> </li> <li> <p>nchan_group_max_messages_disk <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: location  </p> <p>Maximum amount of disk space allowed for the messages of all the channels in the group.    </p> </li> <li> <p>nchan_group_max_messages_memory <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: location  </p> <p>Maximum amount of shared memory allowed for the messages of all the channels in the group.    </p> </li> <li> <p>nchan_group_max_subscribers <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: location  </p> <p>Maximum number of subscribers allowed for the messages of all the channels in the group.    </p> </li> <li> <p>nchan_max_channel_id_length <code>&lt;number&gt;</code>   arguments: 1   default: <code>1024</code>   context: http, server, location   legacy name: push_max_channel_id_length  </p> <p>Maximum permissible channel id length (number of characters). This settings applies to ids before they may be split by the <code>nchan_channel_id_split_delimiter</code> Requests with a channel id that is too long will receive a <code>403 Forbidden</code> response.    </p> </li> <li> <p>nchan_max_channel_subscribers <code>&lt;number&gt;</code>   arguments: 1   default: <code>0 (unlimited)</code>   context: http, server, location   legacy name: push_max_channel_subscribers  </p> <p>Maximum concurrent subscribers to the channel on this Nchan server. Does not include subscribers on other Nchan instances when using a shared Redis server.    </p> </li> <li> <p>nchan_subscribe_existing_channels_only <code>[ on | off ]</code>   arguments: 1   default: <code>off</code>   context: http, server, location   legacy name: push_authorized_channels_only  </p> <p>Whether or not a subscriber may create a channel by sending a request to a subscriber location. If set to on, a publisher must send a POST or PUT request before a subscriber can request messages on the channel. Otherwise, all subscriber requests to nonexistent channels will get a 403 Forbidden response.    </p> </li> <li> <p>nchan_message_buffer_length <code>[ &lt;number&gt; | &lt;variable&gt; ]</code>   arguments: 1   default: <code>10</code>   context: http, server, location   legacy names: push_max_message_buffer_length, push_message_buffer_length  </p> <p>Publisher configuration setting the maximum number of messages to store per channel. A channel's message buffer will retain a maximum of this many most recent messages. An Nginx variable can also be used to set the buffer length dynamically.    </p> </li> <li> <p>nchan_message_temp_path <code>&lt;path&gt;</code>   arguments: 1   default: <code>&lt;client_body_temp_path&gt;</code>   context: http  </p> <p>Large messages are stored in temporary files in the <code>client_body_temp_path</code> or the <code>nchan_message_temp_path</code> if the former is unavailable. Default is the built-in default <code>client_body_temp_path</code> </p> </li> <li> <p>nchan_message_timeout <code>[ &lt;time&gt; | &lt;variable&gt; ]</code>   arguments: 1   default: <code>1h</code>   context: http, server, location   legacy name: push_message_timeout  </p> <p>Publisher configuration setting the length of time a message may be queued before it is considered expired. If you do not want messages to expire, set this to 0. Note that messages always expire from oldest to newest, so an older message may prevent a newer one with a shorter timeout from expiring. An Nginx variable can also be used to set the timeout dynamically.    </p> </li> <li> <p>nchan_redis_accurate_subscriber_count   arguments: 1   default: <code>off</code>   context: upstream  </p> <p>When disabled, use fast but potentially inaccurate subscriber counts. These may become inaccurate if Nginx workers exit uncleanly or are terminated. When enabled, use a slightly slower but completely accurate subscriber count. Defaults to 'off' for legacy reasons, but will be enabled by default in the future.    </p> </li> <li> <p>nchan_redis_cluster_check_interval_backoff <code>&lt;floating point&gt; &gt;= 0, ratio of current delay</code>   arguments: 1   default: <code>2 (increase delay by 200% each try)</code>   context: upstream  </p> <p>Add an exponentially increasing delay to the Redis cluster check interval. <code>Delay[n] = (Delay[n-1] + jitter) * (nchan_redis_cluster_check_interval_backoff + 1)</code>.    </p> </li> <li> <p>nchan_redis_cluster_check_interval_jitter <code>&lt;floating point&gt; &gt;= 0, (0 to disable)</code>   arguments: 1   default: <code>0.2 (20% of interval value)</code>   context: upstream  </p> <p>Introduce random jitter to Redis cluster check interval, where the range is <code>\u00b1(cluster_check_interval * nchan_redis_cluster_check_interval_jitter) / 2</code>.    </p> </li> <li> <p>nchan_redis_cluster_check_interval_max <code>&lt;time&gt; (0 to disable)</code>   arguments: 1   default: <code>30s</code>   context: upstream  </p> <p>Maximum Redis cluster check interval after backoff and jitter.    </p> </li> <li> <p>nchan_redis_cluster_check_interval_min <code>&lt;time&gt;</code>   arguments: 1   default: <code>1s (0 to disable)</code>   context: upstream  </p> <p>When connected to a cluster, periodically check the cluster state and layout via a random master node.    </p> </li> <li> <p>nchan_redis_cluster_connect_timeout   arguments: 1   default: <code>15s</code>   context: upstream  </p> <p>Redis cluster connection timeout.    </p> </li> <li> <p>nchan_redis_cluster_max_failing_time   arguments: 1   default: <code>30s</code>   context: upstream  </p> <p>Maximum time a Redis cluster can be in a failing state before Nchan disconnects from it. During this time, Nchan will try to recover from a cluster or node failure without disconnecting the entire cluster.    </p> </li> <li> <p>nchan_redis_cluster_recovery_delay <code>&lt;time&gt;</code>   arguments: 1   default: <code>100ms</code>   context: upstream  </p> <p>After a cluster recovery failure, wait this long to try again.    </p> </li> <li> <p>nchan_redis_cluster_recovery_delay_backoff <code>&lt;floating point&gt; &gt;= 0, ratio of current delay</code>   arguments: 1   default: <code>0.5 (increase delay by 50% each try)</code>   context: upstream  </p> <p>Add an exponentially increasing delay to Redis cluster recovery retries. <code>Delay[n] = (Delay[n-1] + jitter) * (nchan_redis_cluster_recovery_delay_backoff + 1)</code>.    </p> </li> <li> <p>nchan_redis_cluster_recovery_delay_jitter <code>&lt;floating point&gt; &gt;= 0, (0 to disable)</code>   arguments: 1   default: <code>0.5 (50% of delay value)</code>   context: upstream  </p> <p>Introduce random jitter to Redis cluster recovery retry time, where the range is <code>\u00b1(recovery_delay * nchan_redis_cluster_recovery_delay_jitter) / 2</code>.    </p> </li> <li> <p>nchan_redis_cluster_recovery_delay_max <code>&lt;time&gt; (0 to disable)</code>   arguments: 1   default: <code>2s</code>   context: upstream  </p> <p>Maximum Redis cluster recovery delay after backoff and jitter.    </p> </li> <li> <p>nchan_redis_command_timeout <code>&lt;time&gt; (0 to leave unlimited)</code>   arguments: 1   default: <code>5s</code>   context: upstream  </p> <p>If a Redis server exceeds this time to produce a command reply, it is considered unhealthy and is disconnected.    </p> </li> <li> <p>nchan_redis_connect_timeout   arguments: 1   default: <code>10s</code>   context: upstream  </p> <p>Redis server connection timeout.    </p> </li> <li> <p>nchan_redis_discovered_ip_range_blacklist <code>&lt;CIDR range&gt;</code>   arguments: 1 - 7   context: upstream  </p> <p>do not attempt to connect to autodiscovered nodes with IPs in the specified ranges. Useful for blacklisting private network ranges for clusters and Redis slaves. NOTE that this blacklist applies only to autodiscovered nodes, and not ones specified in the upstream block    </p> </li> <li> <p>nchan_redis_idle_channel_cache_timeout <code>&lt;time&gt;</code>   arguments: 1   default: <code>30s</code>   context: http, server, location  </p> <p>A Redis-stored channel and its messages are removed from memory (local cache) after this timeout, provided there are no local subscribers.    </p> </li> <li> <p>nchan_redis_namespace <code>&lt;string&gt;</code>   arguments: 1   context: http, server, upstream, location  </p> <p>Prefix all Redis keys with this string. All Nchan-related keys in redis will be of the form \"nchan_redis_namespace:*\" . Default is empty.    </p> </li> <li> <p>nchan_redis_nostore_fastpublish <code>[ on | off ]</code>   arguments: 1   default: <code>off</code>   context: http, server, upstream  </p> <p>Increases publishing capacity by 2-3x for Redis nostore mode at the expense of inaccurate subscriber counts in the publisher response.    </p> </li> <li> <p>nchan_redis_optimize_target <code>[ cpu | bandwidth ]</code>   arguments: 1   default: <code>bandwidth</code>   context: upstream  </p> <p>This tweaks whether effect replication is enabled. This setting is obsolete, as effect replication is now always enabled to support other features    </p> </li> <li> <p>nchan_redis_pass <code>&lt;upstream-name&gt;</code>   arguments: 1   context: http, server, location  </p> <p>Use an upstream config block for Redis servers.   more details </p> </li> <li> <p>nchan_redis_password   arguments: 1   default: <code>&lt;none&gt;</code>   context: upstream  </p> <p>Set Redis password for AUTH command. All servers in the upstream block will use this password unless a different password is specified by a server URL.    </p> </li> <li> <p>nchan_redis_ping_interval   arguments: 1   default: <code>4m</code>   context: http, server, upstream, location  </p> <p>Send a keepalive command to redis to keep the Nchan redis clients from disconnecting. Set to 0 to disable.    </p> </li> <li> <p>nchan_redis_reconnect_delay <code>&lt;time&gt;</code>   arguments: 1   default: <code>500ms</code>   context: upstream  </p> <p>After a connection failure, wait this long before trying to reconnect to Redis.    </p> </li> <li> <p>nchan_redis_reconnect_delay_backoff <code>&lt;floating point&gt; &gt;= 0 (0 to disable)</code>   arguments: 1   default: <code>0.5 (increase delay by 50% each try)</code>   context: upstream  </p> <p>Add an exponentially increasing delay to Redis connection retries. <code>Delay[n] = (Delay[n-1] + jitter) * (nchan_redis_reconnect_delay_backoff + 1)</code>.    </p> </li> <li> <p>nchan_redis_reconnect_delay_jitter <code>&lt;floating point&gt; &gt;= 0 (0 to disable)</code>   arguments: 1   default: <code>0.1 (10% of delay value)</code>   context: upstream  </p> <p>Introduce random jitter to Redis reconnection time, where the range is <code>\u00b1(reconnect_delay * nchan_redis_reconnect_delay_jitter) / 2</code>.    </p> </li> <li> <p>nchan_redis_reconnect_delay_max <code>&lt;time&gt; (0 to disable)</code>   arguments: 1   default: <code>10s</code>   context: upstream  </p> <p>Maximum Redis reconnection delay after backoff and jitter.    </p> </li> <li> <p>nchan_redis_retry_commands   arguments: 1   default: <code>on</code>   context: upstream  </p> <p>Allow Nchan to retry some Redis commands on keyslot errors and cluster unavailability. Queuing up a lot of commands while the cluster is unavailable may lead to excessive memory use, but it can also defer commands during transient failures.    </p> </li> <li> <p>nchan_redis_retry_commands_max_wait <code>&lt;time&gt; (0 to leave unlimited)</code>   arguments: 1   default: <code>500ms</code>   context: upstream  </p> <p>When <code>nchan_redis_retry_commands</code> is on, the maximum time a command will stayed queued to be retried.    </p> </li> <li> <p>nchan_redis_server <code>&lt;redis-url&gt; &lt;optional-forced-role&gt;</code>   arguments: 1 - 2   default: <code>&lt;redis-url&gt;</code>   context: upstream  </p> <p>Used in upstream { } blocks to set redis servers. Redis url is in the form 'redis://:password@hostname:6379/0'. Shorthands 'host:port' or 'host' are permitted. A role may optionally be provided as well to force a server to be treated as 'master' or 'slave'.       uri:     </p> </li> <li> <p>nchan_redis_ssl <code>[ on | off ]</code>   arguments: 1   default: <code>off</code>   context: upstream  </p> <p>Enables SSL/TLS for all connections to Redis servers in this upstream block. When enabled, no unsecured connections are permitted    </p> </li> <li> <p>nchan_redis_ssl_ciphers   arguments: 1   default: <code>&lt;system default&gt;</code>   context: upstream  </p> <p>Acceptable ciphers when using TLS for Redis connections    </p> </li> <li> <p>nchan_redis_ssl_client_certificate   arguments: 1   context: upstream  </p> <p>Path to client certificate when using TLS for Redis connections    </p> </li> <li> <p>nchan_redis_ssl_client_certificate_key   arguments: 1   context: upstream  </p> <p>Path to client certificate key when using TLS for Redis connections    </p> </li> <li> <p>nchan_redis_ssl_server_name   arguments: 1   context: upstream  </p> <p>Server name to verify (CN) when using TLS for Redis connections    </p> </li> <li> <p>nchan_redis_ssl_trusted_certificate   arguments: 1   context: upstream  </p> <p>Trusted certificate (CA) when using TLS for Redis connections    </p> </li> <li> <p>nchan_redis_ssl_trusted_certificate_path   arguments: 1   default: <code>&lt;system default&gt;</code>   context: upstream  </p> <p>Trusted certificate (CA) when using TLS for Redis connections. Defaults to the system's SSL cert path unless nchan_redis_ssl_trusted_certificate is set    </p> </li> <li> <p>nchan_redis_ssl_verify_certificate <code>[ on | off ]</code>   arguments: 1   default: <code>on</code>   context: upstream  </p> <p>Should the server certificate be verified when using TLS for Redis connections? Useful to disable when testing with a self-signed server certificate.    </p> </li> <li> <p>nchan_redis_storage_mode <code>[ distributed | backup | nostore ]</code>   arguments: 1   default: <code>distributed</code>   context: http, server, upstream, location  </p> <p>The mode of operation of the Redis server. In <code>distributed</code> mode, messages are published directly to Redis, and retrieved in real-time. Any number of Nchan servers in distributed mode can share the Redis server (or cluster). Useful for horizontal scalability, but suffers the latency penalty of all message publishing going through Redis first.  </p> <p>In <code>backup</code> mode, messages are published locally first, then later forwarded to Redis, and are retrieved only upon channel initialization. Only one Nchan server should use a Redis server (or cluster) in this mode. Useful for data persistence without sacrificing response times to the latency of a round-trip to Redis.  </p> <p>In <code>nostore</code> mode, messages are published as in <code>distributed</code> mode, but are not stored. Thus Redis is used to broadcast messages to many Nchan instances with no delivery guarantees during connection failure, and only local in-memory storage. This means that there are also no message delivery guarantees for subscribers switching from one Nchan instance to another connected to the same Redis server or cluster. Nostore mode increases Redis publishing capacity by an order of magnitude.    </p> </li> <li> <p>nchan_redis_subscribe_weights <code>master=&lt;integer&gt; slave=&lt;integer&gt;</code>   arguments: 1 - 2   default: <code>master=1 slave=1</code>   context: upstream  </p> <p>Determines how subscriptions to Redis PUBSUB channels are distributed between master and slave nodes. The higher the number, the more likely that each node of that type will be chosen for each new channel. The weights for slave nodes are cumulative, so an equal 1:1 master:slave weight ratio with two slaves would have a 1/3 chance of picking a master, and 2/3 chance of picking one of the slaves. The weight must be a non-negative integer.    </p> </li> <li> <p>nchan_redis_upstream_stats <code>&lt;upstream_name&gt;</code>   arguments: 1   default: <code>(none)</code>   context: server, location  </p> <p>Defines a location as redis statistics endpoint. GET requests to this location produce a JSON response with detailed listings of total Redis command times and number of calls, broken down by node and command type. Useful for making graphs about Redis performance. Can be set with nginx variables.    </p> </li> <li> <p>nchan_redis_upstream_stats_disconnected_timeout   arguments: 1   default: <code>5m</code>   context: upstream  </p> <p>Keep stats for disconnected nodes around for this long. Useful for tracking stats for nodes that have intermittent connectivity issues.    </p> </li> <li> <p>nchan_redis_upstream_stats_enabled <code>[ on | off ]</code>   arguments: 1   default: <code>&lt;on&gt; if at least 1 redis stats location is configured, otherwise &lt;off&gt;</code>   context: upstream  </p> <p>Gather Redis node command timings for this upstream    </p> </li> <li> <p>nchan_redis_url <code>&lt;redis-url&gt;</code>   arguments: 1   default: <code>127.0.0.1:6379</code>   context: http, server, location  </p> <p>Use of this command is discouraged in favor of upstreams blocks with <code>nchan_redis_server</code>. The path to a redis server, of the form 'redis://:password@hostname:6379/0'. Shorthand of the form 'host:port' or just 'host' is also accepted.   more details </p> </li> <li> <p>nchan_redis_username   arguments: 1   default: <code>&lt;none&gt;</code>   context: upstream  </p> <p>Set Redis username for AUTH command (available when using ACLs on the Redis server). All servers in the upstream block will use this username unless a different username is specified by a server URL.    </p> </li> <li> <p>nchan_shared_memory_size <code>&lt;size&gt;</code>   arguments: 1   default: <code>128M</code>   context: http   legacy names: push_max_reserved_memory, nchan_max_reserved_memory  </p> <p>Shared memory slab pre-allocated for Nchan. Used for channel statistics, message storage, and interprocess communication.   more details </p> </li> <li> <p>nchan_store_messages <code>[ on | off ]</code>   arguments: 1   default: <code>on</code>   context: http, server, location, if   legacy name: push_store_messages  </p> <p>Publisher configuration. \"<code>off</code>\" is equivalent to setting <code>nchan_message_buffer_length 0</code>, which disables the buffering of old messages. Using this setting is not recommended when publishing very quickly, as it may result in missed messages.    </p> </li> <li> <p>nchan_use_redis <code>[ on | off ]</code>   arguments: 1   default: <code>off</code>   context: http, server, location  </p> <p>Use of this command is discouraged in favor of (<code>nchan_redis_pass</code>)[#nchan_redis_pass]. Use Redis for message storage at this location.   more details </p> </li> <li> <p>nchan_channel_event_string <code>&lt;string&gt;</code>   arguments: 1   default: <code>\"$nchan_channel_event $nchan_channel_id\"</code>   context: server, location, if  </p> <p>Contents of channel event message    </p> </li> <li> <p>nchan_channel_events_channel_id   arguments: 1   context: server, location, if  </p> <p>Channel id where <code>nchan_channel_id</code>'s events should be sent. Events like subscriber enqueue/dequeue, publishing messages, etc. Useful for application debugging. The channel event message is configurable via nchan_channel_event_string. The channel group for events is hardcoded to 'meta'.   more details </p> </li> <li> <p>nchan_stub_status   arguments: 0   context: location  </p> <p>Similar to Nginx's stub_status directive, requests to an <code>nchan_stub_status</code> location get a response with some vital Nchan statistics. This data does not account for information from other Nchan instances, and monitors only local connections, published messages, etc.   more details </p> </li> <li> <p>nchan_channel_timeout   arguments: 1   context: http, server, location   legacy name: push_channel_timeout  </p> <p>Amount of time an empty channel hangs around. Don't mess with this setting unless you know what you are doing!    </p> </li> <li> <p>nchan_storage_engine <code>[ memory | redis ]</code>   arguments: 1   default: <code>memory</code>   context: http, server, location  </p> <p>Development directive to completely replace default storage engine. Don't use unless you are an Nchan developer.    </p> </li> </ul>"},{"location":"modules/nchan/#contribute","title":"Contribute","text":"<p>Please support this project with a donation to keep me warm through the winter. I accept bitcoin at 15dLBzRS4HLRwCCVjx4emYkxXcyAPmGxM3 . Other donation methods can be found at https://nchan.io</p>"},{"location":"modules/nchan/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-nchan.</p>"},{"location":"modules/ndk/","title":"ndk: Nginx Development Kit","text":""},{"location":"modules/ndk/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ndk\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ndk\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ndk_http_module.so;\n</code></pre> <p>This document describes nginx-module-ndk v0.3.4  released on Feb 20 2025.</p> <p>Nginx Development Kit (NDK)</p>"},{"location":"modules/ndk/#synopsis","title":"Synopsis","text":"<p>The NDK is an Nginx module that is designed to extend the core functionality of the excellent Nginx webserver in a way that can be used as a basis of other Nginx modules.</p> <p>It has functions and macros to deal with generic tasks that don't currently have generic code as part of the core distribution.  The NDK itself adds few features that are seen from a user's point of view - it's just designed to help reduce the code that Nginx module developers need to write.</p> <p>Nginx module developers wishing to use any of the features in the NDK should specify that the NDK is a dependency of their module, and that users will need to compile it as well when they compile their own modules.  They will also need to declare in their own modules which features of the NDK they wish to use (explained below).</p> <p>If you are not an Nginx module developer, then the only useful part of this project will be the 'usage for users' section below.</p>"},{"location":"modules/ndk/#status","title":"Status","text":"<p>The NDK is now considered to be stable. It is already being used in quite a few third party modules (see list below).</p>"},{"location":"modules/ndk/#features","title":"Features","text":"<ul> <li>additional conf_set functions for regexes, complex/script values, paths...</li> <li>macros to simplify tasks like checking for NULL values when doing ngx_array_push</li> <li>patches to the main source code</li> <li>ngx_auto_lib_core generic external library handler is included (see separate readme)</li> </ul>"},{"location":"modules/ndk/#design","title":"Design","text":""},{"location":"modules/ndk/#modular","title":"modular","text":"<p>The kit itself is designed in a modular way, so that only the required code is compiled. It's possible to add just a single NDK module, a few or all of them.</p>"},{"location":"modules/ndk/#auto-generated-easily-extensible","title":"auto-generated &amp; easily extensible","text":"<p>Many of the macros available in the NDK are auto-generated from simple configuration files.  This makes creating similar macros for your own code very simple - it's usually just the case of adding an extra line to a config file and re-running the build script.</p>"},{"location":"modules/ndk/#usage-for-users","title":"Usage for users","text":"<p>If another Nginx module you wish to use specifies that the NDK is a dependency, you will need to do the following :</p> <ol> <li>download the source (https://github.com/simpl/ngx_devel_kit)</li> <li>unpack the source (tar -xzf $name)</li> <li>compile Nginx with the following extra option <code>--add-module=/path/to/ngx_devel_kit</code>.</li> </ol> <p>e.g.</p> <pre><code>./configure --add-module=/path/to/ngx_devel_kit \\\n            --add-module=/path/to/another/module\n</code></pre>"},{"location":"modules/ndk/#usage-for-developers","title":"Usage for developers","text":"<p>To use the NDK in your own module, you need to add the following:</p> <ol> <li>add this line to your module</li> </ol> <pre><code>#include    &lt;ndk.h&gt;\n</code></pre> <p>Note: since the NDK includes the following lines</p> <pre><code>#include    &lt;ngx_config.h&gt;\n#include    &lt;ngx_core.h&gt;\n#include    &lt;ngx_http.h&gt;\n</code></pre> <p>you can replace these with the single include above. 2. add the following line in the config file for your module:</p> <pre><code>have=NDK_[module_name]  . auto/have\n</code></pre> <p>for each NDK module that you wish to use (you need to include auto/have multiple times if you wish to use multiple NDK modules.</p> <p>Note: the old method of setting</p> <pre><code>CFLAGS=\"$CFLAGS -DNDK_[module_name]\"\n</code></pre> <p>is now deprecated. It will still work, but results in unnecessary lines being displayed when compiling Nginx.</p>"},{"location":"modules/ndk/#warning-using-ndk_all","title":"Warning: Using NDK_ALL","text":"<p>You can also set <code>NDK_ALL</code> to include all the NDK modules.  This is primarily as a convenience in the early stages of development of another module. However,</p> <p>DO NOT LEAVE <code>NDK_ALL</code> IN YOUR CONFIG FILE WHEN PUBLISHING</p> <p>Although the NDK is fairly small now, it could in time become a large repository of code that would, if using NDK_ALL, result in considerably more code being compiled than is necessary.</p>"},{"location":"modules/ndk/#modules-using-ndk","title":"Modules using NDK","text":"<p>The following 3rd-party modules make use of NDK.</p> <ul> <li>ngx_http_lua_module</li> <li>ngx_http_set_misc_module</li> <li>ngx_http_encrypted_session_module</li> <li>ngx_http_form_input_module</li> <li>ngx_http_iconv_module</li> <li>ngx_http_array_var_module</li> </ul> <p>If you would like to add your module to this list, please let us know.</p>"},{"location":"modules/ndk/#special-thanks","title":"Special Thanks","text":"<p>A special thanks goes to Yichun Zhang for helping to maintain this module.</p>"},{"location":"modules/ndk/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ndk.</p>"},{"location":"modules/njs/","title":"njs: NGINX njs dynamic modules","text":""},{"location":"modules/njs/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-njs\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-njs\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <p><pre><code>load_module modules/ngx_http_js_module.so;\n</code></pre> <pre><code>load_module modules/ngx_stream_js_module.so;\n</code></pre></p> <p>This document describes nginx-module-njs v0.9.4  released on Oct 28 2025.</p> <p> </p> <p></p>"},{"location":"modules/njs/#nginx-javascript","title":"NGINX JavaScript","text":"<p>NGINX JavaScript, also known as NJS, is a dynamic module for NGINX that enables the extension of built-in functionality using familiar JavaScript syntax. The NJS language is a subset of JavaScript, compliant with ES5 (ECMAScript 5.1 Strict Variant) with some ES6 (ECMAScript 6) and newer extensions. See compatibility for more details.</p>"},{"location":"modules/njs/#how-it-works","title":"How it works","text":"<p>NGINX JavaScript is provided as two dynamic modules for NGINX (ngx_http_js_module and ngx_stream_js_module) and can be added to any supported NGINX Open Source or NGINX Plus installation without recompilation. </p> <p>The NJS module allows NGINX administrators to: - Add complex access control and security checks before requests reach upstream servers - Manipulate response headers - Write flexible, asynchronous content handlers, filters, and more!</p> <p>See examples and our various projects developed with NJS:</p>"},{"location":"modules/njs/#httpsgithubcomnginxincnginx-openid-connect","title":"https://github.com/nginxinc/nginx-openid-connect","text":"<p>Extends NGINX Plus functionality to communicate directly with OIDC-compatible Identity Providers, authenticating users and authorizing content delivered by NGINX Plus.</p>"},{"location":"modules/njs/#httpsgithubcomnginxincnginx-saml","title":"https://github.com/nginxinc/nginx-saml","text":"<p>Reference implementation of NGINX Plus as a service provider for SAML authentication.</p>"},{"location":"modules/njs/#httpsgithubcomnginxincnjs-prometheus-module","title":"https://github.com/nginxinc/njs-prometheus-module","text":"<p>Exposes Prometheus metrics endpoint directly from NGINX Plus.</p> <p>[!TIP] NJS can also be used with the NGINX Unit application server. Learn more about NGINX Unit's Control API and how to define function calls with NJS.</p>"},{"location":"modules/njs/#downloading-and-installing","title":"Downloading and installing","text":"<p>Follow these steps to download and install precompiled NGINX and NGINX JavaScript Linux binaries. You may also choose to build the module locally from source code.</p>"},{"location":"modules/njs/#provisioning-the-nginx-package-repository","title":"Provisioning the NGINX package repository","text":"<p>Follow this guide to add the official NGINX package repository to your system and install NGINX Open Source. If you already have NGINX Open Source or NGINX Plus installed, skip the NGINX installation portion in the last step.</p>"},{"location":"modules/njs/#getting-started-with-nginx-javascript","title":"Getting started with NGINX JavaScript","text":"<p>Usage of NJS involves enabling the module, adding JavaScript files with defined functions, and invoking exported functions in NGINX configuration files.</p>"},{"location":"modules/njs/#verify-nginx-is-running","title":"Verify NGINX is running","text":"<p>NGINX JavaScript is a module for NGINX Open Source or NGINX Plus. If you haven't done so already, follow these steps to install NGINX Open Source or NGINX Plus. Once installed, ensure the NGINX instance is running and able to respond to HTTP requests.</p>"},{"location":"modules/njs/#starting-nginx","title":"Starting NGINX","text":"<p>Issue the following command to start NGINX:</p> <pre><code>sudo nginx\n</code></pre>"},{"location":"modules/njs/#verify-nginx-is-responding-to-http-requests","title":"Verify NGINX is responding to HTTP requests","text":"<pre><code>curl -I 127.0.0.1\n</code></pre> <p>You should see the following response: <pre><code>HTTP/1.1 200 OK\nServer: nginx/1.25.5\n</code></pre></p>"},{"location":"modules/njs/#enabling-the-nginx-javascript-modules","title":"Enabling the NGINX JavaScript modules","text":"<p>Once installed, either (or both) NJS module(s) must be included in the NGINX configuration file. On most systems, the NGINX configuration file is located at <code>/etc/nginx/nginx.conf</code> by default.</p>"},{"location":"modules/njs/#edit-the-nginx-configuration-file","title":"Edit the NGINX configuration file","text":"<pre><code>sudo vi /etc/nginx/nginx.conf\n</code></pre>"},{"location":"modules/njs/#enable-dynamic-loading-of-njs-modules","title":"Enable dynamic loading of NJS modules","text":"<p>Use the load_module directive in the top-level (\u201cmain\u201d) context to enable either (or both) module(s).</p> <pre><code>load_module modules/ngx_http_js_module.so;\nload_module modules/ngx_stream_js_module.so;\n</code></pre>"},{"location":"modules/njs/#basics-of-writing-js-script-files","title":"Basics of writing .js script files","text":"<p>NJS script files are typically named with a .js extension and placed in the <code>/etc/nginx/njs/</code> directory. They are usually comprised of functions that are then exported, making them available in NGINX configuration files.</p>"},{"location":"modules/njs/#reference-of-custom-objects-methods-and-properties","title":"Reference of custom objects, methods, and properties","text":"<p>NJS provides a collection of objects with associated methods and properties that are not part of ECMAScript definitions. See the complete reference to these objects and how they can be used to further extend and customize NGINX.</p>"},{"location":"modules/njs/#example-hello-world","title":"Example: Hello World","text":"<p>Here's a basic \"Hello World\" example.</p>"},{"location":"modules/njs/#examplejs","title":"example.js","text":"<p>The <code>hello</code> function in this file returns an HTTP 200 OK status response code along with the string \"Hello World!\", followed by a line feed. The function is then exported for use in an NGINX configuration file.</p> <p>Add this file to the <code>/etc/nginx/njs</code> directory:</p> <pre><code>function hello(r) {\n  r.return(200, \"Hello world!\\n\");\n}\n\nexport default {hello}\n</code></pre>"},{"location":"modules/njs/#nginxconf","title":"nginx.conf","text":"<p>We modify our NGINX configuration (<code>/etc/nginx/nginx.conf</code>) to import the JavaScript file and execute the function under specific circumstances.</p> <pre><code>## Load the ngx_http_js_module module\nload_module modules/ngx_http_js_module.so;\n\nevents {}\n\nhttp {\n  # Set the path to our njs JavaScript files\n  js_path \"/etc/nginx/njs/\";\n\n  # Import our JavaScript file into the variable \"main\"\n  js_import main from http/hello.js;\n\n  server {\n    listen 80;\n\n    location / {\n      # Execute the \"hello\" function defined in our JavaScript file on all HTTP requests\n      # and respond with the contents of our function.\n      js_content main.hello;\n    }\n  }\n}\n</code></pre> <p>For a full list of njs directives, see the ngx_http_js_module and ngx_stream_js_module module documentation pages.</p> <p>[!TIP] A more detailed version of this and other examples can be found in the official njs-examples repository.</p>"},{"location":"modules/njs/#the-njs-command-line-interface-cli","title":"The NJS command line interface (CLI)","text":"<p>NGINX JavaScript installs with a command line interface utility. The interface can be opened as an interactive shell or used to process JavaScript syntax from predefined files or standard input. Since the utility runs independently, NGINX-specific objects such as HTTP and Stream are not available within its runtime.</p>"},{"location":"modules/njs/#example-usage-of-the-interactive-cli","title":"Example usage of the interactive CLI","text":"<pre><code>$ njs\n&gt;&gt; globalThis\nglobal {\n  njs: njs {\n    version: '0.8.4'\n  },\n  global: [Circular],\n  process: process {\n    argv: ['/usr/bin/njs'],\n    env: {\n      PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n      HOSTNAME: 'f777c149d4f8',\n      TERM: 'xterm',\n      NGINX_VERSION: '1.25.5',\n      NJS_VERSION: '0.8.4',\n      PKG_RELEASE: '1~buster',\n      HOME: '/root'\n    }\n  },\n  console: {\n    log: [Function: native],\n    dump: [Function: native],\n    time: [Function: native],\n    timeEnd: [Function: native]\n  },\n  print: [Function: native]\n}\n&gt;&gt;\n</code></pre>"},{"location":"modules/njs/#example-usage-of-the-non-interactive-cli","title":"Example usage of the non-interactive CLI","text":"<pre><code>$ echo \"2**3\" | njs -q\n8\n</code></pre>"},{"location":"modules/njs/#cloning-the-nginx-javascript-github-repository","title":"Cloning the NGINX JavaScript GitHub repository","text":"<p>Using your preferred method, clone the NGINX JavaScript repository into your development directory. See Cloning a GitHub Repository for additional help.</p> <pre><code>https://github.com/nginx/njs.git\n</code></pre>"},{"location":"modules/njs/#configure-and-build","title":"Configure and build","text":"<p>Run the following commands from the root directory of your cloned repository:</p> <pre><code>./configure\n</code></pre> <p>Build NGINX JavaScript: <pre><code>make\n</code></pre></p> <p>The utility should now be available at <code>&lt;NJS_SRC_ROOT_DIR&gt;/build/njs</code>. See The NJS Command Line Interface (CLI) for information on usage.</p>"},{"location":"modules/njs/#cloning-the-nginx-github-repository","title":"Cloning the NGINX GitHub repository","text":"<p>Clone the NGINX source code repository in a directory outside of the previously cloned NJS source repository.</p> <pre><code>https://github.com/nginx/nginx.git\n</code></pre>"},{"location":"modules/njs/#nginx-javascript-technical-specifications","title":"NGINX JavaScript technical specifications","text":"<p>Technical specifications for NJS are identical to those of NGINX.</p>"},{"location":"modules/njs/#supported-distributions","title":"Supported distributions","text":"<p>See Tested Operating Systems and Platforms for a complete list of supported distributions. </p>"},{"location":"modules/njs/#supported-deployment-environments","title":"Supported deployment environments","text":"<ul> <li>Container</li> <li>Public cloud (AWS, Google Cloud Platform, Microsoft Azure)</li> <li>Virtual machine</li> </ul>"},{"location":"modules/njs/#supported-nginx-versions","title":"Supported NGINX versions","text":"<p>NGINX JavaScript is supported by all NGINX Open Source versions starting with nginx-1.14 and all NGINX Plus versions starting with NGINX Plus R15.</p>"},{"location":"modules/njs/#asking-questions-reporting-issues-and-contributing","title":"Asking questions, reporting issues, and contributing","text":"<p>We encourage you to engage with us. Please see the Contributing guide for information on how to ask questions, report issues and contribute code.</p>"},{"location":"modules/njs/#change-log","title":"Change log","text":"<p>See our release page to keep track of updates.</p>"},{"location":"modules/njs/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-njs.</p>"},{"location":"modules/ntlm/","title":"ntlm: NTLM NGINX Module","text":""},{"location":"modules/ntlm/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ntlm\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ntlm\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_upstream_ntlm_module.so;\n</code></pre> <p>This document describes nginx-module-ntlm v1.19.4  released on May 04 2024.</p> <p>The NTLM module allows proxying requests with NTLM Authentication. The upstream connection is bound to the client connection once the client sends a request with the \"Authorization\" header field value starting with \"Negotiate\" or \"NTLM\". Further client requests will be proxied through the same upstream connection, keeping the authentication context.</p>"},{"location":"modules/ntlm/#how-to-use","title":"How to use","text":"<p>Syntax:  ntlm [connections]; Default: ntlm 100; Context: upstream </p> <pre><code>upstream http_backend {\n    server 127.0.0.1:8080;\n\n    ntlm;\n}\n\nserver {\n    ...\n\n    location /http/ {\n        proxy_pass http://http_backend;\n        # next 2 settings are required for the keepalive to work properly\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n    }\n}\n</code></pre> <p>The connections parameter sets the maximum number of connections to the upstream servers that are preserved in the cache.</p> <p>Syntax:  ntlm_timeout timeout; Default: ntlm_timeout 60s; Context: upstream  </p> <p>Sets the timeout during which an idle connection to an upstream server will stay open.</p>"},{"location":"modules/ntlm/#tests","title":"Tests","text":"<p>In order to run the tests you need nodejs and perl installed on your system</p> <pre><code>## instal the test framework\ncpan Test::Nginx\n\n## set the path to your nginx location\nexport PATH=/opt/local/nginx/sbin:$PATH\n\nprove -r t\n</code></pre>"},{"location":"modules/ntlm/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ntlm.</p>"},{"location":"modules/otel/","title":"otel: NGINX OpenTelemetry dynamic module","text":""},{"location":"modules/otel/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-otel\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-otel\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_otel_module.so;\n</code></pre> <p>This document describes nginx-module-otel v0.1.2  released on Mar 15 2025.</p>"},{"location":"modules/otel/#what-is-opentelemetry","title":"What is OpenTelemetry","text":"<p>OpenTelemetry (OTel) is an observability framework for monitoring, tracing, troubleshooting, and optimizing applications. OTel enables the collection of telemetry data from a deployed application stack.</p>"},{"location":"modules/otel/#what-is-the-nginx-native-otel-module","title":"What is the NGINX Native OTel Module","text":"<p>The <code>ngx_otel_module</code> dynamic module enables NGINX Open Source or NGINX Plus to send telemetry data to an OTel collector. It provides support for W3C trace context propagation, OpenTelemetry Protocol (OTLP)/gRPC trace exports and offers several benefits over exiting OTel modules, including:</p>"},{"location":"modules/otel/#better-performance","title":"Better Performance","text":"<p>3rd-party OTel implementations reduce performance of request processing by as much as 50% when tracing is enabled. The NGINX Native module limits this impact to approximately 10-15%.</p>"},{"location":"modules/otel/#easy-provisioning","title":"Easy Provisioning","text":"<p>Setup and configuration can be done right in NGINX configuration files.</p>"},{"location":"modules/otel/#dynamic-variable-based-control","title":"Dynamic, Variable-Based Control","text":"<p>The ability to control trace parameters dynamically using cookies, tokens, and variables. Please see our Ratio-based Tracing example for more details.</p> <p>Additionally, NGINX Plus, available as part of a commercial subscription, enables dynamic control of sampling parameters via the NGINX Plus API and key-value store modules.</p>"},{"location":"modules/otel/#enabling-the-otel-module","title":"Enabling the OTel Module","text":"<p>Following the installation steps above will install the module into <code>/etc/nginx/modules</code> by default. Load the module by adding the following line to the top of the main NGINX configuration file, located at <code>/etc/nginx/nginx.conf</code>.</p> <pre><code>load_module modules/ngx_otel_module.so;\n</code></pre>"},{"location":"modules/otel/#configuring-the-module","title":"Configuring the Module","text":"<p>For a complete list of directives, embedded variables, default span attributes and sample configurations, please refer to the <code>ngx_otel_module</code> documentation.</p>"},{"location":"modules/otel/#examples","title":"Examples","text":"<p>Use these examples to configure some common use-cases for OTel tracing.</p>"},{"location":"modules/otel/#simple-tracing","title":"Simple Tracing","text":"<p>This example sends telemetry data for all http requests.</p> <pre><code>http {\n    otel_exporter {\n        endpoint localhost:4317;\n    }\n\n    otel_trace on;\n\n    server {\n        location / {\n            proxy_pass http://backend;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/otel/#parent-based-tracing","title":"Parent-based Tracing","text":"<p>In this example, we inherit trace contexts from incoming requests and record spans only if a parent span is sampled. We also propagate trace contexts and sampling decisions to upstream servers.</p> <pre><code>http {\n    server {\n        location / {\n            otel_trace $otel_parent_sampled;\n            otel_trace_context propagate;\n\n            proxy_pass http://backend;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/otel/#ratio-based-tracing","title":"Ratio-based Tracing","text":"<p>In this ratio-based example, tracing is configured for a percentage of traffic (in this case 10%):</p> <pre><code>http {\n    # trace 10% of requests\n    split_clients $otel_trace_id $ratio_sampler {\n        10%     on;\n        *       off;\n    }\n\n    # or we can trace 10% of user sessions\n    split_clients $cookie_sessionid $session_sampler {\n        10%     on;\n        *       off;\n    }\n\n    server {\n        location / {\n            otel_trace $ratio_sampler;\n            otel_trace_context inject;\n\n            proxy_pass http://backend;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/otel/#collecting-and-viewing-traces","title":"Collecting and Viewing Traces","text":"<p>There are several methods and available software packages for viewing traces. For a quick start, Jaeger provides an all-in-one container to collect, process and view OTel trace data. Follow these steps to download, install, launch and use Jaeger's OTel services.</p>"},{"location":"modules/otel/#change-log","title":"Change Log","text":"<p>See our release page to keep track of updates.</p>"},{"location":"modules/otel/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-otel.</p>"},{"location":"modules/pagespeed/","title":"pagespeed: PageSpeed dynamic module for NGINX","text":""},{"location":"modules/pagespeed/#installation","title":"Installation","text":"<p>CentOS/RHEL/RockyLinux/etc. and Amazon Linux are supported and require a subscription.</p> <p>Fedora Linux is supported free of charge and doesn't require a subscription.</p>"},{"location":"modules/pagespeed/#os-specific-complete-installation-and-configuration-guides-available","title":"OS-specific complete installation and configuration guides available:","text":"<ul> <li>CentOS/RHEL 7</li> <li>CentOS/RHEL 8</li> <li>Amazon Linux 2</li> </ul>"},{"location":"modules/pagespeed/#other-supported-operating-systems","title":"Other supported operating systems","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install nginx-module-pagespeed\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_pagespeed.so;\n</code></pre> <p>This document describes nginx-module-pagespeed v1.13.35.2  released on Feb 05 2018.</p> <p></p> <p>ngx_pagespeed speeds up your site and reduces page load time by automatically applying web performance best practices to pages and associated assets (CSS, JavaScript, images) without requiring you to modify your existing content or workflow. Features include:</p> <ul> <li>Image optimization: stripping meta-data, dynamic resizing, recompression</li> <li>CSS &amp; JavaScript minification, concatenation, inlining, and outlining</li> <li>Small resource inlining</li> <li>Deferring image and JavaScript loading</li> <li>HTML rewriting</li> <li>Cache lifetime extension</li> <li>and   more</li> </ul> <p>To see ngx_pagespeed in action, with example pages for each of the optimizations, see our demonstration site.</p>"},{"location":"modules/pagespeed/#how-to-use","title":"How to use","text":"<p>Follow the steps on PageSpeed configuration.</p> <p>For feedback, questions, and to follow the progress of the project:</p> <ul> <li>ngx-pagespeed-discuss mailing   list</li> <li>ngx-pagespeed-announce mailing   list</li> </ul>"},{"location":"modules/pagespeed/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-pagespeed.</p>"},{"location":"modules/passenger/","title":"passenger: Passenger module","text":""},{"location":"modules/passenger/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-passenger\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-passenger\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_passenger_module.so;\n</code></pre> <p>This document describes nginx-module-passenger v6.1.0  released on Sep 17 2025.</p> <p></p>"},{"location":"modules/passenger/#phusion-passenger","title":"Phusion Passenger\u00ae","text":"Supercharge your Ruby, Node.js and Python apps <p>Phusion Passenger\u00ae is a web server and application server, designed to be fast, robust and lightweight. It takes a lot of complexity out of deploying web apps, adds powerful enterprise-grade features that are useful in production, and makes administration much easier and less complex. Phusion Passenger supports Ruby, Python, Node.js and Meteor, and is being used by high-profile companies such as Apple, Pixar, New York Times, AirBnB, Juniper etc as well as over 650.000 websites.</p> <p>Phusion Passenger - the smart app server</p> <p>What makes Passenger so fast and reliable is its C++ core, its zero-copy architecture, its watchdog system and its hybrid evented, multi-threaded and multi-process design.</p>"},{"location":"modules/passenger/#learn-more","title":"Learn more:","text":"<ul> <li>Website</li> <li>Fuse Panel</li> <li>Documentation &amp; Support</li> <li>Consultancy</li> <li>Twitter</li> <li>Blog</li> </ul>"},{"location":"modules/passenger/#further-reading","title":"Further reading","text":"<ul> <li>The <code>doc/</code> directory.</li> <li>Contributors Guide</li> <li>Phusion Passenger support page</li> <li>Phusion Passenger release notes</li> </ul>"},{"location":"modules/passenger/#legal","title":"Legal","text":"<p>\"Passenger\" and \"Phusion Passenger\" are registered trademarks of Asynchronous B.V.</p>"},{"location":"modules/passenger/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-passenger.</p>"},{"location":"modules/perl/","title":"perl: NGINX Perl dynamic module","text":""},{"location":"modules/perl/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-perl\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-perl\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_perl_module.so;\n</code></pre> <p>This module is built from the same source as the NGINX core.</p>"},{"location":"modules/perl/#directives","title":"Directives","text":"<p>You may find information about configuration directives for this module at the following links:        </p> <ul> <li>https://nginx.org/en/docs/http/ngx_http_perl_module.html#directives</li> </ul>"},{"location":"modules/phantom-token/","title":"phantom-token: Phantom Token NGINX Module","text":""},{"location":"modules/phantom-token/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-phantom-token\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-phantom-token\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_curity_http_phantom_token_module.so;\n</code></pre> <p>This document describes nginx-module-phantom-token v2.0.0  released on May 22 2025.</p> <p> </p> <p>NGINX module that introspects access tokens according to RFC 7662, producing a \"phantom token\" that can be forwarded to back-end APIs and Web services. Read more about the Phantom Token approach.</p> <p>This module, when enabled, filters incoming requests, denying access to those which do not have a valid OAuth access token presented in an <code>Authorization</code> header. From this header, the access_token is extracted and introspected using the configured endpoint. The Curity Identity Server replies to this request according to the standard. For an active access token, the body of the Curity Identity Server's response contains the JWT that replaces the access token in the header of the request that is forwarded by NGINX to the back-end. If the token is not valid or absent, no request to the back-end is made and the caller is given a 401, unauthorized, error. This flow is shown in the following diagram:</p> <p></p> <p>The initial calls by the app (web or native) are done using OpenID Connect (OIDC). The important part is that the token that is issued is an opaque access token. It is a GUID or UUID or a few handfuls of random bytes; there is no identity-related data in this token. It is a phantom of the actual user data, hence the name -- phantom token. The app presents the token to the NGINX gateway according to the Bearer Token Usage specficiation (i.e., RFC 6750). This standard says that the app should send the phantom token in the <code>Authorization</code> request header. </p> <p>Once the NGINX server receives the access token, this module will kick in. Using configuration like that below, this module will interrogate the request, find the token, and make a sideways call to the Curity Identity Server. This web service request will be done using the Token Introspection standard (RFC 7662) with an <code>Accept</code> type of <code>application/jwt</code> (as defined in RFC 7519). This will cause the Curity Identity Server to return not JSON but just a JWT. Then, the module will forward the JWT token to the back-end APIs and microservices. </p> <p>If the module is also configured to cache the results of the call to the Curity Identity Server (which it should be for production cases), the phantom token will be used as a cache key for the corresponding JWT token. This will eliminate the need for subsequent calls to the Curity Identity Server for as long as it tells the NGINX module it may cache the JWT for.</p> <p>The tl;dr is a very simple API gateway that is blazing fast, highly scalable, and without any bells and whistles to get in the way. All the code is here, so it's easy to change and use with other OAuth servers even!</p>"},{"location":"modules/phantom-token/#module-configuration-directives","title":"Module Configuration Directives","text":"<p>Version 2.0 introduced a BREAKING CHANGE to use updated configuration directives.\\ See previous configuration instructions to configure older releases.</p>"},{"location":"modules/phantom-token/#required-configuration-directives","title":"Required Configuration Directives","text":"<p>The directives in this subsection are required; if any of these are omitted, the module will be disabled.</p>"},{"location":"modules/phantom-token/#phantom_token","title":"phantom_token","text":"<p>Syntax: <code>phantom_token</code> <code>on</code> | <code>off</code></p> <p>Default: <code>off</code></p> <p>Context: <code>location</code></p>"},{"location":"modules/phantom-token/#phantom_token_introspection_endpoint","title":"phantom_token_introspection_endpoint","text":"<p>Syntax: <code>phantom_token_introspection_endpoint</code> <code>string</code></p> <p>Default: <code>\u2014</code></p> <p>Context: <code>location</code></p>"},{"location":"modules/phantom-token/#optional-configuration-directives","title":"Optional Configuration Directives","text":"<p>The following directives are optional and do not need to be configured.</p>"},{"location":"modules/phantom-token/#phantom_token_realm","title":"phantom_token_realm","text":"<p>Syntax: <code>phantom_token_realm</code> <code>string</code></p> <p>Default: <code>api</code></p> <p>Context: <code>location</code></p> <p>The name of the protected realm or scope of protection that should be used when a client does not provide an access token.</p> <p>Example configuration:</p> <pre><code>location / {\n   ...\n   phantom_token_realm \"myGoodRealm\";\n}   \n</code></pre>"},{"location":"modules/phantom-token/#phantom_token_scopes","title":"phantom_token_scopes","text":"<p>Syntax: <code>phantom_token_scopes</code> <code>string</code></p> <p>Default: <code>\u2014</code></p> <p>Context: <code>location</code></p> <p>The space-separated list of scopes that the server should inform the client are required when it does not provide an access token.</p> <p>Example configuration:</p> <pre><code>location / {\n   ...\n   phantom_token_scopes \"scope_a scope_b scope_c\";\n}\n</code></pre>"},{"location":"modules/phantom-token/#phantom_token_scope","title":"phantom_token_scope","text":"<p>Syntax: <code>phantom_token_scope</code> <code>string</code></p> <p>Default: <code>\u2014</code></p> <p>Context: <code>location</code></p> <p>An array of scopes that the server should inform the client are required when it does not provide an access token. If <code>phantom_token_scopes</code> is also configured, that value will supersede these.</p> <p>Example configuration:</p> <pre><code>location / {\n   ...\n   phantom_token_scope \"scope_a\";\n   phantom_token_scope \"scope_b\";\n   phantom_token_scope \"scope_c\";\n}\n</code></pre>"},{"location":"modules/phantom-token/#sample-configuration","title":"Sample Configuration","text":""},{"location":"modules/phantom-token/#loading-the-module","title":"Loading the Module","text":"<p>If the module is downloaded from GitHub or compiled as a shared library (the default) and not explicitly compiled into NGINX, it will need to be loaded using the load_module directive. This needs to be done in the main part of the NGINX configuration:</p> <pre><code>load_module modules/ngx_curity_http_phantom_token_module.so;\n</code></pre> <p>The file can be an absolute or relative path. If it is not absolute, it should be relative to the NGINX root directory.</p>"},{"location":"modules/phantom-token/#nginx-parameters-for-the-introspection-endpoint","title":"NGINX Parameters for the Introspection Endpoint","text":"<p>You must also configure the following NGINX parameters for the introspection subrequest:</p> <pre><code>location curity {\n    internal;\n    proxy_pass_request_headers off;\n    proxy_set_header Accept \"application/jwt\";\n    proxy_set_header Content-Type \"application/x-www-form-urlencoded\";\n    proxy_set_header Authorization \"Basic bXlfY2xpZW50X2lkOm15X2NsaWVudF9zZWNyZXQ=\";\n    proxy_pass \"https://curity.example.com/oauth/v2/oauth-introspect\";\n}\n</code></pre> Introspection Setting Description internal Prevent the introspection endpoint being externally available. proxy_pass_request_headers Set to off to avoid using the main request's headers in the introspection subrequest. Accept header Configure a fixed value of <code>application/jwt</code>. Content-Type header Configure a fixed value of <code>application/x-www-form-urlencoded</code>. Authorization header Configure a basic credential with the introspection client ID and client secret. <p>To get the basic credential, concatenate the client ID, a colon character and the client secret, then base64 encode them. The following command provides an example.</p> <pre><code>echo -n \"my_client_id:my_client_secret\" | base64\n</code></pre>"},{"location":"modules/phantom-token/#simple-configuration","title":"Simple Configuration","text":"<p>The following is a simple configuration that might be used in demo or development environments where the NGINX reverse proxy is on the same host as the Curity Identity Server:</p> <pre><code>server {\n    location /api {\n        phantom_token on;\n        phantom_token_introspection_endpoint curity;\n        proxy_pass https://example.com/api;\n    }\n\n    location curity {\n        internal;\n        proxy_pass_request_headers off;\n        proxy_set_header Accept \"application/jwt\";\n        proxy_set_header Content-Type \"application/x-www-form-urlencoded\";\n        proxy_set_header Authorization \"Basic bXlfY2xpZW50X2lkOm15X2NsaWVudF9zZWNyZXQ=\";\n        proxy_pass \"https://curity.example.com/oauth/v2/oauth-introspect\";\n    }\n}\n</code></pre>"},{"location":"modules/phantom-token/#complex-configuration","title":"Complex Configuration","text":"<p>The following is a more complex configuration where the NGINX reverse proxy is on a separate host to the Curity Identity Server:</p> <pre><code>server {\n    server_name server1.example.com;n\n    location /api {\n        phantom_token on;\n        phantom_token_introspection_endpoint curity;\n        phantom_token_realm \"myGoodAPI\";\n        phantom_token_scopes \"scope_a scope_b scope_c\";\n        proxy_pass https://example.com/api;\n    }\n\n    location curity {\n        internal;\n        proxy_pass_request_headers off;\n        proxy_set_header Accept \"application/jwt\";\n        proxy_set_header Content-Type \"application/x-www-form-urlencoded\";\n        proxy_set_header Authorization \"Basic bXlfY2xpZW50X2lkOm15X2NsaWVudF9zZWNyZXQ=\";\n        proxy_pass \"https://server2.example.com:8443/oauth/v2/oauth-introspect\";\n    }\n}\n\nserver {\n    listen 8443;\n    server_name server2.example.com;\n    location / {\n        proxy_pass \"https://curity.example.com\";\n    }\n}\n</code></pre>"},{"location":"modules/phantom-token/#more-advanced-configuration-with-separate-servers-and-caching","title":"More Advanced Configuration with Separate Servers and Caching","text":"<p>This module takes advantage of NGINX built-in proxy_cache directive. In order to be able to cache the requests made to the introspection endpoint, except of the <code>proxy_cache_path</code> in http context and <code>proxy_cache</code> in location context, you have to add the following 3 directives in the location context of the introspection endpoint.</p> <ul> <li><code>proxy_cache_methods POST;</code> POST requests are not cached by default.</li> <li><code>proxy_cache_key $request_body;</code> The key of the cache is related to the access_token sent in the original request. Different requests using the same access_token reach the same cache.</li> <li><code>proxy_ignore_headers Set-Cookie;</code> NGINX will not cache the response if <code>Set-Cookie</code> header is not ignored.</li> </ul> <pre><code>http {\n    proxy_cache_path /path/to/cache/cache levels=1:2 keys_zone=my_cache:10m max_size=10g\n                     inactive=60m use_temp_path=off;\n    server {\n        server_name server1.example.com;\n        location /api {\n            phantom_token on;\n            phantom_token_introspection_endpoint curity;\n            phantom_token_scopes \"scope_a scope_b scope_c\";\n            phantom_token_realm \"myGoodAPI\";\n            proxy_pass https://example.com/api;\n        }\n\n        location curity {\n            internal;            \n            proxy_pass_request_headers off;\n            proxy_set_header Accept \"application/jwt\";\n            proxy_set_header Content-Type \"application/x-www-form-urlencoded\";\n            proxy_set_header Authorization \"Basic bXlfY2xpZW50X2lkOm15X2NsaWVudF9zZWNyZXQ=\";\n\n            proxy_cache_methods POST;\n            proxy_cache my_cache;\n            proxy_cache_key $request_body;\n            proxy_ignore_headers Set-Cookie;\n\n            proxy_pass \"https://server2.example.com:8443/oauth/v2/oauth-introspect\";\n        }\n    }\n\n    server {\n        listen 8443;\n        server_name server2.example.com;\n        location / {\n            proxy_pass \"https://curity.example.com\";\n        }\n    }\n}   \n</code></pre>"},{"location":"modules/phantom-token/#cacheless-configuration","title":"Cacheless Configuration","text":"<p>It is recommended to cache the results of the call to the Curity Identity Server so that you avoid triggering an introspection request for every API request. If you wish to disable caching you should extend the default proxy_buffer_size to ensure that the module can read large JWTs. Do so by updating the configuration of the introspection request as in the following example.</p> <pre><code>http {\n    server {\n        server_name server1.example.com;\n        location /api {\n            phantom_token on;\n            phantom_token_introspection_endpoint curity;\n            phantom_token_scopes \"scope_a scope_b scope_c\";\n            phantom_token_realm \"myGoodAPI\";\n            proxy_pass https://example.com/api;\n        }\n\n        location curity {\n            internal;\n            proxy_pass_request_headers off;\n            proxy_set_header Accept \"application/jwt\";\n            proxy_set_header Content-Type \"application/x-www-form-urlencoded\";\n            proxy_set_header Authorization \"Basic bXlfY2xpZW50X2lkOm15X2NsaWVudF9zZWNyZXQ=\";\n\n            proxy_ignore_headers Set-Cookie;\n            proxy_buffer_size 16k;\n            proxy_buffers 4 16k;\n\n            proxy_pass \"https://server2.example.com:8443/oauth/v2/oauth-introspect\";\n        }\n    }\n\n    server {\n        listen 8443;\n        server_name server2.example.com;\n        location / {\n            proxy_pass \"https://curity.example.com\";\n        }\n    }\n}   \n</code></pre>"},{"location":"modules/phantom-token/#more-information","title":"More Information","text":"<p>For more information about the Curity Identity Server, its capabilities, and how to use it to issue phantom tokens for microservices, visit curity.io. For background information on using the Curity Identity Server to secure API access, see our API security resources.</p>"},{"location":"modules/phantom-token/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-phantom-token.</p>"},{"location":"modules/pipelog/","title":"pipelog: NGINX pipelog module","text":""},{"location":"modules/pipelog/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-pipelog\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-pipelog\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_pipelog_module.so;\n</code></pre> <p>This document describes nginx-module-pipelog v1.0.4  released on Dec 19 2022.</p> <p>This module allows to send HTTP access log to an external program via pipe.</p>"},{"location":"modules/pipelog/#directives","title":"Directives","text":"<p>pipelog_format</p> <pre><code>pipelog_format name [escape=default|json|none] string ...\n</code></pre> <ul> <li>syntax is same as log_format of HttpLogModule.</li> <li>default value is combined.</li> </ul> <p>pipelog</p> <pre><code>pipelog command [format [nonblocking] [if=condition]];\n\npipelog off;\n</code></pre> <ul> <li>default value is off.</li> <li>command does not need the pipe symbol <code>|</code> prefix.</li> </ul>"},{"location":"modules/pipelog/#example","title":"Example","text":"<pre><code>  pipelog_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n  pipelog \"cat &gt;&gt; /var/log/nginx/access.log\" main;\n</code></pre>"},{"location":"modules/pipelog/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-pipelog.</p>"},{"location":"modules/postgres/","title":"postgres: PostgreSQL module for NGINX","text":""},{"location":"modules/postgres/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-postgres\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-postgres\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_postgres_module.so;\n</code></pre> <p>This document describes nginx-module-postgres v1.0  released on Aug 22 2020.</p> <p><code>ngx_postgres</code> is an upstream module that allows <code>nginx</code> to communicate directly with <code>PostgreSQL</code> database.</p> <p>Response is generated in <code>rds</code> format, so it's compatible with <code>ngx_rds_json</code> and <code>ngx_drizzle</code> modules.</p>"},{"location":"modules/postgres/#status","title":"Status","text":"<p>This module is production-ready and it's compatible with following nginx releases:</p> <ul> <li>0.7.x (tested with 0.7.60 to 0.7.69),</li> <li>0.8.x (tested with 0.8.0 to 0.8.55),</li> <li>0.9.x (tested with 0.9.0 to 0.9.7),</li> <li>1.0.x (tested with 1.0.0 to 1.0.11),</li> <li>1.1.x (tested with 1.1.0 to 1.1.12).</li> <li>1.2.x (tested with 1.2.3 to 1.2.3).</li> <li>1.3.x (tested with 1.3.4 to 1.3.4).</li> </ul>"},{"location":"modules/postgres/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/postgres/#postgres_server","title":"postgres_server","text":"<ul> <li>syntax: <code>postgres_server ip[:port] dbname=dbname user=user password=pass</code></li> <li>default: <code>none</code></li> <li>context: <code>upstream</code></li> </ul> <p>Set details about the database server.</p>"},{"location":"modules/postgres/#postgres_keepalive","title":"postgres_keepalive","text":"<ul> <li>syntax: <code>postgres_keepalive off | max=count [mode=single|multi] [overflow=ignore|reject]</code></li> <li>default: <code>max=10 mode=single overflow=ignore</code></li> <li>context: <code>upstream</code></li> </ul> <p>Configure keepalive parameters:</p> <ul> <li><code>max</code>      - maximum number of keepalive connections (per worker process),</li> <li><code>mode</code>     - backend matching mode,</li> <li><code>overflow</code> - either <code>ignore</code> the fact that keepalive connection pool is full   and allow request, but close connection afterwards or <code>reject</code> request with   <code>503 Service Unavailable</code> response.</li> </ul>"},{"location":"modules/postgres/#postgres_pass","title":"postgres_pass","text":"<ul> <li>syntax: <code>postgres_pass upstream</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code>, <code>if location</code></li> </ul> <p>Set name of an upstream block that will be used for the database connections (it can include variables).</p>"},{"location":"modules/postgres/#postgres_query","title":"postgres_query","text":"<ul> <li>syntax: <code>postgres_query [methods] query</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>if location</code></li> </ul> <p>Set query string (it can include variables). When methods are specified then query is used only for them, otherwise it's used for all methods.</p> <p>This directive can be used more than once within same context.</p>"},{"location":"modules/postgres/#postgres_rewrite","title":"postgres_rewrite","text":"<ul> <li>syntax: <code>postgres_rewrite [methods] condition [=]status_code</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>if location</code></li> </ul> <p>Rewrite response <code>status_code</code> when given condition is met (first one wins!):</p> <ul> <li><code>no_changes</code> - no rows were affected by the query,</li> <li><code>changes</code>    - at least one row was affected by the query,</li> <li><code>no_rows</code>    - no rows were returned in the result-set,</li> <li><code>rows</code>       - at least one row was returned in the result-set.</li> </ul> <p>When <code>status_code</code> is prefixed with <code>=</code> sign then original response body is send to the client instead of the default error page for given <code>status_code</code>.</p> <p>By design both <code>no_changes</code> and <code>changes</code> apply only to <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, <code>MOVE</code>, <code>FETCH</code> and <code>COPY</code> SQL queries.</p> <p>This directive can be used more than once within same context.</p>"},{"location":"modules/postgres/#postgres_output","title":"postgres_output","text":"<ul> <li>syntax: <code>postgres_output rds|text|value|binary_value|none</code></li> <li>default: <code>rds</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code>, <code>if location</code></li> </ul> <p>Set output format:</p> <ul> <li><code>rds</code>          - return all values from the result-set in <code>rds</code> format   (with appropriate <code>Content-Type</code>),</li> <li><code>text</code>         - return all values from the result-set in text format   (with default <code>Content-Type</code>), values are separated by new line,</li> <li><code>value</code>        - return single value from the result-set in text format   (with default <code>Content-Type</code>),</li> <li><code>binary_value</code> - return single value from the result-set in binary format   (with default <code>Content-Type</code>),</li> <li><code>none</code>         - don't return anything, this should be used only when   extracting values with <code>postgres_set</code> for use with other modules (without   <code>Content-Type</code>).</li> </ul>"},{"location":"modules/postgres/#postgres_set","title":"postgres_set","text":"<ul> <li>syntax: <code>postgres_set $variable row column [optional|required]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Get single value from the result-set and keep it in $variable.</p> <p>When requirement level is set to <code>required</code> and value is either out-of-range, <code>NULL</code> or zero-length, then nginx returns <code>500 Internal Server Error</code> response. Such condition is silently ignored when requirement level is set to <code>optional</code> (default).</p> <p>Row and column numbers start at 0. Column name can be used instead of column number.</p> <p>This directive can be used more than once within same context.</p>"},{"location":"modules/postgres/#postgres_escape","title":"postgres_escape","text":"<ul> <li>syntax: <code>postgres_escape $escaped [[=]$unescaped]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Escape and quote <code>$unescaped</code> string. Result is stored in <code>$escaped</code> variable which can be safely used in SQL queries.</p> <p>Because nginx cannot tell the difference between empty and non-existing strings, all empty strings are by default escaped to <code>NULL</code> value. This behavior can be disabled by prefixing <code>$unescaped</code> string with <code>=</code> sign.</p>"},{"location":"modules/postgres/#postgres_connect_timeout","title":"postgres_connect_timeout","text":"<ul> <li>syntax: <code>postgres_connect_timeout timeout</code></li> <li>default: <code>10s</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Set timeout for connecting to the database.</p>"},{"location":"modules/postgres/#postgres_result_timeout","title":"postgres_result_timeout","text":"<ul> <li>syntax: <code>postgres_result_timeout timeout</code></li> <li>default: <code>30s</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Set timeout for receiving result from the database.</p>"},{"location":"modules/postgres/#configuration-variables","title":"Configuration variables","text":""},{"location":"modules/postgres/#postgres_columns","title":"$postgres_columns","text":"<p>Number of columns in received result-set.</p>"},{"location":"modules/postgres/#postgres_rows","title":"$postgres_rows","text":"<p>Number of rows in received result-set.</p>"},{"location":"modules/postgres/#postgres_affected","title":"$postgres_affected","text":"<p>Number of rows affected by <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, <code>MOVE</code>, <code>FETCH</code> or <code>COPY</code> SQL query.</p>"},{"location":"modules/postgres/#postgres_query_1","title":"$postgres_query","text":"<p>SQL query, as seen by <code>PostgreSQL</code> database.</p>"},{"location":"modules/postgres/#sample-configurations","title":"Sample configurations","text":""},{"location":"modules/postgres/#sample-configuration-1","title":"Sample configuration #1","text":"<p>Return content of table <code>cats</code> (in <code>rds</code> format).</p> <pre><code>http {\n    upstream database {\n        postgres_server  127.0.0.1 dbname=test\n                         user=test password=test;\n    }\n\n    server {\n        location / {\n            postgres_pass   database;\n            postgres_query  \"SELECT * FROM cats\";\n        }\n    }\n}\n</code></pre>"},{"location":"modules/postgres/#sample-configuration-2","title":"Sample configuration #2","text":"<p>Return only those rows from table <code>sites</code> that match <code>host</code> filter which is evaluated for each request based on its <code>$http_host</code> variable.</p> <pre><code>http {\n    upstream database {\n        postgres_server  127.0.0.1 dbname=test\n                         user=test password=test;\n    }\n\n    server {\n        location / {\n            postgres_pass   database;\n            postgres_query  SELECT * FROM sites WHERE host='$http_host'\";\n        }\n    }\n}\n</code></pre>"},{"location":"modules/postgres/#sample-configuration-3","title":"Sample configuration #3","text":"<p>Pass request to the backend selected from the database (traffic router).</p> <pre><code>http {\n    upstream database {\n        postgres_server  127.0.0.1 dbname=test\n                         user=test password=test;\n    }\n\n    server {\n        location / {\n            eval_subrequest_in_memory  off;\n\n            eval $backend {\n                postgres_pass    database;\n                postgres_query   \"SELECT * FROM backends LIMIT 1\";\n                postgres_output  value 0 0;\n            }\n\n            proxy_pass  $backend;\n        }\n    }\n}\n</code></pre> <p>Required modules (other than <code>ngx_postgres</code>):</p> <ul> <li>nginx-eval-module (agentzh's fork),</li> </ul>"},{"location":"modules/postgres/#sample-configuration-4","title":"Sample configuration #4","text":"<p>Restrict access to local files by authenticating against <code>PostgreSQL</code> database.</p> <pre><code>http {\n    upstream database {\n        postgres_server  127.0.0.1 dbname=test\n                         user=test password=test;\n    }\n\n    server {\n        location = /auth {\n            internal;\n\n            postgres_escape   $user $remote_user;\n            postgres_escape   $pass $remote_passwd;\n\n            postgres_pass     database;\n            postgres_query    \"SELECT login FROM users WHERE login=$user AND pass=$pass\";\n            postgres_rewrite  no_rows 403;\n            postgres_output   none;\n        }\n\n        location / {\n            auth_request      /auth;\n            root              /files;\n        }\n    }\n}\n</code></pre> <p>Required modules (other than <code>ngx_postgres</code>):</p> <ul> <li>ngx_http_auth_request_module,</li> <li>ngx_coolkit.</li> </ul>"},{"location":"modules/postgres/#sample-configuration-5","title":"Sample configuration #5","text":"<p>Simple RESTful webservice returning JSON responses with appropriate HTTP status codes.</p> <pre><code>http {\n    upstream database {\n        postgres_server  127.0.0.1 dbname=test\n                         user=test password=test;\n    }\n\n    server {\n        set $random  123;\n\n        location = /numbers/ {\n            postgres_pass     database;\n            rds_json          on;\n\n            postgres_query    HEAD GET  \"SELECT * FROM numbers\";\n\n            postgres_query    POST      \"INSERT INTO numbers VALUES('$random') RETURNING *\";\n            postgres_rewrite  POST      changes 201;\n\n            postgres_query    DELETE    \"DELETE FROM numbers\";\n            postgres_rewrite  DELETE    no_changes 204;\n            postgres_rewrite  DELETE    changes 204;\n        }\n\n        location ~ /numbers/(?&lt;num&gt;\\d+) {\n            postgres_pass     database;\n            rds_json          on;\n\n            postgres_query    HEAD GET  \"SELECT * FROM numbers WHERE number='$num'\";\n            postgres_rewrite  HEAD GET  no_rows 410;\n\n            postgres_query    PUT       \"UPDATE numbers SET number='$num' WHERE number='$num' RETURNING *\";\n            postgres_rewrite  PUT       no_changes 410;\n\n            postgres_query    DELETE    \"DELETE FROM numbers WHERE number='$num'\";\n            postgres_rewrite  DELETE    no_changes 410;\n            postgres_rewrite  DELETE    changes 204;\n        }\n    }\n}\n</code></pre> <p>Required modules (other than <code>ngx_postgres</code>):</p> <ul> <li>ngx_rds_json.</li> </ul>"},{"location":"modules/postgres/#sample-configuration-6","title":"Sample configuration #6","text":"<p>Use GET parameter in SQL query.</p> <pre><code>location /quotes {\n    set_unescape_uri  $txt $arg_txt;\n    postgres_escape   $txt;\n    postgres_pass     database;\n    postgres_query    \"SELECT * FROM quotes WHERE quote=$txt\";\n}\n</code></pre> <p>Required modules (other than <code>ngx_postgres</code>):</p> <ul> <li>ngx_set_misc.</li> </ul>"},{"location":"modules/postgres/#testing","title":"Testing","text":"<p><code>ngx_postgres</code> comes with complete test suite based on Test::Nginx.</p> <p>You can test core functionality by running:</p> <p><code>$ TEST_NGINX_IGNORE_MISSING_DIRECTIVES=1 prove</code></p> <p>You can also test interoperability with following modules:</p> <ul> <li>ngx_coolkit,</li> <li>ngx_echo,</li> <li>ngx_form_input,</li> <li>ngx_set_misc,</li> <li>ngx_http_auth_request_module,</li> <li>nginx-eval-module (agentzh's fork),</li> <li>ngx_rds_json.</li> </ul> <p>by running:</p> <p><code>$ prove</code></p>"},{"location":"modules/postgres/#see-also","title":"See also","text":"<ul> <li>ngx_rds_json,</li> <li>ngx_drizzle,</li> <li>ngx_lua,</li> <li>nginx-eval-module (agentzh's fork).</li> </ul>"},{"location":"modules/postgres/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-postgres.</p>"},{"location":"modules/proxy-connect/","title":"proxy-connect: CONNECT method support in NGINX","text":""},{"location":"modules/proxy-connect/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-proxy-connect\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-proxy-connect\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_proxy_connect_module.so;\n</code></pre> <p>This document describes nginx-module-proxy-connect v0.0.2  released on Dec 24 2024.</p> <p>This fork is integrated in NGINX-MOD.</p> <p>[!CAUTION] Compiling as dynamic module is discouraged at present, patched NGINX binary will not pick up the flag NGX_HTTP_PROXY_CONNECT. Only proper way for this is compiling NGINX and dynamic module in one go, then removing the module for packaging</p> <p>[!CAUTION] Existing patch was not ABI compliant because it added fields in the middle</p> <p>This module provides support for the CONNECT method request. This method is mainly used to tunnel SSL requests through proxy servers.</p>"},{"location":"modules/proxy-connect/#example","title":"Example","text":""},{"location":"modules/proxy-connect/#configuration-example","title":"Configuration Example","text":"<pre><code>server {\n    listen                         3128;\n\n    # dns resolver used by forward proxying\n    resolver                       8.8.8.8;\n\n    # forward proxy for CONNECT requests\n    proxy_connect;\n    proxy_connect_allow            443 563;\n    proxy_connect_connect_timeout  10s;\n    proxy_connect_data_timeout     10s;\n\n    # defined by yourself for non-CONNECT requests\n    # Example: reverse proxy for non-CONNECT requests\n    location / {\n        proxy_pass http://$host;\n        proxy_set_header Host $host;\n    }\n}\n</code></pre> <ul> <li>The <code>resolver</code> directive MUST be configured globally in <code>server {}</code> block (or <code>http {}</code> block).</li> <li>Any <code>location {}</code> block, <code>upstream {}</code> block and any other standard backend/upstream directives, such as <code>proxy_pass</code>, do not impact the functionality of this module. (The proxy_connect module only executes the logic for requests that use the CONNECT method and that have a data flow under this tunnel.)</li> <li>If you dont want to handle non-CONNECT requests, you can modify <code>location {}</code> block as following: <pre><code>    location / {\n        return 403 \"Non-CONNECT requests are forbidden\";\n    }\n    ```\n\nExample for curl\n----------------\n\nWith above configuration([configuration example](#configuration-example)\n), you can get any https website via HTTP CONNECT tunnel. A simple test with command `curl` is as following:\n</code></pre> $ curl https://github.com/ -v -x 127.0.0.1:3128</li> <li>Trying 127.0.0.1...                                           -.</li> <li>Connected to 127.0.0.1 (127.0.0.1) port 3128 (#0)                | curl creates TCP connection with nginx (with proxy_connect module).</li> <li> <p>Establish HTTP proxy tunnel to github.com:443                   -'</p> <p>CONNECT github.com:443 HTTP/1.1                                 -. Host: github.com:443                                         (1) | curl sends CONNECT request to create tunnel. User-Agent: curl/7.43.0                                          | Proxy-Connection: Keep-Alive                                    -'</p> <p>&lt; HTTP/1.0 200 Connection Established                             .- nginx replies 200 that tunnel is established. &lt; Proxy-agent: nginx                                           (2)|  (The client is now being proxied to the remote host. Any data sent &lt;                                                                 '-  to nginx is now forwarded, unmodified, to the remote host)</p> </li> <li> <p>Proxy replied OK to CONNECT request</p> </li> <li>TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256  -.</li> <li>Server certificate: github.com                                   |</li> <li>Server certificate: DigiCert SHA2 Extended Validation Server CA  | curl sends \"https://github.com\" request via tunnel,</li> <li>Server certificate: DigiCert High Assurance EV Root CA           | proxy_connect module will proxy data to remote host (github.com). <p>GET / HTTP/1.1                                                   | Host: github.com                                             (3) | User-Agent: curl/7.43.0                                          | Accept: /                                                     -'</p> <p>&lt; HTTP/1.1 200 OK                                                 .- &lt; Date: Fri, 11 Aug 2017 04:13:57 GMT                             | &lt; Content-Type: text/html; charset=utf-8                          |  Any data received from remote host will be sent to client &lt; Transfer-Encoding: chunked                                      |  by proxy_connect module. &lt; Server: GitHub.com                                           (4)| &lt; Status: 200 OK                                                  | &lt; Cache-Control: no-cache                                         | &lt; Vary: X-PJAX                                                    | ...                                                               | ...  ...                  | ...                                                               '- <pre><code>The sequence diagram of above example is as following:\n</code></pre>   curl                     nginx (proxy_connect)            github.com     |                             |                          | (1) |-- CONNECT github.com:443 --&gt;|                          |     |                             |                          |     |                             |----[ TCP connection ]---&gt;|     |                             |                          | (2) |&lt;- HTTP/1.1 200           ---|                          |     |   Connection Established    |                          |     |                             |                          |     |                                                        |     ========= CONNECT tunnel has been established. ===========     |                                                        |     |                             |                          |     |                             |                          |     |   [ SSL stream       ]      |                          | (3) |---[ GET / HTTP/1.1   ]-----&gt;|   [ SSL stream       ]   |     |   [ Host: github.com ]      |---[ GET / HTTP/1.1   ]--&gt;.     |                             |   [ Host: github.com ]   |     |                             |                          |     |                             |                          |     |                             |                          |     |                             |   [ SSL stream       ]   |     |   [ SSL stream       ]      |&lt;--[ HTTP/1.1 200 OK  ]---' (4) |&lt;--[ HTTP/1.1 200 OK  ]------|   [ &lt; html page &gt;    ]   |     |   [ &lt; html page &gt;    ]      |                          |     |                             |                          | <pre><code>configuration example for CONNECT request in HTTPS\n--------------------------------------------------\n\n```nginx\nserver {\n    listen                         3128 ssl;\n\n    # self signed certificate generated via openssl command\n    ssl_certificate_key            /path/to/server.key;\n    ssl_certificate                /path/to/server.crt;\n    ssl_session_cache              shared:SSL:1m;\n\n    # dns resolver used by forward proxying\n    resolver                       8.8.8.8;\n\n    # forward proxy for CONNECT request\n    proxy_connect;\n    proxy_connect_allow            443 563;\n    proxy_connect_connect_timeout  10s;\n    proxy_connect_data_timeout     10s;\n\n    # defined by yourself for non-CONNECT request\n    # Example: reverse proxy for non-CONNECT requests\n    location / {\n        proxy_pass http://$host;\n        proxy_set_header Host $host;\n    }\n}\n</code></pre>"},{"location":"modules/proxy-connect/#example-for-curl-connect-request-in-https","title":"example for curl (CONNECT request in https)","text":"<p>With above configuration(configuration example for CONNECT request in https), you can get any https website via HTTPS CONNECT tunnel(CONNECT request in https). A simple test with command <code>curl</code> is as following:</p> <p>Tips on using curl command:</p> <ul> <li><code>-x https://...</code> makes curl send CONNECT request in https.</li> <li><code>--proxy-insecure</code> disables ssl signature verification for ssl connection established with nginx proxy_connect server(<code>https://localhost:3128</code>), but it does not disable verification with proxied backend server(<code>https://nginx.org</code> in the example below).</li> <li>If you want to disable signature verfication with proxied backend server, you can use <code>-k</code> option.</li> </ul> output of curl command :point_left:  <p> <pre><code>$ curl https://nginx.org/ -sv -o/dev/null -x https://localhost:3128 --proxy-insecure\n*   Trying 127.0.0.1:3128...\n* TCP_NODELAY set\n* Connected to localhost (127.0.0.1) port 3128 (#0)\n* ALPN, offering http/1.1\n* successfully set certificate verify locations:\n*   CAfile: /etc/ssl/certs/ca-certificates.crt\n  CApath: /etc/ssl/certs\n} [5 bytes data]\n* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n} [512 bytes data]\n* TLSv1.3 (IN), TLS handshake, Server hello (2):\n{ [112 bytes data]\n* TLSv1.2 (IN), TLS handshake, Certificate (11):\n{ [799 bytes data]\n* TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n{ [300 bytes data]\n* TLSv1.2 (IN), TLS handshake, Server finished (14):\n{ [4 bytes data]\n* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n} [37 bytes data]\n* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):\n} [1 bytes data]\n* TLSv1.2 (OUT), TLS handshake, Finished (20):\n} [16 bytes data]\n* TLSv1.2 (IN), TLS handshake, Finished (20):\n{ [16 bytes data]\n* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384\n* ALPN, server accepted to use http/1.1\n* Proxy certificate:\n*  subject: C=AU; ST=Some-State; O=Internet Widgits Pty Ltd\n*  start date: Nov 25 08:36:38 2022 GMT\n*  expire date: Nov 25 08:36:38 2023 GMT\n*  issuer: C=AU; ST=Some-State; O=Internet Widgits Pty Ltd\n*  SSL certificate verify result: self signed certificate (18), continuing anyway.\n* allocate connect buffer!\n* Establish HTTP proxy tunnel to nginx.org:443\n} [5 bytes data]\n&gt; CONNECT nginx.org:443 HTTP/1.1\n&gt; Host: nginx.org:443\n&gt; User-Agent: curl/7.68.0\n&gt; Proxy-Connection: Keep-Alive\n&gt;\n{ [5 bytes data]\n&lt; HTTP/1.1 200 Connection Established\n&lt; Proxy-agent: nginx\n&lt;\n* Proxy replied 200 to CONNECT request\n* CONNECT phase completed!\n* ALPN, offering h2\n* ALPN, offering http/1.1\n* successfully set certificate verify locations:\n*   CAfile: /etc/ssl/certs/ca-certificates.crt\n  CApath: /etc/ssl/certs\n} [5 bytes data]\n* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n} [512 bytes data]\n* CONNECT phase completed!\n* CONNECT phase completed!\n{ [5 bytes data]\n* TLSv1.3 (IN), TLS handshake, Server hello (2):\n{ [80 bytes data]\n* TLSv1.2 (IN), TLS handshake, Certificate (11):\n{ [2749 bytes data]\n* TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n{ [300 bytes data]\n* TLSv1.2 (IN), TLS handshake, Server finished (14):\n{ [4 bytes data]\n* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n} [37 bytes data]\n* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):\n} [1 bytes data]\n* TLSv1.2 (OUT), TLS handshake, Finished (20):\n} [16 bytes data]\n* TLSv1.2 (IN), TLS handshake, Finished (20):\n{ [16 bytes data]\n* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384\n* ALPN, server accepted to use http/1.1\n* Server certificate:\n*  subject: CN=nginx.org\n*  start date: Dec  9 15:29:31 2022 GMT\n*  expire date: Mar  9 15:29:30 2023 GMT\n*  subjectAltName: host \"nginx.org\" matched cert's \"nginx.org\"\n*  issuer: C=US; O=Let's Encrypt; CN=R3\n*  SSL certificate verify ok.\n} [5 bytes data]\n&gt; GET / HTTP/1.1\n&gt; Host: nginx.org\n&gt; User-Agent: curl/7.68.0\n&gt; Accept: */*\n&gt;\n{ [5 bytes data]\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 OK\n&lt; Server: nginx/1.21.5\n&lt; Date: Mon, 06 Mar 2023 06:05:24 GMT\n&lt; Content-Type: text/html; charset=utf-8\n&lt; Content-Length: 7488\n&lt; Last-Modified: Tue, 28 Feb 2023 21:07:43 GMT\n&lt; Connection: keep-alive\n&lt; Keep-Alive: timeout=15\n&lt; ETag: \"63fe6d1f-1d40\"\n&lt; Accept-Ranges: bytes\n&lt;\n{ [7488 bytes data]\n* Connection #0 to host localhost left intact\n</code></pre> </p>"},{"location":"modules/proxy-connect/#example-for-browser","title":"Example for browser","text":"<p>You can configure your browser to use this nginx as PROXY server.</p> <ul> <li>Google Chrome HTTPS PROXY SETTING: guide &amp; config for how to configure this module working under SSL layer.</li> </ul>"},{"location":"modules/proxy-connect/#example-for-basic-authentication","title":"Example for Basic Authentication","text":"<p>We can do access control on CONNECT request using nginx auth basic module. See this guide for more details.</p>"},{"location":"modules/proxy-connect/#example-for-proxying-websocket","title":"Example for proxying WebSocket","text":"<ul> <li>Note that nginx has its own WebSocket reverse proxy module, which is is not limited to the CONNECT tunnel, see nginx.org doc: Nginx WebSocket proxying and nginx.com blog: NGINX as a WebSocket Proxy.</li> <li>This module enables the WebSocket protocol to work over the CONNECT tunnel, see https://github.com/chobits/ngx_http_proxy_connect_module/issues/267#issuecomment-1575449174</li> </ul>"},{"location":"modules/proxy-connect/#install","title":"Install","text":""},{"location":"modules/proxy-connect/#select-patch","title":"Select patch","text":"<ul> <li>Select right patch for building:</li> <li>All patch files have been included in <code>patch/</code> directory of this module. You dont need to download the patch directly from web page.</li> </ul> nginx version enable REWRITE phase patch 1.4.x ~ 1.12.x NO proxy_connect.patch 1.4.x ~ 1.12.x YES proxy_connect_rewrite.patch 1.13.x ~ 1.14.x NO proxy_connect_1014.patch 1.13.x ~ 1.14.x YES proxy_connect_rewrite_1014.patch 1.15.2 YES proxy_connect_rewrite_1015.patch 1.15.4 ~ 1.16.x YES proxy_connect_rewrite_101504.patch 1.17.x ~ 1.18.x YES proxy_connect_rewrite_1018.patch 1.19.x ~ 1.21.0 YES proxy_connect_rewrite_1018.patch 1.21.1 ~ 1.22.x YES proxy_connect_rewrite_102101.patch 1.23.x ~ 1.24.0 YES proxy_connect_rewrite_102101.patch 1.25.0 ~ 1.26.x YES proxy_connect_rewrite_102101.patch 1.27.1 YES proxy_connect_rewrite_102101.patch OpenResty version enable REWRITE phase patch 1.13.6 NO proxy_connect_1014.patch 1.13.6 YES proxy_connect_rewrite_1014.patch 1.15.8 YES proxy_connect_rewrite_101504.patch 1.17.8 YES proxy_connect_rewrite_1018.patch 1.19.3 YES proxy_connect_rewrite_1018.patch 1.21.4 YES proxy_connect_rewrite_102101.patch 1.25.3 YES proxy_connect_rewrite_102101.patch <ul> <li><code>proxy_connect_&lt;VERSION&gt;.patch</code> disables nginx REWRITE phase for CONNECT request by default, which means <code>if</code>, <code>set</code>, <code>rewrite_by_lua</code> and other REWRITE phase directives cannot be used.</li> <li><code>proxy_connect_rewrite_&lt;VERSION&gt;.patch</code> enables these REWRITE phase directives.</li> </ul>"},{"location":"modules/proxy-connect/#build-nginx","title":"Build nginx","text":"<ul> <li>Build nginx with this module from source:</li> </ul> <pre><code>$ wget http://nginx.org/download/nginx-1.9.2.tar.gz\n$ tar -xzvf nginx-1.9.2.tar.gz\n$ cd nginx-1.9.2/\n$ patch -p1 &lt; /path/to/ngx_http_proxy_connect_module/patch/proxy_connect.patch\n$ ./configure --add-module=/path/to/ngx_http_proxy_connect_module\n$ make &amp;&amp; make install\n</code></pre>"},{"location":"modules/proxy-connect/#build-as-a-dynamic-module","title":"Build as a dynamic module","text":"<ul> <li>Starting from nginx 1.9.11, you can also compile this module as a dynamic module, by using the <code>--add-dynamic-module=PATH</code> option instead of <code>--add-module=PATH</code> on the <code>./configure</code> command line.</li> </ul> <pre><code>$ wget http://nginx.org/download/nginx-1.9.12.tar.gz\n$ tar -xzvf nginx-1.9.12.tar.gz\n$ cd nginx-1.9.12/\n$ patch -p1 &lt; /path/to/ngx_http_proxy_connect_module/patch/proxy_connect.patch\n$ ./configure --add-dynamic-module=/path/to/ngx_http_proxy_connect_module\n$ make &amp;&amp; make install\n</code></pre> <ul> <li>And then you can explicitly load the module in your nginx.conf via the <code>load_module</code> directive, for example,</li> </ul> <pre><code>load_module /path/to/modules/ngx_http_proxy_connect_module.so;\n</code></pre> <ul> <li> Note that the ngx_http_proxy_connect_module.so file MUST be loaded by nginx binary that is compiled with the .so file at the same time.</li> </ul>"},{"location":"modules/proxy-connect/#build-openresty","title":"Build OpenResty","text":"<ul> <li>Build OpenResty with this module from source:</li> </ul> <pre><code>$ wget https://openresty.org/download/openresty-1.19.3.1.tar.gz\n$ tar -zxvf openresty-1.19.3.1.tar.gz\n$ cd openresty-1.19.3.1\n$ ./configure --add-module=/path/to/ngx_http_proxy_connect_module\n$ patch -d build/nginx-1.19.3/ -p 1 &lt; /path/to/ngx_http_proxy_connect_module/patch/proxy_connect_rewrite_101504.patch\n$ make &amp;&amp; make install\n</code></pre>"},{"location":"modules/proxy-connect/#test-suite","title":"Test Suite","text":"<ul> <li>To run the whole test suite:</li> </ul> <pre><code>$ hg clone http://hg.nginx.org/nginx-tests/\n\n## If you use latest lua-nginx-module that needs lua-resty-core and\n## lua-resty-lrucache, you should add \"lua_package_path ...;\" directive\n## into nginx.conf of test cases. You can use the following command:\n#\n## $ export TEST_NGINX_GLOBALS_HTTP='lua_package_path \"/path/to/nginx/lib/lua/?.lua;;\";'\n\n$ export TEST_NGINX_BINARY=/path/to/nginx/binary\n$ prove -v -I /path/to/nginx-tests/lib /path/to/ngx_http_proxy_connect_module/t/\n</code></pre> <ul> <li>For the complete process of building and testing this module, see:</li> <li>workflow files: here</li> <li>runs from all workflows: here</li> </ul>"},{"location":"modules/proxy-connect/#error-log","title":"Error Log","text":"<p>This module logs its own error message beginning with <code>\"proxy_connect:\"</code> string. Some typical error logs are shown as following:</p> <ul> <li>The proxy_connect module tries to establish tunnel connection with backend server, but the TCP connection timeout occurs.</li> </ul> <pre><code>2019/08/07 17:27:20 [error] 19257#0: *1 proxy_connect: upstream connect timed out (peer:216.58.200.4:443) while connecting to upstream, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\", host: \"www.google.com:443\"\n</code></pre>"},{"location":"modules/proxy-connect/#directive","title":"Directive","text":""},{"location":"modules/proxy-connect/#proxy_connect","title":"proxy_connect","text":"<p>Syntax: proxy_connect Default: <code>none</code> Context: <code>server</code> </p> <p>Enable \"CONNECT\" HTTP method support.</p>"},{"location":"modules/proxy-connect/#proxy_connect_allow","title":"proxy_connect_allow","text":"<p>Syntax: proxy_connect_allow <code>all | [port ...] | [port-range ...]</code> Default: <code>443 563</code> Context: <code>server</code> </p> <p>This directive specifies a list of port numbers or ranges to which the proxy CONNECT method may connect. By default, only the default https port (443) and the default snews port (563) are enabled. Using this directive will override this default and allow connections to the listed ports only.</p> <p>The value <code>all</code> will allow all ports to proxy.</p> <p>The value <code>port</code> will allow specified port to proxy.</p> <p>The value <code>port-range</code> will allow specified range of port to proxy, for example:</p> <pre><code>proxy_connect_allow 1000-2000 3000-4000; # allow range of port from 1000 to 2000, from 3000 to 4000.\n</code></pre>"},{"location":"modules/proxy-connect/#proxy_connect_connect_timeout","title":"proxy_connect_connect_timeout","text":"<p>Syntax: proxy_connect_connect_timeout <code>time</code> Default: <code>none</code> Context: <code>server</code> </p> <p>Defines a timeout for establishing a connection with a proxied server.</p>"},{"location":"modules/proxy-connect/#proxy_connect_data_timeout","title":"proxy_connect_data_timeout","text":"<p>Syntax: proxy_connect_data_timeout <code>time</code> Default: <code>60s</code> Context: <code>server</code> </p> <p>Sets the timeout between two successive read or write operations on client or proxied server connections. If no data is transmitted within this time, the connection is closed.</p>"},{"location":"modules/proxy-connect/#proxy_connect_read_timeout","title":"proxy_connect_read_timeout","text":"<p>Syntax: proxy_connect_read_timeout <code>time</code> Default: <code>60s</code> Context: <code>server</code> </p> <p>Deprecated.</p> <p>It has the same function as the directive <code>proxy_connect_data_timeout</code> for compatibility. You can configure only one of the directives (<code>proxy_connect_data_timeout</code> or <code>proxy_connect_read_timeout</code>).</p>"},{"location":"modules/proxy-connect/#proxy_connect_send_timeout","title":"proxy_connect_send_timeout","text":"<p>Syntax: proxy_connect_send_timeout <code>time</code> Default: <code>60s</code> Context: <code>server</code> </p> <p>Deprecated.</p> <p>It has no function.</p>"},{"location":"modules/proxy-connect/#proxy_connect_address","title":"proxy_connect_address","text":"<p>Syntax: proxy_connect_address <code>address | off</code> Default: <code>none</code> Context: <code>server</code> </p> <p>Specifiy an IP address of the proxied server. The address can contain variables. The special value off is equal to none, which uses the IP address resolved from host name of CONNECT request line.  </p> <p>NOTE: If using <code>set $&lt;nginx variable&gt;</code> and <code>proxy_connect_address $&lt;nginx variable&gt;</code> together, you should use <code>proxy_connect_rewrite.patch</code> instead, see Install for more details.</p>"},{"location":"modules/proxy-connect/#proxy_connect_bind","title":"proxy_connect_bind","text":"<p>Syntax: proxy_connect_bind <code>address [transparent] | off</code> Default: <code>none</code> Context: <code>server</code> </p> <p>Makes outgoing connections to a proxied server originate from the specified local IP address with an optional port. Parameter value can contain variables. The special value off is equal to none, which allows the system to auto-assign the local IP address and port.</p> <p>The transparent parameter allows outgoing connections to a proxied server originate from a non-local IP address, for example, from a real IP address of a client:</p> <pre><code>proxy_connect_bind $remote_addr transparent;\n</code></pre> <p>In order for this parameter to work, it is usually necessary to run nginx worker processes with the superuser privileges. On Linux it is not required (1.13.8) as if the transparent parameter is specified, worker processes inherit the CAP_NET_RAW capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the proxied server.</p> <p>NOTE: If using <code>set $&lt;nginx variable&gt;</code> and <code>proxy_connect_bind $&lt;nginx variable&gt;</code> together, you should use <code>proxy_connect_rewrite.patch</code> instead, see Install for more details.</p>"},{"location":"modules/proxy-connect/#proxy_connect_response","title":"proxy_connect_response","text":"<p>Syntax: proxy_connect_response <code>CONNECT response</code> Default: <code>HTTP/1.1 200 Connection Established\\r\\nProxy-agent: nginx\\r\\n\\r\\n</code> Context: <code>server</code></p> <p>Set the response of CONNECT request.</p> <p>Note that it is only used for CONNECT request, it cannot modify the data flow over CONNECT tunnel.</p> <p>For example:</p> <pre><code>proxy_connect_response \"HTTP/1.1 200 Connection Established\\r\\nProxy-agent: nginx\\r\\nX-Proxy-Connected-Addr: $connect_addr\\r\\n\\r\\n\";\n</code></pre> <p>The <code>curl</code> command test case with above config is as following:</p> <pre><code>$ curl https://github.com -sv -x localhost:3128\n* Connected to localhost (127.0.0.1) port 3128 (#0)\n* allocate connect buffer!\n* Establish HTTP proxy tunnel to github.com:443\n&gt; CONNECT github.com:443 HTTP/1.1\n&gt; Host: github.com:443\n&gt; User-Agent: curl/7.64.1\n&gt; Proxy-Connection: Keep-Alive\n&gt;\n&lt; HTTP/1.1 200 Connection Established            --.\n&lt; Proxy-agent: nginx                               | custom CONNECT response\n&lt; X-Proxy-Connected-Addr: 13.229.188.59:443      --'\n...\n</code></pre>"},{"location":"modules/proxy-connect/#variables","title":"Variables","text":""},{"location":"modules/proxy-connect/#connect_host","title":"$connect_host","text":"<p>host name from CONNECT request line.</p>"},{"location":"modules/proxy-connect/#connect_port","title":"$connect_port","text":"<p>port from CONNECT request line.</p>"},{"location":"modules/proxy-connect/#connect_addr","title":"$connect_addr","text":"<p>IP address and port of the remote host, e.g. \"192.168.1.5:12345\". IP address is resolved from host name of CONNECT request line.</p>"},{"location":"modules/proxy-connect/#proxy_connect_connect_timeout_1","title":"$proxy_connect_connect_timeout","text":"<p>Get or set timeout of <code>proxy_connect_connect_timeout</code> directive.</p> <p>For example:</p> <pre><code>## Set default value\n\nproxy_connect_connect_timeout   10s;\nproxy_connect_data_timeout      10s;\n\n## Overlap default value\n\nif ($host = \"test.com\") {\n    set $proxy_connect_connect_timeout  \"10ms\";\n    set $proxy_connect_data_timeout     \"10ms\";\n}\n</code></pre>"},{"location":"modules/proxy-connect/#proxy_connect_data_timeout_1","title":"$proxy_connect_data_timeout","text":"<p>Get or set a timeout of <code>proxy_connect_data_timeout</code> directive.</p>"},{"location":"modules/proxy-connect/#proxy_connect_read_timeout_1","title":"$proxy_connect_read_timeout","text":"<p>Deprecated.  It still can get or set a timeout of <code>proxy_connect_data_timeout</code> directive for compatibility.</p>"},{"location":"modules/proxy-connect/#proxy_connect_send_timeout_1","title":"$proxy_connect_send_timeout","text":"<p>Deprecated. It has no function.</p>"},{"location":"modules/proxy-connect/#proxy_connect_resolve_time","title":"$proxy_connect_resolve_time","text":"<p>Keeps time spent on name resolving; the time is kept in seconds with millisecond resolution.</p> <ul> <li>Value of \"\" means this module does not work on this request.</li> <li>Value of \"-\" means name resolving failed.</li> </ul>"},{"location":"modules/proxy-connect/#proxy_connect_connect_time","title":"$proxy_connect_connect_time","text":"<p>Keeps time spent on establishing a connection with the upstream server; the time is kept in seconds with millisecond resolution.</p> <ul> <li>Value of \"\" means this module does not work on this request.</li> <li>Value of \"-\" means name resolving or connecting failed.</li> </ul>"},{"location":"modules/proxy-connect/#proxy_connect_first_byte_time","title":"$proxy_connect_first_byte_time","text":"<p>Keeps time to receive the first byte of data from the upstream server; the time is kept in seconds with millisecond resolution.</p> <ul> <li>Value of \"\" means this module does not work on this request.</li> <li>Value of \"-\" means name resolving, connecting or receving failed.</li> </ul>"},{"location":"modules/proxy-connect/#proxy_connect_response_1","title":"$proxy_connect_response","text":"<p>Get or set the response of CONNECT request. The default response of CONNECT request is \"HTTP/1.1 200 Connection Established\\r\\nProxy-agent: nginx\\r\\n\\r\\n\".</p> <p>Note that it is only used for CONNECT request, it cannot modify the data flow over CONNECT tunnel.</p> <p>For example:</p> <pre><code>## modify default Proxy-agent header\nset $proxy_connect_response \"HTTP/1.1 200\\r\\nProxy-agent: nginx/1.19\\r\\n\\r\\n\";\n</code></pre> <p>The variable value does not support nginx variables. You can use lua-nginx-module to construct string that contains nginx variable. For example:</p> <pre><code>## The CONNECT response may be \"HTTP/1.1 200\\r\\nProxy-agent: nginx/1.19.6\\r\\n\\r\\n\"\n\nrewrite_by_lua '\n    ngx.var.proxy_connect_response =\n      string.format(\"HTTP/1.1 200\\\\r\\\\nProxy-agent: nginx/%s\\\\r\\\\n\\\\r\\\\n\", ngx.var.nginx_version)\n';\n</code></pre> <p>Also note that <code>set</code> or <code>rewrite_by_lua*</code> directive is run during the REWRITE phase, which is ahead of dns resolving phase. It cannot get right value of some variables, for example, <code>$connect_addr</code> value is <code>nil</code>. In such case, you should use <code>proxy_connect_response</code> directive instead.</p>"},{"location":"modules/proxy-connect/#compatibility","title":"Compatibility","text":""},{"location":"modules/proxy-connect/#nginx-compatibility","title":"Nginx Compatibility","text":"<p>The latest module is compatible with the following versions of nginx:</p> <ul> <li>1.27.1  (mainline version of 1.27.x)</li> <li>1.26.2  (version of 1.26.x)</li> <li>1.24.0  (version of 1.24.x)</li> <li>1.22.1  (version of 1.22.x)</li> <li>1.20.2  (version of 1.20.x)</li> <li>1.18.0  (version of 1.18.x)</li> <li>1.16.1  (version of 1.16.x)</li> <li>1.14.2  (version of 1.14.x)</li> <li>1.12.1  (version of 1.12.x)</li> <li>1.10.3  (version of 1.10.x)</li> <li>1.8.1   (version of 1.8.x)</li> <li>1.6.3   (version of 1.6.x)</li> <li>1.4.7   (version of 1.4.x)</li> </ul>"},{"location":"modules/proxy-connect/#openresty-compatibility","title":"OpenResty Compatibility","text":"<p>The latest module is compatible with the following versions of OpenResty:</p> <ul> <li>1.25.3 (version: 1.25.3.1)</li> <li>1.21.4 (version: 1.21.4.3)</li> <li>1.19.3 (version: 1.19.3.1)</li> <li>1.17.8 (version: 1.17.8.2)</li> <li>1.15.8 (version: 1.15.8.1)</li> <li>1.13.6 (version: 1.13.6.2)</li> </ul>"},{"location":"modules/proxy-connect/#tengine-compatibility","title":"Tengine Compatibility","text":"<p>This module has been integrated into Tengine 2.3.0.  </p> <ul> <li>Tengine ngx_http_proxy_connect_module documentation</li> <li>Merged pull request for Tengine 2.3.0.</li> </ul>"},{"location":"modules/proxy-connect/#faq","title":"FAQ","text":"<p>See FAQ page.</p>"},{"location":"modules/proxy-connect/#known-issues","title":"Known Issues","text":"<ul> <li>In HTTP/2, the CONNECT method is not supported. It only supports the CONNECT method request in HTTP/1.x and HTTPS.</li> </ul>"},{"location":"modules/proxy-connect/#see-also","title":"See Also","text":"<ul> <li>HTTP tunnel - Wikipedia</li> <li>CONNECT method in HTTP/1.1</li> <li>CONNECT method in HTTP/2</li> </ul>"},{"location":"modules/proxy-connect/#author","title":"Author","text":"<ul> <li>Peng Qi: original author. He contributed this module to Tengine in this pull request.  </li> <li>Xiaochen Wang: current maintainer. Rebuild this module for nginx.</li> </ul>"},{"location":"modules/proxy-connect/#license","title":"LICENSE","text":"<p>See LICENSE for details.</p>"},{"location":"modules/proxy-connect/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-proxy-connect.</p>"},{"location":"modules/pta/","title":"pta: Period of Time Authentication module for NGINX","text":""},{"location":"modules/pta/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-pta\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-pta\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_pta_module.so;\n</code></pre> <p>This document describes nginx-module-pta v1.0.2  released on Jan 07 2025.</p>"},{"location":"modules/pta/#overview","title":"Overview","text":"<p>PTA(Period of Time Authentication) module is a module for NGINX. Using PTA you can control access to your contents. PTA calcurates a encrypted query string or cookie parameter that includes an expiration time and a path of the content.</p>"},{"location":"modules/pta/#usage","title":"Usage","text":"<p>It's an example of nginx.conf below.</p> <pre><code>  worker_processes  1;\n\n  events {\n      worker_connections  1024;\n  }\n\n\n  http {\n      include       mime.types;\n      default_type  application/octet-stream;\n\n      sendfile        on;\n\n      keepalive_timeout  65;\n\n      server {\n          listen       80;\n          server_name  localhost;\n\n          pta_1st_key 0102030405060708090a0b0c0d0e0f00;\n          pta_1st_iv  00000000000000000000000000000000;\n          pta_2nd_key 11111111111111111111111111111111;\n          pta_2nd_iv  22222222222222222222222222222222;\n\n          location / {\n              root   html;\n              index  index.html index.htm;\n          }\n\n          location /foo/ {\n              pta_enable on;\n          }\n\n          error_page   500 502 503 504  /50x.html;\n          location = /50x.html {\n              root   html;\n          }\n      }\n  }\n</code></pre>"},{"location":"modules/pta/#pta_1st_key","title":"pta_1st_key","text":"<ul> <li>Syntax  : pta_1st_key   keystring</li> <li>Default : -</li> <li>Context : server</li> </ul>"},{"location":"modules/pta/#pta_1st_iv","title":"pta_1st_iv","text":"<ul> <li>Syntax  : pta_1st_iv   ivstring;</li> <li>Default : -</li> <li>Context : server</li> </ul>"},{"location":"modules/pta/#pta_2nd_key","title":"pta_2nd_key","text":"<ul> <li>Syntax  : pta_2nd_key   keystring;</li> <li>Default : -</li> <li>Context : server</li> </ul>"},{"location":"modules/pta/#pta_2nd_iv","title":"pta_2nd_iv","text":"<ul> <li>Syntax  : pta_2nd_iv   ivstring;</li> <li>Default : -</li> <li>Context : server</li> </ul>"},{"location":"modules/pta/#pta_enable","title":"pta_enable","text":"<ul> <li>Syntax  : pta_enable   on | off;</li> <li>Default : pta_enable off;</li> <li>Context : location</li> </ul>"},{"location":"modules/pta/#pta_auth_method","title":"pta_auth_method","text":"<ul> <li>Syntax  : pta_auth_method qs | cookie | qs cookie;</li> <li>Default : pta_auth_method qs;</li> <li>Context : location</li> </ul>"},{"location":"modules/pta/#how-it-works","title":"How it works","text":"<p>PTA module decrypts a query string or cookie parameter starting from `pta=...' and check CRC32, expiration time and requested URI path embedded in it. So you need to generate PTA token and add it to a link as query string or cookie parameter. There are some codes under the smaples directory to generate PTA.</p>"},{"location":"modules/pta/#format","title":"format","text":"<p>This byte stream is encrypted with the AES AES 128 bit CBC mode.</p> <pre><code>  +---------------+-------------------------+----------+-----------------+\n  | CRC32 (4byte) | Expiration Time (8byte) | URI Path | Padding         |\n  |               | Unix Time format        |          | pkcs #7 format  |\n  +---------------+-------------------------+----------+-----------------+\n</code></pre>"},{"location":"modules/pta/#crc32","title":"CRC32","text":"<p>It's big endian. It's calculated from the Expiration Time and URI Path. This part is used to check that AES decryption is valid.</p>"},{"location":"modules/pta/#expiration-time","title":"Expiration time","text":"<p>It's big endian. It's compared with the time that request is arrived and if the time is less than or equal to the expiration time that is contained in the PTA token the request is permitted.</p>"},{"location":"modules/pta/#uri-path","title":"URI Path","text":"<p>Basically it must be identical with the path of requested content.</p> <p>e.g.   http://example.com/index.html -&gt; /index.html</p> <p>It must be started from the slash `/'.</p> <p>The asterisk character `*' means wildcard.</p> <ul> <li> <p>The `*' character must be only one.   e.g. /foo/*/bar/*.jpg isn't allowed.</p> </li> <li> <p>You can use the `*' character any part such as a part of directory   name, file name or file name suffix.</p> </li> <li> <p>If you use the `*' character literally, you must escape it with the   back slash.</p> </li> </ul>"},{"location":"modules/pta/#query-string-and-cookie","title":"Query string and Cookie","text":"<p>pta_auth_method directive can specify the method to authenticate.  You can choose the type of query string, cookie, or both as the method.</p> <p>In case of both, query string is evaluated first, and then cookie is done if pta parameter isn't included in query string. When pta parameter in query string isn't valid the authentication  fails, not fallback to ealuate cookie. Only without pta parameter in query string cookie is evaluated.</p>"},{"location":"modules/pta/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-pta.</p>"},{"location":"modules/push-stream/","title":"push-stream: NGINX push stream module","text":""},{"location":"modules/push-stream/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-push-stream\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-push-stream\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_push_stream_module.so;\n</code></pre> <p>This document describes nginx-module-push-stream v0.6.0  released on May 09 2024.</p>"},{"location":"modules/push-stream/#nginx-push-stream-module","title":"Nginx Push Stream Module","text":"<p>A pure stream http push technology for your Nginx setup.</p> <p>Comet made easy and really scalable.</p> <p>Supports EventSource, WebSocket, Long Polling, and Forever Iframe. See some examples bellow.</p> <p>Available on github at nginx_push_stream_module h1. Changelog Always take a look at CHANGELOG.textile to see what\u2019s new.</p> <p>h1. Contribute After you try this module and like it, feel free to give something back, and help in the maintenance of the project ;) :donate h1. Status This module is considered production ready. h1. Basic Configuration \\&lt;pre&gt;  # add the push_stream_shared_memory_size to your http context  http {  push_stream_shared_memory_size 32M;  # define publisher and subscriber endpoints in your server context  server {  location /channels-stats {  # activate channels statistics mode for this location  push_stream_channels_statistics;  # query string based channel id  push_stream_channels_path \\$arg_id;  }  location /pub {  # activate publisher mode for this location  push_stream_publisher admin;  # query string based channel id  push_stream_channels_path \\$arg_id;  }  location \\~ /sub/ {  # activate subscriber mode for this location  push_stream_subscriber;  # positional channel path  push_stream_channels_path \\$1;  }  }  } \\&lt;/pre&gt;</p> <p>h1. Basic Usage You can feel the flavor right now at the command line. Try using more than one terminal and start playing http pubsub: \\&lt;pre&gt;  # Subs  curl ~~s~~v \u2014no-buffer \u2018http://localhost/sub/my_channel_1\u2019  curl ~~s~~v \u2014no-buffer \u2018http://localhost/sub/your_channel_1\u2019  curl ~~s~~v \u2014no-buffer \u2018http://localhost/sub/your_channel_2\u2019  # Pubs  curl ~~s~~v ~~X POST \u2018http://localhost/pub?id=my_channel_1\u2019~~d \u2018Hello World\u2019  curl ~~s~~v ~~X POST \u2018http://localhost/pub?id=your_channel_2\u2019~~d \u2018Goodbye!\u2019  # Channels Stats for publisher  curl ~~s~~v \u2018http://localhost/pub?id=my_channel_1\u2019  # All Channels Stats summarized  curl ~~s~~v \u2018http://localhost/channels-stats\u2019  # All Channels Stats detailed  curl ~~s~~v \u2018http://localhost/channels-stats?id=ALL\u2019  # Prefixed Channels Stats detailed  curl ~~s~~v \u2019http://localhost/channels-stats?id=your_channel***\u2018  # Channels Stats (json format)  curl ~~s~~v \u2019http://localhost/channels-stats?id=my_channel_1\u2019  # Delete Channels  curl ~~s~~v -X DELETE \u2018http://localhost/pub?id=my_channel_1\u2019 \\&lt;/pre&gt;</p> <p>h1. Some Examples   ** Curl examples * Forever (hidden) iFrame * Event Source * WebSocket * Long Polling * JSONP * M-JPEG * Other examples</p>"},{"location":"modules/push-stream/#faq","title":"FAQ","text":"<p>Doubts?! Check the FAQ.</p>"},{"location":"modules/push-stream/#bug-report","title":"Bug report","text":"<p>To report a bug, please provide the following information when applicable</p> <ol> <li>Which push stream module version is been used (commit sha1)?</li> <li>Which nginx version is been used?</li> <li>Nginx configuration in use</li> <li> <p>\u201cnginx ~~V\" command outuput     # Core dump indicating a failure on the module code. Check here how to produce one.     # Step by step description to reproduce the error.     h1. Who is using the module?       Do you use this module? Put your name on the list.</p> <p>h1. Javascript Client   There is a javascript client implementation here, which is framework independent. Try and help improve it. ;) h1. Directives  Defining locations, Main configuration, Subscribers configuration, Publishers configuration, Channels Statistics configuration, WebSocket configuration . | Directive | | | | | | | | push_stream_channels_statistics | \u00a0\u00a0x | \u00a0\u00a0~~ | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_publisher\u201c:push_stream_publisher | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_subscriber\u201c:push_stream_subscriber | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_shared_memory_size\u201c:push_stream_shared_memory_size | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_channel_deleted_message_text\u201c:push_stream_channel_deleted_message_text | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_channel_inactivity_time\u201c:push_stream_channel_inactivity_time | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_ping_message_text\u201c:push_stream_ping_message_text | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_timeout_with_body\u201c:push_stream_timeout_with_body | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_message_ttl\u201c:push_stream_message_ttl | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_max_subscribers_per_channel\u201c:push_stream_max_subscribers_per_channel | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_max_messages_stored_per_channel\u201c:push_stream_max_messages_stored_per_channel | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_max_channel_id_length\u201c:push_stream_max_channel_id_length | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_max_number_of_channels\u201c:push_stream_max_number_of_channels | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_max_number_of_wildcard_channels\u201c:push_stream_max_number_of_wildcard_channels | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_wildcard_channel_prefix\u201c:push_stream_wildcard_channel_prefix | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_events_channel_id\u201c:push_stream_events_channel_id | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_channels_path\u201c:push_stream_channels_path | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0x | \u00a0\u00a0x | \u00a0\u00a0x | |\u201dpush_stream_store_messages\u201c:push_stream_store_messages | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_channel_info_on_publish\u201c:push_stream_channel_info_on_publish | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_authorized_channels_only\u201c:push_stream_authorized_channels_only | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_header_template_file\u201c:push_stream_header_template_file | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_header_template\u201c:push_stream_header_template | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_message_template\u201c:push_stream_message_template | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_footer_template\u201c:push_stream_footer_template | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_wildcard_channel_max_qtd\u201c:push_stream_wildcard_channel_max_qtd | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_ping_message_interval\u201c:push_stream_ping_message_interval | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_subscriber_connection_ttl\u201c:push_stream_subscriber_connection_ttl | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_longpolling_connection_ttl\u201c:push_stream_longpolling_connection_ttl | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_websocket_allow_publish\u201c:push_stream_websocket_allow_publish | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | |\u201dpush_stream_last_received_message_time\u201c:push_stream_last_received_message_time | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_last_received_message_tag\u201c:push_stream_last_received_message_tag | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_last_event_id\u201c:push_stream_last_event_id | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_user_agent\u201c:push_stream_user_agent | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_padding_by_user_agent\u201c:push_stream_padding_by_user_agent | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_allowed_origins\u201c:push_stream_allowed_origins | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0- | |\u201dpush_stream_allow_connections_to_events_channel\u201c:push_stream_allow_connections_to_events_channel | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | \u00a0\u00a0- | \u00a0\u00a0- | \u00a0\u00a0x | h1(#installation). Installation   \\&lt;pre&gt;  # clone the project  git clone https://github.com/wandenberg/nginx-push-stream-module.git  NGINX_PUSH_STREAM_MODULE_PATH=\\$PWD/nginx-push-stream-module  # get desired nginx version (works with 1.2.0+)  wget http://nginx.org/download/nginx-1.2.0.tar.gz  # unpack, configure and build  tar xzvf nginx-1.2.0.tar.gz  cd nginx-1.2.0  ./configure \u2014add-module=../nginx-push-stream-module  make  # install and finish  sudo make install  # check  sudo /usr/local/nginx/sbin/nginx ~~v  nginx version: nginx/1.2.0  # test configuration  sudo /usr/local/nginx/sbin/nginx~~c \\$NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf ~~t  the configuration file \\$NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf syntax is ok  configuration file \\$NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf test is successful  # run  sudo /usr/local/nginx/sbin/nginx~~c \\$NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf \\&lt;/pre&gt; h1(#memory-usage). Memory usage Just as information is listed below the minimum amount of memory used for each object: * message on shared = 200 bytes * channel on shared = 270 bytes * subscriber  * on shared = 160 bytes * on system = 6550 bytes h1(#tests). Tests The server tests for this module are written in Ruby, and are acceptance tests, click\u201dhere\u201c:tests for more details. h1(#discussion). Discussion Nginx Push Stream Module\u201dDiscussion Group\u201c:discussion h1(#contributors). Contributors \u201dPeople\":contributors</p> </li> </ol> <p>[discussion]https://groups.google.com/group/nginxpushstream [donate]https://www.paypal.com/cgi-bin/webscr?cmd=s-xclick&amp;hosted_button_id=4LP6P9A7BC37S http://dev.w3.org/html5/eventsource/ http://dev.w3.org/html5/websockets/ http://en.wikipedia.org/wiki/Comet28programming29 [installation]#installation [examples]#examples [javascript_client]docs/javascript_client.textile#javascript_client [repository]https://github.com/wandenberg/nginx-push-stream-module [contributors]https://github.com/wandenberg/nginx-push-stream-module/contributors [changelog]CHANGELOG.textile [curl]docs/examples/curl.textile#curl [forever_iframe]docs/examples/forever_iframe.textile#forever_iframe [event_source]docs/examples/event_source.textile#event_source [websocket]docs/examples/websocket.textile#websocket [long_polling]docs/examples/long_polling.textile#long_polling [jsonp]docs/examples/long_polling.textile#jsonp [m-jpeg]docs/examples/m_jpeg.textile#m_jpeg [tests]docs/server_tests.textile [push_stream_channels_statistics]docs/directives/channels_statistics.textile#push_stream_channels_statistics [push_stream_publisher]docs/directives/publishers.textile#push_stream_publisher [push_stream_subscriber]docs/directives/subscribers.textile#push_stream_subscriber [push_stream_shared_memory_size]docs/directives/main.textile#push_stream_shared_memory_size [push_stream_channel_deleted_message_text]docs/directives/main.textile#push_stream_channel_deleted_message_text [push_stream_ping_message_text]docs/directives/main.textile#push_stream_ping_message_text [push_stream_channel_inactivity_time]docs/directives/main.textile#push_stream_channel_inactivity_time [push_stream_message_ttl]docs/directives/main.textile#push_stream_message_ttl [push_stream_max_subscribers_per_channel]docs/directives/main.textile#push_stream_max_subscribers_per_channel [push_stream_max_messages_stored_per_channel]docs/directives/main.textile#push_stream_max_messages_stored_per_channel [push_stream_max_channel_id_length]docs/directives/main.textile#push_stream_max_channel_id_length [push_stream_max_number_of_channels]docs/directives/main.textile#push_stream_max_number_of_channels [push_stream_max_number_of_wildcard_channels]docs/directives/main.textile#push_stream_max_number_of_wildcard_channels [push_stream_wildcard_channel_prefix]docs/directives/main.textile#push_stream_wildcard_channel_prefix [push_stream_events_channel_id]docs/directives/main.textile#push_stream_events_channel_id [push_stream_channels_path]docs/directives/subscribers.textile#push_stream_channels_path [push_stream_authorized_channels_only]docs/directives/subscribers.textile#push_stream_authorized_channels_only [push_stream_header_template_file]docs/directives/subscribers.textile#push_stream_header_template_file [push_stream_header_template]docs/directives/subscribers.textile#push_stream_header_template [push_stream_message_template]docs/directives/subscribers.textile#push_stream_message_template [push_stream_footer_template]docs/directives/subscribers.textile#push_stream_footer_template [push_stream_wildcard_channel_max_qtd]docs/directives/subscribers.textile#push_stream_wildcard_channel_max_qtd [push_stream_ping_message_interval]docs/directives/subscribers.textile#push_stream_ping_message_interval [push_stream_subscriber_connection_ttl]docs/directives/subscribers.textile#push_stream_subscriber_connection_ttl [push_stream_longpolling_connection_ttl]docs/directives/subscribers.textile#push_stream_longpolling_connection_ttl [push_stream_timeout_with_body]docs/directives/subscribers.textile#push_stream_timeout_with_body [push_stream_last_received_message_time]docs/directives/subscribers.textile#push_stream_last_received_message_time [push_stream_last_received_message_tag]docs/directives/subscribers.textile#push_stream_last_received_message_tag [push_stream_last_event_id]docs/directives/subscribers.textile#push_stream_last_event_id [push_stream_user_agent]docs/directives/subscribers.textile#push_stream_user_agent [push_stream_padding_by_user_agent]docs/directives/subscribers.textile#push_stream_padding_by_user_agent [push_stream_store_messages]docs/directives/publishers.textile#push_stream_store_messages [push_stream_channel_info_on_publish]docs/directives/publishers.textile#push_stream_channel_info_on_publish [push_stream_allowed_origins]docs/directives/subscribers.textile#push_stream_allowed_origins [push_stream_websocket_allow_publish]docs/directives/subscribers.textile#push_stream_websocket_allow_publish [push_stream_allow_connections_to_events_channel]docs/directives/subscribers.textile#push_stream_allow_connections_to_events_channel [wiki]https://github.com/wandenberg/nginx-push-stream-module/wiki/_pages [nginx_debugging]http://wiki.nginx.org/Debugging</p>"},{"location":"modules/push-stream/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-push-stream.</p>"},{"location":"modules/rdns/","title":"[BETA!] rdns: NGINX HTTP rDNS module","text":""},{"location":"modules/rdns/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-rdns\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-rdns\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_rdns_module.so;\n</code></pre> <p>This document describes nginx-module-rdns v0  released on Jun 08 2020.</p> <p>Production stability is not guaranteed.</p>"},{"location":"modules/rdns/#summary","title":"Summary","text":"<p>This module allows to make a reverse DNS (rDNS) lookup for incoming connection and provides simple access control of incoming hostname by allow/deny rules (similar to HttpAccessModule allow/deny directives; regular expressions are supported). Module works with the DNS server defined by the standard resolver directive. This module uses nginx core resolver cache when resolving DNS lookup, for a maximum of 30 seconds or DNS response TTL.</p>"},{"location":"modules/rdns/#example","title":"Example","text":"<pre><code>location / {\n    resolver 127.0.0.1;\n\n    rdns_deny badone\\.example\\.com;\n\n    if ($http_user_agent ~* FooAgent) {\n        rdns on;\n    }\n\n    if ($rdns_hostname ~* (foo\\.example\\.com)) {\n        set $myvar foo;\n    }\n\n    #...\n}\n</code></pre> <p>In the example above, nginx will make a reverse DNS request (through the 127.0.0.1 DNS server) for each request having the \"FooAgent\" user agent. Requests from badone.example.com will be forbidden. The $rdns_hostname variable will have the rDNS request result or \"not found\" (in case it's not found or any error occured) for any requests made by FooAgent. For other user agents, $rdns_hostname will have a special value \"-\".</p>"},{"location":"modules/rdns/#directives","title":"Directives","text":""},{"location":"modules/rdns/#rdns","title":"rdns","text":"<ul> <li>Syntax: rdns on | off | double</li> <li>Default: -</li> <li>Context: http, server, location, if-in-server, if-in-location</li> <li>Phase: rewrite</li> <li>Variables: rdns_hostname</li> </ul> <p>Enables/disables rDNS lookups.</p> <ul> <li>on     - enable rDNS lookup in this context.</li> <li>double - enable double DNS lookup in this context. If the reverse            lookup (rDNS request) succeeded, module performs a forward            lookup (DNS request) for its result. If this forward            lookup has failed or none of the forward lookup IP            addresses have matched the original address,            $rdns_hostname is set to \"not found\".</li> <li>off    - disable rDNS lookup in this context.</li> </ul> <p>The $rdns_hostname variable may have:</p> <ul> <li>result of lookup;</li> <li>special value \"not found\" if not found or error occurred during   request;</li> <li>special value \"-\" if lookup disabled.</li> </ul> <p>After performing a lookup, module restarts request handling pipeline to make new $rdns_hostname variable value visible to other directives.</p> <p>Notice on server/location \"if\":</p> <p>Internally, in server's or location's \"if\", module works through rewrite module codes. When any enabling directive (rdns on|double) is executed for the first time, it enables DNS lookup and makes a break (to prevent executing further directives in this \"if\"). After the lookup is done, directives in \"if\" using rewrite module codes are executed for the second time, without any breaks. Disabling directive (rdns off) makes no breaks.</p> <p>Core module resolver should be defined to use this directive.</p>"},{"location":"modules/rdns/#rdns_allow","title":"rdns_allow","text":"<ul> <li>Syntax: rdns_allow regex</li> <li>Default: -</li> <li>Context: http, server, location</li> <li>Phase: access</li> <li>Variables: -</li> </ul> <p>Grants access for domain matched by regular expression.</p>"},{"location":"modules/rdns/#rdns_deny","title":"rdns_deny","text":"<ul> <li>Syntax: rdns_deny regex</li> <li>Default: -</li> <li>Context: http, server, location</li> <li>Phase: access</li> <li>Variables: -</li> </ul> <p>Forbids access for domain matched by regular expression.</p>"},{"location":"modules/rdns/#notice-on-access-lists","title":"Notice on access lists","text":"<p>The rdns_allow and rdns_deny directives define a new access list for the context in which they are used.</p> <p>Access list inheritance in contexts works only if child context doesn't define own rules.</p>"},{"location":"modules/rdns/#warning-on-named-locations","title":"Warning on named locations","text":"<p>Making rDNS requests in named locations isn't supported and may invoke a loop. For example:</p> <pre><code>server {\n    rdns on;\n\n    location / {\n        echo_exec @foo;\n    }\n\n    location @foo {\n        #...\n    }\n}\n</code></pre> <p>Being in a named location and restarting request handling pipeline, nginx continue its request handling in usual (unnamed) location. That's why this example will make a loop if you don't disable the module in your named location. The correct config for this example should be as follows:</p> <pre><code>server {\n    rdns on;\n\n    location / {\n        echo_exec @foo;\n    }\n\n    location @foo {\n        rdns off;\n        #...\n    }\n}\n</code></pre>"},{"location":"modules/rdns/#links","title":"Links","text":"<ul> <li>The source code on GitHub:   https://github.com/flant/nginx-http-rdns</li> <li>The module homepage (in Russian):   http://flant.ru/projects/nginx-http-rdns</li> </ul>"},{"location":"modules/rdns/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-rdns.</p>"},{"location":"modules/redis-rate-limit/","title":"redis-rate-limit: Redis backed rate limit module for Nginx","text":""},{"location":"modules/redis-rate-limit/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-redis-rate-limit\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-redis-rate-limit\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_rate_limit_module.so;\n</code></pre> <p>This document describes nginx-module-redis-rate-limit v1.0.0  released on Jul 16 2022.</p> <p></p> <p>A Redis backed rate limit module for Nginx web servers.</p> <p>This implementation is based on the following Redis module:</p> <ul> <li>redis-rate-limiter</li> </ul> <p>Which offers a straightforward implementation of the fairly sophisticated generic cell rate algorithm, in 130 lines of C, without external dependencies.</p>"},{"location":"modules/redis-rate-limit/#status","title":"Status","text":"<p>This module is production ready.</p>"},{"location":"modules/redis-rate-limit/#synopsis","title":"Synopsis","text":"<pre><code>upstream redis {\n   server 127.0.0.1:6379;\n\n   # Or: server unix:/var/run/redis/redis.sock;\n\n   # a pool with at most 1024 connections\n   keepalive 1024;\n}\n\ngeo $limit {\n    default 1;\n    10.0.0.0/8 0;\n    192.168.0.0/24 0;\n}\n\nmap $limit $limit_key {\n    0 \"\";\n    1 $remote_addr;\n}\n\nrate_limit_status 429;\n\nlocation = /limit {\n    rate_limit $limit_key requests=15 period=1m burst=20;\n    rate_limit_pass redis;\n}\n\nlocation = /limit_b {\n    rate_limit $limit_key requests=20 period=1m burst=25;\n    rate_limit_prefix b;\n    rate_limit_pass redis;\n}\n\nlocation = /quota {\n    rate_limit $limit_key requests=15 period=1m burst=20;\n    rate_limit_quantity 0;\n    rate_limit_pass redis;\n    rate_limit_headers on;\n}\n</code></pre>"},{"location":"modules/redis-rate-limit/#here-we-assume-you-would-install-you-nginx-under-optnginx","title":"Here we assume you would install you nginx under /opt/nginx/.","text":"<p>./configure --prefix=/opt/nginx \\             --add-module=rate-limit-nginx-module/</p> <p>make -j$(nproc) make install <pre><code>## Test suite\n\nThe following dependencies are required to run the test suite:\n\n* Nginx version &gt;= 1.9.11\n\n* Perl modules:\n    * [Test::Nginx](https://metacpan.org/pod/Test::Nginx::Socket)\n\n* Nginx modules:\n    * ngx_http_rate_limit_module (i.e., this module)\n\n* Redis modules:\n    * [redis-rate-limiter](https://github.com/onsigntv/redis-rate-limiter)\n\n* Applications:\n    * redis: listening on the default port, 6379.\n\nTo run the whole test suite in the default testing mode:\n```bash\ncd /path/to/rate-limit-nginx-module\nexport PATH=/path/to/your/nginx/sbin:$PATH\nprove -I/path/to/test-nginx/lib -r t\n</code></pre></p> <p>To run specific test files: <pre><code>cd /path/to/rate-limit-nginx-module\nexport PATH=/path/to/your/nginx/sbin:$PATH\nprove -I/path/to/test-nginx/lib t/sanity.t\n</code></pre></p> <p>To run a specific test block in a particular test file, add the line  <code>--- ONLY</code> to the test block you want to run, and then use the <code>prove</code>  utility to run that <code>.t</code> file.</p>"},{"location":"modules/redis-rate-limit/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-redis-rate-limit.</p>"},{"location":"modules/redis2/","title":"redis2: NGINX upstream module for the Redis 2.0 protocol","text":""},{"location":"modules/redis2/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-redis2\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-redis2\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_redis2_module.so;\n</code></pre> <p>This document describes nginx-module-redis2 v0.15  released on Apr 19 2018.</p> <p>ngx_redis2 - Nginx upstream module for the Redis 2.0 protocol</p>"},{"location":"modules/redis2/#status","title":"Status","text":"<p>This module is already production ready.</p>"},{"location":"modules/redis2/#synopsis","title":"Synopsis","text":"<pre><code> location = /foo {\n     set $value 'first';\n     redis2_query set one $value;\n     redis2_pass 127.0.0.1:6379;\n }\n\n # GET /get?key=some_key\n location = /get {\n     set_unescape_uri $key $arg_key;  # this requires ngx_set_misc\n     redis2_query get $key;\n     redis2_pass foo.com:6379;\n }\n\n # GET /set?key=one&amp;val=first%20value\n location = /set {\n     set_unescape_uri $key $arg_key;  # this requires ngx_set_misc\n     set_unescape_uri $val $arg_val;  # this requires ngx_set_misc\n     redis2_query set $key $val;\n     redis2_pass foo.com:6379;\n }\n\n # multiple pipelined queries\n location = /foo {\n     set $value 'first';\n     redis2_query set one $value;\n     redis2_query get one;\n     redis2_query set one two;\n     redis2_query get one;\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /bar {\n     # $ is not special here...\n     redis2_literal_raw_query '*1\\r\\n$4\\r\\nping\\r\\n';\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /bar {\n     # variables can be used below and $ is special\n     redis2_raw_query 'get one\\r\\n';\n     redis2_pass 127.0.0.1:6379;\n }\n\n # GET /baz?get%20foo%0d%0a\n location = /baz {\n     set_unescape_uri $query $query_string; # this requires the ngx_set_misc module\n     redis2_raw_query $query;\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /init {\n     redis2_query del key1;\n     redis2_query lpush key1 C;\n     redis2_query lpush key1 B;\n     redis2_query lpush key1 A;\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /get {\n     redis2_query lrange key1 0 -1;\n     redis2_pass 127.0.0.1:6379;\n }\n</code></pre>"},{"location":"modules/redis2/#description","title":"Description","text":"<p>This is an Nginx upstream module that makes nginx talk to a Redis 2.x server in a non-blocking way. The full Redis 2.0 unified protocol has been implemented including the Redis pipelining support.</p> <p>This module returns the raw TCP response from the Redis server. It's recommended to use my lua-redis-parser (written in pure C) to parse these responses into lua data structure when combined with lua-nginx-module.</p> <p>When used in conjunction with lua-nginx-module, it is recommended to use the lua-resty-redis library instead of this module though, because the former is much more flexible and memory-efficient.</p> <p>If you only want to use the <code>get</code> redis command, you can try out the HttpRedisModule. It returns the parsed content part of the Redis response because only <code>get</code> is needed to implement.</p> <p>Another option is to parse the redis responses on your client side yourself.</p>"},{"location":"modules/redis2/#directives","title":"Directives","text":""},{"location":"modules/redis2/#redis2_query","title":"redis2_query","text":"<p>syntax: redis2_query cmd arg1 arg2 ...</p> <p>default: no</p> <p>context: location, location if</p> <p>Specify a Redis command by specifying its individual arguments (including the Redis command name itself) in a similar way to the <code>redis-cli</code> utility.</p> <p>Multiple instances of this directive are allowed in a single location and these queries will be pipelined. For example,</p> <pre><code> location = /pipelined {\n     redis2_query set hello world;\n     redis2_query get hello;\n\n     redis2_pass 127.0.0.1:$TEST_NGINX_REDIS_PORT;\n }\n</code></pre> <p>then <code>GET /pipelined</code> will yield two successive raw Redis responses</p> <pre><code> +OK\n $5\n world\n</code></pre> <p>while newlines here are actually <code>CR LF</code> (<code>\\r\\n</code>).</p>"},{"location":"modules/redis2/#redis2_raw_query","title":"redis2_raw_query","text":"<p>syntax: redis2_raw_query QUERY</p> <p>default: no</p> <p>context: location, location if</p> <p>Specify raw Redis queries and nginx variables are recognized in the <code>QUERY</code> argument.</p> <p>Only one Redis command is allowed in the <code>QUERY</code> argument, or you'll receive an error. If you want to specify multiple pipelined commands in a single query, use the redis2_raw_queries directive instead.</p>"},{"location":"modules/redis2/#redis2_raw_queries","title":"redis2_raw_queries","text":"<p>syntax: redis2_raw_queries N QUERIES</p> <p>default: no</p> <p>context: location, location if</p> <p>Specify <code>N</code> commands in the <code>QUERIES</code> argument. Both the <code>N</code> and <code>QUERIES</code> arguments can take Nginx variables.</p> <p>Here's some examples <pre><code> location = /pipelined {\n     redis2_raw_queries 3 \"flushall\\r\\nget key1\\r\\nget key2\\r\\n\";\n     redis2_pass 127.0.0.1:6379;\n }\n\n # GET /pipelined2?n=2&amp;cmds=flushall%0D%0Aget%20key%0D%0A\n location = /pipelined2 {\n     set_unescape_uri $n $arg_n;\n     set_unescape_uri $cmds $arg_cmds;\n\n     redis2_raw_queries $n $cmds;\n\n     redis2_pass 127.0.0.1:6379;\n }\n</code></pre> Note that in the second sample above, the set_unescape_uri directive is provided by the set-misc-nginx-module.</p>"},{"location":"modules/redis2/#redis2_literal_raw_query","title":"redis2_literal_raw_query","text":"<p>syntax: redis2_literal_raw_query QUERY</p> <p>default: no</p> <p>context: location, location if</p> <p>Specify a raw Redis query but Nginx variables in it will not be not recognized. In other words, you're free to use the dollar sign character (<code>$</code>) in your <code>QUERY</code> argument.</p> <p>Only One redis command is allowed in the <code>QUERY</code> argument.</p>"},{"location":"modules/redis2/#redis2_pass","title":"redis2_pass","text":"<p>syntax: redis2_pass &lt;upstream_name&gt;</p> <p>syntax: redis2_pass &lt;host&gt;:&lt;port&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: content</p> <p>Specify the Redis server backend. </p>"},{"location":"modules/redis2/#redis2_connect_timeout","title":"redis2_connect_timeout","text":"<p>syntax: redis2_connect_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for connecting to the Redis server, in seconds by default.</p> <p>It's wise to always explicitly specify the time unit to avoid confusion. Time units supported are <code>s</code>(seconds), <code>ms</code>(milliseconds), <code>y</code>(years), <code>M</code>(months), <code>w</code>(weeks), <code>d</code>(days), <code>h</code>(hours), and <code>m</code>(minutes).</p> <p>This time must be less than 597 hours.</p>"},{"location":"modules/redis2/#redis2_send_timeout","title":"redis2_send_timeout","text":"<p>syntax: redis2_send_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for sending TCP requests to the Redis server, in seconds by default.</p> <p>It's wise to always explicitly specify the time unit to avoid confusion. Time units supported are <code>s</code>(seconds), <code>ms</code>(milliseconds), <code>y</code>(years), <code>M</code>(months), <code>w</code>(weeks), <code>d</code>(days), <code>h</code>(hours), and <code>m</code>(minutes).</p>"},{"location":"modules/redis2/#redis2_read_timeout","title":"redis2_read_timeout","text":"<p>syntax: redis2_read_timeout &lt;time&gt;</p> <p>default: 60s</p> <p>context: http, server, location</p> <p>The timeout for reading TCP responses from the redis server, in seconds by default.</p> <p>It's wise to always explicitly specify the time unit to avoid confusion. Time units supported are <code>s</code>(seconds), <code>ms</code>(milliseconds), <code>y</code>(years), <code>M</code>(months), <code>w</code>(weeks), <code>d</code>(days), <code>h</code>(hours), and <code>m</code>(minutes).</p>"},{"location":"modules/redis2/#redis2_buffer_size","title":"redis2_buffer_size","text":"<p>syntax: redis2_buffer_size &lt;size&gt;</p> <p>default: 4k/8k</p> <p>context: http, server, location</p> <p>This buffer size is used for reading Redis replies, but it's not required to be as big as the largest possible Redis reply.</p> <p>This default size is the page size, may be 4k or 8k.</p>"},{"location":"modules/redis2/#redis2_next_upstream","title":"redis2_next_upstream","text":"<p>syntax: redis2_next_upstream [ error | timeout | invalid_response | off ]</p> <p>default: error timeout</p> <p>context: http, server, location</p> <p>Specify which failure conditions should cause the request to be forwarded to another upstream server. Applies only when the value in redis2_pass is an upstream with two or more servers.</p> <p>Here's an artificial example: <pre><code> upstream redis_cluster {\n     server 127.0.0.1:6379;\n     server 127.0.0.1:6380;\n }\n\n server {\n     location = /redis {\n         redis2_next_upstream error timeout invalid_response;\n         redis2_query get foo;\n         redis2_pass redis_cluster;\n     }\n }\n</code></pre></p>"},{"location":"modules/redis2/#connection-pool","title":"Connection Pool","text":"<p>You can use the excellent HttpUpstreamKeepaliveModule with this module to provide TCP connection pool for Redis.</p> <p>A sample config snippet looks like this</p> <pre><code> http {\n     upstream backend {\n       server 127.0.0.1:6379;\n\n       # a pool with at most 1024 connections\n       # and do not distinguish the servers:\n       keepalive 1024;\n     }\n\n     server {\n         ...\n         location = /redis {\n             set_unescape_uri $query $arg_query;\n             redis2_query $query;\n             redis2_pass backend;\n         }\n     }\n }\n</code></pre>"},{"location":"modules/redis2/#selecting-redis-databases","title":"Selecting Redis Databases","text":"<p>Redis provides the select command to switch Redis databaess. This command is no different from other normal commands like get or set. So you can use them in redis2_query directives, for example,</p> <pre><code>redis2_query select 8;\nredis2_query get foo;\n</code></pre>"},{"location":"modules/redis2/#lua-interoperability","title":"Lua Interoperability","text":"<p>This module can be served as a non-blocking redis2 client for lua-nginx-module (but nowadays it is recommended to use the lua-resty-redis library instead, which is much simpler to use and more efficient most of the time). Here's an example using a GET subrequest:</p> <pre><code> location = /redis {\n     internal;\n\n     # set_unescape_uri is provided by ngx_set_misc\n     set_unescape_uri $query $arg_query;\n\n     redis2_raw_query $query;\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /main {\n     content_by_lua '\n         local res = ngx.location.capture(\"/redis\",\n             { args = { query = \"ping\\\\r\\\\n\" } }\n         )\n         ngx.print(\"[\" .. res.body .. \"]\")\n     ';\n }\n</code></pre> <p>Then accessing <code>/main</code> yields</p> <pre><code>[+PONG\\r\\n]\n</code></pre> <p>where <code>\\r\\n</code> is <code>CRLF</code>. That is, this module returns the raw TCP responses from the remote redis server. For Lua-based application developers, they may want to utilize the lua-redis-parser library (written in pure C) to parse such raw responses into Lua data structures.</p> <p>When moving the inlined Lua code into an external <code>.lua</code> file, it's important to use the escape sequence <code>\\r\\n</code> directly. We used <code>\\\\r\\\\n</code> above just because the Lua code itself needs quoting when being put into an Nginx string literal.</p> <p>You can also use POST/PUT subrequests to transfer the raw Redis request via request body, which does not require URI escaping and unescaping, thus saving some CPU cycles. Here's such an example:</p> <pre><code> location = /redis {\n     internal;\n\n     # $echo_request_body is provided by the ngx_echo module\n     redis2_raw_query $echo_request_body;\n\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /main {\n     content_by_lua '\n         local res = ngx.location.capture(\"/redis\",\n             { method = ngx.HTTP_PUT,\n               body = \"ping\\\\r\\\\n\" }\n         )\n         ngx.print(\"[\" .. res.body .. \"]\")\n     ';\n }\n</code></pre> <p>This yeilds exactly the same output as the previous (GET) sample.</p> <p>One can also use Lua to pick up a concrete Redis backend based on some complicated hashing rules. For instance,</p> <pre><code> upstream redis-a {\n     server foo.bar.com:6379;\n }\n\n upstream redis-b {\n     server bar.baz.com:6379;\n }\n\n upstream redis-c {\n     server blah.blah.org:6379;\n }\n\n server {\n     ...\n\n     location = /redis {\n         set_unescape_uri $query $arg_query;\n         redis2_query $query;\n         redis2_pass $arg_backend;\n     }\n\n     location = /foo {\n         content_by_lua \"\n             -- pick up a server randomly\n             local servers = {'redis-a', 'redis-b', 'redis-c'}\n             local i = ngx.time() % #servers + 1;\n             local srv = servers[i]\n\n             local res = ngx.location.capture('/redis',\n                 { args = {\n                     query = '...',\n                     backend = srv\n                   }\n                 }\n             )\n             ngx.say(res.body)\n         \";\n     }\n }\n</code></pre>"},{"location":"modules/redis2/#pipelined-redis-requests-by-lua","title":"Pipelined Redis Requests by Lua","text":"<p>Here's a complete example demonstrating how to use Lua to issue multiple pipelined Redis requests via this Nginx module.</p> <p>First of all, we include the following in our <code>nginx.conf</code> file:</p> <pre><code> location = /redis2 {\n     internal;\n\n     redis2_raw_queries $args $echo_request_body;\n     redis2_pass 127.0.0.1:6379;\n }\n\n location = /test {\n     content_by_lua_file conf/test.lua;\n }\n</code></pre> <p>Basically we use URI query args to pass the number of Redis requests and request body to pass the pipelined Redis request string.</p> <p>And then we create the <code>conf/test.lua</code> file (whose path is relative to the server root of Nginx) to include the following Lua code:</p> <pre><code> -- conf/test.lua\n local parser = require \"redis.parser\"\n\n local reqs = {\n     {\"set\", \"foo\", \"hello world\"},\n     {\"get\", \"foo\"}\n }\n\n local raw_reqs = {}\n for i, req in ipairs(reqs) do\n     table.insert(raw_reqs, parser.build_query(req))\n end\n\n local res = ngx.location.capture(\"/redis2?\" .. #reqs,\n     { body = table.concat(raw_reqs, \"\") })\n\n if res.status ~= 200 or not res.body then\n     ngx.log(ngx.ERR, \"failed to query redis\")\n     ngx.exit(500)\n end\n\n local replies = parser.parse_replies(res.body, #reqs)\n for i, reply in ipairs(replies) do\n     ngx.say(reply[1])\n end\n</code></pre> <p>Here we assume that your Redis server is listening on the default port (6379) of the localhost. We also make use of the lua-redis-parser library to construct raw Redis queries for us and also use it to parse the replies.</p> <p>Accessing the <code>/test</code> location via HTTP clients like <code>curl</code> yields the following output</p> <pre><code>OK\nhello world\n</code></pre> <p>A more realistic setting is to use a proper upstream definition for our Redis backend and enable TCP connection pool via the keepalive directive in it.</p>"},{"location":"modules/redis2/#redis-publishsubscribe-support","title":"Redis Publish/Subscribe Support","text":"<p>This module has limited support for Redis publish/subscribe feature. It cannot be fully supported due to the stateless nature of REST and HTTP model.</p> <p>Consider the following example:</p> <pre><code> location = /redis {\n     redis2_raw_queries 2 \"subscribe /foo/bar\\r\\n\";\n     redis2_pass 127.0.0.1:6379;\n }\n</code></pre> <p>And then publish a message for the key <code>/foo/bar</code> in the <code>redis-cli</code> command line. And then you'll receive two multi-bulk replies from the <code>/redis</code> location.</p> <p>You can surely parse the replies with the lua-redis-parser library if you're using Lua to access this module's location.</p>"},{"location":"modules/redis2/#limitations-for-redis-publishsubscribe","title":"Limitations For Redis Publish/Subscribe","text":"<p>If you want to use the Redis pub/sub feature with this module, then you must note the following limitations:</p> <ul> <li>You cannot use HttpUpstreamKeepaliveModule with this Redis upstream. Only short Redis connections will work.</li> <li>There may be some race conditions that produce the harmless <code>Redis server returned extra bytes</code> warnings in your nginx's error.log. Such warnings might be rare but just be prepared for it.</li> <li>You should tune the various timeout settings provided by this module like redis2_connect_timeout and redis2_read_timeout.</li> </ul> <p>If you cannot stand these limitations, then you are highly recommended to switch to the lua-resty-redis library for lua-nginx-module.</p>"},{"location":"modules/redis2/#performance-tuning","title":"Performance Tuning","text":"<ul> <li>When you're using this module, please ensure you're using a TCP connection pool (provided by HttpUpstreamKeepaliveModule) and Redis pipelining wherever possible. These features will significantly improve performance.</li> <li>Using multiple instance of Redis servers on your multi-core machines also help a lot due to the sequential processing nature of a single Redis server instance.</li> <li>When you're benchmarking performance using something like <code>ab</code> or <code>http_load</code>, please ensure that your error log level is high enough (like <code>warn</code>) to prevent Nginx workers spend too much cycles on flushing the <code>error.log</code> file, which is always non-buffered and blocking and thus very expensive.</li> </ul>"},{"location":"modules/redis2/#see-also","title":"SEE ALSO","text":"<ul> <li>The Redis server homepage.</li> <li>The Redis wire protocol: http://redis.io/topics/protocol</li> <li>a redis response parser and a request constructor for Lua: lua-redis-parser.</li> <li>lua-nginx-module</li> <li>The ngx_openresty bundle.</li> <li>The lua-resty-redis library based on the lua-nginx-module cosocket API.</li> </ul>"},{"location":"modules/redis2/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-redis2.</p>"},{"location":"modules/rtmp/","title":"rtmp: NGINX RTMP module","text":""},{"location":"modules/rtmp/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-rtmp\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-rtmp\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_rtmp_module.so;\n</code></pre> <p>This document describes nginx-module-rtmp v1.2.2  released on Jul 05 2025.</p>"},{"location":"modules/rtmp/#nginx-rtmp-module","title":"nginx-rtmp-module","text":""},{"location":"modules/rtmp/#project-blog","title":"Project blog","text":"<p>http://nginx-rtmp.blogspot.com</p>"},{"location":"modules/rtmp/#wiki-manual","title":"Wiki manual","text":"<p>https://github.com/arut/nginx-rtmp-module/wiki/Directives</p>"},{"location":"modules/rtmp/#google-group","title":"Google group","text":"<p>https://groups.google.com/group/nginx-rtmp</p> <p>https://groups.google.com/group/nginx-rtmp-ru (Russian)</p>"},{"location":"modules/rtmp/#features","title":"Features","text":"<ul> <li> <p>RTMP/HLS/MPEG-DASH live streaming</p> </li> <li> <p>RTMP Video on demand FLV/MP4,   playing from local filesystem or HTTP</p> </li> <li> <p>Stream relay support for distributed   streaming: push &amp; pull models</p> </li> <li> <p>Recording streams in multiple FLVs</p> </li> <li> <p>H264/AAC support</p> </li> <li> <p>Online transcoding with FFmpeg</p> </li> <li> <p>HTTP callbacks (publish/play/record/update etc)</p> </li> <li> <p>Running external programs on certain events (exec)</p> </li> <li> <p>HTTP control module for recording audio/video and dropping clients</p> </li> <li> <p>Advanced buffering techniques   to keep memory allocations at a minimum   level for faster streaming and low   memory footprint</p> </li> <li> <p>Proved to work with Wirecast, FMS, Wowza,   JWPlayer, FlowPlayer, StrobeMediaPlayback,   ffmpeg, avconv, rtmpdump, flvstreamer   and many more</p> </li> <li> <p>Statistics in XML/XSL in machine- &amp; human-   readable form</p> </li> <li> <p>Linux/FreeBSD/MacOS/Windows</p> </li> </ul>"},{"location":"modules/rtmp/#windows-limitations","title":"Windows limitations","text":"<p>Windows support is limited. These features are not supported</p> <ul> <li>execs</li> <li>static pulls</li> <li>auto_push</li> </ul>"},{"location":"modules/rtmp/#rtmp-url-format","title":"RTMP URL format","text":"<pre><code>rtmp://rtmp.example.com/app[/name]\n</code></pre> <p>app -  should match one of application {}          blocks in config</p> <p>name - interpreted by each application          can be empty</p>"},{"location":"modules/rtmp/#multi-worker-live-streaming","title":"Multi-worker live streaming","text":"<p>Module supports multi-worker live streaming through automatic stream pushing to nginx workers. This option is toggled with rtmp_auto_push directive.</p>"},{"location":"modules/rtmp/#example-nginxconf","title":"Example nginx.conf","text":"<pre><code>rtmp {\n\n    server {\n\n        listen 1935;\n\n        chunk_size 4000;\n\n        # TV mode: one publisher, many subscribers\n        application mytv {\n\n            # enable live streaming\n            live on;\n\n            # record first 1K of stream\n            record all;\n            record_path /tmp/av;\n            record_max_size 1K;\n\n            # append current timestamp to each flv\n            record_unique on;\n\n            # publish only from localhost\n            allow publish 127.0.0.1;\n            deny publish all;\n\n            #allow play all;\n        }\n\n        # Transcoding (ffmpeg needed)\n        application big {\n            live on;\n\n            # On every pusblished stream run this command (ffmpeg)\n            # with substitutions: $app/${app}, $name/${name} for application &amp; stream name.\n            #\n            # This ffmpeg call receives stream from this application &amp;\n            # reduces the resolution down to 32x32. The stream is the published to\n            # 'small' application (see below) under the same name.\n            #\n            # ffmpeg can do anything with the stream like video/audio\n            # transcoding, resizing, altering container/codec params etc\n            #\n            # Multiple exec lines can be specified.\n\n            exec ffmpeg -re -i rtmp://localhost:1935/$app/$name -vcodec flv -acodec copy -s 32x32\n                        -f flv rtmp://localhost:1935/small/${name};\n        }\n\n        application small {\n            live on;\n            # Video with reduced resolution comes here from ffmpeg\n        }\n\n        application webcam {\n            live on;\n\n            # Stream from local webcam\n            exec_static ffmpeg -f video4linux2 -i /dev/video0 -c:v libx264 -an\n                               -f flv rtmp://localhost:1935/webcam/mystream;\n        }\n\n        application mypush {\n            live on;\n\n            # Every stream published here\n            # is automatically pushed to\n            # these two machines\n            push rtmp1.example.com;\n            push rtmp2.example.com:1934;\n        }\n\n        application mypull {\n            live on;\n\n            # Pull all streams from remote machine\n            # and play locally\n            pull rtmp://rtmp3.example.com pageUrl=www.example.com/index.html;\n        }\n\n        application mystaticpull {\n            live on;\n\n            # Static pull is started at nginx start\n            pull rtmp://rtmp4.example.com pageUrl=www.example.com/index.html name=mystream static;\n        }\n\n        # video on demand\n        application vod {\n            play /var/flvs;\n        }\n\n        application vod2 {\n            play /var/mp4s;\n        }\n\n        # Many publishers, many subscribers\n        # no checks, no recording\n        application videochat {\n\n            live on;\n\n            # The following notifications receive all\n            # the session variables as well as\n            # particular call arguments in HTTP POST\n            # request\n\n            # Make HTTP request &amp; use HTTP retcode\n            # to decide whether to allow publishing\n            # from this connection or not\n            on_publish http://localhost:8080/publish;\n\n            # Same with playing\n            on_play http://localhost:8080/play;\n\n            # Publish/play end (repeats on disconnect)\n            on_done http://localhost:8080/done;\n\n            # All above mentioned notifications receive\n            # standard connect() arguments as well as\n            # play/publish ones. If any arguments are sent\n            # with GET-style syntax to play &amp; publish\n            # these are also included.\n            # Example URL:\n            #   rtmp://localhost/myapp/mystream?a=b&amp;c=d\n\n            # record 10 video keyframes (no audio) every 2 minutes\n            record keyframes;\n            record_path /tmp/vc;\n            record_max_frames 10;\n            record_interval 2m;\n\n            # Async notify about an flv recorded\n            on_record_done http://localhost:8080/record_done;\n\n        }\n\n\n        # HLS\n\n        # For HLS to work please create a directory in tmpfs (/tmp/hls here)\n        # for the fragments. The directory contents is served via HTTP (see\n        # http{} section in config)\n        #\n        # Incoming stream must be in H264/AAC. For iPhones use baseline H264\n        # profile (see ffmpeg example).\n        # This example creates RTMP stream from movie ready for HLS:\n        #\n        # ffmpeg -loglevel verbose -re -i movie.avi  -vcodec libx264\n        #    -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1\n        #    -f flv rtmp://localhost:1935/hls/movie\n        #\n        # If you need to transcode live stream use 'exec' feature.\n        #\n        application hls {\n            live on;\n            hls on;\n            hls_path /tmp/hls;\n        }\n\n        # MPEG-DASH is similar to HLS\n\n        application dash {\n            live on;\n            dash on;\n            dash_path /tmp/dash;\n        }\n    }\n}\n\n# HTTP can be used for accessing RTMP stats\nhttp {\n\n    server {\n\n        listen      8080;\n\n        # This URL provides RTMP statistics in XML\n        location /stat {\n            rtmp_stat all;\n\n            # Use this stylesheet to view XML as web page\n            # in browser\n            rtmp_stat_stylesheet stat.xsl;\n        }\n\n        location /stat.xsl {\n            # XML stylesheet to view RTMP stats.\n            # Copy stat.xsl wherever you want\n            # and put the full directory path here\n            root /path/to/stat.xsl/;\n        }\n\n        location /hls {\n            # Serve HLS fragments\n            types {\n                application/vnd.apple.mpegurl m3u8;\n                video/mp2t ts;\n            }\n            root /tmp;\n            add_header Cache-Control no-cache;\n        }\n\n        location /dash {\n            # Serve DASH fragments\n            root /tmp;\n            add_header Cache-Control no-cache;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/rtmp/#multi-worker-streaming-example","title":"Multi-worker streaming example","text":"<pre><code>rtmp_auto_push on;\n\nrtmp {\n    server {\n        listen 1935;\n\n        application mytv {\n            live on;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/rtmp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-rtmp.</p>"},{"location":"modules/secure-token/","title":"secure-token: Secure token module for NGINX","text":""},{"location":"modules/secure-token/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-secure-token\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-secure-token\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_secure_token_filter_module.so;\n</code></pre> <p>This document describes nginx-module-secure-token v1.5  released on Jun 27 2022.</p> <p>Generates CDN tokens, either as a cookie or as a query string parameter (m3u8,mpd,f4m only). Currently supports Akamai v2 tokens, and Amazon CloudFront tokens. In addition, the module supports the encryption of URIs with a configured key.</p>"},{"location":"modules/secure-token/#configuration","title":"Configuration","text":""},{"location":"modules/secure-token/#generic-token-parameters","title":"Generic token parameters","text":""},{"location":"modules/secure-token/#secure_token","title":"secure_token","text":"<ul> <li>syntax: <code>secure_token value</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the token that should be embedded in the manifest/returned as a cookie. The parameter value can contain variables, and often points to variables set by this module (using <code>secure_token_akamai</code> / <code>secure_token_cloudfront</code> blocks)</p>"},{"location":"modules/secure-token/#secure_token_avoid_cookies","title":"secure_token_avoid_cookies","text":"<ul> <li>syntax: <code>secure_token_avoid_cookies on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the module prefers to use a query string token instead of a cookie token. A query string token is currently supported only for the following mime types (other mime types return a cookie token): * application/vnd.apple.mpegurl * application/dash+xml * video/f4m</p>"},{"location":"modules/secure-token/#secure_token_types","title":"secure_token_types","text":"<ul> <li>syntax: <code>secure_token_types mime_type ...</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Defines a set of mime types that should return a token</p>"},{"location":"modules/secure-token/#secure_token_uri_filename_prefix","title":"secure_token_uri_filename_prefix","text":"<ul> <li>syntax: <code>secure_token_uri_filename_prefix prefix</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Defines a set of prefixes that will be matched against the URI file name, only URIs whose file name starts with one of the defined prefixes will return a token</p>"},{"location":"modules/secure-token/#secure_token_expires_time","title":"secure_token_expires_time","text":"<ul> <li>syntax: <code>secure_token_expires_time time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the expiration time of responses that are not tokenized  (determines the values of the Cache-Control and Expires HTTP headers)</p>"},{"location":"modules/secure-token/#secure_token_cookie_token_expires_time","title":"secure_token_cookie_token_expires_time","text":"<ul> <li>syntax: <code>secure_token_cookie_token_expires_time time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the expiration time of responses that are tokenized with a cookie token  (determines the values of the Cache-Control and Expires HTTP headers)</p>"},{"location":"modules/secure-token/#secure_token_query_token_expires_time","title":"secure_token_query_token_expires_time","text":"<ul> <li>syntax: <code>secure_token_query_token_expires_time time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the expiration time of responses that are tokenized with a query string token  (determines the values of the Cache-Control and Expires HTTP headers)</p>"},{"location":"modules/secure-token/#secure_token_cache_scope","title":"secure_token_cache_scope","text":"<ul> <li>syntax: <code>secure_token_cache_scope scope</code></li> <li>default: <code>public</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the cache scope (public/private) of responses that are not tokenized</p>"},{"location":"modules/secure-token/#secure_token_token_cache_scope","title":"secure_token_token_cache_scope","text":"<ul> <li>syntax: <code>secure_token_token_cache_scope scope</code></li> <li>default: <code>private</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the cache scope (public/private) of responses that are tokenized (query / cookie)</p>"},{"location":"modules/secure-token/#secure_token_last_modified","title":"secure_token_last_modified","text":"<ul> <li>syntax: <code>secure_token_last_modified time</code></li> <li>default: <code>Sun, 19 Nov 2000 08:52:00 GMT</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the last-modified header of responses that are not tokenized. An empty string leaves the value of last-modified unaltered, while the string \"now\" sets the header to the server current time.</p>"},{"location":"modules/secure-token/#secure_token_token_last_modified","title":"secure_token_token_last_modified","text":"<ul> <li>syntax: <code>secure_token_token_last_modified time</code></li> <li>default: <code>now</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the last-modified header of responses that are tokenized (query / cookie) An empty string leaves the value of last-modified unaltered, while the string \"now\" sets the header to the server current time.</p>"},{"location":"modules/secure-token/#secure_token_content_type_m3u8","title":"secure_token_content_type_m3u8","text":"<ul> <li>syntax: <code>secure_token_content_type_m3u8 type</code></li> <li>default: <code>application/vnd.apple.mpegurl</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the content type that should be parsed as m3u8 for token insertion</p>"},{"location":"modules/secure-token/#secure_token_content_type_mpd","title":"secure_token_content_type_mpd","text":"<ul> <li>syntax: <code>secure_token_content_type_mpd type</code></li> <li>default: <code>application/dash+xml</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the content type that should be parsed as mpd for token insertion</p>"},{"location":"modules/secure-token/#secure_token_content_type_f4m","title":"secure_token_content_type_f4m","text":"<ul> <li>syntax: <code>secure_token_content_type_f4m type</code></li> <li>default: <code>video/f4m</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the content type that should be parsed as f4m for token insertion</p>"},{"location":"modules/secure-token/#akamai-token-parameters","title":"Akamai token parameters","text":""},{"location":"modules/secure-token/#secure_token_akamai","title":"secure_token_akamai","text":"<ul> <li>syntax: <code>secure_token_akamai $variable { ... }</code></li> <li>context: <code>http</code></li> </ul> <p>Creates a new variable whose value is an Akamai token, created according to the  parameters specified within the block.</p> <p>The block supports the following parameters:</p>"},{"location":"modules/secure-token/#key","title":"key","text":"<ul> <li>syntax: <code>key key_hex</code></li> <li>default: <code>N/A (mandatory)</code></li> </ul> <p>Sets the secret key.</p>"},{"location":"modules/secure-token/#param_name","title":"param_name","text":"<ul> <li>syntax: <code>param_name name</code></li> <li>default: <code>__hdnea__</code></li> </ul> <p>Sets the token parameter name (either the name of the cookie or the query string parameter)</p>"},{"location":"modules/secure-token/#acl","title":"acl","text":"<ul> <li>syntax: <code>acl acl</code></li> <li>default: <code>$secure_token_baseuri_comma</code></li> </ul> <p>Sets the signed part of the URL (ACL). The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#start","title":"start","text":"<ul> <li>syntax: <code>start time</code></li> <li>default: <code>0</code></li> </ul> <p>Sets the start time of the token (see <code>Time format</code> below)</p>"},{"location":"modules/secure-token/#end","title":"end","text":"<ul> <li>syntax: <code>end time</code></li> <li>default: <code>86400</code></li> </ul> <p>Sets the end time of the token (see <code>Time format</code> below)</p>"},{"location":"modules/secure-token/#ip_address","title":"ip_address","text":"<ul> <li>syntax: <code>ip_address address</code></li> <li>default: <code>none</code></li> </ul> <p>Sets the IP address that should be embedded in the token. The parameter value can contain variables, e.g. $remote_addr.</p>"},{"location":"modules/secure-token/#cloudfront-token-parameters","title":"CloudFront token parameters","text":""},{"location":"modules/secure-token/#secure_token_cloudfront","title":"secure_token_cloudfront","text":"<ul> <li>syntax: <code>secure_token_cloudfront $variable { ... }</code></li> <li>context: <code>http</code></li> </ul> <p>Creates a new variable whose value is a CloudFront token, created according to the  parameters specified within the block.</p> <p>The block supports the following parameters:</p>"},{"location":"modules/secure-token/#private_key_file","title":"private_key_file","text":"<ul> <li>syntax: <code>private_key_file filename</code></li> <li>default: <code>N/A (mandatory)</code></li> </ul> <p>Sets the file name of the private key (PEM file)</p>"},{"location":"modules/secure-token/#key_pair_id","title":"key_pair_id","text":"<ul> <li>syntax: <code>key_pair_id id</code></li> <li>default: <code>N/A (mandatory)</code></li> </ul> <p>Sets the key pair id</p>"},{"location":"modules/secure-token/#acl_1","title":"acl","text":"<ul> <li>syntax: <code>acl acl</code></li> <li>default: <code>$secure_token_baseuri_comma</code></li> </ul> <p>Sets the signed part of the URL (ACL). The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#end_1","title":"end","text":"<ul> <li>syntax: <code>end time</code></li> <li>default: <code>86400</code></li> </ul> <p>Sets the end time of the token (see <code>Time format</code> below)</p>"},{"location":"modules/secure-token/#ip_address_1","title":"ip_address","text":"<ul> <li>syntax: <code>ip_address address</code></li> <li>default: <code>none</code></li> </ul> <p>Sets the IP address that should be embedded in the token. The parameter value can contain variables, e.g. $remote_addr/32 can be used to limit the token to the specific IP of the client.</p>"},{"location":"modules/secure-token/#broadpeak-token-parameters","title":"Broadpeak token parameters","text":""},{"location":"modules/secure-token/#secure_token_broadpeak","title":"secure_token_broadpeak","text":"<ul> <li>syntax: <code>secure_token_broadpeak $variable { ... }</code></li> <li>context: <code>http</code></li> </ul> <p>Creates a new variable whose value is a Broadpeak token, created according to the parameters specified within the block.</p> <p>The block supports the following parameters:</p>"},{"location":"modules/secure-token/#key_1","title":"key","text":"<ul> <li>syntax: <code>key key</code></li> <li>default: <code>N/A (mandatory)</code></li> </ul> <p>Sets the secret key. The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#param_name_1","title":"param_name","text":"<ul> <li>syntax: <code>param_name name</code></li> <li>default: <code>token</code></li> </ul> <p>Sets the token parameter name (either the name of the cookie or the query string parameter)</p>"},{"location":"modules/secure-token/#acl_2","title":"acl","text":"<ul> <li>syntax: <code>acl acl</code></li> <li>default: <code>$secure_token_baseuri_comma</code></li> </ul> <p>Sets the signed part of the URL (ACL). The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#start_1","title":"start","text":"<ul> <li>syntax: <code>start time</code></li> <li>default: <code>0</code></li> </ul> <p>Sets the start time of the token (see <code>Time format</code> below)</p>"},{"location":"modules/secure-token/#end_2","title":"end","text":"<ul> <li>syntax: <code>end time</code></li> <li>default: <code>86400</code></li> </ul> <p>Sets the end time of the token (see <code>Time format</code> below)</p>"},{"location":"modules/secure-token/#session_start","title":"session_start","text":"<ul> <li>syntax: <code>session_start time</code></li> <li>default: <code>N/A</code></li> </ul> <p>Sets the start time of the session, required for catchup. The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#session_end","title":"session_end","text":"<ul> <li>syntax: <code>session_end time</code></li> <li>default: <code>N/A</code></li> </ul> <p>Sets the end time of the session, required for catchup. The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#additional_querylist","title":"additional_querylist","text":"<ul> <li>syntax: <code>additional_querylist expr</code></li> <li>default: <code>N/A</code></li> </ul> <p>Sets the primary token value, the value needs to be a list of name=value pairs without any separator. For example, \"ip=${arg_ip}account=${arg_account}device=${arg_device}\". The parameter value can contain variables.</p>"},{"location":"modules/secure-token/#uri-encryption-parameters","title":"URI encryption parameters","text":""},{"location":"modules/secure-token/#secure_token_encrypt_uri","title":"secure_token_encrypt_uri","text":"<ul> <li>syntax: <code>secure_token_encrypt_uri on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables/disables uri encryption</p>"},{"location":"modules/secure-token/#secure_token_encrypt_uri_key","title":"secure_token_encrypt_uri_key","text":"<ul> <li>syntax: <code>secure_token_encrypt_uri_key key_hex</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the encryption key, the key has to be 256 bits (64 hex characters)</p>"},{"location":"modules/secure-token/#secure_token_encrypt_uri_iv","title":"secure_token_encrypt_uri_iv","text":"<ul> <li>syntax: <code>secure_token_encrypt_uri_iv iv_hex</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the encryption iv, the iv has to be 128 bits (32 hex characters)</p>"},{"location":"modules/secure-token/#secure_token_encrypt_uri_part","title":"secure_token_encrypt_uri_part","text":"<ul> <li>syntax: <code>secure_token_encrypt_uri_part expression</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>An expression that calculates the part of the URL that should be encrypted in regular expression locations. For non-regular expression locations, the encrypted part is everything following the path defined on the location block.</p> <p>Example 1: <pre><code>  location /secret_param/([^/]+)/some_other_param/.* {\n    secure_token_encrypt_uri_part $1;\n    ...\n  }\n</code></pre>   In this configuration, only the value of secret_param will be encrypted/decrypted.</p> <p>Example 2: <pre><code>  location /base/ {\n    ...\n  }\n</code></pre>   In this configuration, everything following /base/ will be encrypted/decrypted.</p>"},{"location":"modules/secure-token/#secure_token_encrypt_uri_hash_size","title":"secure_token_encrypt_uri_hash_size","text":"<ul> <li>syntax: <code>secure_token_encrypt_uri_hash_size size</code></li> <li>default: <code>8</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The size in bytes of hash used to validate the uri after decryption, the value has to be between 0 and 16.</p>"},{"location":"modules/secure-token/#time-format","title":"Time format","text":"<p>Some of the configuration parameters mentioned above, support both absolute timestamps, and timestamps relative to <code>now</code>. These parameters can be set in the configuration using one of the following formats: * <code>epoch</code> - unix timestamp 0 (01/01/1970) * <code>max</code> - unix timestamp 2147483647 (18/01/2038) * <code>@1481230000</code> - unix timestamp 1481230000 (8/12/2016) * <code>10d</code> / <code>+10d</code> - <code>now</code> + 10 days * <code>-5m</code> - <code>now</code> - 5 minutes</p>"},{"location":"modules/secure-token/#sample-configurations","title":"Sample configurations","text":""},{"location":"modules/secure-token/#hls-packaging-with-akamai-tokens","title":"HLS packaging with Akamai tokens","text":"<pre><code>    secure_token_akamai $token {\n        key 1234;\n        acl \"$secure_token_baseuri_comma*\";\n    }\n\n    server {\n\n        location ~ ^/hls/p/\\d+/(sp/\\d+/)?serveFlavor/ {\n            vod hls;\n\n            g2o        on;\n\n            secure_token $token;\n            secure_token_types application/vnd.apple.mpegurl;\n\n            secure_token_expires_time 100d;\n            secure_token_query_token_expires_time 1h;\n\n            more_set_headers 'Access-Control-Allow-Headers: *';\n            more_set_headers 'Access-Control-Expose-Headers: Server,range,Content-Length,Content-Range';\n            more_set_headers 'Access-Control-Allow-Methods: GET, HEAD, OPTIONS';\n            more_set_headers 'Access-Control-Allow-Origin: *';\n        }\n\n    }\n</code></pre>"},{"location":"modules/secure-token/#hds-packaging-with-cloudfront-tokens","title":"HDS packaging with CloudFront tokens","text":"<pre><code>    secure_token_cloudfront $token {\n        private_key_file /path/to/pem;\n        key_pair_id ABCDEF;\n        acl \"$scheme://$http_host$secure_token_baseuri_comma*\";\n    }\n\n    server {\n\n        location ~ ^/hds/p/\\d+/(sp/\\d+/)?serveFlavor/ {\n            vod hds;\n            vod_segment_duration 6000;\n            vod_align_segments_to_key_frames on;\n            vod_segment_count_policy last_rounded;\n\n            secure_token $token;\n            secure_token_types video/f4m;\n\n            secure_token_expires_time 100d;\n            secure_token_query_token_expires_time 1h;\n\n            more_set_headers 'Access-Control-Allow-Headers: *';\n            more_set_headers 'Access-Control-Expose-Headers: Server,range,Content-Length,Content-Range';\n            more_set_headers 'Access-Control-Allow-Methods: GET, HEAD, OPTIONS';\n            more_set_headers 'Access-Control-Allow-Origin: *';\n        }\n\n    }\n</code></pre>"},{"location":"modules/secure-token/#encrypted-hls-with-token-security-on-the-encryption-key","title":"Encrypted HLS with token security on the encryption key","text":"<p>This configuration enables token security while having static URLs for the video segments, this enables the caching of the segments transparently by proxies. <pre><code>    secure_token_akamai $token {\n        key 1234;\n        acl \"$secure_token_baseuri_comma*\";\n    }\n\n    server {\n\n        location ~ ^/s/hls/enc/p/\\d+/(sp/\\d+/)?serveFlavor/ {\n            vod hls;\n            vod_secret_key \"password$vod_filepath\";\n\n            secure_token $token;\n            secure_token_types application/vnd.apple.mpegurl;\n\n            secure_token_expires_time 100d;\n            secure_token_query_token_expires_time 1h;\n\n            secure_token_uri_filename_prefix index;\n            secure_token_tokenize_segments off;\n\n            akamai_token_validate $arg___hdnea__;\n            akamai_token_validate_key 1234;\n            akamai_token_validate_uri_filename_prefix encryption;\n            akamai_token_validate_uri_filename_prefix index;\n        }\n\n    }\n</code></pre> Note: this configuration requires the module https://github.com/kaltura/nginx-akamai-token-validate-module in addition to nginx-secure-token-module</p>"},{"location":"modules/secure-token/#adding-token-security-on-top-of-an-existing-hdshls-live-stream","title":"Adding token security on top of an existing HDS/HLS live stream","text":"<p><pre><code>    secure_token_akamai $token {\n        key 1234;\n        acl \"$secure_token_baseuri_comma*\";\n    }\n\n    server {\n\n        location /secure-live/ {\n            proxy_pass http://original.live.domain;\n\n            secure_token $token;\n            secure_token_types text/xml application/vnd.apple.mpegurl;      \n            secure_token_content_type_f4m text/xml;\n\n            secure_token_expires_time 100d;\n            secure_token_query_token_expires_time 1h;\n\n            akamai_token_validate $arg___hdnea__;\n            akamai_token_validate_key 1234;\n            akamai_token_validate_strip_token __hdnea__;\n        }\n\n    }\n</code></pre> Note: this configuration requires the module https://github.com/kaltura/nginx-akamai-token-validate-module in addition to nginx-secure-token-module</p>"},{"location":"modules/secure-token/#uri-encryption","title":"URI encryption","text":"<pre><code>    location ~ ^/hls/p/\\d+/(sp/\\d+/)?serveFlavor/entryId/([^/]+)/(.*) {\n        vod hls;\n        vod_secret_key \"password$2\";\n\n        secure_token_encrypt_uri on;\n        secure_token_encrypt_uri_key 000102030405060708090a0b0c0d0e0f101112131415161718191a1b1c1d1e1f;\n        secure_token_encrypt_uri_iv 00000000000000000000000000000000;\n        secure_token_encrypt_uri_part $3;\n        secure_token_types application/vnd.apple.mpegurl;\n\n        add_header Last-Modified \"Sun, 19 Nov 2000 08:52:00 GMT\";\n        expires 100d;\n    }\n</code></pre>"},{"location":"modules/secure-token/#nginx-variables","title":"Nginx variables","text":"<p>The module adds the following nginx variables: * <code>$secure_token_baseuri</code> - contains the value of the <code>$uri</code> built in variable truncated up to the last slash (/).      For exmaple, if <code>$uri</code> is /a/b/c.htm then <code>$secure_token_baseuri</code> will be /a/b/. * <code>$secure_token_baseuri_comma</code> - same as <code>$secure_token_baseuri</code>, except that if this value contains a comma (,)      the value is truncated up to the comma position.     For exmaple, if <code>$uri</code> is /a/b/c.htm then <code>$secure_token_baseuri_comma</code> will be /a/b/;      if <code>$uri</code> is /a/b,c/d.htm then <code>$secure_token_baseuri_comma</code> will be /a/b. * <code>$secure_token_original_uri</code> - contains the original (encrypted) uri when using uri encryption.     Note that the built in <code>$uri</code> variable contains the modified (decrypted) uri in this case.</p>"},{"location":"modules/secure-token/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-secure-token.</p>"},{"location":"modules/security-headers/","title":"security-headers: NGINX module for sending security headers","text":""},{"location":"modules/security-headers/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-security-headers\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-security-headers\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_security_headers_module.so;\n</code></pre> <p>This document describes nginx-module-security-headers v0.1.2  released on Apr 26 2025.</p> <p>This NGINX module adds security headers and removes insecure headers, the right way (c). </p> <p></p>"},{"location":"modules/security-headers/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    security_headers on;\n    ...\n}\n</code></pre> <p>Running <code>curl -IL https://example.com/</code> will yield the added security headers:</p> <pre>\nHTTP/1.1 200 OK\nServer: nginx\nDate: Tue, 21 May 2019 16:15:46 GMT\nContent-Type: text/html; charset=UTF-8\nVary: Accept-Encoding\nAccept-Ranges: bytes\nConnection: keep-alive\nX-Frame-Options: SAMEORIGIN\nX-Content-Type-Options: nosniff\nX-XSS-Protection: 0\nReferrer-Policy: strict-origin-when-cross-origin\nStrict-Transport-Security: max-age=31536000; includeSubDomains; preload\n</pre> <p>In general, the module features sending security HTTP headers in a way that better conforms to the standards. For instance, <code>Strict-Transport-Security</code> header should not be sent for plain HTTP requests. The module follows this recommendation.</p>"},{"location":"modules/security-headers/#important-note-on-strict-transport-security","title":"Important note on <code>Strict-Transport-Security</code>","text":"<p>The module adds several security headers, including <code>Strinct-Transport-Security</code>. Note that <code>preload</code> is sent in the value of this header, by default. This means Chrome may and will include your websites to its preload list of domains which are HTTPS only.</p> <p>It is usually what you want anyway, but bear in mind that in some edge cases you want to access a subdomain via plan unencrypted connection.</p> <p>If you absolutely sure that all your domains and subdomains used with the module will ever primarily operate on HTTPs, proceed without any extra step.</p> <p>If you are not sure if you have or will have a need to access your websites or any of its subdomains over plain insecure HTTP protocol, ensure <code>security_headers_hsts_preload off;</code> in your config before you ever start NGINX with the module to avoid having your domain preloaded by Chrome.</p>"},{"location":"modules/security-headers/#key-features","title":"Key Features","text":"<ul> <li>Plug-n-Play: the default set of security headers can be enabled with <code>security_headers on;</code> in your NGINX configuration</li> <li>Sends HTML-only security headers for relevant types only, not sending for others, e.g. <code>X-Frame-Options</code> is useless for CSS</li> <li>Plays well with conditional <code>GET</code> requests: the security headers are not included there unnecessarily</li> <li>Does not suffer the <code>add_header</code> directive's pitfalls</li> <li>Hides <code>X-Powered-By</code> and other headers which often leak software version information</li> <li>Hides <code>Server</code> header altogether, not just the version information</li> </ul>"},{"location":"modules/security-headers/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/security-headers/#security_headers","title":"<code>security_headers</code>","text":"<ul> <li>syntax: <code>security_headers on | off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables or disables applying security headers. The default set includes:</p> <ul> <li><code>X-Frame-Options: SAMEORIGIN</code></li> <li><code>X-XSS-Protection: 0</code></li> <li><code>Referrer-Policy: strict-origin-when-cross-origin</code></li> <li><code>X-Content-Type-Options: nosniff</code></li> </ul> <p>The values of these headers (or their inclusion) can be controlled with other <code>security_headers_*</code> directives below.</p>"},{"location":"modules/security-headers/#hide_server_tokens","title":"<code>hide_server_tokens</code>","text":"<ul> <li>syntax: <code>hide_server_tokens on | off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables hiding headers which leak software information:</p> <ul> <li><code>Server</code></li> <li><code>X-Powered-By</code></li> <li><code>X-Page-Speed</code></li> <li><code>X-Varnish</code></li> </ul> <p>It's worth noting that some of those headers bear functional use, e.g. <code>X-Page-Speed</code> docs mention:</p> <p>... it is used to prevent infinite loops and unnecessary rewrites when PageSpeed  fetches resources from an origin that also uses PageSpeed</p> <p>So it's best to specify <code>hide_server_tokens on;</code> in a front-facing NGINX instances, e.g. the one being accessed by actual browsers, and not the ones consumed by Varnish or other software.</p> <p>In most cases you will be just fine with <code>security_headers on;</code> and <code>hide_server_tokens on;</code>, without any adjustments.</p> <p>For fine-tuning, use the header-specific directives below.  A special value <code>omit</code> disables sending a particular header by the module (useful if you want to let your backend app to send it). </p>"},{"location":"modules/security-headers/#security_headers_xss","title":"<code>security_headers_xss</code>","text":"<ul> <li>syntax: <code>security_headers_xss off | on | block | omit</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Controls <code>X-XSS-Protection</code> header.  Special <code>omit</code> value will disable sending the header by the module.  The <code>off</code> value is for disabling XSS protection: <code>X-XSS-Protection: 0</code>. This is the default because  modern browsers do not support it and where it is  supported, it introduces vulnerabilities.</p>"},{"location":"modules/security-headers/#security_headers_frame","title":"<code>security_headers_frame</code>","text":"<ul> <li>syntax: <code>security_headers_frame sameorigin | deny | omit</code></li> <li>default: <code>sameorigin</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Controls inclusion and value of <code>X-Frame-Options</code> header.  Special <code>omit</code> value will disable sending the header by the module. </p>"},{"location":"modules/security-headers/#security_headers_referrer_policy","title":"<code>security_headers_referrer_policy</code>","text":"<ul> <li>syntax: <code>security_headers_referrer_policy no-referrer | no-referrer-when-downgrade | same-origin | origin  | strict-origin | origin-when-cross-origin | strict-origin-when-cross-origin | unsafe-url | omit</code></li> <li>default: <code>strict-origin-when-cross-origin</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Controls inclusion and value of <code>Referrer-Policy</code> header.  Special <code>omit</code> value will disable sending the header by the module. </p>"},{"location":"modules/security-headers/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-security-headers.</p>"},{"location":"modules/security/","title":"security: ModSecurity v3 Nginx Connector","text":""},{"location":"modules/security/#installation","title":"Installation","text":"<p>CentOS/RHEL/RockyLinux/etc. and Amazon Linux are supported and require a subscription.</p> <p>Fedora Linux is supported free of charge and doesn't require a subscription.</p>"},{"location":"modules/security/#os-specific-complete-installation-and-configuration-guides-available","title":"OS-specific complete installation and configuration guides available:","text":"<ul> <li>CentOS/RHEL 7</li> <li>CentOS/RHEL 8</li> </ul>"},{"location":"modules/security/#other-supported-operating-systems","title":"Other supported operating systems","text":"<pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm\ndnf -y install nginx-module-security\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_modsecurity_module.so;\n</code></pre> <p>This document describes nginx-module-security v1.0.4  released on May 21 2025.</p> <p></p> <p></p> <p>The ModSecurity-nginx connector is the connection point between nginx and libmodsecurity (ModSecurity v3). Said another way, this project provides a communication channel between nginx and libmodsecurity. This connector is required to use LibModSecurity with nginx. </p> <p>The ModSecurity-nginx connector takes the form of an nginx module. The module simply serves as a layer of communication between nginx and ModSecurity.</p> <p>Notice that this project depends on libmodsecurity rather than ModSecurity (version 2.9 or less).</p>"},{"location":"modules/security/#what-is-the-difference-between-this-project-and-the-old-modsecurity-add-on-for-nginx","title":"What is the difference between this project and the old ModSecurity add-on for nginx?","text":"<p>The old version uses ModSecurity standalone, which is a wrapper for Apache internals to link ModSecurity to nginx. This current version is closer to nginx, consuming the new libmodsecurity which is no longer dependent on Apache. As a result, this current version has less dependencies, fewer bugs, and is faster. In addition, some new functionality is also provided - such as the possibility of use of global rules configuration with per directory/location customizations (e.g. SecRuleRemoveById).</p>"},{"location":"modules/security/#usage","title":"Usage","text":"<p>ModSecurity for nginx extends your nginx configuration directives. It adds four new directives and they are:</p>"},{"location":"modules/security/#modsecurity","title":"modsecurity","text":"<p>syntax: modsecurity on | off</p> <p>context: http, server, location</p> <p>default: off</p> <p>Turns on or off ModSecurity functionality. Note that this configuration directive is no longer related to the SecRule state. Instead, it now serves solely as an nginx flag to enable or disable the module.</p>"},{"location":"modules/security/#modsecurity_rules_file","title":"modsecurity_rules_file","text":"<p>syntax: modsecurity_rules_file &lt;path to rules file&gt;</p> <p>context: http, server, location</p> <p>default: no</p> <p>Specifies the location of the modsecurity configuration file, e.g.:</p> <pre><code>server {\n    modsecurity on;\n    location / {\n        root /var/www/html;\n        modsecurity_rules_file /etc/my_modsecurity_rules.conf;\n    }\n}\n</code></pre>"},{"location":"modules/security/#modsecurity_rules_remote","title":"modsecurity_rules_remote","text":"<p>syntax: modsecurity_rules_remote &lt;key&gt; &lt;URL to rules&gt;</p> <p>context: http, server, location</p> <p>default: no</p> <p>Specifies from where (on the internet) a modsecurity configuration file will be downloaded. It also specifies the key that will be used to authenticate to that server:</p> <pre><code>server {\n    modsecurity on;\n    location / {\n        root /var/www/html;\n        modsecurity_rules_remote my-server-key https://my-own-server/rules/download;\n    }\n}\n</code></pre>"},{"location":"modules/security/#modsecurity_rules","title":"modsecurity_rules","text":"<p>syntax: modsecurity_rules &lt;modsecurity rule&gt;</p> <p>context: http, server, location</p> <p>default: no</p> <p>Allows for the direct inclusion of a ModSecurity rule into the nginx configuration. The following example is loading rules from a file and injecting specific configurations per directory/alias:</p> <pre><code>server {\n    modsecurity on;\n    location / {\n        root /var/www/html;\n        modsecurity_rules_file /etc/my_modsecurity_rules.conf;\n    }\n    location /ops {\n        root /var/www/html/opts;\n        modsecurity_rules '\n          SecRuleEngine On\n          SecDebugLog /tmp/modsec_debug.log\n          SecDebugLogLevel 9\n          SecRuleRemoveById 10\n        ';\n    }\n}\n</code></pre>"},{"location":"modules/security/#modsecurity_transaction_id","title":"modsecurity_transaction_id","text":"<p>syntax: modsecurity_transaction_id string</p> <p>context: http, server, location</p> <p>default: no</p> <p>Allows to pass transaction ID from nginx instead of generating it in the library. This can be useful for tracing purposes, e.g. consider this configuration:</p> <pre><code>log_format extended '$remote_addr - $remote_user [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\" $request_id';\n\nserver {\n    server_name host1;\n    modsecurity on;\n    modsecurity_transaction_id \"host1-$request_id\";\n    access_log logs/host1-access.log extended;\n    error_log logs/host1-error.log;\n    location / {\n        ...\n    }\n}\n\nserver {\n    server_name host2;\n    modsecurity on;\n    modsecurity_transaction_id \"host2-$request_id\";\n    access_log logs/host2-access.log extended;\n    error_log logs/host2-error.log;\n    location / {\n        ...\n    }\n}\n</code></pre> <p>Using a combination of log_format and modsecurity_transaction_id you will be able to find correlations between access log and error log entries using the same unique identificator.</p> <p>String can contain variables.</p>"},{"location":"modules/security/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-security.</p>"},{"location":"modules/set-misc/","title":"set-misc: NGINX Set-Misc module","text":""},{"location":"modules/set-misc/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-set-misc\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-set-misc\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_set_misc_module.so;\n</code></pre> <p>This document describes nginx-module-set-misc v0.33  released on Sep 06 2021.</p>"},{"location":"modules/set-misc/#name","title":"Name","text":"<p>ngx_set_misc - Various set_xxx directives added to nginx's rewrite module (md5/sha1, sql/json quoting, and many more)</p>"},{"location":"modules/set-misc/#synopsis","title":"Synopsis","text":"<pre><code> location /foo {\n     set $a $arg_a;\n     set_if_empty $a 56;\n\n     # GET /foo?a=32 will yield $a == 32\n     # while GET /foo and GET /foo?a= will\n     # yeild $a == 56 here.\n }\n\n location /bar {\n     set $foo \"hello\\n\\n'\\\"\\\\\";\n     set_quote_sql_str $foo $foo; # for mysql\n\n     # OR in-place editing:\n     #   set_quote_sql_str $foo;\n\n     # now $foo is: 'hello\\n\\n\\'\\\"\\\\'\n }\n\n location /bar {\n     set $foo \"hello\\n\\n'\\\"\\\\\";\n     set_quote_pgsql_str $foo;  # for PostgreSQL\n\n     # now $foo is: E'hello\\n\\n\\'\\\"\\\\'\n }\n\n location /json {\n     set $foo \"hello\\n\\n'\\\"\\\\\";\n     set_quote_json_str $foo $foo;\n\n     # OR in-place editing:\n     #   set_quote_json_str $foo;\n\n     # now $foo is: \"hello\\n\\n'\\\"\\\\\"\n }\n\n location /baz {\n     set $foo \"hello%20world\";\n     set_unescape_uri $foo $foo;\n\n     # OR in-place editing:\n     #   set_unescape_uri $foo;\n\n     # now $foo is: hello world\n }\n\n upstream_list universe moon sun earth;\n upstream moon { ... }\n upstream sun { ... }\n upstream earth { ... }\n location /foo {\n     set_hashed_upstream $backend universe $arg_id;\n     drizzle_pass $backend; # used with ngx_drizzle\n }\n\n location /base32 {\n     set $a 'abcde';\n     set_encode_base32 $a;\n     set_decode_base32 $b $a;\n\n     # now $a == 'c5h66p35' and\n     # $b == 'abcde'\n }\n\n location /base64 {\n     set $a 'abcde';\n     set_encode_base64 $a;\n     set_decode_base64 $b $a;\n\n     # now $a == 'YWJjZGU=' and\n     # $b == 'abcde'\n }\n\n location /hex {\n     set $a 'abcde';\n     set_encode_hex $a;\n     set_decode_hex $b $a;\n\n     # now $a == '6162636465' and\n     # $b == 'abcde'\n }\n\n # GET /sha1 yields the output\n #   aaf4c61ddcc5e8a2dabede0f3b482cd9aea9434d\n location /sha1 {\n     set_sha1 $a hello;\n     echo $a;\n }\n\n # ditto\n location /sha1 {\n     set $a hello;\n     set_sha1 $a;\n     echo $a;\n }\n\n # GET /today yields the date of today in local time using format 'yyyy-mm-dd'\n location /today {\n     set_local_today $today;\n     echo $today;\n }\n\n # GET /signature yields the hmac-sha-1 signature\n # given a secret and a string to sign\n # this example yields the base64 encoded singature which is\n # \"HkADYytcoQQzqbjQX33k/ZBB/DQ=\"\n location /signature {\n     set $secret_key 'secret-key';\n     set $string_to_sign \"some-string-to-sign\";\n     set_hmac_sha1 $signature $secret_key $string_to_sign;\n     set_encode_base64 $signature $signature;\n     echo $signature;\n }\n\n location = /rand {\n     set $from 3;\n     set $to 15;\n     set_random $rand $from $to;\n\n     # or write directly\n     #   set_random $rand 3 15;\n\n     echo $rand;  # will print a random integer in the range [3, 15]\n }\n</code></pre>"},{"location":"modules/set-misc/#description","title":"Description","text":"<p>This module extends the standard HttpRewriteModule's directive set to provide more functionalities like URI escaping and unescaping, JSON quoting, Hexadecimal/MD5/SHA1/Base32/Base64 digest encoding and decoding, random number generator, and more!</p> <p>Every directive provided by this module can be mixed freely with other ngx_http_rewrite_module's directives, like if and set. (Thanks to the Nginx Devel Kit!)</p>"},{"location":"modules/set-misc/#directives","title":"Directives","text":""},{"location":"modules/set-misc/#set_if_empty","title":"set_if_empty","text":"<p>syntax: set_if_empty $dst &lt;src&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Assign the value of the argument <code>&lt;src&gt;</code> if and only if variable <code>$dst</code> is empty (i.e., not found or has an empty string value).</p> <p>In the following example,</p> <pre><code> set $a 32;\n set_if_empty $a 56;\n</code></pre> <p>the variable <code>$dst</code> will take the value 32 at last. But in the sample</p> <pre><code> set $a '';\n set $value \"hello, world\"\n set_if_empty $a $value;\n</code></pre> <p><code>$a</code> will take the value <code>\"hello, world\"</code> at last.</p>"},{"location":"modules/set-misc/#set_quote_sql_str","title":"set_quote_sql_str","text":"<p>syntax: set_quote_sql_str $dst &lt;src&gt;</p> <p>syntax: set_quote_sql_str $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will quote the value of the second argument <code>&lt;src&gt;</code> by MySQL's string value quoting rule and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $value \"hello\\n\\r'\\\"\\\\\";\n     set_quote_sql_str $quoted $value;\n\n     echo $quoted;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code> 'hello\\n\\r\\'\\\"\\\\'\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"hello\\n\\r'\\\"\\\\\";\n     set_quote_sql_str $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive is usually used to prevent SQL injection.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_quote_pgsql_str","title":"set_quote_pgsql_str","text":"<p>syntax: set_quote_pgsql_str $dst &lt;src&gt;</p> <p>syntax: set_quote_pgsql_str $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Very much like set_quote_sql_str, but with PostgreSQL quoting rules for SQL string literals.</p>"},{"location":"modules/set-misc/#set_quote_json_str","title":"set_quote_json_str","text":"<p>syntax: set_quote_json_str $dst &lt;src&gt;</p> <p>syntax: set_quote_json_str $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will quote the value of the second argument <code>&lt;src&gt;</code> by JSON string value quoting rule and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $value \"hello\\n\\r'\\\"\\\\\";\n     set_quote_json_str $quoted $value;\n\n     echo $quoted;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code> \"hello\\n\\r'\\\"\\\\\"\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"hello\\n\\r'\\\"\\\\\";\n     set_quote_json_str $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_unescape_uri","title":"set_unescape_uri","text":"<p>syntax: set_unescape_uri $dst &lt;src&gt;</p> <p>syntax: set_unescape_uri $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will unescape the value of the second argument <code>&lt;src&gt;</code> as a URI component and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set_unescape_uri $key $arg_key;\n     echo $key;\n }\n</code></pre> <p>Then request <code>GET /test?key=hello+world%21</code> will yield the following output</p> <pre><code>hello world!\n</code></pre> <p>The nginx standard $arg_PARAMETER variable holds the raw (escaped) value of the URI parameter. So we need the <code>set_unescape_uri</code> directive to unescape it first.</p> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $key $arg_key;\n     set_unescape_uri $key;\n\n     echo $key;\n }\n</code></pre> <p>then request <code>GET /test?key=hello+world%21</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_escape_uri","title":"set_escape_uri","text":"<p>syntax: set_escape_uri $dst &lt;src&gt;</p> <p>syntax: set_escape_uri $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Very much like the set_unescape_uri directive, but does the conversion the other way around, i.e., URL component escaping.</p>"},{"location":"modules/set-misc/#set_hashed_upstream","title":"set_hashed_upstream","text":"<p>syntax: set_hashed_upstream $dst &lt;upstream_list_name&gt; &lt;src&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Hashes the string argument <code>&lt;src&gt;</code> into one of the upstream name included in the upstream list named <code>&lt;upstream_list_name&gt;</code>. The hash function being used is simple modulo.</p> <p>Here's an example,</p> <pre><code> upstream moon { ... }\n upstream sun { ... }\n upstream earth { ... }\n\n upstream_list universe moon sun earth;\n\n location /test {\n     set_unescape_uri $key $arg_key;\n     set $list_name universe;\n     set_hashed_upstream $backend $list_name $key;\n\n     echo $backend;\n }\n</code></pre> <p>Then <code>GET /test?key=blah</code> will output either \"moon\", \"sun\", or \"earth\", depending on the actual value of the <code>key</code> query argument.</p> <p>This directive is usually used to compute an nginx variable to be passed to memc-nginx-module's memc_pass directive, redis2-nginx-module's [[HttpRedis2Module#redis2_pass]] directive, and ngx_http_proxy_module's proxy_pass directive, among others.</p>"},{"location":"modules/set-misc/#set_encode_base32","title":"set_encode_base32","text":"<p>syntax: set_encode_base32 $dst &lt;src&gt;</p> <p>syntax: set_encode_base32 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its base32(hex) digest and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $raw \"abcde\";\n     set_encode_base32 $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>c5h66p35\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>RFC forces the <code>[A-Z2-7]</code> RFC-3548 compliant encoding, but we are using the \"base32hex\" encoding (<code>[0-9a-v]</code>) by default. The set_base32_alphabet directive (first introduced in <code>v0.28</code>) allows you to change the alphabet used for encoding/decoding so RFC-3548 compliant encoding is still possible by custom configurations.</p> <p>By default, the <code>=</code> character is used to pad the left-over bytes due to alignment. But the padding behavior can be completely disabled by setting set_base32_padding <code>off</code>.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"abcde\";\n     set_encode_base32 $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_base32_padding","title":"set_base32_padding","text":"<p>syntax: set_base32_padding on|off</p> <p>default: on</p> <p>context: http, server, server if, location, location if</p> <p>phase: no</p> <p>This directive can control whether to pad left-over bytes with the \"=\" character when encoding a base32 digest by the set_encode_base32 directive.</p> <p>This directive was first introduced in <code>v0.28</code>. If you use earlier versions of this module, then you should use set_misc_base32_padding instead.</p>"},{"location":"modules/set-misc/#set_misc_base32_padding","title":"set_misc_base32_padding","text":"<p>syntax: set_misc_base32_padding on|off</p> <p>default: on</p> <p>context: http, server, server if, location, location if</p> <p>phase: no</p> <p>This directive has been deprecated since <code>v0.28</code>. Use set_base32_padding instead if you are using <code>v0.28+</code>.</p>"},{"location":"modules/set-misc/#set_base32_alphabet","title":"set_base32_alphabet","text":"<p>syntax: set_base32_alphabet &lt;alphabet&gt;</p> <p>default: \"0123456789abcdefghijklmnopqrstuv\"</p> <p>context: http, server, server if, location, location if</p> <p>phase: no</p> <p>This directive controls the alphabet used for encoding/decoding a base32 digest. It accepts a string containing the desired alphabet like \"ABCDEFGHIJKLMNOPQRSTUVWXYZ234567\" for standard alphabet.</p> <p>Extended (base32hex) alphabet is used by default.</p> <p>This directive was first introduced in <code>v0.28</code>.</p>"},{"location":"modules/set-misc/#set_decode_base32","title":"set_decode_base32","text":"<p>syntax: set_decode_base32 $dst &lt;src&gt;</p> <p>syntax: set_decode_base32 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Similar to the set_encode_base32 directive, but does exactly the opposite operation, .i.e, decoding a base32(hex) digest into its original form.</p>"},{"location":"modules/set-misc/#set_encode_base64","title":"set_encode_base64","text":"<p>syntax: set_encode_base64 $dst &lt;src&gt;</p> <p>syntax: set_encode_base64 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its base64 digest and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $raw \"abcde\";\n     set_encode_base64 $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>YWJjZGU=\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"abcde\";\n     set_encode_base64 $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_encode_base64url","title":"set_encode_base64url","text":"<p>syntax: set_encode_base64url $dst &lt;src&gt;</p> <p>syntax: set_encode_base64url $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its base64 url safe digest and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $raw \"abcde\";\n     set_encode_base64url $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>YWJjZGU=\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"abcde\";\n     set_encode_base64url $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_decode_base64","title":"set_decode_base64","text":"<p>syntax: set_decode_base64 $dst &lt;src&gt;</p> <p>syntax: set_decode_base64 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Similar to the set_encode_base64 directive, but does exactly the opposite operation, .i.e, decoding a base64 digest into its original form.</p>"},{"location":"modules/set-misc/#set_decode_base64url","title":"set_decode_base64url","text":"<p>syntax: set_decode_base64url $dst &lt;src&gt;</p> <p>syntax: set_decode_base64url $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Similar to the set_encode_base64url directive, but does exactly the the opposite operation, .i.e, decoding a base64 url safe digest into its original form.</p>"},{"location":"modules/set-misc/#set_encode_hex","title":"set_encode_hex","text":"<p>syntax: set_encode_hex $dst &lt;src&gt;</p> <p>syntax: set_encode_hex $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its hexadecimal digest and assign the result into the first argument, variable <code>$dst</code>. For example,</p> <pre><code> location /test {\n     set $raw \"\u7ae0\u4ea6\u6625\";\n     set_encode_hex $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>e7aba0e4baa6e698a5\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"\u7ae0\u4ea6\u6625\";\n     set_encode_hex $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_decode_hex","title":"set_decode_hex","text":"<p>syntax: set_decode_hex $dst &lt;src&gt;</p> <p>syntax: set_decode_hex $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>Similar to the set_encode_hex directive, but does exactly the opposite operation, .i.e, decoding a hexadecimal digest into its original form.</p>"},{"location":"modules/set-misc/#set_sha1","title":"set_sha1","text":"<p>syntax: set_sha1 $dst &lt;src&gt;</p> <p>syntax: set_sha1 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its SHA-1 digest and assign the result into the first argument, variable <code>$dst</code>. The hexadecimal form of the <code>SHA-1</code> digest will be generated automatically, use set_decode_hex to decode the result if you want the binary form of the <code>SHA-1</code> digest.</p> <p>For example,</p> <pre><code> location /test {\n     set $raw \"hello\";\n     set_sha1 $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>aaf4c61ddcc5e8a2dabede0f3b482cd9aea9434d\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"hello\";\n     set_sha1 $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_md5","title":"set_md5","text":"<p>syntax: set_md5 $dst &lt;src&gt;</p> <p>syntax: set_md5 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>category: ndk_set_var_value</p> <p>When taking two arguments, this directive will encode the value of the second argument <code>&lt;src&gt;</code> to its MD5 digest and assign the result into the first argument, variable <code>$dst</code>. The hexadecimal form of the <code>MD5</code> digest will be generated automatically, use set_decode_hex to decode the result if you want the binary form of the <code>MD5</code> digest.</p> <p>For example,</p> <pre><code> location /test {\n     set $raw \"hello\";\n     set_md5 $digest $raw;\n\n     echo $digest;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>5d41402abc4b2a76b9719d911017c592\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>When taking a single argument, this directive will do in-place modification of the argument variable. For example,</p> <pre><code> location /test {\n     set $value \"hello\";\n     set_md5 $value;\n\n     echo $value;\n }\n</code></pre> <p>then request <code>GET /test</code> will give exactly the same output as the previous example.</p> <p>This directive can be invoked by lua-nginx-module's ndk.set_var.DIRECTIVE interface and array-var-nginx-module's array_map_op directive.</p>"},{"location":"modules/set-misc/#set_hmac_sha1","title":"set_hmac_sha1","text":"<p>syntax: set_hmac_sha1 $dst &lt;secret_key&gt; &lt;src&gt;</p> <p>syntax: set_hmac_sha1 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Computes the HMAC-SHA1 digest of the argument <code>&lt;src&gt;</code> and assigns the result into the argument variable <code>$dst</code> with the secret key <code>&lt;secret_key&gt;</code>.</p> <p>The raw binary form of the <code>HMAC-SHA1</code> digest will be generated, use set_encode_base64, for example, to encode the result to a textual representation if desired.</p> <p>For example,</p> <pre><code> location /test {\n     set $secret 'thisisverysecretstuff';\n     set $string_to_sign 'some string we want to sign';\n     set_hmac_sha1 $signature $secret $string_to_sign;\n     set_encode_base64 $signature $signature;\n     echo $signature;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>R/pvxzHC4NLtj7S+kXFg/NePTmk=\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>This directive requires the OpenSSL library enabled in your Nginx build (usually by passing the <code>--with-http_ssl_module</code> option to the <code>./configure</code> script).</p>"},{"location":"modules/set-misc/#set_hmac_sha256","title":"set_hmac_sha256","text":"<p>syntax: set_hmac_sha256 $dst &lt;secret_key&gt; &lt;src&gt;</p> <p>syntax: set_hmac_sha256 $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Computes the HMAC-SHA256 digest of the argument <code>&lt;src&gt;</code> and assigns the result into the argument variable <code>$dst</code> with the secret key <code>&lt;secret_key&gt;</code>.</p> <p>The raw binary form of the <code>HMAC-SHA256</code> digest will be generated, use set_encode_base64, for example, to encode the result to a textual representation if desired.</p> <p>For example,</p> <pre><code> location /test {\n     set $secret 'thisisverysecretstuff';\n     set $string_to_sign 'some string we want to sign';\n     set_hmac_sha256 $signature $secret $string_to_sign;\n     set_encode_base64 $signature $signature;\n     echo $signature;\n }\n</code></pre> <p>Then request <code>GET /test</code> will yield the following output</p> <pre><code>4pU3GRQrKKIoeLb9CqYsavHE2l6Hx+KMmRmesU+Cfrs=\n</code></pre> <p>Please note that we're using echo-nginx-module's echo directive here to output values of nginx variables directly.</p> <p>This directive requires the OpenSSL library enabled in your Nginx build (usually by passing the <code>--with-http_ssl_module</code> option to the <code>./configure</code> script).</p>"},{"location":"modules/set-misc/#set_random","title":"set_random","text":"<p>syntax: set_random $res &lt;from&gt; &lt;to&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Generates a (pseudo) random number (in textual form) within the range <code>[&lt;$from&gt;, &lt;$to&gt;]</code> (inclusive).</p> <p>Only non-negative numbers are allowed for the <code>&lt;from&gt;</code> and <code>&lt;to&gt;</code> arguments.</p> <p>When <code>&lt;from&gt;</code> is greater than <code>&lt;to&gt;</code>, their values will be exchanged accordingly.</p> <p>For instance,</p> <pre><code> location /test {\n     set $from 5;\n     set $to 7;\n     set_random $res $from $to;\n\n     echo $res;\n }\n</code></pre> <p>then request <code>GET /test</code> will output a number between 5 and 7 (i.e., among 5, 6, 7).</p> <p>For now, there's no way to configure a custom random generator seed.</p> <p>Behind the scene, it makes use of the standard C function <code>rand()</code>.</p> <p>This directive was first introduced in the <code>v0.22rc1</code> release.</p> <p>See also set_secure_random_alphanum and set_secure_random_lcalpha.</p>"},{"location":"modules/set-misc/#set_secure_random_alphanum","title":"set_secure_random_alphanum","text":"<p>syntax: set_secure_random_alphanum $res &lt;length&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Generates a cryptographically-strong random string <code>&lt;length&gt;</code> characters long with the alphabet <code>[a-zA-Z0-9]</code>.</p> <p><code>&lt;length&gt;</code> may be between 1 and 64, inclusive.</p> <p>For instance,</p> <pre><code> location /test {\n     set_secure_random_alphanum $res 32;\n\n     echo $res;\n }\n</code></pre> <p>then request <code>GET /test</code> will output a string like <code>ivVVRP2DGaAqDmdf3Rv4ZDJ7k0gOfASz</code>.</p> <p>This functionality depends on the presence of the <code>/dev/urandom</code> device, available on most UNIX-like systems.</p> <p>See also set_secure_random_lcalpha and set_random.</p> <p>This directive was first introduced in the <code>v0.22rc8</code> release.</p>"},{"location":"modules/set-misc/#set_secure_random_lcalpha","title":"set_secure_random_lcalpha","text":"<p>syntax: set_secure_random_lcalpha $res &lt;length&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Generates a cryptographically-strong random string <code>&lt;length&gt;</code> characters long with the alphabet <code>[a-z]</code>.</p> <p><code>&lt;length&gt;</code> may be between 1 and 64, inclusive.</p> <p>For instance,</p> <pre><code> location /test {\n     set_secure_random_lcalpha $res 32;\n\n     echo $res;\n }\n</code></pre> <p>then request <code>GET /test</code> will output a string like <code>kcuxcddktffsippuekhshdaclaquiusj</code>.</p> <p>This functionality depends on the presence of the <code>/dev/urandom</code> device, available on most UNIX-like systems.</p> <p>This directive was first introduced in the <code>v0.22rc8</code> release.</p> <p>See also set_secure_random_alphanum and set_random.</p>"},{"location":"modules/set-misc/#set_rotate","title":"set_rotate","text":"<p>syntax: set_rotate $value &lt;from&gt; &lt;to&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Increments <code>$value</code> but keeps it in range from <code>&lt;from&gt;</code> to <code>&lt;to&gt;</code>.  If <code>$value</code> is greater than <code>&lt;to&gt;</code> or less than <code>&lt;from&gt;</code> is will be  set to <code>&lt;from&gt;</code> value.</p> <p>The current value after running this directive will always be saved on a per-location basis. And the this saved value will be used for incrementation when the <code>$value</code> is not initialized or has a bad value.</p> <p>Only non-negative numbers are allowed for the <code>&lt;from&gt;</code> and <code>&lt;to&gt;</code> arguments.</p> <p>When <code>&lt;from&gt;</code> is greater than <code>&lt;to&gt;</code>, their values will be exchanged accordingly.</p> <p>For instance,</p> <pre><code> location /rotate {\n     default_type text/plain;\n     set $counter $cookie_counter;\n     set_rotate $counter 1 5;\n     echo $counter;\n     add_header Set-Cookie counter=$counter;\n }\n</code></pre> <p>then request <code>GET /rotate</code> will output next number between 1 and 5 (i.e., 1, 2, 3, 4, 5) on each refresh of the page. This directive may be userful for banner rotation purposes.</p> <p>Another example is to use server-side value persistence to do simple round-robin:</p> <pre><code> location /rotate {\n     default_type text/plain;\n     set_rotate $counter 0 3;\n     echo $counter;\n }\n</code></pre> <p>And accessing <code>/rotate</code> will also output integer sequence 0, 1, 2, 3, 0, 1, 2, 3, and so on.</p> <p>This directive was first introduced in the <code>v0.22rc7</code> release.</p>"},{"location":"modules/set-misc/#set_local_today","title":"set_local_today","text":"<p>syntax: set_local_today $dst</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Set today's date (\"yyyy-mm-dd\") in localtime to the argument variable <code>$dst</code>.</p> <p>Here's an example,</p> <pre><code> location /today {\n     set_local_today $today;\n     echo $today;\n }\n</code></pre> <p>then request <code>GET /today</code> will output something like</p> <pre><code>2011-08-16\n</code></pre> <p>and year, the actual date you get here will vary every day ;)</p> <p>Behind the scene, this directive utilizes the <code>ngx_time</code> API in the Nginx core, so usually no syscall is involved due to the time caching mechanism in the Nginx core.</p>"},{"location":"modules/set-misc/#set_formatted_gmt_time","title":"set_formatted_gmt_time","text":"<p>syntax: set_formatted_gmt_time $res &lt;time-format&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Set a formatted GMT time to variable <code>$res</code> (as the first argument) using the format string in the second argument.</p> <p>All the conversion specification notations in the standard C function <code>strftime</code> are supported, like <code>%Y</code> (for 4-digit years) and <code>%M</code> (for minutes in decimal). See http://linux.die.net/man/3/strftime for a complete list of conversion specification symbols.</p> <p>Below is an example:</p> <pre><code> location = /t {\n     set_formatted_gmt_time $timestr \"%a %b %e %H:%M:%S %Y GMT\";\n     echo $timestr;\n }\n</code></pre> <p>Accessing <code>/t</code> yields the output</p> <pre><code>Fri Dec 13 15:34:37 2013 GMT\n</code></pre> <p>This directive was first added in the <code>0.23</code> release.</p> <p>See also set_formatted_local_time.</p>"},{"location":"modules/set-misc/#set_formatted_local_time","title":"set_formatted_local_time","text":"<p>syntax: set_formatted_local_time $res &lt;time-format&gt;</p> <p>default: no</p> <p>context: location, location if</p> <p>phase: rewrite</p> <p>Set a formatted local time to variable <code>$res</code> (as the first argument) using the format string in the second argument.</p> <p>All the conversion specification notations in the standard C function <code>strftime</code> are supported, like <code>%Y</code> (for 4-digit years) and <code>%M</code> (for minutes in decimal). See http://linux.die.net/man/3/strftime for a complete list of conversion specification symbols.</p> <p>Below is an example:</p> <pre><code> location = /t {\n     set_formatted_local_time $timestr \"%a %b %e %H:%M:%S %Y %Z\";\n     echo $timestr;\n }\n</code></pre> <p>Accessing <code>/t</code> yields the output</p> <pre><code>Fri Dec 13 15:42:15 2013 PST\n</code></pre> <p>This directive was first added in the <code>0.23</code> release.</p> <p>See also set_formatted_gmt_time.</p>"},{"location":"modules/set-misc/#caveats","title":"Caveats","text":"<p>Do not use $arg_PARAMETER, $cookie_COOKIE, $http_HEADER or other special variables defined in the Nginx core module as the target variable in this module's directives. For instance,</p> <pre><code> set_if_empty $arg_user 'foo';  # DO NOT USE THIS!\n</code></pre> <p>may lead to segmentation faults.</p>"},{"location":"modules/set-misc/#changes","title":"Changes","text":"<p>The change logs for every release of this module can be obtained from the OpenResty bundle's change logs:</p> <p>http://openresty.org/#Changes</p>"},{"location":"modules/set-misc/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too. Thanks to the Test::Nginx module in the Perl world.</p> <p>To run it on your side:</p> <pre><code> $ PATH=/path/to/your/nginx-with-set-misc-module:$PATH prove -r t\n</code></pre> <p>You need to terminate any Nginx processes before running the test suite if you have changed the Nginx server binary.</p> <p>Because a single nginx server (by default, <code>localhost:1984</code>) is used across all the test scripts (<code>.t</code> files), it's meaningless to run the test suite in parallel by specifying <code>-jN</code> when invoking the <code>prove</code> utility.</p>"},{"location":"modules/set-misc/#see-also","title":"See Also","text":"<ul> <li>Nginx Devel Kit</li> <li>The OpenResty bundle</li> </ul>"},{"location":"modules/set-misc/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-set-misc.</p>"},{"location":"modules/shibboleth/","title":"shibboleth: Shibboleth Auth Request module for NGINX","text":""},{"location":"modules/shibboleth/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-shibboleth\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-shibboleth\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_shibboleth_module.so;\n</code></pre> <p>This document describes nginx-module-shibboleth v2.0.2  released on May 26 2023.</p>"},{"location":"modules/shibboleth/#shibboleth-auth-request-module-for-nginx","title":"Shibboleth auth request module for Nginx","text":"<p>This module allows Nginx to work with Shibboleth, by way of Shibboleth's FastCGI authorizer. This module requires specific configuration in order to work correctly, as well as Shibboleth's FastCGI authorizer application available on the system. It aims to be similar to parts of Apache's mod_shib, though Shibboleth authorisation and authentication settings are configured via shibboleth2.xml rather than in the web server configuration.</p> <p>With this module configured against a <code>location</code> block, incoming requests are authorized within Nginx based upon the result of a subrequest to Shibboleth's FastCGI authorizer. In this process, this module can be used to copy user attributes from a successful authorizer response into Nginx's original request as headers or environment parameters for use by any backend application. If authorization is not successful, the authorizer response status and headers are returned to the client, denying access or redirecting the user's browser accordingly (such as to a WAYF page, if so configured).</p> <p>This module works at access phase and therefore may be combined with other access modules (such as <code>access</code>, <code>auth_basic</code>) via the <code>satisfy</code> directive. This module can be also compiled alongside <code>ngx_http_auth_request_module</code>, though use of both of these modules in the same <code>location</code> block is untested and not advised.</p> <p>Read more about the Behaviour_ below and consult Configuration_ for important notes on avoiding spoofing if using headers for attributes.</p> <p>For further information on why this is a dedicated module, see https://forum.nginx.org/read.php?2,238523,238523#msg-238523</p>"},{"location":"modules/shibboleth/#directives","title":"Directives","text":"<p>The following directives are added into your Nginx configuration files. The contexts mentioned below show where they may be added.</p> <p>shib_request \\&lt;uri&gt;|off Context: <code>http</code>, <code>server</code>, <code>location</code> Default: <code>off</code></p> <p>Switches the Shibboleth auth request module on and sets URI which will be asked for authorization. The configured URI should refer to a Nginx location block that points to your Shibboleth FastCGI authorizer.</p> <p>The HTTP status and headers of the response resulting from the sub-request to the configured URI will be returned to the user, in accordance with the FastCGI Authorizer specification. The one (potentially significant) caveat is that due to the way Nginx operates at present with regards to subrequests (what an Authorizer effectively requires), the request body will not be forwarded to the authorizer, and similarly, the response body from the authorizer will not be returned to the client.</p> <p>Configured URIs are not restricted to using a FastCGI backend to generate a response, however. This may be useful during testing or otherwise, as you can use Nginx's built in <code>return</code> and <code>rewrite</code> directives to produce a suitable response. Additionally, this module may be used with any FastCGI authorizer, although operation may be affected by the above caveat.</p> <p>warning</p> <p>The <code>shib_request</code> directive no longer requires the <code>shib_authorizer</code> flag. This must be removed for Nginx to start. No other changes are required.</p> <p>shib_request_set \\&lt;variable&gt; \\&lt;value&gt; Context: <code>http</code>, <code>server</code>, <code>location</code> Default: <code>none</code></p> <p>Set the <code>variable</code> to the specified <code>value</code> after the auth request has completed. The <code>value</code> may contain variables from the auth request's response. For instance, <code>$upstream_http_*</code>, <code>$upstream_status</code>, and any other variables mentioned in the nginx_http_upstream_module documentation.</p> <p>This directive can be used to introduce Shibboleth attributes into the environment of the backend application, such as \\$_SERVER for a FastCGI PHP application and is the recommended method of doing so. See the Configuration_ documentation for an example.</p> <p>shib_request_use_headers on|off Context: <code>http</code>, <code>server</code>, <code>location</code> Default: <code>off</code></p> <p>note</p> <p>Added in v2.0.0.</p> <p>Copy attributes from the Shibboleth authorizer response into the main request as headers, making them available to upstream servers and applications. Use this option only if your upstream/application does not support server parameters via <code>shib_request_set</code>.</p> <p>With this setting enabled, Authorizer response headers beginning with <code>Variable-\\*</code> are extracted, stripping the <code>Variable-</code> substring from the header name, and copied into the main request before it is sent to the backend. For example, an authorizer response header such as <code>Variable-Commonname: John Smith</code> would result in <code>Commonname: John Smith</code> being added to the main request, and thus sent to the backend.</p> <p>Beware of spoofing - you must ensure that your backend application is protected from injection of headers. Consult the Configuration_ example on how to achieve this.</p>"},{"location":"modules/shibboleth/#installation_1","title":"Installation","text":"<p>This module can either be compiled statically or dynamically, since the introduction of dynamic modules in Nginx 1.9.11. The practical upshot of dynamic modules is that they can be loaded, as opposed to static modules which are permanently present and enabled.</p> <p>The easiest way to obtain a packaged version of this module is to use the pkg-oss tool from Nginx, which provides for packaging of dynamic modules for installation alongside the official releases of Nginx from the main repositories and helps avoid the need to compile Nginx by hand.</p> <p>Otherwise, to compile Nginx with this module dynamically, pass the following option to <code>./configure</code> when building Nginx:</p> <pre><code>--add-dynamic-module=&lt;path&gt;\n</code></pre> <p>You will need to explicitly load the module in your <code>nginx.conf</code> by including:</p> <pre><code>load_module /path/to/modules/ngx_http_shibboleth_module.so;\n</code></pre> <p>and reload or restart Nginx.</p> <p>To compile Nginx with this module statically, pass the following option to <code>./configure</code> when building Nginx:</p> <pre><code>--add-module=&lt;path&gt;\n</code></pre> <p>With a static build, no additional loading is required as the module is built-in to Nginx.</p>"},{"location":"modules/shibboleth/#configuration","title":"Configuration","text":"<p>For full details about configuring the Nginx/Shibboleth environment, see the documentation at https://github.com/nginx-shib/nginx-http-shibboleth/blob/master/CONFIG.rst.</p> <p>An example <code>server</code> block consists of the following:</p> <pre><code>#FastCGI authorizer for Auth Request module\nlocation = /shibauthorizer {\n    internal;\n    include fastcgi_params;\n    fastcgi_pass unix:/opt/shibboleth/shibauthorizer.sock;\n}\n\n#FastCGI responder\nlocation /Shibboleth.sso {\n    include fastcgi_params;\n    fastcgi_pass unix:/opt/shibboleth/shibresponder.sock;\n}\n\n## Using the ``shib_request_set`` directive, we can introduce attributes as\n## environment variables for the backend application. In this example, we\n## set ``fastcgi_param`` but this could be any type of Nginx backend that\n## supports parameters (by using the appropriate *_param option)\n#\n## The ``shib_fastcgi_params`` is an optional set of default parameters,\n## available in the ``includes/`` directory in this repository.\n#\n## Choose this type of configuration unless your backend application\n## doesn't support server parameters or specifically requires headers.\nlocation /secure-environment-vars {\n    shib_request /shibauthorizer;\n    include shib_fastcgi_params;\n    shib_request_set $shib_commonname $upstream_http_variable_commonname;\n    shib_request_set $shib_email $upstream_http_variable_email;\n    fastcgi_param COMMONNAME $shib_commonname;\n    fastcgi_param EMAIL $shib_email;\n    fastcgi_pass unix:/path/to/backend.socket;\n}\n\n## A secured location. All incoming requests query the Shibboleth FastCGI authorizer.\n## Watch out for performance issues and spoofing!\n#\n## Choose this type of configuration for ``proxy_pass`` applications\n## or backends that don't support server parameters.\nlocation /secure {\n    shib_request /shibauthorizer;\n    shib_request_use_headers on;\n\n    # Attributes from Shibboleth are introduced as headers by the FastCGI\n    # authorizer so we must prevent spoofing. The\n    # ``shib_clear_headers`` is a set of default header directives,\n    # available in the `includes/` directory in this repository.\n    include shib_clear_headers;\n\n    # Add *all* attributes that your application uses, including all\n    #variations.\n    more_clear_input_headers 'displayName' 'mail' 'persistent-id';\n\n    # This backend application will receive Shibboleth variables as request\n    # headers (from Shibboleth's FastCGI authorizer)\n    proxy_pass http://localhost:8080;\n}\n</code></pre> <p>Note that we use the headers-more-nginx-module to clear potentially dangerous input headers and avoid the potential for spoofing. The latter example with environment variables isn't susceptible to header spoofing, as long as the backend reads data from the environment parameters only.</p> <p>A default configuration is available to clear the basic headers from the Shibboleth authorizer, but you must ensure you write your own clear directives for all attributes your application uses. Bear in mind that some applications will try to read a Shibboleth attribute from the environment and then fall back to headers, so review your application's code even if you are not using <code>shib_request_use_headers</code>.</p> <p>With use of <code>shib_request_set</code>, a default params file is available which you can use as an nginx <code>include</code> to ensure all core Shibboleth variables get passed from the FastCGI authorizer to the application. Numerous default attributes are included so remove the ones that aren't required by your application and add Federation or IDP attributes that you need. This default params file can be re-used for upstreams that aren't FastCGI by simply changing the <code>fastcgi_param</code> directives to <code>uwsgi_param</code>, <code>scgi_param</code> or so forth.</p>"},{"location":"modules/shibboleth/#gotchas","title":"Gotchas","text":"<ul> <li> <p>Subrequests, such as the Shibboleth auth request, aren't processed through header filters. This means that built-in directives like <code>add_header</code> will not work if configured as part of the a <code>/shibauthorizer</code> block. If you need to manipulate subrequest headers, use <code>more_set_headers</code> from the module <code>headers-more</code>.</p> <p>See https://forum.nginx.org/read.php?29,257271,257272#msg-257272.</p> </li> </ul>"},{"location":"modules/shibboleth/#behaviour","title":"Behaviour","text":"<p>This module follows the FastCGI Authorizer specification where possible, but has some notable deviations - with good reason. The behaviour is thus:</p> <ul> <li>An authorizer subrequest is comprised of all aspects of the original request, excepting the request body as Nginx does not support buffering of request bodies. As the Shibboleth FastCGI authorizer does not consider the request body, this is not an issue.</li> <li> <p>If an authorizer subrequest returns a <code>200</code> status, access is allowed.</p> <p>If <code>shib_request_use_headers</code> is enabled, and response headers beginning with <code>Variable-\\*</code> are extracted, stripping the <code>Variable-</code> substring from the header name, and copied into the main request. Other authorizer response headers not prefixed with <code>Variable-</code> and the response body are ignored. The FastCGI spec calls for <code>Variable-*</code> name-value pairs to be included in the FastCGI environment, but we make them headers so as they may be used with any backend (such as <code>proxy_pass</code>) and not just restrict ourselves to FastCGI applications. By passing the <code>Variable-*</code> data as headers instead, we end up following the behaviour of <code>ShibUseHeaders On</code> in <code>mod_shib</code> for Apache, which passes these user attributes as headers.</p> <p>In order to pass attributes as environment variables (the equivalent to <code>ShibUseEnvironment On</code> in <code>mod_shib</code>), attributes must be manually extracted using <code>shib_request_set</code> directives for each attribute. This cannot (currently) be done en masse for all attributes as each backend may accept parameters in a different way (<code>fastcgi_param</code>, <code>uwsgi_param</code> etc). Pull requests are welcome to automate this behaviour.</p> </li> <li> <p>If the authorizer subrequest returns any other status (including redirects or errors), the authorizer response's status and headers are returned to the client.</p> <p>This means that on <code>401 Unauthorized</code> or <code>403 Forbidden</code>, access will be denied and headers (such as <code>WWW-Authenticate</code>) from the authorizer will be passed to client. All other authorizer responses (such as <code>3xx</code> redirects) are passed back to the client, including status and headers, allowing redirections such as those to WAYF pages and the Shibboleth responder (<code>Shibboleth.sso</code>) to work correctly.</p> <p>The FastCGI Authorizer spec calls for the response body to be returned to the client, but as Nginx does not currently support buffering subrequest responses (<code>NGX_HTTP_SUBREQUEST_IN_MEMORY</code>), the authorizer response body is effectively ignored. A workaround is to have Nginx serve an <code>error_page</code> of its own, like so:</p> <pre><code>location /secure {\n   shib_request /shibauthorizer;\n   error_page 403 /shibboleth-forbidden.html;\n   ...\n}\n</code></pre> <p>This serves the given error page if the Shibboleth authorizer denies the user access to this location. Without <code>error_page</code> specified, Nginx will serve its generic error pages.</p> <p>Note that this does not apply to the Shibboleth responder (typically hosted at <code>Shibboleth.sso</code>) as it is a FastCGI responder and Nginx is fully compatible with this as no subrequests are used.</p> <p>For more details, see https://forum.nginx.org/read.php?2,238444,238453.</p> </li> </ul> <p>Whilst this module is geared specifically for Shibboleth's FastCGI authorizer, it will likely work with other authorizers, bearing in mind the deviations from the spec above.</p>"},{"location":"modules/shibboleth/#tests","title":"Tests","text":"<p>Tests are automatically run on GitHub Actions (using this configuration) whenever new commits are made to the repository or when new pull requests are opened. If something breaks, you'll be informed and the results will be reported on GitHub.</p> <p>Tests are written using a combination of a simple Bash script for compilation of our module with different versions and configurations of Nginx and the Test::Nginx Perl test scaffolding for integration testing. Consult the previous link for information on how to extend the tests, and also refer to the underlying Test::Base documentation on aspects like the blocks() function.</p> <p>Integration tests are run automatically by CI but can also be run manually (requires Perl &amp; CPAN to be installed):</p> <pre><code>cd nginx-http-shibboleth\ncpanm --notest --local-lib=$HOME/perl5 Test::Nginx\n## nginx must be present in PATH and built with debugging symbols\nPERL5LIB=$HOME/perl5/lib/perl5 prove\n</code></pre>"},{"location":"modules/shibboleth/#help-support","title":"Help &amp; Support","text":"<p>Support requests for Shibboleth configuration and Nginx or web server setup should be directed to the Shibboleth community users mailing list. See https://www.shibboleth.net/community/lists/ for details.</p>"},{"location":"modules/shibboleth/#debugging","title":"Debugging","text":"<p>Because of the complex nature of the nginx/FastCGI/Shibboleth stack, debugging configuration issues can be difficult. Here's some key points:</p> <ol> <li>Confirm that <code>nginx-http-shibboleth</code> is successfully built and installed within nginx. You can check by running <code>nginx -V</code> and inspecting the output for <code>--add-module=[path]/nginx-http-shibboleth</code> or <code>--add-dynamic-module=[path]/nginx-http-shibboleth</code>.</li> <li>If using dynamic modules for nginx, confirm you have used the <code>load_module</code> directive to load this module. Your use of <code>shib_request</code> and other directives will fail if you have forgotten to load the module.</li> <li>If using a version of nginx that is different to those we test with or if you are using other third-party modules, you should run the test suite above to confirm compatibility. If any tests fail, then check your configuration or consider updating your nginx version.</li> <li>Shibboleth configuration: check your <code>shibboleth2.xml</code> and associated configuration to ensure your hosts, paths and attributes are being correctly released. An example configuration can help you identify key \"gotchas\" to configuring <code>shibboleth2.xml</code> to work with the FastCGI authorizer.</li> <li>Application-level: within your code, always start with the simplest possible debugging output (such as printing the request environment) and work up from there. If you want to create a basic, stand-alone app, take a look at the Bottle configuration on the wiki.</li> <li> <p>Debugging module internals: if you've carefully checked all of the above, then you can also debug the behaviour of this module itself. You will need to have compiled nginx with debugging support (via <code>./auto/configure --with-debug ...</code>) and when running nginx, it is easiest if you're able run in the foreground with debug logging enabled. Add the following to your <code>nginx.conf</code>:</p> <pre><code>daemon off;\nerror_log stderr debug;\n</code></pre> <p>and run nginx. Upon starting nginx you should see lines containing [debug] and as you make requests, console logging will continue. If this doesn't happen, then check your nginx configuration and compilation process.</p> <p>When you eventually make a request that hits (or should invoke) the <code>shib_request</code> location block, you will see lines like so in the output:</p> <pre><code>[debug] 1234#0: shib request handler\n[debug] 1234#0: shib request set variables\n[debug] 1234#0: shib request authorizer handler\n[debug] 1234#0: shib request authorizer allows access\n[debug] 1234#0: shib request authorizer copied header: \"AUTH_TYPE: shibboleth\"\n[debug] 1234#0: shib request authorizer copied header: \"REMOTE_USER: john.smith@example.com\"\n...\n</code></pre> <p>If you don't see these types of lines containing shib request ..., or if you see some of the lines above but not where headers/variables are being copied, then double-check your nginx configuration. If you're still not getting anywhere, then you can add your own debugging lines into the source (follow this module's examples) to eventually determine what is going wrong and when. If doing this, don't forget to recompile nginx and/or <code>nginx-http-shibboleth</code> whenever you make a change.</p> </li> </ol> <p>If you believe you've found a bug in the core module code, then please create an issue.</p> <p>You can also search existing issues as it is likely someone else has encountered a similar issue before.</p>"},{"location":"modules/shibboleth/#versioning","title":"Versioning","text":"<p>This module uses Semantic Versioning and all releases are tagged on GitHub, which allows package downloads of individual tags.</p>"},{"location":"modules/shibboleth/#license","title":"License","text":"<p>This project is licensed under the same license that nginx is, the 2-clause BSD-like license.</p>"},{"location":"modules/shibboleth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-shibboleth.</p>"},{"location":"modules/slowfs/","title":"slowfs: NGINX SlowFS Cache Module","text":""},{"location":"modules/slowfs/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-slowfs\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-slowfs\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_slowfs_module.so;\n</code></pre> <p>This document describes nginx-module-slowfs v1.11  released on Aug 23 2020.</p> <p><code>ngx_slowfs_cache</code> is <code>nginx</code> module which allows caching of static files (served using <code>root</code> directive). This enables one to create fast caches for files stored on slow filesystems, for example:</p> <ul> <li>storage: network disks, cache: local disks,</li> <li>storage: 7,2K SATA drives, cache: 15K SAS drives in RAID0.</li> </ul> <p>WARNING! There is no point in using this module when cache is placed on the same speed disk(s) as origin.</p>"},{"location":"modules/slowfs/#sponsors","title":"Sponsors","text":"<p><code>ngx_slowfs_cache</code> was fully funded by c2hosting.com.</p>"},{"location":"modules/slowfs/#status","title":"Status","text":"<p>This module is production-ready and it's compatible with following nginx releases:</p> <ul> <li>0.7.x (tested with 0.7.60 to 0.7.69),</li> <li>0.8.x (tested with 0.8.0 to 0.8.55),</li> <li>0.9.x (tested with 0.9.0 to 0.9.7),</li> <li>1.0.x (tested with 1.0.0 to 1.0.15),</li> <li>1.1.x (tested with 1.1.0 to 1.1.19),</li> <li>1.2.x (tested with 1.2.0 to 1.2.7),</li> <li>1.3.x (tested with 1.3.0 to 1.3.14).</li> </ul>"},{"location":"modules/slowfs/#configuration-notes","title":"Configuration notes","text":"<p><code>slowfs_cache_path</code> and <code>slowfs_temp_path</code> values should point to the same filesystem, otherwise files will be copied twice.</p> <p><code>ngx_slowfs_cache</code> currently doesn't work when AIO is enabled.</p>"},{"location":"modules/slowfs/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/slowfs/#slowfs_cache","title":"slowfs_cache","text":"<ul> <li>syntax: <code>slowfs_cache zone_name</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets area used for caching (previously defined using <code>slowfs_cache_path</code>).</p>"},{"location":"modules/slowfs/#slowfs_cache_key","title":"slowfs_cache_key","text":"<ul> <li>syntax: <code>slowfs_cache_key key</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets key for caching.</p>"},{"location":"modules/slowfs/#slowfs_cache_purge","title":"slowfs_cache_purge","text":"<ul> <li>syntax: <code>slowfs_cache_purge zone_name key</code></li> <li>default: <code>none</code></li> <li>context: <code>location</code></li> </ul> <p>Sets area and key used for purging selected pages from cache.</p>"},{"location":"modules/slowfs/#slowfs_cache_path","title":"slowfs_cache_path","text":"<ul> <li>syntax: <code>slowfs_cache_path path [levels] keys_zone=zone_name:zone_size [inactive] [max_size]</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code></li> </ul> <p>Sets cache area and its structure.</p>"},{"location":"modules/slowfs/#slowfs_temp_path","title":"slowfs_temp_path","text":"<ul> <li>syntax: <code>slowfs_temp_path path [level1] [level2] [level3]</code></li> <li>default: <code>/tmp 1 2</code></li> <li>context: <code>http</code></li> </ul> <p>Sets temporary area where files are stored before they are moved to cache area.</p>"},{"location":"modules/slowfs/#slowfs_cache_min_uses","title":"slowfs_cache_min_uses","text":"<ul> <li>syntax: <code>slowfs_cache_min_uses number</code></li> <li>default: <code>1</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets number of uses after which file is copied to cache.</p>"},{"location":"modules/slowfs/#slowfs_cache_valid","title":"slowfs_cache_valid","text":"<ul> <li>syntax: <code>slowfs_cache_valid [reply_code] time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets time for which file will be served from cache.</p>"},{"location":"modules/slowfs/#slowfs_big_file_size","title":"slowfs_big_file_size","text":"<ul> <li>syntax: <code>slowfs_big_file_size size</code></li> <li>default: <code>128k</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets minimum file size for <code>big</code> files. Worker processes <code>fork()</code> child process before they start copying <code>big</code> files to avoid any service disruption. </p>"},{"location":"modules/slowfs/#configuration-variables","title":"Configuration variables","text":""},{"location":"modules/slowfs/#slowfs_cache_status","title":"$slowfs_cache_status","text":"<p>Represents availability of cached file.</p> <p>Possible values are: <code>MISS</code>, <code>HIT</code> and <code>EXPIRED</code>.</p>"},{"location":"modules/slowfs/#sample-configuration","title":"Sample configuration","text":"<pre><code>http {\n    slowfs_cache_path  /tmp/cache levels=1:2 keys_zone=fastcache:10m;\n    slowfs_temp_path   /tmp/temp 1 2;\n\n    server {\n        location / {\n            root                /var/www;\n            slowfs_cache        fastcache;\n            slowfs_cache_key    $uri;\n            slowfs_cache_valid  1d;\n        }\n\n        location ~ /purge(/.*) {\n            allow               127.0.0.1;\n            deny                all;\n            slowfs_cache_purge  fastcache $1;\n        }\n   }\n}\n</code></pre>"},{"location":"modules/slowfs/#testing","title":"Testing","text":"<p><code>ngx_slowfs_cache</code> comes with complete test suite based on Test::Nginx.</p> <p>You can test it by running:</p> <p><code>$ prove</code></p>"},{"location":"modules/slowfs/#see-also","title":"See also","text":"<ul> <li>ngx_cache_purge.</li> </ul>"},{"location":"modules/slowfs/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-slowfs.</p>"},{"location":"modules/small-light/","title":"small-light: Dynamic image transformation module For NGINX","text":""},{"location":"modules/small-light/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-small-light\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-small-light\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_small_light_module.so;\n</code></pre> <p>This document describes nginx-module-small-light v0.9.4  released on May 27 2020.</p> <p>A dynamic image transformation module for nginx.</p>"},{"location":"modules/small-light/#getting-started","title":"Getting started","text":"<p>Add the configuration below to some server context in nginx.conf and start nginx.</p> <pre><code>small_light on;\nlocation ~ small_light[^/]*/(.+)$ {\n    set $file $1;\n    rewrite ^ /$file;\n}\n</code></pre> <p>If you can get the original image of image.jpg from the URL below,</p> <pre><code>http://$host:$port/img/image.jpg\n</code></pre> <p>You will be able to get the converted image of image.jpg from the URL below.</p> <pre><code>http://$host:$port/small_light(dw=300,dh=300)/img/image.jpg\n</code></pre> <p>The part of <code>small_light(...)</code> is called small_light function.</p>"},{"location":"modules/small-light/#configuration-example","title":"Configuration example","text":"<p>There is some configuration example below.</p> <pre><code>server {\n    listen 8000;\n    server_name localhost;\n\n    small_light on;\n    small_light_pattern_define msize dw=500,dh=500,da=l,q=95,e=imagemagick,jpeghint=y;\n    small_light_pattern_define ssize dw=120,dh=120,da=l,q=95,e=imlib2,jpeghint=y;\n\n    # http://localhost:8000/small_light(p=msize)/img/filename.jpg -&gt; generate msize image\n    # http://localhost:8000/small_light(p=ssize)/img/filename.jpg -&gt; generate ssize image\n    # http://localhost:8000/small_light(of=gif,q=100)/img/filename.jpg -&gt; generate gif image which quality is 100\n    location ~ small_light[^/]*/(.+)$ {\n        set $file $1;\n        rewrite ^ /$file;\n    }\n} \n</code></pre>"},{"location":"modules/small-light/#directives","title":"Directives","text":""},{"location":"modules/small-light/#small_light","title":"small_light","text":"Syntax small_light on | off Default off Context server, location <p>This directive sets whether image-processing with <code>ngx_small_light</code> is enabled in a server context.</p>"},{"location":"modules/small-light/#small_light_getparam_mode","title":"small_light_getparam_mode","text":"Syntax small_light_getparam_mode on | off Default off Context server, location <p>This directive sets whether converting-image is enabled by GET parameters  instead of small_light function (e.g. <code>/small_light(dw=200,dh=200)</code>). At the expense of it, a small_light function is disabled. But you need to set both <code>small_light</code> and <code>small_light_getparam_mode</code> on to enable the feature of this directive.</p>"},{"location":"modules/small-light/#small_light_material_dir","title":"small_light_material_dir","text":"Syntax small_light_material_dir path Default Context server <p>This directive assigns the directory for embedded icon images.</p>"},{"location":"modules/small-light/#small_light_pattern_define","title":"small_light_pattern_define","text":"Syntax small_light_pattern_define pattern_name parameters Default Context server <p>This directive names comma-delimited parameters.</p>"},{"location":"modules/small-light/#small_light_radius_max","title":"small_light_radius_max","text":"Syntax small_light_radius_max number Default 10 Context server,location <p>This directive sets maximum radius value of geometry for <code>sharpen</code> and <code>unsharp</code> and <code>blur</code>.</p>"},{"location":"modules/small-light/#small_light_sigma_max","title":"small_light_sigma_max","text":"Syntax small_light_sigma_max number Default 10 Context server,location <p>This directive sets maximum sigma value of geometry for <code>sharpen</code> and <code>unsharp</code> and <code>blur</code>.</p>"},{"location":"modules/small-light/#small_light_imlib2_temp_dir","title":"small_light_imlib2_temp_dir","text":"Syntax small_light_imlib2_temp_dir path [level1 [level2 [level 3 ]]] Default small_light_imlib2_temp 1 2 Context server <p>This directive assigns the directory for temporary file for Imlib2 processing. This directive is available when Imlib2 is enabled.</p>"},{"location":"modules/small-light/#small_light_buffer","title":"small_light_buffer","text":"Syntax small_ligh_buffer size Default 1m Context server <p>This directive assigns the maximum size of the buffer used for reading images when Content-Length is not set in response headers.</p>"},{"location":"modules/small-light/#parameters-for-small_light-function","title":"Parameters for small_light function","text":"Parameter Type Default Description ImageMagick Imlib2 GD p string named pattern of comma-delimited parameters e string imagemagick engine name (imagemagick, imlib2, gd) q number quality of string output format (jpg, gif, png, webp) jpeghint char n enable jpeg hinting (y, n) dw coord sw destination width dh coord sh destination height dx coord sx destination x coordinate dy coord sy destination y coordinate da char l destination aspect ratio contol (l, s, n) ds char n destination scaling control (s, n) cw number canvas width ch number canvas height cc color 000000 canvas color bw number border width bh number border height bc color 000000 border color sw coord source witdh sh coord source height sx coord source x coordinate sy coord source y coordinate pt char n pass through control (y, n) sharpen string radius,sigma (e.g. 10x5) unsharp string radius,sigma,amount,threshold (e.g 2x5+0.5+0) blur string radius,sigma (e.g. 5x10) embedicon string embedded icon file in <code>small_light_material_dir</code> ix number 0 embedded icon x coordinate iy number 0 embedded icon y coordinate angle number 0 angle of rotation (90, 180, 270) progressive char n make JPEG progressive (y, n) cmyk2rgb char n convert colorspace from CMYK to sRGB (y, n) rmprof char n remove profile (y, n) autoorient char n enable adjust image orientation automatically (y, n) <p>The values of <code>da</code> are <code>l</code> and <code>s</code> and <code>n</code>. These present the meanings below.</p> <ul> <li><code>l</code>: long-edge based</li> <li><code>s</code>: short-edge based</li> <li><code>n</code>: nope</li> </ul> <p>There are any limitations below.</p> <ul> <li><code>of=gif</code> and <code>of=webp</code> are not supported when <code>e=imlib2</code>.</li> <li><code>autoorient</code> is available ImageMagick-6.9.0 or later.</li> <li>The value of <code>radius,sigma</code> for <code>sharpen</code> and <code>unsharp</code> and <code>blur</code> is limited by <code>small_light_radius_max</code> and <code>small_light_sigma_max</code>.</li> </ul> <p>There are the types of each parameter below.</p> Type Description coord coordicante or pixel. percent when appending 'p' char character number integer number color rrggbb or rrggbbaa string string"},{"location":"modules/small-light/#named-pattern","title":"Named Pattern","text":"<p><code>ngx_small_light</code> supports to name comma-delimited parameters with the <code>small_light_define_patern</code>.</p> <pre><code>small_light_pattern_define small dw=120,dh=120,q=80,e=imagemagick,jpeghint=y;\n</code></pre> <p>If the line above is added to some server context in nginx.conf, the two URLs below return same response.</p> <ul> <li><code>http://$host:$port/small_light(p=small)/img/image.jpg</code></li> <li><code>http://$host:$port/small_light(dw=120,dh=120,q=80,e=imagemagick,jpeghint=y)/img/image.jpg</code></li> </ul>"},{"location":"modules/small-light/#using-get-parameters","title":"Using GET parameters","text":"<p><code>ngx_small_light</code> supports to convert image not only by small_light function but by GET paramenters in <code>v0.5.0</code> or later. You need to set both <code>small_light</code> and <code>small_light_getparam_mode</code> on to enable this feature. At the expense of enabling this feature, small_light function (e.g. <code>/small_light(dw=300,dh=300)/img.jpg</code> is disabled.</p> <pre><code>small_light on;\nsmall_light_getparam_mode on;\n</code></pre> <p>In the configuration above, the url below does not return converted image.</p> <pre><code>http://localhost:8000/small_light(dw=200,dh=200)/img/image.jpg\n</code></pre> <p>Instead the url below returns converted image expected by right.</p> <pre><code>http://localhost:8000/img/image.jpg?dw=200&amp;dh=200\n</code></pre>"},{"location":"modules/small-light/#enabling-webp-transformation","title":"Enabling WebP Transformation","text":"<p><code>ngx_small_light</code> supports WebP transformation with ImageMagick and GD. Given <code>of=webp</code> to small_light function, <code>ngx_small_light</code> transforms image format into WebP. But ImageMagick requires libwebp and GD requires libvpx. You need to embed these libraries in building ImageMagick and GD for enabling WebP transformation.</p> <p>If WebP transformation is not available, <code>nginx</code> outputs the line like below in error.log in processing image with <code>of=webp</code>.</p> <pre><code>WebP is not supported\n</code></pre> <p>If WebP transformation with ImageMagick is available, the output of <code>convert -list format</code> includes the line like below.</p> <pre><code>$ convert -list format | grep -i webp\n     WEBP* WEBP      rw-   WebP Image Format (libwebp 0.5.0[0208])\n</code></pre> <p>If WebP transformation with GD is available, the output of <code>gdlib-config --libs</code> includes <code>-lvpx</code>.</p> <p>In general, the packages of ImageMagick and GD provided from the linux distributions such as Ubuntu and CentOS does not embed the library for WebP transformation by default. In such cases, you need to build ImageMagick or GD yourself.</p>"},{"location":"modules/small-light/#optimizing-tips","title":"Optimizing Tips","text":"<p>There are some optimizing tips for <code>ngx_small_light</code>.</p>"},{"location":"modules/small-light/#jpeg-hinting","title":"JPEG hinting","text":"<p>When the output format is JPEG and image-converting engine is ImageMagick or Imlib2, you may give <code>jpeghint=y</code>. The speed of processing images is improved dramatically.</p>"},{"location":"modules/small-light/#limit-thread-number-with-openmp","title":"Limit thread-number with OpenMP","text":"<p>When image-converting engine is ImageMagick and the version of <code>ngx_small_light</code> is lower than <code>v0.6.14</code>,  giving 1 to <code>OMP_NUM_THREADS</code> or <code>MAGICK_THREAD_LIMIT</code> in <code>nginx.conf</code> is recommended strongly. Because OpenMP is enabled in ImageMagick by default and ImageMagick enabled OpenMP is very slow on multi-process environment.</p> <pre><code>env OMP_NUM_THREADS=1; # or env MAGICK_THREAD_LIMIT=1;\n</code></pre> <p>Or you can avoid this problem by building ImageMagick with <code>--disable-openmp</code>.</p> <p>In <code>v0.6.14</code> or later, they are no longer required. Because <code>ngx_small_light</code> always sets the thread-number with OpenMP 1.</p>"},{"location":"modules/small-light/#limitations","title":"Limitations","text":"<p><code>ngx_small_light</code> has the limitations below.</p>"},{"location":"modules/small-light/#not-supported-features-with-imlib2","title":"Not supported features with Imlib2","text":"<p>The transformation with Imlib2 does not support to write GIF-image. Because Imlib2 has the function for loading GIF-image but does not have the function for saving. Additionally, the transformation by Imlib2 does not support to write and read WebP-image. So <code>of=gif</code> and <code>e=imlib2</code> are not enabled to specify at once. If these are specified, <code>ngx_small_light</code> returns 415(Unsupported Media Type).</p>"},{"location":"modules/small-light/#not-supported-features-with-gd","title":"Not supported features with GD","text":"<p>The transformation with GD supports to write WebP-image. But it is the experimental feature.</p>"},{"location":"modules/small-light/#not-supported-animated-gif","title":"Not supported animated GIF","text":"<p><code>ngx_small_light</code> does not support the transformation kept animation for animated GIF. Because it takes long time to transform(e.g. resize, crop) animated GIF kept animation. So it is not realistic for <code>ngx_small_light</code> to support an animated GIF.</p> <p>If the animated GIF is given, <code>ngx_small_light</code> transforms only the first frame.</p>"},{"location":"modules/small-light/#running-tests","title":"Running Tests","text":"<pre><code>perl Build.PL\ncpanm --installdeps .\nNGINX_BIN=${nginx_prefix_dir}/sbin/nginx ./Build test\n## or\nNGINX_BIN=${nginx_prefix_dir}/sbin/nginx prove t/**/*.t\n</code></pre>"},{"location":"modules/small-light/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-small-light.</p>"},{"location":"modules/spnego-http-auth/","title":"spnego-http-auth: Nginx module for HTTP SPNEGO auth","text":""},{"location":"modules/spnego-http-auth/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-spnego-http-auth\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-spnego-http-auth\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_auth_spnego_module.so;\n</code></pre> <p>This document describes nginx-module-spnego-http-auth v1.1.3  released on May 12 2025.</p> <p>This module implements adds SPNEGO support to nginx(http://nginx.org).  It currently supports only Kerberos authentication via GSSAPI</p>"},{"location":"modules/spnego-http-auth/#prerequisites","title":"Prerequisites","text":"<p>Authentication has been tested with (at least) the following:</p> <ul> <li>Nginx 1.2 through 1.15</li> <li>Internet Explorer 8 and above</li> <li>Firefox 10 and above</li> <li>Chrome 20 and above</li> <li>Curl 7.x (GSS-Negotiate), 7.x (SPNEGO/fbopenssl)</li> </ul> <p>The underlying kerberos library used for these tests was MIT KRB5 v1.12.</p>"},{"location":"modules/spnego-http-auth/#configuration-reference","title":"Configuration reference","text":"<p>You can configure GSS authentication on a per-location and/or a global basis:</p> <p>These options are required. * <code>auth_gss</code>: on/off, for ease of unsecuring while leaving other options in   the config file * <code>auth_gss_keytab</code>: absolute path-name to keytab file containing service   credentials</p> <p>These options should ONLY be specified if you have a keytab containing privileged principals.  In nearly all cases, you should not put these in the configuration file, as <code>gss_accept_sec_context</code> will do the right thing. * <code>auth_gss_realm</code>: Kerberos realm name.  If this is specified, the realm is only passed to the nginx variable $remote_user if it differs from this default.  To override this behavior, set auth_gss_format_full to 1 in your configuration. * <code>auth_gss_service_name</code>: service principal name to use when acquiring   credentials.</p> <p>If you would like to authorize only a specific set of principals, you can use the <code>auth_gss_authorized_principal</code> directive.  The configuration syntax supports multiple entries, one per line.</p> <pre><code>auth_gss_authorized_principal &lt;primary1&gt;@&lt;realm&gt;\nauth_gss_authorized_principal &lt;primary2&gt;@&lt;realm&gt;\n</code></pre> <p>Principals can also be authorized using a regex pattern via the <code>auth_gss_authorized_principal_regex</code> directive. This directive can be used together with the <code>auth_gss_authorized_principal</code> directive.</p> <pre><code>auth_gss_authorized_principal &lt;primary1&gt;@&lt;realm&gt;\nauth_gss_authorized_principal_regex ^(&lt;primary2&gt;)/(&lt;instance&gt;)@&lt;realm&gt;$\n</code></pre> <p>The remote user header in nginx can only be set by doing basic authentication. Thus, this module sets a bogus basic auth header that will reach your backend application in order to set this header/nginx variable.  The easiest way to disable this behavior is to add the following configuration to your location config.</p> <pre><code>proxy_set_header Authorization \"\";\n</code></pre> <p>A future version of the module may make this behavior an option, but this should be a sufficient workaround for now.</p> <p>If you would like to enable GSS local name rules to rewrite usernames, you can specify the <code>auth_gss_map_to_local</code> option.</p>"},{"location":"modules/spnego-http-auth/#credential-delegation","title":"Credential Delegation","text":"<p>User credentials can be delegated to nginx using the <code>auth_gss_delegate_credentials</code>   directive. This directive will enable unconstrained delegation if the user chooses   to delegate their credentials. Constrained delegation (S4U2proxy) can also be enabled using the   <code>auth_gss_constrained_delegation</code> directive together with the <code>auth_gss_delegate_credentials</code>   directive. To specify the ccache file name to store the service ticket used for constrained   delegation, set the <code>auth_gss_service_ccache</code> directive. Otherwise, the default ccache name   will be used.</p> <pre><code>auth_gss_service_ccache /tmp/krb5cc_0;\nauth_gss_delegate_credentials on;\nauth_gss_constrained_delegation on;\n</code></pre> <p>The delegated credentials will be stored within the systems tmp directory. Once the  request is completed, the credentials file will be destroyed. The name of the credentials   file will be specified within the nginx variable <code>$krb5_cc_name</code>. Usage of the variable   can include passing it to a fcgi program using the <code>fastcgi_param</code> directive.</p> <pre><code>fastcgi_param KRB5CCNAME $krb5_cc_name;\n</code></pre> <p>Constrained delegation is currently only supported using the negotiate authentication scheme  and has only been testing with MIT Kerberos (Use at your own risk if using Heimdal Kerberos).</p>"},{"location":"modules/spnego-http-auth/#basic-authentication-fallback","title":"Basic authentication fallback","text":"<p>The module falls back to basic authentication by default if no negotiation is attempted by the client.  If you are using SPNEGO without SSL, it is recommended you disable basic authentication fallback, as the password would be sent in plaintext.  This is done by setting <code>auth_gss_allow_basic_fallback</code> in the config file.</p> <pre><code>auth_gss_allow_basic_fallback off\n</code></pre> <p>These options affect the operation of basic authentication: * <code>auth_gss_realm</code>: Kerberos realm name.  If this is specified, the realm is   only passed to the nginx variable $remote_user if it differs from this   default.  To override this behavior, set auth_gss_format_full to 1 in your   configuration. * <code>auth_gss_force_realm</code>: Forcibly authenticate using the realm configured in   <code>auth_gss_realm</code> or the system default realm if <code>auth_gss_realm</code> is not set.   This will rewrite $remote_user if the client provided a different realm.  If   auth_gss_format_full is not set, $remote_user will not include a realm even   if one was specified by the client.</p>"},{"location":"modules/spnego-http-auth/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/spnego-http-auth/#_1","title":"Nginx module for HTTP SPNEGO auth","text":"<p>Check the logs.  If you see a mention of NTLM, your client is attempting to connect using NTLMSSP, which is unsupported and insecure.</p>"},{"location":"modules/spnego-http-auth/#verify-that-you-have-an-http-principal-in-your-keytab","title":"Verify that you have an HTTP principal in your keytab","text":""},{"location":"modules/spnego-http-auth/#mit-kerberos-utilities","title":"MIT Kerberos utilities","text":"<pre><code>$ KRB5_KTNAME=FILE:&lt;path to your keytab&gt; klist -k\n</code></pre> <p>or</p> <pre><code>$ ktutil\nktutil: read_kt &lt;path to your keytab&gt;\nktutil: list\n</code></pre>"},{"location":"modules/spnego-http-auth/#heimdal-kerberos-utilities","title":"Heimdal Kerberos utilities","text":"<pre><code>$ ktutil -k &lt;path to your keytab&gt; list\n</code></pre>"},{"location":"modules/spnego-http-auth/#obtain-an-http-principal","title":"Obtain an HTTP principal","text":"<p>If you find that you do not have the HTTP service principal, are running in an Active Directory environment, and are bound to the domain such that Samba tools work properly</p> <pre><code>$ env KRB5_KTNAME=FILE:&lt;path to your keytab&gt; net ads -P keytab add HTTP\n</code></pre> <p>If you are running in a different kerberos environment, you can likely run</p> <pre><code>$ env KRB5_KTNAME=FILE:&lt;path to your keytab&gt; krb5_keytab HTTP\n</code></pre>"},{"location":"modules/spnego-http-auth/#increase-maximum-allowed-header-size","title":"Increase maximum allowed header size","text":"<p>In Active Directory environment, SPNEGO token in the Authorization header includes PAC (Privilege Access Certificate) information, which includes all security groups the user belongs to. This may cause the header to grow beyond default 8kB limit and causes following error message:</p> <pre><code>400 Bad Request\nRequest Header Or Cookie Too Large\n</code></pre> <p>For performance reasons, best solution is to reduce the number of groups the user belongs to. When this is impractical, you may also choose to increase the allowed header size by explicitly setting the number and size of Nginx header buffers:</p> <pre><code>large_client_header_buffers 8 32k;\n</code></pre>"},{"location":"modules/spnego-http-auth/#debugging","title":"Debugging","text":"<p>The module prints all sort of debugging information if nginx is compiled with the <code>--with-debug</code> option, and the <code>error_log</code> directive has a <code>debug</code> level.</p>"},{"location":"modules/spnego-http-auth/#ntlm","title":"NTLM","text":"<p>Note that the module does not support NTLMSSP in Negotiate. NTLM, both v1 and v2, is an exploitable protocol and should be avoided where possible.</p>"},{"location":"modules/spnego-http-auth/#windows","title":"Windows","text":"<p>For Windows KDC/AD environments, see the documentation here.</p>"},{"location":"modules/spnego-http-auth/#help","title":"Help","text":"<p>If you're unable to figure things out, please feel free to open an issue on Github and I'll do my best to help you.</p>"},{"location":"modules/spnego-http-auth/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-spnego-http-auth.</p>"},{"location":"modules/srcache/","title":"srcache: Transparent subrequest-based caching layout for arbitrary NGINX locations","text":""},{"location":"modules/srcache/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-srcache\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-srcache\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_srcache_filter_module.so;\n</code></pre> <p>This document describes nginx-module-srcache v0.32  released on Jun 28 2022.</p> <p>ngx_srcache - Transparent subrequest-based caching layout for arbitrary nginx locations</p>"},{"location":"modules/srcache/#status","title":"Status","text":"<p>This module is production ready.</p>"},{"location":"modules/srcache/#synopsis","title":"Synopsis","text":"<pre><code> upstream my_memcached {\n     server 10.62.136.7:11211;\n     keepalive 10;\n }\n\n location = /memc {\n     internal;\n\n     memc_connect_timeout 100ms;\n     memc_send_timeout 100ms;\n     memc_read_timeout 100ms;\n     memc_ignore_client_abort on;\n\n     set $memc_key $query_string;\n     set $memc_exptime 300;\n\n     memc_pass my_memcached;\n }\n\n location /foo {\n     set $key $uri$args;\n     srcache_fetch GET /memc $key;\n     srcache_store PUT /memc $key;\n     srcache_store_statuses 200 301 302 307 308;\n\n     # proxy_pass/fastcgi_pass/drizzle_pass/echo/etc...\n     # or even static files on the disk\n }\n</code></pre> <pre><code> location = /memc2 {\n     internal;\n\n     memc_connect_timeout 100ms;\n     memc_send_timeout 100ms;\n     memc_read_timeout 100ms;\n     memc_ignore_client_abort on;\n\n     set_unescape_uri $memc_key $arg_key;\n     set $memc_exptime $arg_exptime;\n\n     memc_pass unix:/tmp/memcached.sock;\n }\n\n location /bar {\n     set_escape_uri $key $uri$args;\n     srcache_fetch GET /memc2 key=$key;\n     srcache_store PUT /memc2 key=$key&amp;exptime=$srcache_expire;\n\n     # proxy_pass/fastcgi_pass/drizzle_pass/echo/etc...\n     # or even static files on the disk\n }\n</code></pre> <pre><code> map $request_method $skip_fetch {\n     default     0;\n     POST        1;\n     PUT         1;\n }\n\n server {\n     listen 8080;\n\n     location /api/ {\n         set $key \"$uri?$args\";\n\n         srcache_fetch GET /memc $key;\n         srcache_store PUT /memc $key;\n\n         srcache_methods GET PUT POST;\n         srcache_fetch_skip $skip_fetch;\n\n         # proxy_pass/drizzle_pass/content_by_lua/echo/...\n     }\n }\n</code></pre>"},{"location":"modules/srcache/#description","title":"Description","text":"<p>This module provides a transparent caching layer for arbitrary nginx locations (like those use an upstream or even serve static disk files). The caching behavior is mostly compatible with RFC 2616.</p> <p>Usually, memc-nginx-module is used together with this module to provide a concrete caching storage backend. But technically, any modules that provide a REST interface can be used as the fetching and storage subrequests used by this module.</p> <p>For main requests, the srcache_fetch directive works at the end of the access phase, so the standard access module's allow and deny direcives run before ours, which is usually the desired behavior for security reasons.</p> <p>The workflow of this module looks like below:</p> <p></p>"},{"location":"modules/srcache/#subrequest-caching","title":"Subrequest caching","text":"<p>For subrequests, we explicitly disallow the use of this module because it's too difficult to get right. There used to be an implementation but it was buggy and I finally gave up fixing it and abandoned it.</p> <p>However, if you're using lua-nginx-module, it's easy to do subrequest caching in Lua all by yourself. That is, first issue a subrequest to an memc-nginx-module location to do an explicit cache lookup, if cache hit, just use the cached data returned; otherwise, fall back to the true backend, and finally do a cache insertion to feed the data into the cache.</p> <p>Using this module for main request caching and Lua for subrequest caching is the approach that we're taking in our business. This hybrid solution works great in production.</p>"},{"location":"modules/srcache/#distributed-memcached-caching","title":"Distributed Memcached Caching","text":"<p>Here is a simple example demonstrating a distributed memcached caching mechanism built atop this module. Suppose we do have three different memcached nodes and we use simple modulo to hash our keys.</p> <p><pre><code> http {\n     upstream moon {\n         server 10.62.136.54:11211;\n         server unix:/tmp/memcached.sock backup;\n     }\n\n     upstream earth {\n         server 10.62.136.55:11211;\n     }\n\n     upstream sun {\n         server 10.62.136.56:11211;\n     }\n\n     upstream_list universe moon earth sun;\n\n     server {\n         memc_connect_timeout 100ms;\n         memc_send_timeout 100ms;\n         memc_read_timeout 100ms;\n\n         location = /memc {\n             internal;\n\n             set $memc_key $query_string;\n             set_hashed_upstream $backend universe $memc_key;\n             set $memc_exptime 3600; # in seconds\n             memc_pass $backend;\n         }\n\n         location / {\n             set $key $uri;\n             srcache_fetch GET /memc $key;\n             srcache_store PUT /memc $key;\n\n             # proxy_pass/fastcgi_pass/content_by_lua/drizzle_pass/...\n         }\n     }\n }\n</code></pre> Here's what is going on in the sample above: 1. We first define three upstreams, <code>moon</code>, <code>earth</code>, and <code>sun</code>. These are our three memcached servers. 1. And then we group them together as an upstream list entity named <code>universe</code> with the <code>upstream_list</code> directive provided by set-misc-nginx-module. 1. After that, we define an internal location named <code>/memc</code> for talking to the memcached cluster. 1. In this <code>/memc</code> location, we first set the <code>$memc_key</code> variable with the query string (<code>$args</code>), and then use the set_hashed_upstream directive to hash our $memc_key over the upsteam list <code>universe</code>, so as to obtain a concrete upstream name to be assigned to the variable <code>$backend</code>. 1. We pass this <code>$backend</code> variable into the memc_pass directive. The <code>$backend</code> variable can hold a value among <code>moon</code>, <code>earth</code>, and <code>sun</code>. 1. Also, we define the memcached caching expiration time to be 3600 seconds (i.e., an hour) by overriding the $memc_exptime variable. 1. In our main public location <code>/</code>, we configure the <code>$uri</code> variable as our cache key, and then configure srcache_fetch for cache lookups and srcache_store for cache updates. We're using two subrequests to our <code>/memc</code> location defined earlier in these two directives.</p> <p>One can use lua-nginx-module's set_by_lua or rewrite_by_lua directives to inject custom Lua code to compute the <code>$backend</code> and/or <code>$key</code> variables in the sample above.</p> <p>One thing that should be taken care of is that memcached does have restriction on key lengths, i.e., 250 bytes, so for keys that may be very long, one could use the set_md5 directive or its friends to pre-hash the key to a fixed-length digest before assigning it to <code>$memc_key</code> in the <code>/memc</code> location or the like.</p> <p>Further, one can utilize the srcache_fetch_skip and srcache_store_skip directives to control what to cache and what not on a per-request basis, and Lua can also be used here in a similar way. So the possibility is really unlimited.</p> <p>To maximize speed, we often enable TCP (or Unix Domain Socket) connection pool for our memcached upstreams provided by HttpUpstreamKeepaliveModule, for example,</p> <pre><code> upstream moon {\n     server 10.62.136.54:11211;\n     server unix:/tmp/memcached.sock backup;\n     keepalive 10;\n }\n</code></pre> <p>where we define a connection pool which holds up to 10 keep-alive connections (per nginx worker process) for our <code>moon</code> upstream (cluster).</p>"},{"location":"modules/srcache/#caching-with-redis","title":"Caching with Redis","text":"<p>Redis is an alternative key-value store with many additional features.</p> <p>Here is a working example using the lua-resty-redis module:</p> <pre><code>  location ~ '\\.php$|^/update.php' {\n    # cache setup\n    set $key $request_uri;\n    try_files $uri =404;\n\n    srcache_fetch_skip $skip_cache;\n    srcache_store_skip $skip_cache;\n\n    srcache_response_cache_control off;\n    srcache_store_statuses 200 201 301 302 307 308 404 503;\n\n    set_escape_uri $escaped_key $key;\n\n    srcache_fetch GET /redis-fetch $key;\n    srcache_store PUT /redis-store key=$escaped_key;\n\n    more_set_headers 'X-Cache-Fetch-Status $srcache_fetch_status';\n    more_set_headers 'X-Cache-Store-Status $srcache_store_status';\n\n    fastcgi_split_path_info ^(.+?\\.php)(|/.*)$;\n    # Security note: If you're running a version of PHP older than the\n    # latest 5.3, you should have \"cgi.fix_pathinfo = 0;\" in php.ini.\n    # See http://serverfault.com/q/627903/94922 for details.\n    include fastcgi_params;\n    # Block httproxy attacks. See https://httpoxy.org/.\n    fastcgi_param HTTP_PROXY \"\";\n    fastcgi_param SCRIPT_FILENAME /var/www/html/$fastcgi_script_name;\n    fastcgi_param PATH_INFO $fastcgi_path_info;\n    fastcgi_param QUERY_STRING $query_string;\n    fastcgi_intercept_errors on;\n\n    fastcgi_pass upstream-name;\n  }\n\n  location /redis-fetch {\n    internal;\n\n    resolver 8.8.8.8 valid=300s;\n    resolver_timeout 10s;\n\n    content_by_lua_block {\n      local key = assert(ngx.var.request_uri, \"no key found\")\n      local redis = require \"resty.redis\"\n      local red, err = redis:new()\n      if not red then\n        ngx.log(ngx.ERR, \"Failed to create redis variable, error -&gt; \", err)\n        ngx.exit(500)\n      end\n      assert(red:connect(\"redis-master.default.svc.cluster.local\", 6379))\n      if not red then\n        ngx.log(ngx.ERR, \"Failed to connect to redis, error -&gt; \", err)\n        ngx.exit(500)\n      end\n      local res, err = red:auth(\"redispassword\")\n      if not res then\n        ngx.say(\"failed to authenticate, \", err)\n        ngx.exit(500)\n      end\n      local data = assert(red:get(key))\n      assert(red:set_keepalive(10000, 100))\n      if res == ngx.null then\n        return ngx.exit(404)\n      end\n      ngx.print(data)\n    }\n  }\n\n  location /redis-store {\n    internal;\n\n    resolver 8.8.8.8 valid=300s;\n    resolver_timeout 10s;\n\n    content_by_lua_block {\n      local value = assert(ngx.req.get_body_data(), \"no value found\")\n      local key = assert(ngx.var.request_uri, \"no key found\")\n      local redis = require \"resty.redis\"\n      local red, err = redis:new()\n      if not red then\n        ngx.log(ngx.ERR, \"Failed to create redis variable, error -&gt; \", err)\n        ngx.exit(500)\n      end\n      assert(red:connect(\"redis-master.default.svc.cluster.local\", 6379))\n      if not red then\n        ngx.log(ngx.ERR, \"Failed to connect to redis, error -&gt; \", err)\n        ngx.exit(500)\n      end\n      local res, err = red:auth(\"redispassword\")\n      if not res then\n        ngx.say(\"failed to authenticate, \", err)\n        ngx.exit(500)\n      end\n      local data = assert(red:set(key, value))\n      assert(red:set_keepalive(10000, 100))\n      if res == ngx.null then\n        return ngx.exit(404)\n      end\n    }\n  }\n</code></pre> <p>Here is a working example by using the HTTPRedis (fetch) and Redis2 (store) modules:</p> <pre><code> location /api {\n     default_type text/css;\n\n     set $key $uri;\n     set_escape_uri $escaped_key $key;\n\n     srcache_fetch GET /redis $key;\n     srcache_store PUT /redis2 key=$escaped_key&amp;exptime=120;\n\n     # fastcgi_pass/proxy_pass/drizzle_pass/postgres_pass/echo/etc\n }\n\n location = /redis {\n     internal;\n\n     set_md5 $redis_key $args;\n     redis_pass 127.0.0.1:6379;\n }\n\n location = /redis2 {\n     internal;\n\n     set_unescape_uri $exptime $arg_exptime;\n     set_unescape_uri $key $arg_key;\n     set_md5 $key;\n\n     redis2_query set $key $echo_request_body;\n     redis2_query expire $key $exptime;\n     redis2_pass 127.0.0.1:6379;\n }\n</code></pre> <p>This example makes use of the $echo_request_body variable provided by echo-nginx-module. Note that you need the latest version of echo-nginx-module, <code>v0.38rc2</code> because earlier versions may not work reliably.</p> <p>Also, you need both HttpRedisModule and redis2-nginx-module. The former is used in the srcache_fetch subrequest and the latter is used in the srcache_store subrequest.</p> <p>The Nginx core also has a bug that could prevent redis2-nginx-module's pipelining support from working properly in certain extreme conditions. And the following patch fixes this:</p> <p>http://mailman.nginx.org/pipermail/nginx-devel/2012-March/002040.html</p> <p>Note that, however, if you are using the OpenResty 1.0.15.3 bundle or later, then you already have everything that you need here in the bundle.</p>"},{"location":"modules/srcache/#cache-key-preprocessing","title":"Cache Key Preprocessing","text":"<p>It is often desired to preprocess the cache key to exclude random noises that may hurt the cache hit rate. For example, random session IDs in the URI arguments are usually desired to get removed.</p> <p>Consider the following URI querystring</p> <pre><code>SID=BC3781C3-2E02-4A11-89CF-34E5CFE8B0EF&amp;UID=44332&amp;L=EN&amp;M=1&amp;H=1&amp;UNC=0&amp;SRC=LK&amp;RT=62\n</code></pre> <p>we want to remove the <code>SID</code> and <code>UID</code> arguments from it. It is easy to achieve if you use lua-nginx-module at the same time:</p> <pre><code> location = /t {\n     rewrite_by_lua '\n         local args = ngx.req.get_uri_args()\n         args.SID = nil\n         args.UID = nil\n         ngx.req.set_uri_args(args)\n     ';\n\n     echo $args;\n }\n</code></pre> <p>Here we use the echo directive from echo-nginx-module to dump out the final value of $args in the end. You can replace it with your srcache-nginx-module configurations and upstream configurations instead for your case. Let's test this /t interface with curl:</p> <pre><code>$ curl 'localhost:8081/t?RT=62&amp;SID=BC3781C3-2E02-4A11-89CF-34E5CFE8B0EF&amp;UID=44332&amp;L=EN&amp;M=1&amp;H=1&amp;UNC=0&amp;SRC=LK'\nM=1&amp;UNC=0&amp;RT=62&amp;H=1&amp;L=EN&amp;SRC=LK\n</code></pre> <p>It is worth mentioning that, if you want to retain the order of the URI arguments, then you can do string substitutions on the value of $args directly, for example,</p> <pre><code>location = /t {\n    rewrite_by_lua '\n        local args = ngx.var.args\n        newargs, n, err = ngx.re.gsub(args, [[\\b[SU]ID=[^&amp;]*&amp;?]], \"\", \"jo\")\n        if n and n &gt; 0 then\n            ngx.var.args = newargs\n        end\n    ';\n\n    echo $args;\n}\n</code></pre> <p>Now test it with the original curl command again, we get exactly what we would expect:</p> <pre><code>RT=62&amp;L=EN&amp;M=1&amp;H=1&amp;UNC=0&amp;SRC=LK\n</code></pre> <p>But for caching purposes, it's good to normalize the URI argument order so that you can increase the cache hit rate. And the hash table entry order used by LuaJIT or Lua can be used to normalize the order as a nice side effect.</p>"},{"location":"modules/srcache/#directives","title":"Directives","text":""},{"location":"modules/srcache/#srcache_fetch","title":"srcache_fetch","text":"<p>syntax: srcache_fetch &lt;method&gt; &lt;uri&gt; &lt;args&gt;?</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: post-access</p> <p>This directive registers an access phase handler that will issue an Nginx subrequest to lookup the cache.</p> <p>When the subrequest returns status code other than <code>200</code>, than a cache miss is signaled and the control flow will continue to the later phases including the content phase configured by ngx_http_proxy_module, ngx_http_fastcgi_module, and others. If the subrequest returns <code>200 OK</code>, then a cache hit is signaled and this module will send the subrequest's response as the current main request's response to the client directly.</p> <p>This directive will always run at the end of the access phase, such that ngx_http_access_module's allow and deny will always run before this.</p> <p>You can use the srcache_fetch_skip directive to disable cache look-up selectively.</p>"},{"location":"modules/srcache/#srcache_fetch_skip","title":"srcache_fetch_skip","text":"<p>syntax: srcache_fetch_skip &lt;flag&gt;</p> <p>default: srcache_fetch_skip 0</p> <p>context: http, server, location, location if</p> <p>phase: post-access</p> <p>The <code>&lt;flag&gt;</code> argument supports nginx variables. When this argument's value is not empty and not equal to <code>0</code>, then the fetching process will be unconditionally skipped.</p> <p>For example, to skip caching requests which have a cookie named <code>foo</code> with the value <code>bar</code>, we can write</p> <p><pre><code> location / {\n     set $key ...;\n     set_by_lua $skip '\n         if ngx.var.cookie_foo == \"bar\" then\n             return 1\n         end\n         return 0\n     ';\n\n     srcache_fetch_skip $skip;\n     srcache_store_skip $skip;\n\n     srcache_fetch GET /memc $key;\n     srcache_store GET /memc $key;\n\n     # proxy_pass/fastcgi_pass/content_by_lua/...\n }\n</code></pre> where lua-nginx-module is used to calculate the value of the <code>$skip</code> variable at the (earlier) rewrite phase. Similarly, the <code>$key</code> variable can be computed by Lua using the set_by_lua or rewrite_by_lua directive too.</p> <p>The standard map directive can also be used to compute the value of the <code>$skip</code> variable used in the sample above:</p> <pre><code> map $cookie_foo $skip {\n     default     0;\n     bar         1;\n }\n</code></pre> <p>but your map statement should be put into the <code>http</code> config block in your <code>nginx.conf</code> file though.</p>"},{"location":"modules/srcache/#srcache_store","title":"srcache_store","text":"<p>syntax: srcache_store &lt;method&gt; &lt;uri&gt; &lt;args&gt;?</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: output-filter</p> <p>This directive registers an output filter handler that will issue an Nginx subrequest to save the response of the current main request into a cache backend. The status code of the subrequest will be ignored.</p> <p>You can use the srcache_store_skip and srcache_store_max_size directives to disable caching for certain requests in case of a cache miss.</p> <p>Since the <code>v0.12rc7</code> release, both the response status line, response headers, and response bodies will be put into the cache. By default, the following special response headers will not be cached:</p> <ul> <li>Connection</li> <li>Keep-Alive</li> <li>Proxy-Authenticate</li> <li>Proxy-Authorization</li> <li>TE</li> <li>Trailers</li> <li>Transfer-Encoding</li> <li>Upgrade</li> <li>Set-Cookie</li> </ul> <p>You can use the srcache_store_pass_header and/or srcache_store_hide_header directives to control what headers to cache and what not.</p> <p>The original response's data chunks get emitted as soon as they arrive. <code>srcache_store</code> just copies and collects the data in an output filter without postponing them from being sent downstream.</p> <p>But please note that even though all the response data will be sent immediately, the current Nginx request lifetime will not finish until the srcache_store subrequest completes. That means a delay in closing the TCP connection on the server side (when HTTP keepalive is disabled, but proper HTTP clients should close the connection actively on the client side, which adds no extra delay or other issues at all) or serving the next request sent on the same TCP connection (when HTTP keepalive is in action).</p>"},{"location":"modules/srcache/#srcache_store_max_size","title":"srcache_store_max_size","text":"<p>syntax: srcache_store_max_size &lt;size&gt;</p> <p>default: srcache_store_max_size 0</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>When the response body length is exceeding this size, this module will not try to store the response body into the cache using the subrequest template that is specified in srcache_store.</p> <p>This is particular useful when using a cache storage backend that does have a hard upper limit on the input data. For example, the Memcached server has a default limit of <code>1 MB</code> by item.</p> <p>When <code>0</code> is specified (the default value), there's no limit check at all.</p>"},{"location":"modules/srcache/#srcache_store_skip","title":"srcache_store_skip","text":"<p>syntax: srcache_store_skip &lt;flag&gt;</p> <p>default: srcache_store_skip 0</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>The <code>&lt;flag&gt;</code> argument supports Nginx variables. When this argument's value is not empty and not equal to <code>0</code>, then the storing process will be unconditionally skipped.</p> <p>Starting from the <code>v0.25</code> release, the <code>&lt;flag&gt;</code> expression (possibly containing Nginx variables) can be evaluated up to twice: the first time is right after the response header is being sent and when the <code>&lt;flag&gt;</code> expression is not evaluated to true values it will be evaluated again right after the end of the response body data stream is seen. Before <code>v0.25</code>, only the first time evaluation is performed.</p> <p>Here's an example using Lua to set $nocache to avoid storing URIs that contain the string \"/tmp\":</p> <pre><code> set_by_lua $nocache '\n     if string.match(ngx.var.uri, \"/tmp\") then\n         return 1\n     end\n     return 0';\n\n srcache_store_skip $nocache;\n</code></pre>"},{"location":"modules/srcache/#srcache_store_statuses","title":"srcache_store_statuses","text":"<p>syntax: srcache_store_statuses &lt;status1&gt; &lt;status2&gt; ..</p> <p>default: srcache_store_statuses 200 301 302 307 308</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>This directive controls what responses to store to the cache according to their status code.</p> <p>By default, only <code>200</code>, <code>301</code>, <code>302</code>, <code>307</code> and <code>308</code> responses will be stored to cache and any other responses will skip srcache_store.</p> <p>You can specify arbitrary positive numbers for the response status code that you'd like to cache, even including error code like <code>404</code> and <code>503</code>. For example:</p> <pre><code> srcache_store_statuses 200 201 301 302 307 308 404 503;\n</code></pre> <p>At least one argument should be given to this directive.</p> <p>This directive was first introduced in the <code>v0.13rc2</code> release.</p>"},{"location":"modules/srcache/#srcache_store_ranges","title":"srcache_store_ranges","text":"<p>syntax: srcache_store_ranges on|off</p> <p>default: srcache_store_ranges off</p> <p>context: http, server, location, location if</p> <p>phase: output-body-filter</p> <p>When this directive is turned on (default to <code>off</code>), srcache_store will also store 206 Partial Content responses generated by the standard <code>ngx_http_range_filter_module</code>. If you turn this directive on, you MUST add <code>$http_range</code> to your cache keys. For example,</p> <pre><code> location / {\n     set $key \"$uri$args$http_range\";\n     srcache_fetch GET /memc $key;\n     srcache_store PUT /memc $key;\n }\n</code></pre> <p>This directive was first introduced in the <code>v0.27</code> release.</p>"},{"location":"modules/srcache/#srcache_header_buffer_size","title":"srcache_header_buffer_size","text":"<p>syntax: srcache_header_buffer_size &lt;size&gt;</p> <p>default: srcache_header_buffer_size 4k/8k</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>This directive controles the header buffer when serializing response headers for srcache_store. The default size is the page size, usually <code>4k</code> or <code>8k</code> depending on specific platforms.</p> <p>Note that the buffer is not used to hold all the response headers, but just each individual header. So the buffer is merely needed to be big enough to hold the longest response header.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_store_hide_header","title":"srcache_store_hide_header","text":"<p>syntax: srcache_store_hide_header &lt;header&gt;</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>By default, this module caches all the response headers except the following ones:</p> <ul> <li>Connection</li> <li>Keep-Alive</li> <li>Proxy-Authenticate</li> <li>Proxy-Authorization</li> <li>TE</li> <li>Trailers</li> <li>Transfer-Encoding</li> <li>Upgrade</li> <li>Set-Cookie</li> </ul> <p>You can hide even more response headers from srcache_store by listing their names (case-insensitive) by means of this directive. For examples,</p> <pre><code> srcache_store_hide_header X-Foo;\n srcache_store_hide_header Last-Modified;\n</code></pre> <p>Multiple occurrences of this directive are allowed in a single location.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p> <p>See also srcache_store_pass_header.</p>"},{"location":"modules/srcache/#srcache_store_pass_header","title":"srcache_store_pass_header","text":"<p>syntax: srcache_store_pass_header &lt;header&gt;</p> <p>default: no</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>By default, this module caches all the response headers except the following ones:</p> <ul> <li>Connection</li> <li>Keep-Alive</li> <li>Proxy-Authenticate</li> <li>Proxy-Authorization</li> <li>TE</li> <li>Trailers</li> <li>Transfer-Encoding</li> <li>Upgrade</li> <li>Set-Cookie</li> </ul> <p>You can force srcache_store to store one or more of these response headers from srcache_store by listing their names (case-insensitive) by means of this directive. For examples,</p> <pre><code> srcache_store_pass_header Set-Cookie;\n srcache_store_pass_header Proxy-Autenticate;\n</code></pre> <p>Multiple occurrences of this directive are allowed in a single location.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p> <p>See also srcache_store_hide_header.</p>"},{"location":"modules/srcache/#srcache_methods","title":"srcache_methods","text":"<p>syntax: srcache_methods &lt;method&gt;...</p> <p>default: srcache_methods GET HEAD</p> <p>context: http, server, location</p> <p>phase: post-access, output-header-filter</p> <p>This directive specifies HTTP request methods that are considered by either srcache_fetch or srcache_store. HTTP request methods not listed will be skipped completely from the cache.</p> <p>The following HTTP methods are allowed: <code>GET</code>, <code>HEAD</code>, <code>POST</code>, <code>PUT</code>, and <code>DELETE</code>. The <code>GET</code> and <code>HEAD</code> methods are always implicitly included in the list regardless of their presence in this directive.</p> <p>Note that since the <code>v0.17</code> release <code>HEAD</code> requests are always skipped by srcache_store because their responses never carry a response body.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_ignore_content_encoding","title":"srcache_ignore_content_encoding","text":"<p>syntax: srcache_ignore_content_encoding on|off</p> <p>default: srcache_ignore_content_encoding off</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>When this directive is turned <code>off</code> (which is the default), non-empty <code>Content-Encoding</code> response header will cause srcache_store skip storing the whole response into the cache and issue a warning into nginx's <code>error.log</code> file like this:</p> <pre><code>[warn] 12500#0: *1 srcache_store skipped due to response header \"Content-Encoding: gzip\"\n            (maybe you forgot to disable compression on the backend?)\n</code></pre> <p>Turning on this directive will ignore the <code>Content-Encoding</code> response header and store the response as usual (and also without warning).</p> <p>It's recommended to always disable gzip/deflate compression on your backend server by specifying the following line in your <code>nginx.conf</code> file:</p> <pre><code> proxy_set_header  Accept-Encoding  \"\";\n</code></pre> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_request_cache_control","title":"srcache_request_cache_control","text":"<p>syntax: srcache_request_cache_control on|off</p> <p>default: srcache_request_cache_control off</p> <p>context: http, server, location</p> <p>phase: post-access, output-header-filter</p> <p>When this directive is turned <code>on</code>, the request headers <code>Cache-Control</code> and <code>Pragma</code> will be honored by this module in the following ways:</p> <ol> <li>srcache_fetch, i.e., the cache lookup operation, will be skipped when request headers <code>Cache-Control: no-cache</code> and/or <code>Pragma: no-cache</code> are present.</li> <li>srcache_store, i.e., the cache store operation, will be skipped when the request header <code>Cache-Control: no-store</code> is specified.</li> </ol> <p>Turning off this directive will disable this functionality and is considered safer for busy sites mainly relying on cache for speed.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p> <p>See also srcache_response_cache_control.</p>"},{"location":"modules/srcache/#srcache_response_cache_control","title":"srcache_response_cache_control","text":"<p>syntax: srcache_response_cache_control on|off</p> <p>default: srcache_response_cache_control on</p> <p>context: http, server, location</p> <p>phase: output-header-filter</p> <p>When this directive is turned <code>on</code>, the response headers <code>Cache-Control</code> and <code>Expires</code> will be honored by this module in the following ways:</p> <ul> <li><code>Cache-Control: private</code> skips srcache_store,</li> <li><code>Cache-Control: no-store</code> skips srcache_store,</li> <li><code>Cache-Control: no-cache</code> skips srcache_store,</li> <li><code>Cache-Control: max-age=0</code> skips srcache_store,</li> <li>and <code>Expires: &lt;date-no-more-recently-than-now&gt;</code> skips srcache_store.</li> </ul> <p>This directive takes priority over the srcache_store_no_store, srcache_store_no_cache, and srcache_store_private directives.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p> <p>See also srcache_request_cache_control.</p>"},{"location":"modules/srcache/#srcache_store_no_store","title":"srcache_store_no_store","text":"<p>syntax: srcache_store_no_store on|off</p> <p>default: srcache_store_no_store off</p> <p>context: http, server, location</p> <p>phase: output-header-filter</p> <p>Turning this directive on will force responses with the header <code>Cache-Control: no-store</code> to be stored into the cache when srcache_response_cache_control is turned <code>on</code> and other conditions are met. Default to <code>off</code>.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_store_no_cache","title":"srcache_store_no_cache","text":"<p>syntax: srcache_store_no_cache on|off</p> <p>default: srcache_store_no_cache off</p> <p>context: http, server, location</p> <p>phase: output-header-filter</p> <p>Turning this directive on will force responses with the header <code>Cache-Control: no-cache</code> to be stored into the cache when srcache_response_cache_control is turned <code>on</code> and other conditions are met. Default to <code>off</code>.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_store_private","title":"srcache_store_private","text":"<p>syntax: srcache_store_private on|off</p> <p>default: srcache_store_private off</p> <p>context: http, server, location</p> <p>phase: output-header-filter</p> <p>Turning this directive on will force responses with the header <code>Cache-Control: private</code> to be stored into the cache when srcache_response_cache_control is turned <code>on</code> and other conditions are met. Default to <code>off</code>.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_default_expire","title":"srcache_default_expire","text":"<p>syntax: srcache_default_expire &lt;time&gt;</p> <p>default: srcache_default_expire 60s</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>This directive controls the default expiration time period that is allowed for the $srcache_expire variable value when neither <code>Cache-Control: max-age=N</code> nor <code>Expires</code> are specified in the response headers.</p> <p>The <code>&lt;time&gt;</code> argument values are in seconds by default. But it's wise to always explicitly specify the time unit to avoid confusion. Time units supported are \"s\"(seconds), \"ms\"(milliseconds), \"y\"(years), \"M\"(months), \"w\"(weeks), \"d\"(days), \"h\"(hours), and \"m\"(minutes). For example,</p> <pre><code> srcache_default_expire 30m; # 30 minutes\n</code></pre> <p>This time must be less than 597 hours.</p> <p>The semantics of a zero expiration time depends on the actual cache backend storage you are currently using, which is agnostic to this module. In the case of memcached, for example, zero expiration times mean that the item will never expire.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_max_expire","title":"srcache_max_expire","text":"<p>syntax: srcache_max_expire &lt;time&gt;</p> <p>default: srcache_max_expire 0</p> <p>context: http, server, location, location if</p> <p>phase: output-header-filter</p> <p>This directive controls the maximal expiration time period that is allowed for the $srcache_expire variable value. This setting takes priority over other calculating methods.</p> <p>The <code>&lt;time&gt;</code> argument values are in seconds by default. But it's wise to always explicitly specify the time unit to avoid confusion. Time units supported are \"s\"(seconds), \"ms\"(milliseconds), \"y\"(years), \"M\"(months), \"w\"(weeks), \"d\"(days), \"h\"(hours), and \"m\"(minutes). For example,</p> <pre><code> srcache_max_expire 2h;  # 2 hours\n</code></pre> <p>This time must be less than 597 hours.</p> <p>When <code>0</code> is specified, which is the default setting, then there will be no limit at all.</p> <p>This directive was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#variables","title":"Variables","text":""},{"location":"modules/srcache/#srcache_expire","title":"$srcache_expire","text":"<p>type: integer</p> <p>cacheable: no</p> <p>writable: no</p> <p>This Nginx variable gives the recommended expiration time period (in seconds) for the current response being stored into the cache. The algorithm of computing the value is as follows:</p> <ol> <li>When the response header <code>Cache-Control: max-age=N</code> is specified, then <code>N</code> will be used as the expiration time,</li> <li>otherwise if the response header <code>Expires</code> is specified, then the expiration time will be obtained by subtracting the current time stamp from the time specified in the <code>Expires</code> header,</li> <li>when neither <code>Cache-Control: max-age=N</code> nor <code>Expires</code> headers are specified, use the value specified in the srcache_default_expire directive.</li> </ol> <p>The final value of this variable will be the value specified by the srcache_max_expire directive if the value obtained in the algorithm above exceeds the maximal value (if any).</p> <p>You don't have to use this variable for the expiration time.</p> <p>This variable was first introduced in the <code>v0.12rc7</code> release.</p>"},{"location":"modules/srcache/#srcache_fetch_status","title":"$srcache_fetch_status","text":"<p>type: string</p> <p>cacheable: no</p> <p>writable: no</p> <p>This Nginx variable is evaluated to the status of the \"fetch\" phase for the caching system. Three values are possible, <code>HIT</code>, <code>MISS</code>, and <code>BYPASS</code>.</p> <p>When the \"fetch\" subrequest returns status code other than <code>200</code> or its response data is not well-formed, then this variable is evaluated to the value <code>MISS</code>.</p> <p>The value of this variable is only meaningful after the <code>access</code> request processing phase, or <code>BYPASS</code> is always given.</p> <p>This variable was first introduced in the <code>v0.14</code> release.</p>"},{"location":"modules/srcache/#srcache_store_status","title":"$srcache_store_status","text":"<p>type: string</p> <p>cacheable: no</p> <p>writable: no</p> <p>This Nginx variable gives the current caching status for the \"store\" phase. Two possible values, <code>STORE</code> and <code>BYPASS</code> can be obtained.</p> <p>Because the responses for the \"store\" subrequest are always discarded, so the value of this variable will always be <code>STORE</code> as long as the \"store\" subrequest is actually issued.</p> <p>The value of this variable is only meaningful at least when the request headers of the current (main) request are being sent. The final result can only be obtained after all the response body has been sent if the <code>Content-Length</code> response header is not specified for the main request.</p> <p>This variable was first introduced in the <code>v0.14</code> release.</p>"},{"location":"modules/srcache/#known-issues","title":"Known Issues","text":"<ul> <li>On certain systems, enabling aio and/or sendfile may stop srcache_store from working. You can disable them in the locations configured by srcache_store.</li> <li>The srcache_store directive can not be used to capture the responses generated by echo-nginx-module's subrequest directivees like echo_subrequest_async and echo_location. You are recommended to use HttpLuaModule to initiate and capture subrequests, which should work with srcache_store.</li> </ul>"},{"location":"modules/srcache/#caveats","title":"Caveats","text":"<ul> <li>It is recommended to disable your backend server's gzip compression and use nginx's ngx_http_gzip_module to do the job. In case of ngx_http_proxy_module, you can use the following configure setting to disable backend gzip compression: <pre><code> proxy_set_header  Accept-Encoding  \"\";\n</code></pre></li> <li>Do not use ngx_http_rewrite_module's if directive in the same location as this module's, because \"if is evil\". Instead, use ngx_http_map_module or lua-nginx-module combined with this module's srcache_store_skip and/or srcache_fetch_skip directives. For example: <pre><code> map $request_method $skip_fetch {\n     default     0;\n     POST        1;\n     PUT         1;\n }\n\n server {\n     listen 8080;\n\n     location /api/ {\n         set $key \"$uri?$args\";\n\n         srcache_fetch GET /memc $key;\n         srcache_store PUT /memc $key;\n\n         srcache_methods GET PUT POST;\n         srcache_fetch_skip $skip_fetch;\n\n         # proxy_pass/drizzle_pass/content_by_lua/echo/...\n     }\n }\n</code></pre></li> </ul>"},{"location":"modules/srcache/#trouble-shooting","title":"Trouble Shooting","text":"<p>To debug issues, you should always check your Nginx <code>error.log</code> file first. If no error messages are printed, you need to enable the Nginx debugging logs to get more details, as explained in debugging log.</p> <p>Several common pitfalls for beginners:</p> <ul> <li>The original response carries a <code>Cache-Control</code> header that explicitly disables caching and you do not configure directives like srcache_response_cache_control.</li> <li>The original response is already gzip compressed, which is not cached by default (see srcache_ignore_content_encoding).</li> <li>Memcached might return <code>CLIENT_ERROR bad command line format</code> when using a too long key (250 chars as of version 1.4.25). It is thus safer to use <code>set_md5 $key $uri$args;</code> instead of <code>set $key $uri$args;</code>. The <code>set_md5</code> directive (and more) is available from OpenResty's set-misc module.</li> <li>Nginx might return <code>client intended to send too large body</code> when trying to store objects larger than 1m to the storage backend, in which case nginx <code>client_max_body_size</code> must be set to a higher value.</li> <li>Memcached might fail to store objects larger than 1m, causing errors like <code>srcache_store subrequest failed status=502</code>. Since version 1.4.2, memcached supports a command-line <code>-I</code> option to override the default size of each slab page. Please read its manpage for more information.</li> </ul>"},{"location":"modules/srcache/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too. Thanks to the Test::Nginx module in the Perl world.</p> <p>To run it on your side: <pre><code> $ PATH=/path/to/your/nginx-with-srcache-module:$PATH prove -r t\n</code></pre> You need to terminate any Nginx processes before running the test suite if you have changed the Nginx server binary.</p> <p>Because a single nginx server (by default, <code>localhost:1984</code>) is used across all the test scripts (<code>.t</code> files), it's meaningless to run the test suite in parallel by specifying <code>-jN</code> when invoking the <code>prove</code> utility.</p> <p>Some parts of the test suite requires modules ngx_http_rewrite_module, echo-nginx-module, rds-json-nginx-module, and drizzle-nginx-module to be enabled as well when building Nginx.</p>"},{"location":"modules/srcache/#see-also","title":"See Also","text":"<ul> <li>memc-nginx-module</li> <li>lua-nginx-module</li> <li>set-misc-nginx-module</li> <li>The openresty bundle</li> </ul>"},{"location":"modules/srcache/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-srcache.</p>"},{"location":"modules/srt/","title":"srt: Nginx SRT Module","text":""},{"location":"modules/srt/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-srt\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-srt\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_srt_module.so;\n</code></pre> <p>This document describes nginx-module-srt v1.1  released on Feb 05 2024.</p> <p>Haivision SRT (Secure Reliable Transfer) / TCP gateway. Supports both SRT to TCP and TCP to SRT, including bidirectional data transfer.</p> <p>The implementation uses libsrt for SRT communication. The libsrt code executes on a side thread, eventfd notifications are used in order to communicate with the main nginx thread.</p>"},{"location":"modules/srt/#configuration","title":"Configuration","text":""},{"location":"modules/srt/#sample-configuration","title":"Sample configuration","text":"<pre><code>## SRT -&gt; TCP proxy\nsrt {\n    server {\n        listen 4321;\n        proxy_pass tcp://127.0.0.1:5678;\n    }\n}\n\n## TCP -&gt; SRT proxy\nstream {\n    server {\n        listen 5432;\n        srt_proxy_pass srt://127.0.0.1:4321;\n    }\n}\n</code></pre>"},{"location":"modules/srt/#srt-core-directives","title":"srt core directives","text":""},{"location":"modules/srt/#srt","title":"srt","text":"<ul> <li>syntax: <code>srt { ... }</code></li> <li>default: <code>-</code></li> <li>context: <code>main</code></li> </ul> <p>Provides the configuration file context in which the srt <code>server</code> directives are specified.</p>"},{"location":"modules/srt/#server","title":"server","text":"<ul> <li>syntax: <code>server { ... }</code></li> <li>default: <code>-</code></li> <li>context: <code>srt</code></li> </ul> <p>Sets the configuration for a server.</p>"},{"location":"modules/srt/#listen","title":"listen","text":"<ul> <li>syntax: <code>listen address:port [backlog=number] [bind] [ipv6only=on|off] [reuseport];</code></li> <li>default: <code>-</code></li> <li>context: <code>server</code></li> </ul> <p>Sets the address and port for the UDP socket on which the server will accept connections.</p> <p>See the documentation of the <code>listen</code> directive of the nginx <code>stream</code> module for more details on the optional parameters supported by this directive.</p>"},{"location":"modules/srt/#variables_hash_max_size","title":"variables_hash_max_size","text":"<ul> <li>syntax: <code>variables_hash_max_size size;</code></li> <li>default: <code>1024</code></li> <li>context: <code>srt</code></li> </ul> <p>Sets the maximum size of the variables hash table.</p>"},{"location":"modules/srt/#variables_hash_bucket_size","title":"variables_hash_bucket_size","text":"<ul> <li>syntax: <code>variables_hash_bucket_size size;</code></li> <li>default: <code>64</code></li> <li>context: <code>srt</code></li> </ul> <p>Sets the bucket size for the variables hash table.</p>"},{"location":"modules/srt/#error_log","title":"error_log","text":"<ul> <li>syntax: <code>error_log file [level];</code></li> <li>default: <code>logs/error.log error</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Configures logging, see the documentation of the nginx core <code>error_log</code> directive for more details.</p>"},{"location":"modules/srt/#fc_pkts","title":"fc_pkts","text":"<ul> <li>syntax: <code>fc_pkts number;</code></li> <li>default: <code>25600</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the maximum number of \"in flight\" packets (packets that were sent, but not yet acknowledged).</p> <p>See the libsrt documentation of the <code>SRTO_FC</code> option for more details.</p>"},{"location":"modules/srt/#mss","title":"mss","text":"<ul> <li>syntax: <code>mss size;</code></li> <li>default: <code>1500</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Maximum segment size, in bytes.</p> <p>See the libsrt documentation of the <code>SRTO_MSS</code> option for more details.</p>"},{"location":"modules/srt/#recv_buf","title":"recv_buf","text":"<ul> <li>syntax: <code>recv_buf size;</code></li> <li>default: <code>8192 buffers</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Receive buffer size, in bytes.</p> <p>See the libsrt documentation of the <code>SRTO_RCVBUF</code> option for more details.</p>"},{"location":"modules/srt/#recv_udp_buf","title":"recv_udp_buf","text":"<ul> <li>syntax: <code>recv_udp_buf size;</code></li> <li>default: <code>8192 buffers</code></li> <li>context: <code>srt, server</code></li> </ul> <p>UDP socket receive buffer size, in bytes.</p> <p>See the libsrt documentation of the <code>SRTO_UDP_RCVBUF</code> option for more details.</p>"},{"location":"modules/srt/#recv_latency","title":"recv_latency","text":"<ul> <li>syntax: <code>recv_latency size;</code></li> <li>default: <code>120ms</code></li> <li>context: <code>srt, server</code></li> </ul> <p>The latency on the receiving side, in milliseconds.</p> <p>See the libsrt documentation of the <code>SRTO_RCVLATENCY</code> option for more details.</p>"},{"location":"modules/srt/#send_buf","title":"send_buf","text":"<ul> <li>syntax: <code>send_buf size;</code></li> <li>default: <code>8192 buffers</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Send buffer size, in bytes.</p> <p>See the libsrt documentation of the <code>SRTO_SNDBUF</code> option for more details.</p>"},{"location":"modules/srt/#send_udp_buf","title":"send_udp_buf","text":"<ul> <li>syntax: <code>send_udp_buf size;</code></li> <li>default: <code>65536</code></li> <li>context: <code>srt, server</code></li> </ul> <p>UDP socket send buffer size, in bytes.</p> <p>See the libsrt documentation of the <code>SRTO_UDP_SNDBUF</code> option for more details.</p>"},{"location":"modules/srt/#send_latency","title":"send_latency","text":"<ul> <li>syntax: <code>send_latency size;</code></li> <li>default: <code>120ms</code></li> <li>context: <code>srt, server</code></li> </ul> <p>The minimum receiving latency, provided by the sender.</p> <p>See the libsrt documentation of the <code>SRTO_PEERLATENCY</code> option for more details.</p>"},{"location":"modules/srt/#passphrase","title":"passphrase","text":"<ul> <li>syntax: <code>passphrase expr;</code></li> <li>default: ``</li> <li>context: <code>srt, server</code></li> </ul> <p>Sets a passphrase for encryption, see the libsrt documentation of the <code>SRTO_PASSPHRASE</code> option for more details.</p> <p>The parameter value can contain variables.</p>"},{"location":"modules/srt/#in_buf_size","title":"in_buf_size","text":"<ul> <li>syntax: <code>in_buf_size size;</code></li> <li>default: <code>64k</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the size of the buffer used for reading data from the client.</p>"},{"location":"modules/srt/#srt-map-directives","title":"srt map directives","text":""},{"location":"modules/srt/#map","title":"map","text":"<ul> <li>syntax: <code>map string $variable { ... }</code></li> <li>default: ``</li> <li>context: <code>srt</code></li> </ul> <p>Creates a new variable whose value depends on values of one or more of the source variables specified in the first parameter.</p> <p>See the documentation of the <code>map</code> directive of the nginx <code>stream</code> module for more details.</p>"},{"location":"modules/srt/#map_hash_max_size","title":"map_hash_max_size","text":"<ul> <li>syntax: <code>map_hash_max_size size;</code></li> <li>default: <code>2048</code></li> <li>context: <code>srt</code></li> </ul> <p>Sets the maximum size of the map variables hash table.</p>"},{"location":"modules/srt/#map_hash_bucket_size","title":"map_hash_bucket_size","text":"<ul> <li>syntax: <code>map_hash_bucket_size size;</code></li> <li>default: <code>32|64|128</code></li> <li>context: <code>srt</code></li> </ul> <p>Sets the bucket size for the map variables hash table.</p>"},{"location":"modules/srt/#srt-log-directives","title":"srt log directives","text":""},{"location":"modules/srt/#access_log","title":"access_log","text":"<ul> <li>syntax: <code>access_log path format [buffer=size] [gzip[=level]] [flush=time] [if=condition];</code></li> <li>default: <code>off</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the path, format, and configuration for a buffered log write.</p> <p>See the documentation of the <code>access_log</code> directive of the nginx <code>stream</code> module for more details.</p>"},{"location":"modules/srt/#log_format","title":"log_format","text":"<ul> <li>syntax: <code>log_format name [escape=default|json|none] string ...;</code></li> <li>default: ``</li> <li>context: <code>srt</code></li> </ul> <p>Defines a log format.</p> <p>See the documentation of the <code>log_format</code> directive of the nginx <code>stream</code> module for more details.</p>"},{"location":"modules/srt/#open_log_file_cache","title":"open_log_file_cache","text":"<ul> <li>syntax: <code>open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];</code></li> <li>default: <code>off</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Defines a cache that stores the file descriptors of frequently used logs whose names contain variables.</p> <p>See the documentation of the <code>open_log_file_cache</code> directive of the nginx <code>stream</code> module for more details.</p>"},{"location":"modules/srt/#srt-proxy-directives","title":"srt proxy directives","text":""},{"location":"modules/srt/#proxy_pass","title":"proxy_pass","text":"<ul> <li>syntax: <code>proxy_pass address;</code></li> <li>default: ``</li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the address of the proxied server.</p>"},{"location":"modules/srt/#proxy_connect_timeout","title":"proxy_connect_timeout","text":"<ul> <li>syntax: <code>proxy_connect_timeout timeout;</code></li> <li>default: <code>60s</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Defines a timeout for establishing a connection with a proxied server.</p>"},{"location":"modules/srt/#proxy_timeout","title":"proxy_timeout","text":"<ul> <li>syntax: <code>proxy_timeout timeout;</code></li> <li>default: <code>10m</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the timeout between two successive read or write operations on client or proxied server connections. If no data is transmitted within this time, the connection is closed.</p>"},{"location":"modules/srt/#proxy_buffer_size","title":"proxy_buffer_size","text":"<ul> <li>syntax: <code>proxy_buffer_size size;</code></li> <li>default: <code>64k</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the size of the buffer used for reading data from the proxied server.</p>"},{"location":"modules/srt/#proxy_protocol","title":"proxy_protocol","text":"<ul> <li>syntax: <code>proxy_protocol on | off;</code></li> <li>default: <code>off</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Enables the PROXY protocol for connections to a proxied server.</p>"},{"location":"modules/srt/#proxy_header","title":"proxy_header","text":"<ul> <li>syntax: <code>proxy_header expr;</code></li> <li>default: ``</li> <li>context: <code>srt, server</code></li> </ul> <p>Defines a string that is sent to the proxied server before any data received over SRT.</p> <p>The parameter value can contain variables.</p>"},{"location":"modules/srt/#srt-set-misc-directives","title":"srt set misc directives","text":""},{"location":"modules/srt/#set_decode_base64","title":"set_decode_base64","text":"<ul> <li>syntax: <code>set_decode_base64 $dst src;</code></li> <li>default: ``</li> <li>context: <code>srt</code></li> </ul> <p>Performs base64 decode of the value of the second argument, and assigns the result to the variable specified in the first argument.</p>"},{"location":"modules/srt/#set_decode_base64url","title":"set_decode_base64url","text":"<ul> <li>syntax: <code>set_decode_base64url $dst src;</code></li> <li>default: ``</li> <li>context: <code>srt</code></li> </ul> <p>Performs url-safe-base64 decode of the value of the second argument, and assigns the result to the variable specified in the first argument.</p>"},{"location":"modules/srt/#set_aes_decrypt","title":"set_aes_decrypt","text":"<ul> <li>syntax: <code>set_aes_decrypt $dst base64_key base64_iv src;</code></li> <li>default: ``</li> <li>context: <code>srt</code></li> </ul> <p>Performs AES-256-CBC decryption of the value of the last argument, using the supplied key/iv, and assigns the result to the variable specified in the first argument.</p>"},{"location":"modules/srt/#stream-srt-proxy-directives","title":"stream srt proxy directives","text":""},{"location":"modules/srt/#srt_proxy_pass","title":"srt_proxy_pass","text":"<ul> <li>syntax: <code>srt_proxy_pass address;</code></li> <li>default: ``</li> <li>context: <code>stream, server</code></li> </ul> <p>Sets the address of the proxied server.</p>"},{"location":"modules/srt/#srt_proxy_connect_timeout","title":"srt_proxy_connect_timeout","text":"<ul> <li>syntax: <code>srt_proxy_connect_timeout timeout;</code></li> <li>default: <code>60s</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Defines a timeout for establishing a connection with a proxied server.</p>"},{"location":"modules/srt/#srt_proxy_timeout","title":"srt_proxy_timeout","text":"<ul> <li>syntax: <code>srt_proxy_timeout timeout;</code></li> <li>default: <code>10m</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the timeout between two successive read or write operations on client or proxied server connections. If no data is transmitted within this time, the connection is closed.</p>"},{"location":"modules/srt/#srt_proxy_buffer_size","title":"srt_proxy_buffer_size","text":"<ul> <li>syntax: <code>srt_proxy_buffer_size size;</code></li> <li>default: <code>64k</code></li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the size of the buffer used for reading data from the proxied server.</p>"},{"location":"modules/srt/#srt_proxy_stream_id","title":"srt_proxy_stream_id","text":"<ul> <li>syntax: <code>srt_proxy_stream_id expr;</code></li> <li>default: ``</li> <li>context: <code>srt, server</code></li> </ul> <p>Sets the SRT stream id, see the libsrt documentation of the <code>SRTO_STREAMID</code> option for more details.</p> <p>The parameter value can contain variables.</p>"},{"location":"modules/srt/#srt_proxy_passphrase","title":"srt_proxy_passphrase","text":"<ul> <li>syntax: <code>srt_proxy_passphrase expr;</code></li> <li>default: ``</li> <li>context: <code>srt, server</code></li> </ul> <p>Sets a passphrase for encryption, see the libsrt documentation of the <code>SRTO_PASSPHRASE</code> option for more details.</p> <p>The parameter value can contain variables.</p>"},{"location":"modules/srt/#embedded-variables","title":"Embedded Variables","text":""},{"location":"modules/srt/#core","title":"Core","text":"<ul> <li><code>binary_remote_addr</code> - client address in a binary form, the length of the value is always 4 bytes for IPv4 addresses or 16 bytes for IPv6 addresses</li> <li><code>bytes_received</code> - number of bytes received from the client</li> <li><code>bytes_sent</code> - number of bytes sent to the client</li> <li><code>connection</code> - connection serial number</li> <li><code>hostname</code> - host name</li> <li><code>msec</code> - current time, in seconds with milliseconds resolution</li> <li><code>nginx_version</code> - nginx version</li> <li><code>peer_version</code> - libsrt version of the remote peer, see the libsrt documentation of the <code>SRTO_PEERVERSION</code> option for more details.</li> <li><code>pid</code> - PID of the worker process</li> <li><code>protocol</code> - protocol used to communicate with the client, always evaluates to <code>SRT</code></li> <li><code>remote_addr</code> - client address</li> <li><code>remote_port</code> - client port</li> <li><code>server_addr</code> - the address of the server which accepted the connection</li> <li><code>server_port</code> - the port of the server which accepted the connection</li> <li><code>session_time</code> - session duration, in seconds with a milliseconds resolution</li> <li><code>status</code> - session status</li> <li><code>stream_id</code> - SRT stream id, see the libsrt documentation of the <code>SRTO_STREAMID</code> option for more details.</li> <li><code>time_iso8601</code> - local time, in ISO 8601 standard format</li> <li><code>time_local</code> - local time, in the Common Log Format</li> </ul>"},{"location":"modules/srt/#upstream","title":"Upstream","text":"<ul> <li><code>upstream_addr</code> - the IP address and port of the upstream server</li> <li><code>upstream_bytes_received</code> - number of bytes received from the upstream server</li> <li><code>upstream_bytes_sent</code> - number of bytes sent to the upstream server</li> <li><code>upstream_connect_time</code> - time to connect to the upstream server, in seconds with millisecond resolution</li> <li><code>upstream_first_byte_time</code> - time to receive the first byte of data, in seconds with millisecond resolution</li> <li><code>upstream_session_time</code> - session duration, in seconds with millisecond resolution</li> </ul>"},{"location":"modules/srt/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-srt.</p>"},{"location":"modules/statsd/","title":"statsd: NGINX module for sending stats to statsd","text":""},{"location":"modules/statsd/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-statsd\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-statsd\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_statsd_module.so;\n</code></pre> <p>This document describes nginx-module-statsd v0.0.1  released on Feb 24 2020.</p> <p>An nginx module for sending statistics to statsd.</p> <p>This is how to use the nginx-statsd module:</p> <pre><code>http {\n\n    # Set the server that you want to send stats to.\n    statsd_server your.statsd.server.com;\n\n    # Randomly sample 10% of requests so that you do not overwhelm your statsd server.\n    # Defaults to sending all statsd (100%). \n    statsd_sample_rate 10; # 10% of requests\n\n\n    server {\n        listen 80;\n        server_name www.your.domain.com;\n\n        # Increment \"your_product.requests\" by 1 whenever any request hits this server. \n        statsd_count \"your_product.requests\" 1;\n\n        location / {\n\n            # Increment the key by 1 when this location is hit.\n            statsd_count \"your_product.pages.index_requests\" 1;\n\n            # Increment the key by 1, but only if $request_completion is set to something.\n            statsd_count \"your_product.pages.index_responses\" 1 \"$request_completion\";\n\n            # Send a timing to \"your_product.pages.index_response_time\" equal to the value\n            # returned from the upstream server. If this value evaluates to 0 or empty-string,\n            # it will not be sent. Thus, there is no need to add a test.\n            statsd_timing \"your_product.pages.index_response_time\" \"$upstream_response_time\";\n\n            # Increment a key based on the value of a custom header. Only sends the value if\n            # the custom header exists in the upstream response.\n            statsd_count \"your_product.custom_$upstream_http_x_some_custom_header\" 1 \n                \"$upstream_http_x_some_custom_header\";\n\n            proxy_pass http://some.other.domain.com;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/statsd/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-statsd.</p>"},{"location":"modules/sticky/","title":"sticky: NGINX sticky cookie module","text":""},{"location":"modules/sticky/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-sticky\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-sticky\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_sticky_module.so;\n</code></pre> <p>This document describes nginx-module-sticky v1.3.0  released on Jun 27 2022.</p> <p>modified and extended version; see Changelog.txt </p>"},{"location":"modules/sticky/#description","title":"Description","text":"<p>A nginx module to add a sticky cookie to be always forwarded to the same upstream server.</p> <p>When dealing with several backend servers, it's sometimes useful that one client (browser) is always served by the same backend server (for session persistance for example).</p> <p>Using a persistance by IP (with the ip_hash upstream module) is maybe not a good idea because there could be situations where a lot of different browsers are coming with the same IP address (behind proxies)and the load balancing system won't be fair.</p> <p>Using a cookie to track the upstream server makes each browser unique.</p> <p>When the sticky module can't apply, it switchs back to the classic Round Robin Upstream or returns a \"Bad Gateway\" (depending on the no_fallback flag).</p> <p>Sticky module can't apply when cookies are not supported by the browser</p> <p>Sticky module is based on a \"best effort\" algorithm. Its aim is not to handle security somehow. It's been made to ensure that normal users are always redirected to the same  backend server: that's all!</p>"},{"location":"modules/sticky/#usage","title":"Usage","text":"<pre><code>upstream {\n  sticky;\n  server 127.0.0.1:9000;\n  server 127.0.0.1:9001;\n  server 127.0.0.1:9002;\n}\n\n  sticky [hash=index|md5|sha1] [no_fallback]\n       [name=route] [domain=.foo.bar] [path=/] [expires=1h] [secure] [httponly];\n   or\n  sticky [hmac=md5|sha1 hmac_key=&lt;foobar_key&gt;] [no_fallback]\n       [name=route] [domain=.foo.bar] [path=/] [expires=1h] [secure] [httponly];\n   or\n  sticky [text=raw] [no_fallback]\n       [name=route] [domain=.foo.bar] [path=/] [expires=1h] [secure] [httponly];\n</code></pre> <p>Server selection algorithm: - hash:    the hash mechanism to encode upstream server. It can't be used with hmac or text.   default: md5</p> <pre><code>- md5|sha1: well known hash\n- index:    it's not hashed, an in-memory index is used instead, it's quicker and the overhead is shorter\nWarning: the matching against upstream servers list\nis inconsistent. So, at reload, if upstreams servers\nhas changed, index values are not guaranted to\ncorrespond to the same server as before!\nUSE IT WITH CAUTION and only if you need to!\n</code></pre> <ul> <li> <p>hmac:    the HMAC hash mechanism to encode upstream server     It's like the hash mechanism but it uses hmac_key     to secure the hashing. It can't be used with hash or text.     md5|sha1: well known hash</p> </li> <li> <p>hmac_key: the key to use with hmac. It's mandatory when hmac is set</p> </li> <li> <p>no_fallback: when this flag is set, nginx will return a 502 (Bad Gateway or               Proxy Error) if a request comes with a cookie and the               corresponding backend is unavailable. You can set it to the               upstream block, or set \"sticky_no_fallback\" in a server or               location block.</p> </li> </ul> <p>Cookie settings: - name:    the name of the cookie used to track the persistant upstream srv;   default: route</p> <ul> <li> <p>domain:  the domain in which the cookie will be valid   default: none. Let the browser handle this.</p> </li> <li> <p>path:    the path in which the cookie will be valid   default: /</p> </li> <li> <p>expires: the validity duration of the cookie   default: nothing. It's a session cookie.   restriction: must be a duration greater than one second</p> </li> <li> <p>secure    enable secure cookies; transferred only via https</p> </li> <li>httponly  enable cookies not to be leaked via js</li> </ul>"},{"location":"modules/sticky/#detail-mechanism","title":"Detail Mechanism","text":"<ul> <li>see docs/sticky.{vsd,pdf} </li> </ul>"},{"location":"modules/sticky/#issues-and-warnings","title":"Issues and Warnings:","text":"<ul> <li> <p>when using different upstream-configs with stickyness that use the same domain but    refer to different location - configs it might be wise to set a different path / route -   option on each of this upstream-configs like described here:   https://bitbucket.org/nginx-goodies/nginx-sticky-module-ng/issue/7/leaving-cookie-path-empty-in-module</p> </li> <li> <p>sticky module does not work with the \"backup\" option of the \"server\" configuration item.</p> </li> <li>sticky module might work with the nginx_http_upstream_check_module (up from version 1.2.3)</li> </ul>"},{"location":"modules/sticky/#downloads","title":"Downloads","text":"<ul> <li>tarballs are available via tags from the repo: https://bitbucket.org/nginx-goodies/nginx-sticky-module-ng/downloads</li> </ul>"},{"location":"modules/sticky/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-sticky.</p>"},{"location":"modules/stream-lua/","title":"stream-lua: Lua scripting support for NGINX streams","text":""},{"location":"modules/stream-lua/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-stream-lua\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-stream-lua\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_stream_lua_module.so;\n</code></pre> <p>This document describes nginx-module-stream-lua v0.0.17.post2  released on Nov 03 2025.</p>"},{"location":"modules/stream-lua/#name","title":"Name","text":"<p>ngx_stream_lua_module - Embed the power of Lua into Nginx stream/TCP Servers.</p> <p>This module is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty.</p> <p>instructions](#installation).</p>"},{"location":"modules/stream-lua/#status","title":"Status","text":"<p>Production ready.</p>"},{"location":"modules/stream-lua/#synopsis","title":"Synopsis","text":"<pre><code>events {\n    worker_connections 1024;\n}\n\nstream {\n    # define a TCP server listening on the port 1234:\n    server {\n        listen 1234;\n\n        content_by_lua_block {\n            ngx.say(\"Hello, Lua!\")\n        }\n    }\n}\n</code></pre> <p>Set up as an SSL TCP server:</p> <pre><code>stream {\n    server {\n        listen 4343 ssl;\n\n        ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;\n        ssl_ciphers         AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5;\n        ssl_certificate     /path/to/cert.pem;\n        ssl_certificate_key /path/to/cert.key;\n        ssl_session_cache   shared:SSL:10m;\n        ssl_session_timeout 10m;\n\n        content_by_lua_block {\n            local sock = assert(ngx.req.socket(true))\n            local data = sock:receive()  -- read a line from downstream\n            if data == \"thunder!\" then\n                ngx.say(\"flash!\")  -- output data\n            else\n                ngx.say(\"boom!\")\n            end\n            ngx.say(\"the end...\")\n        }\n    }\n}\n</code></pre> <p>Listening on a UNIX domain socket is also supported:</p> <pre><code>stream {\n    server {\n        listen unix:/tmp/nginx.sock;\n\n        content_by_lua_block {\n            ngx.say(\"What's up?\")\n            ngx.flush(true)  -- flush any pending output and wait\n            ngx.sleep(3)  -- sleeping for 3 sec\n            ngx.say(\"Bye bye...\")\n        }\n    }\n}\n</code></pre>"},{"location":"modules/stream-lua/#description","title":"Description","text":"<p>This is a port of the ngx_http_lua_module to the Nginx \"stream\" subsystem so as to support generic stream/TCP clients.</p> <p>The available Lua APIs and Nginx directives remain the same as those of the ngx_http_lua module.</p>"},{"location":"modules/stream-lua/#directives","title":"Directives","text":"<p>The following directives are ported directly from ngx_http_lua. Please check the documentation of ngx_http_lua for more details about their usage and behavior.</p> <ul> <li>lua_load_resty_core</li> <li>lua_code_cache</li> <li>lua_regex_cache_max_entries</li> <li>lua_package_path</li> <li>lua_package_cpath</li> <li>init_by_lua_block</li> <li>init_by_lua_file</li> <li>init_worker_by_lua_block</li> <li>init_worker_by_lua_file</li> <li>preread_by_lua_block</li> <li>preread_by_lua_file</li> <li>content_by_lua_block</li> <li>content_by_lua_file</li> <li>balancer_by_lua_block</li> <li>balancer_by_lua_file</li> <li>log_by_lua_block</li> <li>log_by_lua_file</li> <li>ssl_client_hello_by_lua_block</li> <li>ssl_client_hello_by_lua_file</li> <li>ssl_certificate_by_lua_block</li> <li>ssl_certificate_by_lua_file</li> <li>proxy_ssl_verify_by_lua_block</li> <li>proxy_ssl_verify_by_lua_file</li> <li>lua_shared_dict</li> <li>lua_socket_connect_timeout</li> <li>lua_socket_buffer_size</li> <li>lua_socket_pool_size</li> <li>lua_socket_keepalive_timeout</li> <li>lua_socket_log_errors</li> <li>lua_ssl_ciphers</li> <li>lua_ssl_crl</li> <li>lua_ssl_protocols</li> <li>lua_ssl_certificate</li> <li>lua_ssl_certificate_key</li> <li>lua_ssl_trusted_certificate</li> <li>lua_ssl_verify_depth</li> <li>lua_ssl_key_log</li> <li>lua_ssl_conf_command</li> <li>lua_upstream_skip_openssl_default_verify</li> <li>lua_check_client_abort</li> <li>lua_max_pending_timers</li> <li>lua_max_running_timers</li> <li>lua_sa_restart</li> <li>lua_add_variable</li> <li>lua_capture_error_log</li> <li>preread_by_lua_no_postpone</li> </ul> <p>The send_timeout directive in the Nginx \"http\" subsystem is missing in the \"stream\" subsystem. As such, ngx_stream_lua_module uses the <code>lua_socket_send_timeout</code> directive for this purpose instead.</p> <p>Note: the lingering close directive that used to exist in older version of <code>stream_lua_nginx_module</code> has been removed and can now be simulated with the newly added tcpsock:shutdown API if necessary.</p>"},{"location":"modules/stream-lua/#preread_by_lua_block","title":"preread_by_lua_block","text":"<p>syntax: preread_by_lua_block { lua-script }</p> <p>context: stream, server</p> <p>phase: preread</p> <p>Acts as a <code>preread</code> phase handler and executes Lua code string specified in <code>lua-script</code> for every connection (or packet in datagram mode). The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).</p> <p>It is possible to acquire the raw request socket using ngx.req.socket and receive data from or send data to the client. However, keep in mind that calling the <code>receive()</code> method of the request socket will consume the data from the buffer and such consumed data will not be seen by handlers further down the chain.</p> <p>The <code>preread_by_lua_block</code> code will always run at the end of the <code>preread</code> processing phase unless preread_by_lua_no_postpone is turned on.</p> <p>This directive was first introduced in the <code>v0.0.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#preread_by_lua_file","title":"preread_by_lua_file","text":"<p>syntax: preread_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: stream, server</p> <p>phase: preread</p> <p>Equivalent to preread_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code or LuaJIT bytecode to be executed.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, it will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option given when starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first connection and cached. The Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid having to reload Nginx.</p> <p>This directive was first introduced in the <code>v0.0.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#log_by_lua_block","title":"log_by_lua_block","text":"<p>syntax: log_by_lua_block { lua-script }</p> <p>context: stream, server</p> <p>phase: log</p> <p>Runs the Lua source code specified as <code>&lt;lua-script&gt;</code> during the <code>log</code> request processing phase. This does not replace the current access logs, but runs before.</p> <p>Yielding APIs such as <code>ngx.req.socket</code>, <code>ngx.socket.*</code>, <code>ngx.sleep</code>, or <code>ngx.say</code> are not available in this phase.</p> <p>This directive was first introduced in the <code>v0.0.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#log_by_lua_file","title":"log_by_lua_file","text":"<p>syntax: log_by_lua_file &lt;path-to-lua-script-file&gt;</p> <p>context: stream, server</p> <p>phase: log</p> <p>Equivalent to log_by_lua_block, except that the file specified by <code>&lt;path-to-lua-script-file&gt;</code> contains the Lua code or LuaJIT bytecode to be executed.</p> <p>Nginx variables can be used in the <code>&lt;path-to-lua-script-file&gt;</code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.</p> <p>When a relative path like <code>foo/bar.lua</code> is given, it will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option given when starting the Nginx server.</p> <p>When the Lua code cache is turned on (by default), the user code is loaded once at the first connection and cached. The Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache <code>off</code> in <code>nginx.conf</code> to avoid having to reload Nginx.</p> <p>This directive was first introduced in the <code>v0.0.3</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#lua_add_variable","title":"lua_add_variable","text":"<p>syntax: lua_add_variable $var</p> <p>context: stream</p> <p>Add the variable <code>$var</code> to the \"stream\" subsystem and makes it changeable. If <code>$var</code> already exists, this directive will do nothing.</p> <p>By default, variables added using this directive are considered \"not found\" and reading them using <code>ngx.var</code> will return <code>nil</code>. However, they could be re-assigned via the <code>ngx.var.VARIABLE</code> API at any time.</p> <p>This directive was first introduced in the <code>v0.0.4</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#preread_by_lua_no_postpone","title":"preread_by_lua_no_postpone","text":"<p>syntax: preread_by_lua_no_postpone on|off</p> <p>context: stream</p> <p>Controls whether or not to disable postponing preread_by_lua* directives to run at the end of the <code>preread</code> processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the <code>preread</code> phase.</p> <p>This directive was first introduced in the <code>v0.0.4</code> release.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#nginx-api-for-lua","title":"Nginx API for Lua","text":"<p>Many Lua API functions are ported from ngx_http_lua. Check out the official manual of ngx_http_lua for more details on these Lua API functions.</p> <ul> <li>ngx.var.VARIABLE</li> </ul> <p>This module fully supports the new variable subsystem inside the Nginx stream core. You may access any built-in variables provided by the stream core or other stream modules. * Core constants</p> <pre><code>`ngx.OK`, `ngx.ERROR`, and etc.\n</code></pre> <ul> <li> <p>Nginx log level constants</p> <p><code>ngx.ERR</code>, <code>ngx.WARN</code>, and etc. * print * ngx.ctx * ngx.balancer</p> </li> <li> <p>ngx.req.socket</p> </li> </ul> <p>Only raw request sockets are supported, for obvious reasons. The <code>raw</code> argument value is ignored and the raw request socket is always returned. Unlike ngx_http_lua, you can still call output API functions like <code>ngx.say</code>, <code>ngx.print</code>, and <code>ngx.flush</code> after acquiring the raw request socket via this function.</p> <p>When the stream server is in UDP mode, reading from the downstream socket returned by the <code>ngx.req.socket</code> call will only return the content of a single packet. Therefore the reading call will never block and will return <code>nil, \"no more data\"</code> when all the data from the datagram has been consumed. However, you may choose to send multiple UDP packets back to the client using the downstream socket.</p> <p>The raw TCP sockets returned by this module will contain the following extra method:</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#reqsockreceiveany","title":"reqsock:receiveany","text":"<p>syntax: data, err = reqsock:receiveany(max)</p> <p>context: content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*</p> <p>This method is similar to tcpsock:receiveany method</p> <p>This method was introduced into <code>stream-lua-nginx-module</code> since <code>v0.0.8</code>.</p> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#tcpsockshutdown","title":"tcpsock:shutdown","text":"<p>syntax: ok, err = tcpsock:shutdown(\"send\")</p> <p>context: content_by_lua*</p> <p>Shuts down the write part of the request socket, prevents all further writing to the client and sends TCP FIN, while keeping the reading half open.</p> <p>Currently only the <code>\"send\"</code> direction is supported. Using any parameters other than \"send\" will return an error.</p> <p>If you called any output functions (like ngx.say) before calling this method, consider use <code>ngx.flush(true)</code> to make sure all busy buffers are complely flushed before shutting down the socket. If any busy buffers were detected, this method will return <code>nil</code> will error message <code>\"socket busy writing\"</code>.</p> <p>This feature is particularly useful for protocols that generate a response before actually finishing consuming all incoming data. Normally, the kernel will send RST to the client when tcpsock:close is called without emptying the receiving buffer first. Calling this method will allow you to keep reading from the receiving buffer and prevents RST from being sent.</p> <p>You can also use this method to simulate lingering close similar to that provided by the ngx_http_core_module for protocols in need of such behavior. Here is an example:</p> <pre><code>local LINGERING_TIME = 30 -- 30 seconds\nlocal LINGERING_TIMEOUT = 5000 -- 5 seconds\n\nlocal ok, err = sock:shutdown(\"send\")\nif not ok then\n    ngx.log(ngx.ERR, \"failed to shutdown: \", err)\n    return\nend\n\nlocal deadline = ngx.time() + LINGERING_TIME\n\nsock:settimeouts(nil, nil, LINGERING_TIMEOUT)\n\nrepeat\n    local data, _, partial = sock:receive(1024)\nuntil (not data and not partial) or ngx.time() &gt;= deadline\n</code></pre> <p>Back to TOC</p>"},{"location":"modules/stream-lua/#reqsockpeek","title":"reqsock:peek","text":"<p>syntax: ok, err = reqsock:peek(size)</p> <p>context: preread_by_lua*</p> <p>Peeks into the preread buffer that contains downstream data sent by the client without consuming them. That is, data returned by this API will still be forwarded upstream in later phases.</p> <p>This function takes a single required argument, <code>size</code>, which is the number of bytes to be peeked. Repeated calls to this function always returns data from the beginning of the preread buffer.</p> <p>Note that preread phase happens after the TLS handshake. If the stream server was configured with TLS enabled, the returned data will be in clear text.</p> <p>If preread buffer does not have the requested amount of data, then the current Lua thread will be yielded until more data is available, <code>preread_buffer_size</code> has been exceeded, or <code>preread_timeout</code> has elapsed. Successful calls always return the requested amounts of data, that is, no partial data will be returned.</p> <p>When <code>preread_buffer_size</code> has been exceeded, the current stream session will be terminated with the session status code <code>400</code> immediately by the stream core module, with error message <code>\"preread buffer full\"</code> that will be printed to the error log.</p> <p>When <code>preread_timeout</code> has been exceeded, the current stream session will be terminated with the session status code <code>200</code> immediately by the stream core module.</p> <p>In both cases, no further processing on the session is possible (except <code>log_by_lua*</code>). The connection will be closed by the stream core module automatically.</p> <p>Note that this API cannot be used if consumption of client data has occurred. For example, after calling <code>reqsock:receive</code>. If such an attempt was made, the Lua error <code>\"attempt to peek on a consumed socket\"</code> will be thrown. Consuming client data after calling this API is allowed and safe.</p> <p>Here is an example of using this API:</p> <pre><code>local sock = assert(ngx.req.socket())\n\nlocal data = assert(sock:peek(1)) -- peek the first 1 byte that contains the length\ndata = string.byte(data)\n\ndata = assert(sock:peek(data + 1)) -- peek the length + the size byte\n\nlocal payload = data:sub(2) -- trim the length byte to get actual payload\n\nngx.log(ngx.INFO, \"payload is: \", payload)\n</code></pre> <p>This API was first introduced in the <code>v0.0.6</code> release.</p> <p>Back to TOC</p> <ul> <li>ngx.print</li> <li>ngx.say</li> <li>ngx.log</li> <li> <p>ngx.flush</p> <p>This call currently ignores the <code>wait</code> argument and always wait for all the pending output to be completely flushed out (to the system socket send buffers). * ngx.exit * ngx.eof * ngx.sleep * ngx.escape_uri * ngx.unescape_uri * ngx.encode_args * ngx.decode_args * ngx.encode_base64 * ngx.decode_base64 * ngx.crc32_short * ngx.crc32_long * ngx.hmac_sha1 * ngx.md5 * ngx.md5_bin * ngx.sha1_bin * ngx.quote_sql_str * ngx.today * ngx.time * ngx.now * ngx.update_time * ngx.localtime * ngx.utctime * ngx.re.match * ngx.re.find * ngx.re.gmatch * ngx.re.sub * ngx.re.gsub * ngx.shared.DICT * ngx.socket.tcp * ngx.socket.udp * ngx.socket.connect * ngx.get_phase * ngx.thread.spawn * ngx.thread.wait * ngx.thread.kill * ngx.on_abort * ngx.timer.at * ngx.timer.running_count * ngx.timer.pending_count * ngx.config.debug * ngx.config.subsystem</p> <p>Always takes the Lua string value <code>\"stream\"</code> in this module. * ngx.config.prefix * ngx.config.nginx_version * ngx.config.nginx_configure * ngx.config.ngx_lua_version * ngx.worker.exiting * ngx.worker.pid * ngx.worker.pids * ngx.worker.count * ngx.worker.id * coroutine.create * coroutine.resume * coroutine.yield * coroutine.wrap * coroutine.running * coroutine.status</p> </li> </ul>"},{"location":"modules/stream-lua/#nginx-compatibility","title":"Nginx Compatibility","text":"<p>The latest version of this module is compatible with the following versions of Nginx:</p> <ul> <li>1.29.x (last tested: 1.29.2)</li> <li>1.27.x (last tested: 1.27.1)</li> <li>1.25.x (last tested: 1.25.1)</li> <li>1.21.x (last tested: 1.21.4)</li> <li>1.19.x (last tested: 1.19.3)</li> <li>1.17.x (last tested: 1.17.8)</li> <li>1.15.x (last tested: 1.15.8)</li> <li>1.13.x (last tested: 1.13.6)</li> </ul> <p>Nginx cores older than 1.13.6 (exclusive) are not tested and may or may not work. Use at your own risk!</p>"},{"location":"modules/stream-lua/#tell-nginxs-build-system-where-to-find-luajit-21","title":"tell nginx's build system where to find LuaJIT 2.1:","text":"<p>export LUAJIT_LIB=/path/to/luajit/lib export LUAJIT_INC=/path/to/luajit/include/luajit-2.1</p>"},{"location":"modules/stream-lua/#here-we-assume-nginx-is-to-be-installed-under-optnginx","title":"Here we assume Nginx is to be installed under /opt/nginx/.","text":"<p>./configure --prefix=/opt/nginx \\         --with-ld-opt=\"-Wl,-rpath,/path/to/luajit-or-lua/lib\" \\         --with-stream \\         --with-stream_ssl_module \\         --add-module=/path/to/stream-lua-nginx-module</p>"},{"location":"modules/stream-lua/#code-repository","title":"Code Repository","text":"<p>The code repository of this project is hosted on GitHub at openresty/stream-lua-nginx-module.</p>"},{"location":"modules/stream-lua/#see-also","title":"See Also","text":"<ul> <li>ngx_http_lua_module</li> <li>ngx_stream_echo_module</li> <li>OpenResty</li> </ul>"},{"location":"modules/stream-lua/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-stream-lua.</p>"},{"location":"modules/stream-sts/","title":"stream-sts: Nginx stream server traffic status core module","text":""},{"location":"modules/stream-sts/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-stream-sts\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-stream-sts\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_stream_server_traffic_status_module.so;\n</code></pre> <p>This document describes nginx-module-stream-sts v0.1.1  released on Jul 04 2018.</p> <p></p> <p>Nginx stream server traffic status core module</p>"},{"location":"modules/stream-sts/#screenshots","title":"Screenshots","text":""},{"location":"modules/stream-sts/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    stream_server_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            stream_server_traffic_status_display;\n            stream_server_traffic_status_display_format html;\n        }\n    }\n}\n\nstream {\n    server_traffic_status_zone;\n\n    ...\n\n    server {\n        ...\n    }\n}\n</code></pre>"},{"location":"modules/stream-sts/#description","title":"Description","text":"<p>This is an Nginx module that provides access to stream server traffic status information. This is a porting version of the nginx-module-vts to the NGINX \"stream\" subsystem so as to support the same features in nginx-module-vts. It contains the current status such as servers, upstreams, user-defined filter. This module is the core module of two modules(nginx-module-sts, nginx-module-stream-sts).</p> <p>The functions of each module are as follows:</p> <ul> <li>nginx-module-stream-sts</li> <li>Support for implementing stream server stats.</li> <li>Support for implementing stream filter.</li> <li>Support for implementing stream limit.</li> <li>Support for implementing stream embedded variables.</li> <li>nginx-module-sts</li> <li>Support for implementing display of stream server stats.</li> <li>Support for implementing control of stream server stats.</li> </ul>"},{"location":"modules/stream-sts/#see-also","title":"See Also","text":"<ul> <li>nginx-module-sts</li> <li>nginx-module-vts</li> </ul>"},{"location":"modules/stream-sts/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-stream-sts.</p>"},{"location":"modules/stream-upsync/","title":"stream-upsync: NGINX module for syncing stream backends from consul or etcd","text":""},{"location":"modules/stream-upsync/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-stream-upsync\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-stream-upsync\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_stream_upsync_module.so;\n</code></pre> <p>This document describes nginx-module-stream-upsync v1.2.2  released on Jan 02 2020.</p> <p>nginx-stream-upsync-module - Nginx C module, sync upstreams from consul or others, dynamically modify backend-servers attribute(weight, max_fails,...), needn't reload nginx.</p> <p>It may not always be convenient to modify configuration files and restart NGINX. For example, if you are experiencing large amounts of traffic and high load, restarting NGINX and reloading the configuration at that point further increases load on the system and can temporarily degrade performance.</p> <p>The module can be more smoothly expansion and constriction, and will not influence the performance.</p> <p>Another module, nginx-upsync-module supports nginx http module(HTTP protocol), please be noticed.</p> <p>If you want to use nginx-upsync-module and nginx-stream-upsync-module both, please refer to nginx-upsync.</p>"},{"location":"modules/stream-upsync/#status","title":"Status","text":"<p>This module is still under active development and is considered production ready.</p>"},{"location":"modules/stream-upsync/#synopsis","title":"Synopsis","text":"<p>nginx-consul: <pre><code>stream {\n    upstream test {\n        upsync 127.0.0.1:8500/v1/kv/upstreams/test/ upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 12345;\n\n        proxy_connect_timeout 1s;\n        proxy_timeout 3s;\n        proxy_pass test;\n    }\n\n    server {\n        listen 2345;\n\n        upstream_show\n    }\n\n    server {\n        listen 127.0.0.1:9091;\n\n        proxy_responses 1;\n        proxy_timeout 20s;\n        proxy_pass bar;\n    }\n}\n</code></pre> nginx-etcd: <pre><code>stream {\n    upstream test {\n        upsync 127.0.0.1:2379/v2/keys/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=etcd strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 12345;\n\n        proxy_connect_timeout 1s;\n        proxy_timeout 3s;\n        proxy_pass test;\n    }\n\n    server {\n        listen 2345;\n\n        upstream_show\n    }\n\n    server {\n        listen 127.0.0.1:9091;\n\n        proxy_responses 1;\n        proxy_timeout 20s;\n        proxy_pass bar;\n    }\n}\n</code></pre> upsync_lb: <pre><code>stream {\n    upstream test {\n        least_conn; //hash $uri consistent;\n\n        upsync 127.0.0.1:8500/v1/kv/upstreams/test/ upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n        upsync_lb least_conn; //hash_ketama;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 12345;\n\n        proxy_connect_timeout 1s;\n        proxy_timeout 3s;\n        proxy_pass test;\n    }\n\n    server {\n        listen 2345;\n\n        upstream_show\n    }\n\n    server {\n        listen 127.0.0.1:9091;\n\n        proxy_responses 1;\n        proxy_timeout 20s;\n        proxy_pass bar;\n    }\n}\n</code></pre></p> <p>NOTE: upstream: include command is neccesary, first time the dumped file should include all the servers.</p>"},{"location":"modules/stream-upsync/#description","title":"Description","text":"<p>This module provides a method to discover backend servers. Supporting dynamicly adding or deleting backend server through consul/etcd and dynamicly adjusting backend servers weight, module will timely pull new backend server list from consul/etcd to upsync nginx ip router. Nginx needn't reload. Having some advantages than others:</p> <ul> <li> <p>timely</p> <p>module send key to consul/etcd with index, consul/etcd will compare it with its index, if index doesn't change connection will hang five minutes, in the period any operation to the key-value, will feed back rightaway.</p> </li> <li> <p>performance</p> <p>Pulling from consul/etcd equal a request to nginx, updating ip router nginx needn't reload, so affecting nginx performance is little.</p> </li> <li> <p>stability</p> <p>Even if one pulling failed, it will pull next upsync_interval, so guaranteing backend server stably provides service. And support dumping the latest config to location, so even if consul/etcd hung up, and nginx can be reload anytime. </p> </li> </ul>"},{"location":"modules/stream-upsync/#directives","title":"Directives","text":""},{"location":"modules/stream-upsync/#upsync","title":"upsync","text":"<p><pre><code>syntax: upsync $consul/etcd.api.com:$port/v1/kv/upstreams/$upstream_name/ [upsync_type=consul/etcd] [upsync_interval=second/minutes] [upsync_timeout=second/minutes] [strong_dependency=off/on]\n</code></pre> default: none, if parameters omitted, default parameters are upsync_interval=5s upsync_timeout=6m strong_dependency=off</p> <p>context: upstream</p> <p>description: Pull upstream servers from consul/etcd... .</p> <p>The parameters' meanings are:</p> <ul> <li> <p>upsync_interval</p> <p>pulling servers from consul/etcd interval time.</p> </li> <li> <p>upsync_timeout</p> <p>pulling servers from consul/etcd request timeout.</p> </li> <li> <p>upsync_type</p> <p>pulling servers from conf server type.</p> </li> <li> <p>strong_dependency</p> <p>when nginx start up if strong_dependency is on that means servers will be depended on consul/etcd and will pull servers from consul/etcd.</p> </li> </ul>"},{"location":"modules/stream-upsync/#upsync_dump_path","title":"upsync_dump_path","text":"<p><code>syntax: upsync_dump_path $path</code></p> <p>default: /tmp/servers_$host.conf</p> <p>context: upstream</p> <p>description: dump the upstream backends to the $path.</p>"},{"location":"modules/stream-upsync/#upsync_lb","title":"upsync_lb","text":"<p><code>syntax: upsync_lb $load_balance</code></p> <p>default: round_robin/ip_hash/hash modula</p> <p>context: upstream</p> <p>description: mainly for least_conn and hash consistent, when using one of them, you must point out using upsync_lb.</p>"},{"location":"modules/stream-upsync/#upsync_show","title":"upsync_show","text":"<p><code>syntax: upsync_show</code></p> <p>default: none</p> <p>context: server</p> <p>description: show all upstreams.</p> <pre><code>curl http://localhost:2345/upstream_show\n\nshow all upstreams\n</code></pre>"},{"location":"modules/stream-upsync/#consul_interface","title":"Consul_interface","text":"<p>Data can be taken from key/value store or service catalog. In the first case parameter upsync_type of directive must be consul. For example</p> <pre><code>    upsync 127.0.0.1:8500/v1/kv/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n</code></pre> <p>In the second case it must be consul_services.</p> <pre><code>    upsync 127.0.0.1:8500/v1/catalog/service/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul_services strong_dependency=off;\n</code></pre> <p>you can add or delete backend server through consul_ui or http_interface. Below are examples for key/value store.</p> <p>http_interface example:</p> <ul> <li>add <pre><code>    curl -X PUT http://$consul_ip:$port/v1/kv/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre>     default: weight=1 max_fails=2 fail_timeout=10 down=0 backup=0;</li> </ul> <p><pre><code>    curl -X PUT -d \"{\\\"weight\\\":1, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":1, \"max_fails\":2, \"fail_timeout\":10}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre>     value support json format.</p> <ul> <li> <p>delete <pre><code>    curl -X DELETE http://$consul_ip:$port/v1/kv/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>adjust-weight <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":2, \"max_fails\":2, \"fail_timeout\":10}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>mark server-down <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10, \\\"down\\\":1}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":2, \"max_fails\":2, \"fail_timeout\":10, \"down\":1}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>check <pre><code>    curl http://$consul_ip:$port/v1/kv/upstreams/$upstream_name?recurse\n</code></pre></p> </li> </ul>"},{"location":"modules/stream-upsync/#etcd_interface","title":"Etcd_interface","text":"<p>you can add or delete backend server through http_interface.</p> <p>mainly like etcd, http_interface example:</p> <ul> <li>add <pre><code>    curl -X PUT http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre>     default: weight=1 max_fails=2 fail_timeout=10 down=0 backup=0;</li> </ul> <p><pre><code>    curl -X PUT -d value=\"{\\\"weight\\\":1, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre>     value support json format.</p> <ul> <li> <p>delete <pre><code>    curl -X DELETE http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>adjust-weight <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>mark server-down <pre><code>    curl -X PUT -d value=\"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10, \\\"down\\\":1}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>check <pre><code>    curl http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name\n</code></pre></p> </li> </ul>"},{"location":"modules/stream-upsync/#code-style","title":"Code style","text":"<p>Code style is mainly based on style</p>"},{"location":"modules/stream-upsync/#see-also","title":"see also","text":"<ul> <li>the nginx_upstream_check_module: https://github.com/alibaba/tengine/blob/master/src/http/ngx_http_upstream_check_module.c</li> <li>the nginx_upstream_check_module patch: https://github.com/yaoweibin/nginx_upstream_check_module</li> <li>or based on https://github.com/xiaokai-wang/nginx_upstream_check_module</li> </ul>"},{"location":"modules/stream-upsync/#source-dependency","title":"source dependency","text":"<ul> <li>Cjson: https://github.com/kbranigan/cJSON</li> <li>http-parser: https://github.com/nodejs/http-parser</li> </ul>"},{"location":"modules/stream-upsync/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-stream-upsync.</p>"},{"location":"modules/sts/","title":"sts: Nginx stream server traffic status module","text":""},{"location":"modules/sts/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-sts\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-sts\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_stream_server_traffic_status_module.so;\n</code></pre> <p>This document describes nginx-module-sts v0.1.1  released on Jul 04 2018.</p> <p></p> <p>Nginx stream server traffic status module</p>"},{"location":"modules/sts/#screenshots","title":"Screenshots","text":""},{"location":"modules/sts/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    stream_server_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            stream_server_traffic_status_display;\n            stream_server_traffic_status_display_format html;\n        }\n    }\n}\n\nstream {\n    server_traffic_status_zone;\n\n    ...\n\n    server {\n        ...\n    }\n}\n</code></pre>"},{"location":"modules/sts/#description","title":"Description","text":"<p>This is an Nginx module that provides access to stream server traffic status information. This is a porting version of the nginx-module-vts to the NGINX \"stream\" subsystem so as to support the same features in nginx-module-vts. It contains the current status such as servers, upstreams, user-defined filter.</p> <p>First of all, It is required both the directive <code>server_traffic_status_zone</code> in stream block and <code>stream_server_traffic_status_zone</code> in http block, and then if the directive <code>stream_server_traffic_status_display</code> is set, can be access to as follows:</p> <ul> <li>/status/format/json</li> <li>If you request <code>/status/format/json</code>, will respond with a JSON document containing the current activity data for using in live dashboards and third-party monitoring tools.</li> <li>/status/format/html</li> <li>If you request <code>/status/format/html</code>, will respond with the built-in live dashboard in HTML that requests internally to <code>/status/format/json</code>.</li> <li>/status/format/jsonp</li> <li>If you request <code>/status/format/jsonp</code>, will respond with a JSONP callback function containing the current activity data for using in live dashboards and third-party monitoring tools. </li> <li>/status/format/prometheus                                                                                                                                                                         </li> <li>If you request <code>/status/format/prometheus</code>, will respond with a prometheus document containing the current activity data.   </li> <li>/status/control</li> <li>If you request <code>/status/control</code>, will respond with a JSON document after it reset or delete zones through a query string. See the Control.</li> </ul> <p>JSON document contains as follows:</p> <pre><code>{\n    \"hostName\": ...,\n    \"nginxVersion\": ...,\n    \"loadMsec\": ...,\n    \"nowMsec\": ...,\n    \"connections\": {\n        \"active\":...,\n        \"reading\":...,\n        \"writing\":...,\n        \"waiting\":...,\n        \"accepted\":...,\n        \"handled\":...,\n        \"requests\":...\n    },\n    \"sharedZones\": {\n        \"name\":...,\n        \"maxSize\":...,\n        \"usedSize\":...,\n        \"usedNode\":...\n    },\n    \"streamServerZones\": {\n        \"...\":{\n            \"port\":...,\n            \"protocol\":...,\n            \"connectCounter\":...,\n            \"inBytes\":...,\n            \"outBytes\":...,\n            \"responses\":{\n                \"1xx\":...,\n                \"2xx\":...,\n                \"3xx\":...,\n                \"4xx\":...,\n                \"5xx\":...,\n            },\n            \"sessionMsecCounter\":...,\n            \"sessionMsec\":...,\n            \"sessionMsecs\":{\n                \"times\":[...],\n                \"msecs\":[...]\n            },\n            \"sessionBuckets\":{\n                \"msecs\":[...],\n                \"counters\":[...]\n            }\n        }\n        ...\n    },\n    \"streamFilterZones\": {\n        \"...\":{\n            \"...\":{\n\n                \"port\":...,\n                \"protocol\":...,\n                \"connectCounter\":...,\n                \"inBytes\":...,\n                \"outBytes\":...,\n                \"responses\":{\n                    \"1xx\":...,\n                    \"2xx\":...,\n                    \"3xx\":...,\n                    \"4xx\":...,\n                    \"5xx\":...,\n                },\n                \"sessionMsecCounter\":...,\n                \"sessionMsec\":...,\n                \"sessionMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"sessionBuckets\":{\n                    \"msecs\":[...],\n                    \"counters\":[...]\n                }\n            },\n            ...\n        },\n        ...\n    },\n    \"streamUpstreamZones\": {\n        \"...\":[\n            {\n                \"server\":...,\n                \"connectCounter\":...,\n                \"inBytes\":...,\n                \"outBytes\":...,\n                \"responses\":{\n                    \"1xx\":...,\n                    \"2xx\":...,\n                    \"3xx\":...,\n                    \"4xx\":...,\n                    \"5xx\":...\n                },\n                \"sessionMsecCounter\":...,\n                \"sessionMsec\":...,\n                \"sessionMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"sessionBuckets\":{\n                    \"msecs\":[...]\n                    \"counters\":[...]\n                },\n                \"uSessionMsecCounter\":...,\n                \"uSessionMsec\":...,\n                \"uSessionMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"uSessionBuckets\":{\n                    \"msecs\":[...]\n                    \"counters\":[...]\n                },\n                \"uConnectMsecCounter\":...,\n                \"uConnectMsec\":...,\n                \"uConnectMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"uConnectBuckets\":{\n                    \"msecs\":[...]\n                    \"counters\":[...]\n                },\n                \"uFirstByteMsecCounter\":...,\n                \"uFirstByteMsec\":...,\n                \"uFirstByteMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"uFirstByteBuckets\":{\n                    \"msecs\":[...]\n                    \"counters\":[...]\n                },\n                \"weight\":...,\n                \"maxFails\":...,\n                \"failTimeout\":...,\n                \"backup\":...,\n                \"down\":...\n            }\n            ...\n        ],\n        ...\n    }\n}\n</code></pre> <ul> <li>main</li> <li>Basic version, uptime((nowMsec - loadMsec)/1000)</li> <li>nowMsec, loadMsec is a millisecond.</li> <li>connections</li> <li>Total connections and requests(same as stub_status_module in NGINX)</li> <li>streamServerZones</li> <li>Traffic(in/out) and request and response counts and status(1xx,2xx...) hit ratio per each server zone</li> <li>Total traffic(In/Out) and request and response counts(It zone name is <code>*</code>) and hit ratio</li> <li>streamFilterZones</li> <li>Traffic(in/out) and request and response counts and status(1xx,2xx...) hit ratio per each server zone filtered through the <code>server_traffic_status_filter_by_set_key</code> directive</li> <li>Total traffic(In/Out) and request and response counts(It zone name is <code>*</code>) and hit ratio filtered through the <code>server_traffic_status_filter_by_set_key</code> directive</li> <li>streamUpstreamZones</li> <li>Traffic(in/out) and request and response counts per server in each upstream group</li> <li>Current settings(weight, maxfails, failtimeout...) in nginx.conf</li> </ul> <p>The directive <code>stream_server_traffic_status_display_format</code> sets the default ouput format that is one of json,jsonp,html,prometheus. (Default: json)</p> <p>Traffic calculation as follows:</p> <ul> <li>streamServerZones</li> <li>in += requested_bytes</li> <li>out += sent_bytes</li> <li>streamFilterZones</li> <li>in += requested_bytes via the filter</li> <li>out += sent_bytes via the filter</li> <li>streamUpstreamZones</li> <li>in += requested_bytes via the ServerZones</li> <li>out += sent_bytes via the ServerZones</li> </ul> <p>All calculations are working in log processing phase of Nginx.</p> <p><code>Caveats:</code> this module relies on nginx logging system(NGX_STREAM_LOG_PHASE:last phase of the nginx stream), so the traffic may be in certain cirumstances different that real bandwidth traffic. Websocket, canceled downloads may be cause of inaccuracies. The working of the module doesn't matter at all whether the access_log directive \"on\" or \"off\". Again, this module works well on \"access_log off\".</p>"},{"location":"modules/sts/#control","title":"Control","text":"<p>It is able to reset or delete traffic zones through a query string. The request responds with a JSON document.</p> <ul> <li>URI Syntax</li> <li>/<code>{status_uri}</code>/control?cmd=<code>{command}</code>&amp;group=<code>{group}</code>&amp;zone=<code>{name}</code></li> </ul> <pre><code>http {\n\n    stream_server_traffic_status_zone;\n\n    ...\n\n    server {\n\n        server_name example.org;\n\n        ...\n\n\n        location /status {\n            stream_server_traffic_status_display;\n            stream_server_traffic_status_display_format html;\n        }\n    }                                                                                                                                                                                           }\n}\n\nstream {\n    geoip_country    /usr/share/GeoIP/GeoIP.dat;\n\n    server_traffic_status_zone;\n\n    server_traffic_status_filter_by_set_key $geoip_country_code country::*;\n\n    server {\n\n        ...\n\n    }\n\n    ...\n\n}\n</code></pre> <p>If it set as above, then the control uri is like <code>example.org/status/control</code>.</p> <p>The available request arguments are as follows: * cmd=\\&lt;<code>status</code>|<code>reset</code>|<code>delete</code>&gt;   * status     * It returns status of traffic zones to json format like <code>status/format/json</code>.   * reset     * It reset traffic zones without deleting nodes in shared memory.(= init to 0)   * delete     * It delete traffic zones in shared memory. when re-request recreated.  * group=\\&lt;<code>server</code>|<code>filter</code>|<code>upstream@alone</code>|<code>upstream@group</code>|<code>*</code>&gt;   * server   * filter   * upstream@alone   * upstream@group   * * * zone=name   * server     * name   * filter     * filter_group@name   * upstream@group     * upstream_group@name   * upstream@alone     * @name</p>"},{"location":"modules/sts/#to-get-status-of-traffic-zones-on-the-fly","title":"To get status of traffic zones on the fly","text":"<p>This is similar to the <code>status/format/json</code> except that it can get each zones.</p>"},{"location":"modules/sts/#to-get-fully-zones","title":"To get fully zones","text":"<ul> <li>It is exactly the same with the <code>status/format/json</code>.</li> <li>/status/control?cmd=status&amp;group=*</li> </ul>"},{"location":"modules/sts/#to-get-group-zones","title":"To get group zones","text":"<ul> <li>streamServerZones</li> <li>/status/control?cmd=status&amp;group=server&amp;zone=*</li> <li>streamFilterZones</li> <li>/status/control?cmd=status&amp;group=filter&amp;zone=*</li> <li>streamUpstreamZones</li> <li>/status/control?cmd=status&amp;group=upstream@group&amp;zone=*</li> <li>streamUpstreamZones::nogroups</li> <li>/status/control?cmd=status&amp;group=upstream@alone&amp;zone=*</li> </ul>"},{"location":"modules/sts/#to-get-each-zones","title":"To get each zones","text":"<ul> <li>single zone in streamServerZones</li> <li>/status/control?cmd=status&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in streamFilterZones</li> <li>/status/control?cmd=status&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones</li> <li>/status/control?cmd=status&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones::nogroups</li> <li>/status/control?cmd=status&amp;group=upstream@alone&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/sts/#to-reset-traffic-zones-on-the-fly","title":"To reset traffic zones on the fly","text":"<p>It reset the values of specified zones to 0.</p>"},{"location":"modules/sts/#to-reset-fully-zones","title":"To reset fully zones","text":"<ul> <li>/status/control?cmd=reset&amp;group=*</li> </ul>"},{"location":"modules/sts/#to-reset-group-zones","title":"To reset group zones","text":"<ul> <li>streamServerZones</li> <li>/status/control?cmd=reset&amp;group=server&amp;zone=*</li> <li>streamFilterZones</li> <li>/status/control?cmd=reset&amp;group=filter&amp;zone=*</li> <li>streamUpstreamZones</li> <li>/status/control?cmd=reset&amp;group=upstream@group&amp;zone=*</li> <li>streamUpstreamZones::nogroups</li> <li>/status/control?cmd=reset&amp;group=upstream@alone&amp;zone=*</li> </ul>"},{"location":"modules/sts/#to-reset-each-zones","title":"To reset each zones","text":"<ul> <li>single zone in streamServerZones</li> <li>/status/control?cmd=reset&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in streamFilterZones</li> <li>/status/control?cmd=reset&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones</li> <li>/status/control?cmd=reset&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones::nogroups</li> <li>/status/control?cmd=reset&amp;group=upstream@alone&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/sts/#to-delete-traffic-zones-on-the-fly","title":"To delete traffic zones on the fly","text":"<p>It delete the specified zones in shared memory.</p>"},{"location":"modules/sts/#to-delete-fully-zones","title":"To delete fully zones","text":"<ul> <li>/status/control?cmd=delete&amp;group=*</li> </ul>"},{"location":"modules/sts/#to-delete-group-zones","title":"To delete group zones","text":"<ul> <li>streamServerZones</li> <li>/status/control?cmd=delete&amp;group=server&amp;zone=*</li> <li>streamFilterZones</li> <li>/status/control?cmd=delete&amp;group=filter&amp;zone=*</li> <li>streamUpstreamZones</li> <li>/status/control?cmd=delete&amp;group=upstream@group&amp;zone=*</li> <li>streamUpstreamZones::nogroups</li> <li>/status/control?cmd=delete&amp;group=upstream@alone&amp;zone=*</li> </ul>"},{"location":"modules/sts/#to-delete-each-zones","title":"To delete each zones","text":"<ul> <li>single zone in streamServerZones</li> <li>/status/control?cmd=delete&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in streamFilterZones</li> <li>/status/control?cmd=delete&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones</li> <li>/status/control?cmd=delete&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in streamUpstreamZones::nogroups</li> <li>/status/control?cmd=delete&amp;group=upstream@alone&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/sts/#json","title":"JSON","text":"<p>The following status information is provided in the JSON format:</p>"},{"location":"modules/sts/#json-used-by-status","title":"Json used by status","text":"<p>/<code>{status_uri}</code>/format/json</p> <p>/<code>{status_uri}</code>/control?cmd=status&amp;...</p> <ul> <li>hostName</li> <li>Host name.</li> <li>nginxVersion</li> <li>Version of the provided.</li> <li>loadMsec</li> <li>Loaded process time in milliseconds.</li> <li>nowMsec</li> <li>Current time in milliseconds</li> <li>connections</li> <li>active<ul> <li>The current number of active client connections.</li> </ul> </li> <li>reading<ul> <li>The total number of reading client connections.</li> </ul> </li> <li>writing<ul> <li>The total number of writing client connections.</li> </ul> </li> <li>waiting<ul> <li>The total number of wating client connections.</li> </ul> </li> <li>accepted<ul> <li>The total number of accepted client connections.</li> </ul> </li> <li>handled<ul> <li>The total number of handled client connections.</li> </ul> </li> <li>requests<ul> <li>The total number of requested client connections.</li> </ul> </li> <li>sharedZones</li> <li>name<ul> <li>The name of shared memory specified in the configuration.(default: <code>stream_server_traffic_status</code>)</li> </ul> </li> <li>maxSize<ul> <li>The limit on the maximum size of the shared memory specified in the configuration.</li> </ul> </li> <li>usedSize<ul> <li>The current size of the shared memory.</li> </ul> </li> <li>usedNode<ul> <li>The current number of node using in shared memory. It can get an approximate size for one node with the following formula: (usedSize / usedNode)</li> </ul> </li> <li>streamServerZones</li> <li>connectCounter<ul> <li>The total number of client requests received from clients.</li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from clients.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent to clients.</li> </ul> </li> <li>responses<ul> <li>1xx, 2xx, 3xx, 4xx, 5xx</li> <li>The number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.</li> </ul> </li> <li>sessionMsecCounter<ul> <li>The number of accumulated request processing time in milliseconds.</li> </ul> </li> <li>sessionMsec<ul> <li>The average of request processing times in milliseconds.</li> </ul> </li> <li>sessionMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The request processing times in milliseconds.</li> </ul> </li> <li>sessionBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>server_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the request processing time.</li> </ul> </li> <li>streamFilterZones</li> <li>It provides the same fields with <code>streamServerZones</code> except that it included group names.</li> <li>streamUpstreamZones</li> <li>server<ul> <li>An address of the server.</li> </ul> </li> <li>connectCounter<ul> <li>The total number of client connections forwarded to this server.</li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from this server.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent to this server.</li> </ul> </li> <li>responses<ul> <li>1xx, 2xx, 3xx, 4xx, 5xx</li> <li>The number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.</li> </ul> </li> <li>sessionMsecCounter<ul> <li>The number of accumulated request processing times in milliseconds including upstream.</li> </ul> </li> <li>sessionMsec<ul> <li>The average of request processing times in millseconds including upstream.</li> </ul> </li> <li>sessionMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The request processing times in milliseconds including upstream.</li> </ul> </li> <li>sessionBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>server_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the request processing time.</li> </ul> </li> <li>uSessionMsecCounter<ul> <li>The number of accumulated the session duration time in milliseconds to the upstream server.</li> </ul> </li> <li>uSessionMsec<ul> <li>The average of the session duration times in milliseconds to the upstream server.</li> </ul> </li> <li>uSessionMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The session duration times in milliseconds to the upstream server.</li> </ul> </li> <li>uSessionBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>server_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the session duration time to the upstream server.</li> </ul> </li> <li>uConnectMsecCounter<ul> <li>The number of accumulated the time to connect to the upstream server.</li> </ul> </li> <li>uConnectMsec<ul> <li>The average of the times in milliseconds to connect to the upstream server (1.11.4).</li> </ul> </li> <li>uConnectMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The times in milliseconds to connect to the upstream server.</li> </ul> </li> <li>uConnectBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>server_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the time to connect to the upstream server.</li> </ul> </li> <li>uFirstByteMsecCounter<ul> <li>The number of accumulated the times in milliseconds to receive the first byte of data.</li> </ul> </li> <li>uFirstByteMsec<ul> <li>The average of the times in milliseconds to receive the first byte of data (1.11.4).</li> </ul> </li> <li>uFirstByteMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The times in milliseconds to receive the first byte of data (1.11.4).</li> </ul> </li> <li>uFirstByteBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>server_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the time to receive the first byte of data.</li> </ul> </li> <li>weight<ul> <li>Current <code>weight</code> setting of the server.</li> </ul> </li> <li>maxFails<ul> <li>Current <code>max_fails</code> setting of the server.</li> </ul> </li> <li>failTimeout<ul> <li>Current <code>fail_timeout</code> setting of the server.</li> </ul> </li> <li>backup<ul> <li>Current <code>backup</code> setting of the server.</li> </ul> </li> <li>down<ul> <li>Current <code>down</code> setting of the server.</li> </ul> </li> </ul>"},{"location":"modules/sts/#json-used-by-control","title":"Json used by control","text":"<p>/<code>{status_uri}</code>/control?cmd=reset&amp;...</p> <p>/<code>{status_uri}</code>/control?cmd=delete&amp;...</p> <ul> <li>processingReturn</li> <li>The result of true or false.</li> <li>processingCommandString</li> <li>The requested command string.</li> <li>processingGroupString</li> <li>The requested group string.</li> <li>processingZoneString</li> <li>The requested zone string.</li> <li>processingCounts</li> <li>The actual processing number.</li> </ul>"},{"location":"modules/sts/#variables","title":"Variables","text":"<p>The following embedded variables are provided in <code>stream</code> block:</p> <ul> <li>$sts_connect_counter</li> <li>The total number of client requests received from clients.</li> <li>$sts_in_bytes</li> <li>The total number of bytes received from clients.</li> <li>$sts_out_bytes</li> <li>The total number of bytes sent to clients.</li> <li>$sts_1xx_counter</li> <li>The number of responses with status codes 1xx.</li> <li>$sts_2xx_counter</li> <li>The number of responses with status codes 2xx.</li> <li>$sts_3xx_counter</li> <li>The number of responses with status codes 3xx.</li> <li>$sts_4xx_counter</li> <li>The number of responses with status codes 4xx.</li> <li>$sts_5xx_counter</li> <li>The number of responses with status codes 5xx.</li> <li>$sts_session_time</li> <li>The average of request processing times.</li> </ul>"},{"location":"modules/sts/#limit","title":"Limit","text":"<p>It is able to limit total traffic per each server by using the directive <code>server_traffic_status_limit_traffic</code>. It also is able to limit all traffic by using the directive <code>server_traffic_status_limit_traffic_by_set_key</code>. When the limit is exceeded, the server will return the 503 (Service Temporarily Unavailable) error in reply to a request.  The return code can be changeable.</p>"},{"location":"modules/sts/#to-limit-traffic-for-server","title":"To limit traffic for server","text":"<pre><code>stream {\n\n    server_traffic_status_zone;\n\n    ...\n\n    server {\n\n        listen 1981;\n\n        server_traffic_status_limit_traffic in:64G;\n        server_traffic_status_limit_traffic out:1024G;\n\n        ...\n    }\n}\n</code></pre> <ul> <li>Limit in/out total traffic on the <code>1981/tcp</code> to 64G and 1024G respectively.</li> </ul>"},{"location":"modules/sts/#to-limit-traffic-for-filter","title":"To limit traffic for filter","text":"<pre><code>stream {\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    server_traffic_status_zone;\n\n    ...\n\n    server {\n\n        listen 1981;\n\n        server_traffic_status_filter_by_set_key $geoip_country_code country::$server_addr;\n        server_traffic_status_limit_traffic_by_set_key FG@country::$server_addr@US out:1024G;\n        server_traffic_status_limit_traffic_by_set_key FG@country::$server_addr@CN out:2048G;\n\n        ...\n\n    }\n}\n</code></pre> <ul> <li>Limit total traffic of going into US and CN on the <code>example.org</code> to 1024G and 2048G respectively.</li> </ul>"},{"location":"modules/sts/#to-limit-traffic-for-upstream","title":"To limit traffic for upstream","text":"<pre><code>stream {\n\n    server_traffic_status_zone;\n\n    ...\n\n    upstream backend {\n        server 10.10.10.17:80;\n        server 10.10.10.18:80;\n    }\n\n    server {\n\n        listen 1981;\n\n        server_traffic_status_limit_traffic_by_set_key UG@backend@10.10.10.17:80 in:512G;\n        server_traffic_status_limit_traffic_by_set_key UG@backend@10.10.10.18:80 in:1024G;\n        proxy_pass backend;\n\n        ...\n\n    }\n}\n</code></pre> <ul> <li>Limit total traffic of going into upstream backend on the <code>1981/tcp</code> to 512G and 1024G per each peer.</li> </ul> <p><code>Caveats:</code> Traffic is the cumulative transfer or counter, not a bandwidth.</p>"},{"location":"modules/sts/#use-cases","title":"Use cases","text":"<p>It is able to calculate the user defined individual stats by using the directive <code>server_traffic_status_filter_by_set_key</code>.</p>"},{"location":"modules/sts/#to-calculate-traffic-for-individual-country-using-geoip","title":"To calculate traffic for individual country using GeoIP","text":"<pre><code>stream {\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    server_traffic_status_zone;\n    server_traffic_status_filter_by_set_key $geoip_country_code country::*;\n\n    ...\n\n    server {\n\n        ...\n\n        server_traffic_status_filter_by_set_key $geoip_country_code country::$server_addr:$server_port;\n\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual country of total server groups.</li> <li>Calculate traffic for individual country of each server groups.</li> </ul> <p>Basically, country flags image is built-in in HTML. The country flags image is enabled if the <code>country</code> string is included in group name which is second argument of <code>server_traffic_status_filter_by_set_key</code> directive.</p>"},{"location":"modules/sts/#customizing","title":"Customizing","text":""},{"location":"modules/sts/#to-customize-after-the-module-installed","title":"To customize after the module installed","text":"<ol> <li> <p>You need to change the <code>{{uri}}</code> string to your status uri in status.template.html as follows:  <pre><code>shell&gt; vi share/status.template.html\n</code></pre> <pre><code>var vtsStatusURI = \"yourStatusUri/format/json\", vtsUpdateInterval = 1000;\n</code></pre></p> </li> <li> <p>And then, customizing and copy status.template.html to server root directory as follows:  <pre><code>shell&gt; cp share/status.template.html /usr/share/nginx/html/status.html\n</code></pre></p> </li> <li> <p>Configure <code>nginx.conf</code> <pre><code>   server {\n       server_name example.org;\n       root /usr/share/nginx/html;\n\n       # Redirect requests for / to /status.html\n       location = / {\n           return 301 /status.html;\n       }\n\n       location = /status.html {}\n\n       # Everything beginning /status (except for /status.html) is\n       # processed by the status handler\n       location /status {\n           stream_server_traffic_status_display;\n           stream_server_traffic_status_display_format json;\n       }\n   }\n</code></pre></p> </li> <li> <p>Access to your html.  <pre><code>http://example.org/status.html\n</code></pre></p> </li> </ol>"},{"location":"modules/sts/#to-customize-before-the-module-installed","title":"To customize before the module installed","text":"<ol> <li> <p>Modify <code>share/status.template.html</code> (Do not change <code>{{uri}}</code> string)</p> </li> <li> <p>Recreate the <code>ngx_http_stream_server_traffic_status_module_html.h</code> as follows:  <pre><code>shell&gt; cd util\nshell&gt; ./tplToDefine.sh ../share/status.template.html &gt; ../src/ngx_http_stream_server_traffic_status_module_html.h\n</code></pre></p> </li> <li> <p>Add the module to the build configuration by adding   <pre><code>--add-module=/path/to/nginx-module-sts\n--add-module=/path/to/nginx-module-stream-sts\n</code></pre></p> </li> <li> <p>Build the nginx binary.</p> </li> <li> <p>Install the nginx binary.</p> </li> </ol>"},{"location":"modules/sts/#directives","title":"Directives","text":""},{"location":"modules/sts/#stream_server_traffic_status","title":"stream_server_traffic_status","text":"- - Syntax stream_server_traffic_status \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables the module working. If you set <code>stream_server_traffic_status_zone</code> directive, is automatically enabled.</p>"},{"location":"modules/sts/#stream_server_traffic_status_zone","title":"stream_server_traffic_status_zone","text":"- - Syntax stream_server_traffic_status_zone [shared:name] Default shared:stream_server_traffic_status Context http <p><code>Description:</code> Sets parameters for a shared memory zone specified by <code>server_traffic_status_zone</code> directive in stream block. <code>Caveats:</code> The <code>name</code> must be same as specified by <code>server_traffic_status_zone</code>.</p>"},{"location":"modules/sts/#stream_server_traffic_status_display","title":"stream_server_traffic_status_display","text":"- - Syntax stream_server_traffic_status_display Default - Context http, server, location <p><code>Description:</code> Enables or disables the module display handler.</p>"},{"location":"modules/sts/#stream_server_traffic_status_display_format","title":"stream_server_traffic_status_display_format","text":"- - Syntax stream_server_traffic_status_display_format \\&lt;json|html|jsonp|prometheus&gt; Default json Context http, server, location <p><code>Description:</code> Sets the display handler's output format. If you set <code>json</code>, will respond with a JSON document. If you set <code>html</code>, will respond with the built-in live dashboard in HTML. If you set <code>jsonp</code>, will respond with a JSONP callback function(default: ngx_http_stream_server_traffic_status_jsonp_callback). If you set <code>prometheus</code>, will respond with a prometheus document.</p>"},{"location":"modules/sts/#stream_server_traffic_status_display_jsonp","title":"stream_server_traffic_status_display_jsonp","text":"- - Syntax stream_server_traffic_status_display_jsonp callback Default ngx_http_stream_server_traffic_status_jsonp_callback Context http, server, location <p><code>Description:</code> Sets the callback name for the JSONP.</p>"},{"location":"modules/sts/#stream_server_traffic_status_average_method","title":"stream_server_traffic_status_average_method","text":"- - Syntax stream_server_traffic_status_average_method \\&lt;AMM|WMA&gt; [period] Default AMM 60s Context http, server, location <p><code>Description:</code> Sets the method which is a formula that calculate the average of response processing times. The period is an effective time of the values used for the average calculation.(Default: 60s) If period set to 0, effective time is ignored. In this case, the last average value is displayed even if there is no requests and after the elapse of time. The corresponding values are <code>sessionMsec</code>, <code>uSessionMsec</code>, <code>uConnectMsec</code>, <code>uFirstByteMsec</code> in JSON.</p> <ul> <li>AMM</li> <li>The AMM is the arithmetic mean.</li> <li>WMA</li> <li>THE WMA is the weighted moving average.</li> </ul>"},{"location":"modules/sts/#server_traffic_status","title":"server_traffic_status","text":"- - Syntax server_traffic_status \\&lt;on|off&gt; Default off Context stream, server <p><code>Description:</code> Enables or disables the module working. If you set <code>server_traffic_status_zone</code> directive, is automatically enabled.</p>"},{"location":"modules/sts/#server_traffic_status_zone","title":"server_traffic_status_zone","text":"- - Syntax server_traffic_status_zone [shared:name:size] Default shared:stream_server_traffic_status:1m Context stream <p><code>Description:</code> Sets parameters for a shared memory zone that will keep states for various keys. The cache is shared between all worker processes.</p>"},{"location":"modules/sts/#server_traffic_status_filter","title":"server_traffic_status_filter","text":"- - Syntax server_traffic_status_filter \\&lt;on|off&gt; Default on Context stream, server <p><code>Description:</code> Enables or disables the filter features.</p>"},{"location":"modules/sts/#server_traffic_status_filter_by_set_key","title":"server_traffic_status_filter_by_set_key","text":"- - Syntax server_traffic_status_filter_by_set_key key [name] Default - Context stream, server <p><code>Description:</code> Enables the keys by user defined variable. The key is a key string to calculate traffic. The name is a group string to calculate traffic. The key and name can contain variables such as $host, $server_addr, $server_port. The name's group belongs to <code>streamFilterZones</code> if specified. The key's group belongs to <code>streamServerZones</code> if not specified second argument name. The example with geoip module is as follows:</p> <pre><code>stream {\n\n      ...\n\n      server {\n          listen 1981;\n          server_traffic_status_filter_by_set_key $geoip_country_code country::$server_addr:$server_port;\n\n          ...\n\n      }\n}\n</code></pre> <pre><code>  ...\n  \"streamServerZones\": {\n  ...\n  },\n  \"streamFilterZones\": {\n      \"country::example.org\": {\n          \"KR\": {\n              \"port\":...,\n              \"protocol\":...,\n              \"connectCounter\":...,\n              \"inBytes\":...,\n              \"outBytes\":...,\n              \"responses\":{\n                  \"1xx\":...,\n                  \"2xx\":...,\n                  \"3xx\":...,\n                  \"4xx\":...,\n                  \"5xx\":...,\n              },\n              \"sessionMsec\":...\n              \"sessionMsecs\":{\n                  \"times\":[...],\n                  \"msecs\":[...]\n              },\n            },\n          },\n          \"US\": {\n          ...\n          },\n          ...\n      },\n      ...\n  },\n  ...\n</code></pre>"},{"location":"modules/sts/#server_traffic_status_filter_check_duplicate","title":"server_traffic_status_filter_check_duplicate","text":"- - Syntax server_traffic_status_filter_check_duplicate \\&lt;on|off&gt; Default on Context stream, server <p><code>Description:</code> Enables or disables the deduplication of server_traffic_status_filter_by_set_key. It is processed only one of duplicate values(<code>key</code> + <code>name</code>) in each directives(stream, server) if this option is enabled.</p>"},{"location":"modules/sts/#server_traffic_status_limit","title":"server_traffic_status_limit","text":"- - Syntax server_traffic_status_limit \\&lt;on|off&gt; Default on Context stream, server <p><code>Description:</code> Enables or disables the limit features.</p>"},{"location":"modules/sts/#server_traffic_status_limit_traffic","title":"server_traffic_status_limit_traffic","text":"- - Syntax server_traffic_status_limit_traffic member:size [code] Default - Context stream, server <p><code>Description:</code> Enables the traffic limit for specified member. The member is a member string to limit traffic. The size is a size(k/m/g) to limit traffic. The code is a code to return in response to rejected requests.(Default: 503)</p> <p>The available <code>member</code> strings are as follows: * connect   * The total number of client connects received from clients. * in   * The total number of bytes received from clients. * out   * The total number of bytes sent to clients. * 1xx   * The number of responses with status codes 1xx. * 2xx   * The number of responses with status codes 2xx. * 3xx   * The number of responses with status codes 3xx. * 4xx   * The number of responses with status codes 4xx. * 5xx   * The number of responses with status codes 5xx.</p>"},{"location":"modules/sts/#server_traffic_status_limit_traffic_by_set_key","title":"server_traffic_status_limit_traffic_by_set_key","text":"- - Syntax server_traffic_status_limit_traffic_by_set_key key member:size [code] Default - Context stream, server <p><code>Description:</code> Enables the traffic limit for specified key and member. The key is a key string to limit traffic. The member is a member string to limit traffic. The size is a size(k/m/g) to limit traffic. The code is a code to return in response to rejected requests.(Default: 503)</p> <p>The <code>key</code> syntax is as follows: * <code>group</code>@[<code>subgroup</code>@]<code>name</code></p> <p>The available <code>group</code> strings are as follows: * NO   * The group of server. * UA   * The group of upstream alone. * UG   * The group of upstream group.(use <code>subgroup</code>) * FG   * The group of filter.(use <code>subgroup</code>)</p> <p>The available <code>member</code> strings are as follows: * connect   * The total number of client requests received from clients. * in   * The total number of bytes received from clients. * out   * The total number of bytes sent to clients. * 1xx   * The number of responses with status codes 1xx. * 2xx   * The number of responses with status codes 2xx. * 3xx   * The number of responses with status codes 3xx. * 4xx   * The number of responses with status codes 4xx. * 5xx   * The number of responses with status codes 5xx.</p> <p>The member is the same as <code>server_traffic_status_limit_traffic</code> directive.</p>"},{"location":"modules/sts/#server_traffic_status_limit_check_duplicate","title":"server_traffic_status_limit_check_duplicate","text":"- - Syntax server_traffic_status_limit_check_duplicate \\&lt;on|off&gt; Default on Context stream, server <p><code>Description:</code> Enables or disables the deduplication of server_traffic_status_limit_by_set_key. It is processed only one of duplicate values(<code>member</code> | <code>key</code> + <code>member</code>) in each directives(stream, server) if this option is enabled.</p>"},{"location":"modules/sts/#server_traffic_status_average_method","title":"server_traffic_status_average_method","text":"- - Syntax server_traffic_status_average_method \\&lt;AMM|WMA&gt; [period] Default AMM 60s Context stream, server <p><code>Description:</code> Sets the method which is a formula that calculate the average of response processing times. The period is an effective time of the values used for the average calculation.(Default: 60s) If period set to 0, effective time is ignored. In this case, the last average value is displayed even if there is no requests and after the elapse of time. The corresponding value is only $sts_session_time variable.</p> <ul> <li>AMM</li> <li>The AMM is the arithmetic mean.</li> <li>WMA</li> <li>THE WMA is the weighted moving average.</li> </ul> <p><code>Caveats</code>: The $sts_session_time variable is the value calculated at the time of the last request. It is not calculated when using variables.</p>"},{"location":"modules/sts/#server_traffic_status_histogram_buckets","title":"server_traffic_status_histogram_buckets","text":"- - Syntax server_traffic_status_histogram_buckets second ... Default - Context stream <p><code>Description:</code> Sets the observe buckets to be used in the histograms. By default, if you do not set this directive, it will not work. The second can be expressed in decimal places with a minimum value of 0.001(1ms). The maximum size of the buckets is 32. If this value is insufficient for you, change the <code>NGX_STREAM_SERVER_TRAFFIC_STATUS_DEFAULT_BUCKET_LEN</code> in the <code>nginx-mdule-stream-sts/src/ngx_stream_server_traffic_status_node.h</code> and the <code>NGX_HTTP_STREAM_SERVER_TRAFFIC_STATUS_DEFAULT_BUCKET_LEN</code> in the <code>nginx-module-sts/src/ngx_http_stream_server_traffic_status_node.h</code>.</p> <p>For examples: * server_traffic_status_histogram_buckets <code>0.005</code> <code>0.01</code> <code>0.05</code> <code>0.1</code> <code>0.5</code> <code>1</code> <code>5</code> <code>10</code>   * The observe buckets are [5ms 10ms 50ms 1s 5s 10s]. * server_traffic_status_histogram_buckets <code>0.005</code> <code>0.01</code> <code>0.05</code> <code>0.1</code>   * The observe buckets are [5ms 10ms 50ms 1s].</p> <p><code>Caveats:</code> By default, if you do not set this directive, the histogram statistics does not work.</p>"},{"location":"modules/sts/#see-also","title":"See Also","text":"<ul> <li>nginx-module-stream-sts</li> <li>nginx-module-vts</li> </ul>"},{"location":"modules/sts/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-sts.</p>"},{"location":"modules/substitutions/","title":"substitutions: String substitutions module for nginx","text":""},{"location":"modules/substitutions/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-substitutions\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-substitutions\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_subs_filter_module.so;\n</code></pre> <p>This document describes nginx-module-substitutions v0.6.6  released on Dec 30 2021.</p> <p>nginx_substitutions_filter     Note: this module is not distributed with the Nginx source.     Installation instructions can be found below.</p> <p>Description     nginx_substitutions_filter is a filter module which can do both regular     expression and fixed string substitutions on response bodies. This     module is quite different from the Nginx's native Substitution Module.     It scans the output chains buffer and matches string line by line, just     like Apache's mod_substitute     (http://httpd.apache.org/docs/trunk/mod/mod_substitute.html).</p> <p>Example     location / {</p> <pre><code>    subs_filter_types text/html text/css text/xml;\n    subs_filter st(\\d*).example.com $1.example.com ir;\n    subs_filter a.example.com s.example.com;\n    subs_filter http://$host https://$host;\n}\n</code></pre> <p>Directives     *   subs_filter_types</p> <pre><code>*   subs_filter\n</code></pre> <p>subs_filter_types     syntax: *subs_filter_types mime-type [mime-types] *</p> <pre><code>default: *subs_filter_types text/html*\n\ncontext: *http, server, location*\n\n*subs_filter_types* is used to specify which content types should be\nchecked for *subs_filter*, in addition to *text/html*. The default is\nonly *text/html*.\n\nThis module just works with plain text. If the response is compressed,\nit can't uncompress the response and will ignore this response. This\nmodule can be compatible with gzip filter module. But it will not work\nwith proxy compressed response. You can disable the compressed response\nlike this:\n\nproxy_set_header Accept-Encoding \"\";\n</code></pre> <p>subs_filter     syntax: *subs_filter source_str destination_str [gior] *</p> <pre><code>default: *none*\n\ncontext: *http, server, location*\n\n*subs_filter* allows replacing source string(regular expression or\nfixed) in the nginx response with destination string. The variables \nin matching text is only avaiable under fixed string mode, which means \nthe matching text could not contain variables if it is a regular \nexpression. Substitution text may contain variables. More than one \nsubstitution rules per location is supported. \nThe meaning of the third flags are:\n\n*   *g*(default): Replace all the match strings.\n\n*   *i*: Perform a case-insensitive match.\n\n*   *o*: Just replace the first one.\n\n*   *r*: The pattern is treated as a regular expression, default is\n    fixed string.\n</code></pre> <p>subs_filter_bypass     syntax: subs_filter_bypass $variable1 ...</p> <pre><code>default: *none*\n\ncontext: *http, server, location*\n\nYou can sepcify several variables with this directive. If at least one\nof the variable is not empty and is not equal to '0', this substitution\nfilter will be disabled.\n</code></pre> <p>Installation     To install, get the source with subversion:</p> <pre><code>git clone\ngit://github.com/yaoweibin/ngx_http_substitutions_filter_module.git\n\nand then compile nginx with the following option:\n\n./configure --add-module=/path/to/module\n</code></pre> <p>Known issue     *   Can't substitute the response header.</p> <p>CHANGES     Changes with nginx_substitutions_filter 0.6.4 2014-02-15</p> <pre><code>*   Now non-200 response will work\n\n*   added the subs_filter_bypass directive\n\nChanges with nginx_substitutions_filter 0.6.2 2012-08-26\n\n*   fixed a bug of buffer overlap\n\n*   fixed a bug with last zero buffer\n\nChanges with nginx_substitutions_filter 0.6.0 2012-06-30\n\n*   refactor this module\n\nChanges with nginx_substitutions_filter 0.5.2 2010-08-11\n\n*   do many optimizing for this module\n\n*   fix a bug of buffer overlap\n\n*   fix a segment fault bug when output chain return NGX_AGAIN.\n\n*   fix a bug about last buffer with no linefeed. This may cause segment\n    fault. Thanks for Josef Fr\u00f6hle\n\nChanges with nginx_substitutions_filter 0.5 2010-04-15\n\n*   refactor the source structure, create branches of dev\n\n*   fix a bug of small chunk of buffers causing lose content\n\n*   fix the bug of last_buf and the nginx's compatibility above 0.8.25\n\n*   fix a bug with unwanted capture config error in fix string\n    substitution\n\n*   add feature of regex captures\n\nChanges with nginx_substitutions_filter 0.4 2009-12-23\n\n*   fix many bugs\n\nChanges with nginx_substitutions_filter 0.3 2009-02-04\n\n*   Initial public release\n</code></pre> <p>Reporting a bug     Questions/patches may be directed to Weibin Yao, yaoweibin@gmail.com.</p> <p>Copyright &amp; License     This module is licensed under the BSD license.</p> <pre><code>Copyright (C) 2014 by Weibin Yao &lt;yaoweibin@gmail.com&gt;.\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n*\n      Redistributions of source code must retain the above copyright\n\n    notice, this list of conditions and the following disclaimer.\n\n*\n      Redistributions in binary form must reproduce the above copyright\n\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\nIS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\nTO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>"},{"location":"modules/substitutions/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-substitutions.</p>"},{"location":"modules/sxg/","title":"sxg: Signed HTTP Exchange(SXG) support for NGINX","text":""},{"location":"modules/sxg/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-sxg\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-sxg\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_sxg_filter_module.so;\n</code></pre> <p>This document describes nginx-module-sxg v4.5  released on Mar 11 2021.</p> <p>Signed HTTP Exchange (SXG) support for nginx. Nginx will convert responses from the upstream application into SXG when client requests include the <code>Accept: application/signed-exchange;v=b3</code> HTTP header with highest qvalue.</p>"},{"location":"modules/sxg/#configuration","title":"Configuration","text":"<p>Nginx-SXG module requires configuration on nginx.</p>"},{"location":"modules/sxg/#directives","title":"Directives","text":""},{"location":"modules/sxg/#sxg","title":"sxg","text":"<p>Activation flag of SXG module.</p> <ul> <li><code>on</code>: Enable this plugin.</li> <li><code>off</code>: Disable this plugin.</li> </ul> <p>Default value is <code>off</code>.</p>"},{"location":"modules/sxg/#sxg_certificate","title":"sxg_certificate","text":"<p>Full path for the certificate file. The certificate requires all of the conditions below to match.</p> <ul> <li>Has <code>CanSignHttpExchanges</code> extension.</li> <li>Uses ECDSA256 or ECDSA384.</li> </ul> <p>This directive is always required.</p>"},{"location":"modules/sxg/#sxg_certificate_key","title":"sxg_certificate_key","text":"<p>Full path for the private key for the certificate.</p> <p>This directive is always required.</p>"},{"location":"modules/sxg/#sxg_cert_url","title":"sxg_cert_url","text":"<p>URL for CBOR encoded certificate file. The protocol must be <code>https</code>.</p> <p>This directive is always required.</p>"},{"location":"modules/sxg/#sxg_validity_url","title":"sxg_validity_url","text":"<p>URL for the validity information file. It must be <code>https</code> and must be the same origin with the website.</p> <p>This directive is always required.</p>"},{"location":"modules/sxg/#sxg_max_payload","title":"sxg_max_payload","text":"<p>Maximum HTTP body size this module can generate SXG from. Default value is <code>67108864</code> (64 MiB).</p>"},{"location":"modules/sxg/#sxg_cert_path","title":"sxg_cert_path","text":"<p>An absolute path in which nginx will generate and serve the CBOR-encoded certificate file. But make sure that the OCSP responder for the certificate is accessible from your nginx server to get OCSP responses. This directive is optional.</p>"},{"location":"modules/sxg/#sxg_expiry_seconds","title":"sxg_expiry_seconds","text":"<p>The life-span of generated SXG file in seconds. It must not be bigger than 604800 (1 week). This directive is optional. The default value is <code>86400</code> (1 day).</p>"},{"location":"modules/sxg/#sxg_fallback_host","title":"sxg_fallback_host","text":"<p>The hostname of fallback url of generated SXG file. This directive is optional. The default value is Host field parameter of HTTP request header.</p>"},{"location":"modules/sxg/#config-example","title":"Config Example","text":"<pre><code>load_module \"modules/ngx_http_sxg_filter_module.so\";\n\nhttp {\n    upstream app {\n        server 127.0.0.1:3000;\n    }\n    include       mime.types;\n    default_type  application/octet-stream;\n    subrequest_output_buffer_size   4096k;\n\n    server {\n        listen    80;\n        server_name  example.com;\n\n        sxg on;\n        sxg_certificate     /path/to/certificate-ecdsa.pem;\n        sxg_certificate_key /path/to/private-key-ecdsa.key;\n        sxg_cert_url        https://cdn.test.com/example.com.cert.cbor;\n        sxg_validity_url    https://example.com/validity/resource.msg;\n        sxg_expiry_seconds 604800;\n        sxg_fallback_host  example.com;\n\n        location / {\n            proxy_pass http://app;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/sxg/#subresource-support","title":"Subresource support","text":"<p>nginx-sxg-module automatically includes signatures of subresources in its responses, allowing end users to prefetch it from distributor. When finding <code>link: rel=\"preload\"</code> entry in HTTP response header from upstream, this plugin will collect the specified resource to the upstream and append <code>rel=\"allowed-alt-sxg\";header-integrity=\"sha256-....\"</code> to the original HTTP response automatically. This functionality is essential to subresource preloading for faster cross-site navigation.</p>"},{"location":"modules/sxg/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-sxg.</p>"},{"location":"modules/sysguard/","title":"sysguard: NGINX sysguard module","text":""},{"location":"modules/sysguard/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-sysguard\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-sysguard\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_sysguard_module.so;\n</code></pre> <p>This document describes nginx-module-sysguard v0.0.1  released on Feb 29 2020.</p> <p></p> <p>Nginx sysguard module</p>"},{"location":"modules/sysguard/#synopsis","title":"Synopsis","text":"<pre><code>http {\n\n    ...\n\n    server {\n\n        ...\n\n        sysguard on;\n        sysguard_mode or;\n\n        sysguard_load load=10.5 action=/loadlimit;\n        sysguard_mem swapratio=20% action=/swaplimit;\n        sysguard_mem free=100M action=/freelimit;\n        sysguard_rt rt=0.01 period=5s method=AMM:10 action=/rtlimit;\n\n        location /loadlimit {\n            return 503;\n        }\n\n        location /swaplimit {\n            return 503;\n        }\n\n        location /freelimit {\n            return 503;\n        }\n\n        location /rtlimit {\n            return 503;\n        }\n    }\n\n    ...\n\n    server {\n\n        ...\n\n        location /api {\n            sysguard on;\n            sysguard_mode or;\n            sysguard_load load=20 action=/limit;\n            sysguard_mem swapratio=10% action=/limit;\n            sysguard_rt rt=2.01 period=5s method=WMA:10 action=/limit;\n\n            ... \n\n        }\n\n        location /images {\n            sysguard on;\n            sysguard_mode and;\n            sysguard_load load=20 action=/limit;\n            sysguard_mem swapratio=10% action=/limit;\n            sysguard_rt rt=2.01 period=5s method=WMA:10 action=/limit;\n\n            ...\n\n        }\n\n        location /limit {\n            return 503;\n        }\n    }\n\n}\n</code></pre>"},{"location":"modules/sysguard/#description","title":"Description","text":"<p>This module can be used to protect your server in case system load, memory use goes too high or requests are responded too slow. This is a porting version of the sysguard in tengine to the pure NGINX so as to support the same features.</p> <p><code>Caveats:</code> Note this module requires the sysinfo(2) system call, or getloadavg(3) function in glibc. It also requires the /proc file system to get memory information.</p>"},{"location":"modules/sysguard/#embedded-variables","title":"Embedded Variables","text":"<p>The following embedded variables are provided:</p> <ul> <li>$sysguard_load</li> <li>The load of system. If <code>$sysguard_load</code>'s value is 100, then load is 0.1(100/1000). (/msec)</li> <li>$sysguard_swapstat</li> <li>The ratio of using swap. (/per)</li> <li>$sysguard_free</li> <li>The real free space of memory. (/byte)</li> <li>$sysguard_rt</li> <li>The average of request processing times. If <code>$sysguard_rt</code>'s value is 100, then response time is 0.1sec(100/1000). (/msec)</li> <li>$sysguard_meminfo_totalram</li> <li>The total memory of meminfo. (/byte)</li> <li>$sysguard_meminfo_freeram</li> <li>The free memory of meminfo. (/byte)</li> <li>$sysguard_meminfo_bufferram</li> <li>The buffer memory of meminfo. (/byte)</li> <li>$sysguard_meminfo_cachedram</li> <li>The cached memory of meminfo. (/byte)</li> <li>$sysguard_meminfo_totalswap</li> <li>The total swap of meminfo. (/byte)</li> <li>$sysguard_meminfo_freeswap</li> <li>The free swap of meminfo. (/byte)</li> </ul>"},{"location":"modules/sysguard/#directives","title":"Directives","text":""},{"location":"modules/sysguard/#sysguard","title":"sysguard","text":"- - Syntax sysguard \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables the module working.</p>"},{"location":"modules/sysguard/#sysguard_load","title":"sysguard_load","text":"- - Syntax sysguard_load load=number [action=/url] Default - Context http, server, location <p><code>Description:</code> Specify the load threshold. When the system load exceeds this threshold, all subsequent requests will be redirected to the URL specified by the 'action' parameter. It will return 503 if there's no 'action' URL defined. This directive also support using ncpuratio to instead of the fixed threshold, 'ncpu' means the number of cpu's cores, you can use this directive like this: load=ncpu1.5</p>"},{"location":"modules/sysguard/#sysguard_mem","title":"sysguard_mem","text":"- - Syntax sysguard_mem swapratio=ratio% free=size [action=/url] Default - Context http, server, location <p><code>Description:</code> Specify the used swap memory or free memory threshold. When the swap memory use ratio exceeds this threshold or memory free less than the size, all subsequent requests will be redirected to the URL specified by the 'action' parameter. It will return 503 if there's no 'action' URL. Sysguard uses this strategy to calculate memory free: \"memfree = free + buffered + cached\"</p>"},{"location":"modules/sysguard/#sysguard_rt","title":"sysguard_rt","text":"- - Syntax sysguard_rt rt=second period=time [method=\\&lt;AMM|WMA&gt;:number] [action=/url] Default - Context http, server, location <p><code>Description:</code> Specify the response time threshold. Parameter rt is used to set a threshold of the average response time, in second. Parameter period is used to specifiy the period of the statistics cycle. If the average response time of the system exceeds the threshold specified by the user, the incoming request will be redirected to a specified url which is defined by parameter 'action'. If no 'action' is presented, the request will be responsed with 503 error directly. The <code>method</code> is a formula that calculate the average of response processing times. The <code>number</code> in method is the number of samples to calculate the average. The default method is set to be <code>method=AMM:period</code>.</p> <ul> <li>AMM</li> <li>The AMM is the arithmetic mean.</li> <li>WMA</li> <li>THE WMA is the weighted moving average.</li> </ul>"},{"location":"modules/sysguard/#sysguard_mode","title":"sysguard_mode","text":"- - Syntax sysguard_mode \\&lt;and|or&gt; Default or Context http, server, location <p><code>Description:</code> If there are more than one type of monitor, this directive is used to specified the relations among all the monitors which are: 'and' for all matching and 'or' for any matching.</p>"},{"location":"modules/sysguard/#sysguard_interval","title":"sysguard_interval","text":"- - Syntax sysguard_interval time Default 1s Context http, server, location <p><code>Description:</code> Specify the time interval to update your system information. The default value is one second, which means sysguard updates the server status once a second.</p>"},{"location":"modules/sysguard/#sysguard_log_level","title":"sysguard_log_level","text":"- - Syntax sysguard_log_level \\&lt;info|notice|warn|error&gt; Default error Context http, server, location <p><code>Description:</code> Specify the log level of sysguard.</p>"},{"location":"modules/sysguard/#see-also","title":"See Also","text":"<ul> <li>nginx-module-vts</li> <li>nginx-module-sts</li> </ul>"},{"location":"modules/sysguard/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-sysguard.</p>"},{"location":"modules/testcookie/","title":"testcookie: NGINX testcookie robot mitigation module","text":""},{"location":"modules/testcookie/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-testcookie\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-testcookie\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_testcookie_access_module.so;\n</code></pre> <p>This document describes nginx-module-testcookie v1.28  released on Jul 19 2022.</p> <p>testcookie-nginx-module is a simple robot mitigation module using cookie based challenge/response.</p> <p>Challenge cookies can be set using different methods:</p> <ul> <li>\"Set-Cookie\" + 302/307 HTTP Location redirect</li> <li>\"Set-Cookie\" + HTML meta refresh redirect</li> <li>Custom template, JavaScript can be used here.</li> </ul> <p>To prevent automatic parsing, challenge cookie value can be encrypted with AES-128 in CBC mode using custom/random key and iv, and then decrypted at client side with JavaScript.</p>"},{"location":"modules/testcookie/#directives","title":"Directives","text":""},{"location":"modules/testcookie/#testcookie","title":"testcookie","text":"<p>syntax: testcookie (on|off|var);</p> <p>default: off</p> <p>context: http, server, location, if</p> <p>on - Enable module</p> <p>off - Disable module</p> <p>var - Don't intercept requests, only set module variables.</p>"},{"location":"modules/testcookie/#testcookie_name","title":"testcookie_name","text":"<p>syntax: testcookie_name &lt;string&gt;</p> <p>default: TCK</p> <p>context: http, server, location</p> <p>Sets cookie name.</p>"},{"location":"modules/testcookie/#testcookie_domain","title":"testcookie_domain","text":"<p>syntax: testcookie_domain &lt;string&gt;</p> <p>default: none, set by browser</p> <p>context: http, server, location</p> <p>Sets cookie domain.</p>"},{"location":"modules/testcookie/#testcookie_expires","title":"testcookie_expires","text":"<p>syntax: testcookie_expires &lt;string&gt;</p> <p>default: 31 Dec 2037 23:55:55 GMT</p> <p>context: http, server, location</p> <p>Sets cookie expiration value.</p>"},{"location":"modules/testcookie/#testcookie_path","title":"testcookie_path","text":"<p>syntax: testcookie_path &lt;string&gt;</p> <p>default: /</p> <p>context: http, server, location</p> <p>Sets cookie path, useful if you plan to use different keys for locations.</p>"},{"location":"modules/testcookie/#testcookie_samesite","title":"testcookie_samesite","text":"<p>syntax: testcookie_samesite &lt;string&gt;</p> <p>default: None</p> <p>context: http, server, location</p> <p>Sets cookie attribute, allows you to declare if your cookie should be restricted to a first-party or same-site context. Default is None (Cookies will be sent in all contexts, i.e sending cross-origin is allowed.) Accepts values: Lax, Strict, None.</p>"},{"location":"modules/testcookie/#testcookie_secret","title":"testcookie_secret","text":"<p>syntax: testcookie_secret &lt;string&gt;</p> <p>default: required configuration directive</p> <p>context: http, server, location</p> <p>Secret string, used in challenge cookie computation, should be 32 bytes or more, better to be long but static to prevent cookie reset for legitimate users every server restart. If set to \"random\" - new secret will be generated every server restart, not recomended(all cookies with previous key will be invalid),</p>"},{"location":"modules/testcookie/#testcookie_session","title":"testcookie_session","text":"<p>syntax: testcookie_session &lt;variable&gt;</p> <p>default: required configuration directive</p> <p>context: http, server, location</p> <p>Sets the challenge generation function input, *   $remote_addr - clients IP address will be used as an user unique identifier *   $remote_addr$http_user_agent - clients IP + User-Agent</p>"},{"location":"modules/testcookie/#testcookie_arg","title":"testcookie_arg","text":"<p>syntax: testcookie_arg &lt;string&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Sets GET parameter name, used for cookie setting attempts computation,</p> <p>If not set - server will try to set cookie infinitely.</p>"},{"location":"modules/testcookie/#testcookie_max_attempts","title":"testcookie_max_attempts","text":"<p>syntax: testcookie_max_attempts &lt;integer&gt;</p> <p>default: 5</p> <p>context: http, server, location</p> <p>Sets maximum number of redirects before user will be sent to fallback URL, according to RFC1945 can't be more than 5.</p> <p>If set to 0 - server will try to set cookie infinitely(actually, browser will show the error page).</p>"},{"location":"modules/testcookie/#testcookie_p3p","title":"testcookie_p3p","text":"<p>syntax: testcookie_p3p &lt;string&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Sets P3P policy.</p>"},{"location":"modules/testcookie/#testcookie_fallback","title":"testcookie_fallback","text":"<p>syntax: testcookie_fallback &lt;script&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Sets the fallback URL, user will be redirected to after maximum number of attempts, specified by directive testcookie_max_attempts exceded. Nginx scripting variables can be used here. If not set - client will get 403 after max attempts reached.</p>"},{"location":"modules/testcookie/#testcookie_whitelist","title":"testcookie_whitelist","text":"<p>syntax: testcookie_whitelist &lt;network list&gt;</p> <p>default: none</p> <p>context: http, server</p> <p>Sets the networks for which the testing will not be used, add search engine networks here. Currently IPv4 CIDR only.</p>"},{"location":"modules/testcookie/#testcookie_pass","title":"testcookie_pass","text":"<p>syntax: testcookie_pass $variable;</p> <p>default: none</p> <p>context: http, server</p> <p>Sets the variable name to test if cookie check should be bypassed. If variable value set to 1 during the request - cookie check will not be performed. Can be used for more complex whitelisting.</p>"},{"location":"modules/testcookie/#testcookie_redirect_via_refresh","title":"testcookie_redirect_via_refresh","text":"<p>syntax: testcookie_redirect_via_refresh (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Set cookie and redirect using HTTP meta refresh, required if testcookie_refresh_template used.</p>"},{"location":"modules/testcookie/#testcookie_refresh_template","title":"testcookie_refresh_template","text":"<p>syntax: testcookie_refresh_template &lt;string&gt;</p> <p>default: none</p> <p>context: http, server, location</p> <p>Use custom html instead of simple HTTP meta refresh, you need to set cookie manually from the template Available all the nginx variables and</p> <pre><code>$testcookie_nexturl - URL the client should be redirected to, if max_attempts exceeded *testcookie_fallback* value will be here\n$testcookie_got - cookie value received from client, empty if no cookie or it does not match format\n$testcookie_set - correct cookie value we're expecting from client\n$testcookie_ok - user passed test (1 - passed, 0 - not passed) Note: changed from \"yes\"/\"no\" in v1.10\n</code></pre> <p>also, if testcookie_refresh_encrypt_cookie enabled there are three more variables:</p> <pre><code>$testcookie_enc_key - encryption key (32 hex digits)\n$testcookie_enc_iv - encryption iv (32 hex digits)\n$testcookie_enc_sec - encrypted cookie value (32 hex digits)\n</code></pre>"},{"location":"modules/testcookie/#testcookie_refresh_status","title":"testcookie_refresh_status","text":"<p>syntax: testcookie_refresh_status &lt;code&gt;</p> <p>default: 200</p> <p>context: http, server, location</p> <p>Use custom HTTP status code when serving html.</p>"},{"location":"modules/testcookie/#testcookie_deny_keepalive","title":"testcookie_deny_keepalive","text":"<p>syntax: testcookie_deny_keepalive (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Close connection just after setting the cookie, no reason to keep connections with bots.</p>"},{"location":"modules/testcookie/#testcookie_get_only","title":"testcookie_get_only","text":"<p>syntax: testcookie_get_only (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Process only GET requests, POST requests will be bypassed.</p>"},{"location":"modules/testcookie/#testcookie_https_location","title":"testcookie_https_location","text":"<p>syntax: testcookie_https_location (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Redirect client to https protocol after setting the cookie, also affects $testcookie_nexturl, useful with 3dparty SSL offload.</p>"},{"location":"modules/testcookie/#testcookie_refresh_encrypt_cookie","title":"testcookie_refresh_encrypt_cookie","text":"<p>syntax: testcookie_refresh_encrypt_cookie (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Encrypt cookie variable, used with testcookie_refresh_template to force client-side decryption with AES-128 CBC.</p>"},{"location":"modules/testcookie/#testcookie_refresh_encrypt_cookie_key","title":"testcookie_refresh_encrypt_cookie_key","text":"<p>syntax: testcookie_refresh_encrypt_cookie_key &lt;32 hex digits|random&gt;</p> <p>default: required directive if encryption enabled</p> <p>context: http, server, location</p> <p>Sets encryption key.</p> <p>Possible values:</p> <pre><code>random - new key generated every nginx restart\n32 hex digits - static key, useful if you plan to obfuscate it deep in client-side javascript.\n</code></pre>"},{"location":"modules/testcookie/#testcookie_refresh_encrypt_iv","title":"testcookie_refresh_encrypt_iv","text":"<p>syntax: testcookie_refresh_encrypt_iv &lt;32 hex digits|random|random2&gt;</p> <p>default: random</p> <p>context: http, server, location</p> <p>Sets encryption iv.</p> <p>Possible values:     random - new iv generated for every client request     random2 - new iv generated for every nginx restart     32 hex digits - static iv, useful if you plan to obfuscate it deep in client-side javascript</p>"},{"location":"modules/testcookie/#testcookie_internal","title":"testcookie_internal","text":"<p>syntax: testcookie_internal (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Enable testcookie check for internal redirects (disabled by default for optimization purposes!), useful for this type of configs:</p> <pre><code>rewrite ^/(.*)$ /index.php?$1 last;\n</code></pre>"},{"location":"modules/testcookie/#testcookie_httponly_flag","title":"testcookie_httponly_flag","text":"<p>syntax: testcookie_httponly_flag (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Enable HttpOnly flag for cookie.</p>"},{"location":"modules/testcookie/#testcookie_secure_flag","title":"testcookie_secure_flag","text":"<p>syntax: testcookie_secure_flag (on|off|$variable);</p> <p>default: on</p> <p>context: http, server, location</p> <p>Enable Secure flag for cookie. Any variable value except \"on\" interpreted as False.</p>"},{"location":"modules/testcookie/#testcookie_port_in_redirect","title":"testcookie_port_in_redirect","text":"<p>syntax: testcookie_port_in_redirect (on|off);</p> <p>default: off</p> <p>context: http, server, location</p> <p>Expose port in redirect.</p>"},{"location":"modules/testcookie/#example-configuration","title":"Example configuration","text":"<pre><code>http {\n    #default config, module disabled\n    testcookie off;\n\n    #setting cookie name\n    testcookie_name BPC;\n\n    #setting secret\n    testcookie_secret keepmesecret;\n\n    #setting session key\n    testcookie_session $remote_addr;\n\n    #setting argument name\n    testcookie_arg ckattempt;\n\n    #setting maximum number of cookie setting attempts\n    testcookie_max_attempts 3;\n\n    #setting p3p policy\n    testcookie_p3p 'CP=\"CUR ADM OUR NOR STA NID\", policyref=\"/w3c/p3p.xml\"';\n\n    #setting fallback url\n    testcookie_fallback http://google.com/cookies.html?backurl=http://$host$request_uri;\n\n    #configuring whitelist\n    testcookie_whitelist {\n        8.8.8.8/32;\n    }\n\n\n    #setting redirect via html code\n    testcookie_redirect_via_refresh on;\n\n    #enable encryption\n    testcookie_refresh_encrypt_cookie on;\n\n    #setting encryption key\n    testcookie_refresh_encrypt_cookie_key deadbeefdeadbeefdeadbeefdeadbeef;\n\n    #setting encryption iv\n    testcookie_refresh_encrypt_cookie_iv deadbeefdeadbeefdeadbeefdeadbeef;\n\n    #setting response template\n    testcookie_refresh_template '&lt;html&gt;&lt;body&gt;setting cookie...&lt;script type=\\\"text/javascript\\\" src=\\\"/aes.min.js\\\" &gt;&lt;/script&gt;&lt;script&gt;function toNumbers(d){var e=[];d.replace(/(..)/g,function(d){e.push(parseInt(d,16))});return e}function toHex(){for(var d=[],d=1==arguments.length&amp;&amp;arguments[0].constructor==Array?arguments[0]:arguments,e=\"\",f=0;f&lt;d.length;f++)e+=(16&gt;d[f]?\"0\":\"\")+d[f].toString(16);return e.toLowerCase()}var a=toNumbers(\"$testcookie_enc_key\"),b=toNumbers(\"$testcookie_enc_iv\"),c=toNumbers(\"$testcookie_enc_set\");document.cookie=\"BPC=\"+toHex(slowAES.decrypt(c,2,a,b))+\"; expires=Thu, 31-Dec-37 23:55:55 GMT; path=/\";location.href=\"$testcookie_nexturl\";&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;';\n\n    server {\n        listen 80;\n        server_name test.com;\n\n\n        location = /aes.min.js {\n            gzip  on;\n            gzip_min_length 1000;\n            gzip_types      text/plain;\n            root /var/www/public_html;\n        }\n\n        location = /w3c/p3p.xml {\n            root /var/www/public_html;\n        }\n\n        location / {\n            #enable module for specific location\n            testcookie on;\n            proxy_set_header   Host             $host;\n            proxy_set_header   X-Real-IP        $remote_addr;\n            proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:80;\n        }\n    }\n}\n</code></pre> <p>See more cases in \"docs\" directory of the project.</p>"},{"location":"modules/testcookie/#test-suite","title":"Test suite","text":"<p>This module comes with a Perl-driven test suite. Thanks to the Test::Nginx module in the Perl world.</p>"},{"location":"modules/testcookie/#sources","title":"Sources","text":"<p>Available on github at kyprizel/testcookie-nginx-module.</p>"},{"location":"modules/testcookie/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-testcookie.</p>"},{"location":"modules/traffic-accounting/","title":"traffic-accounting: Monitor the incoming and outgoing traffic metrics in realtime for NGINX","text":""},{"location":"modules/traffic-accounting/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-traffic-accounting\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-traffic-accounting\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_accounting_module.so;\n</code></pre> <p>This document describes nginx-module-traffic-accounting v2.0.4  released on May 16 2022.</p> <p>Monitor the incoming and outgoing traffic metrics in realtime for <code>NGINX</code>.</p> <p>A realtime traffic and status code monitor solution for NGINX, which needs less memory and cpu than other realtime log analyzing solutions. Useful for traffic accounting based on NGINX config logic (by location / server / user-defined-variables).</p> <p> </p>"},{"location":"modules/traffic-accounting/#why","title":"Why?","text":"<p>Realtime log analysis solutions, which requires multiple machines for storage and analysis, are too heavy for application monitoring.</p> <p>An cost-effective solution is in need to monitor the traffic metrics/status of application requests. This solution should be accurate, sensitive, robust, light weight enough, and not affected by traffic peaks.</p>"},{"location":"modules/traffic-accounting/#how-it-works","title":"How it works?","text":"<p>This module keeps a list of metrics identified by <code>accounting_id</code> in its context.</p> <p>When a new request hits the server, the module will try to find its <code>accounting_id</code>, calculate statistics, and aggregate them into the corresponding metrics by <code>accounting_id</code>.</p> <p>For each time period (defined by\u00a0<code>interval</code>), a timer event is triggered, those metrics are rotated and exported to log files or sent to remote log servers.</p>"},{"location":"modules/traffic-accounting/#_1","title":"Monitor the incoming and outgoing traffic metrics in realtime for NGINX","text":""},{"location":"modules/traffic-accounting/#dashboard","title":"Dashboard","text":"<p>Dashboard - Visualize with Grafana </p>"},{"location":"modules/traffic-accounting/#_2","title":"Monitor the incoming and outgoing traffic metrics in realtime for NGINX","text":""},{"location":"modules/traffic-accounting/#configuration","title":"Configuration","text":"<p>Edit your nginx.conf.</p> <p>Example:</p> <pre><code>http {\n    # turn on accounting function\n    accounting  on;\n    accounting_log  logs/http-accounting.log;\n    ...\n    server {\n        server_name example.com;\n\n        accounting_id  $http_host;  # set accounting_id string by variable\n\n        location / {\n            accounting_id  accounting_id_str;  # set accounting_id string by location\n\n            ...\n        }\n\n        location /api {\n            accounting_id  API_PC;   # for pc\n\n            if ($http_user_agent ~* '(Android|webOS|iPhone|iPod|BlackBerry)') {\n                accounting_id  API_MOBILE;   # for mobile\n            }\n\n            ...\n        }\n    }\n\n}\n</code></pre>"},{"location":"modules/traffic-accounting/#directives","title":"Directives","text":""},{"location":"modules/traffic-accounting/#accounting","title":"accounting","text":"<p>syntax: accounting on | off</p> <p>default: accounting off</p> <p>context: http</p>"},{"location":"modules/traffic-accounting/#accounting_log","title":"accounting_log","text":"<p>syntax: accounting_log \\ [level]</p> <p>default: -</p> <p>context: http</p> <p>Configures logging.</p> <p>Support both local <code>file</code> path, or <code>stderr</code>, or <code>syslog:</code>. The second parameter is the log level. For more details of supported params, refer to this page from nginx.org.</p> <p>If not specified, accounting log will be written to <code>/dev/log</code>.</p>"},{"location":"modules/traffic-accounting/#accounting_id","title":"accounting_id","text":"<p>syntax: accounting_id \\ <p>default: accounting_id default</p> <p>context: http, server, location, if in location</p> <p>Sets the <code>accounting_id</code> string by user defined variable.</p> <p>This string is used to determine which <code>metrics</code> a request/session should be aggregated to.</p>"},{"location":"modules/traffic-accounting/#accounting_interval","title":"accounting_interval","text":"<p>syntax: accounting_interval \\ <p>default: accounting_interval 60</p> <p>context: http</p> <p>Specifies the reporting interval.  Defaults to 60 seconds.</p>"},{"location":"modules/traffic-accounting/#accounting_perturb","title":"accounting_perturb","text":"<p>syntax: accounting_perturb on | off</p> <p>default: accounting_perturb off</p> <p>context: http</p> <p>Randomly staggers the reporting interval by 20% from the usual time.</p>"},{"location":"modules/traffic-accounting/#usage","title":"Usage","text":"<p>This module can be configured to writes metrics to local file, remote log server or local syslog device.</p> <p>Open-source log-aggregation software such as logstash also support syslog input, which will help you establish a central log server. See samples/logstash/ for examples. [Recommended]</p> <p>To collect logs with local syslog, refer Lax/ngx_http_accounting_module-utils to for sample configuration / utils.</p>"},{"location":"modules/traffic-accounting/#docker-docker-compose","title":"docker / docker-compose","text":"<p>To demonstrate with docker-compose, run</p> <pre><code>docker-compose build\ndocker-compose up -d\n</code></pre> <p>Open Grafana (address: <code>http://localhost:3000</code>) in your browser.</p> <p>Create and configurate elasticsearch datasource with options: <pre><code>Type: elasticsearch\nURL: http://elasticsearch:9200\nVersion: 5.6+\nMin time interval: 1m\n</code></pre></p> <p>Then import accounting dashboard from  <code>samples/accounting-dashboard-grafana.json</code>.</p>"},{"location":"modules/traffic-accounting/#metrics-log-format","title":"Metrics log format","text":"<pre><code>## HTTP\n2018/05/14 14:18:18 [notice] 5#0: pid:5|from:1526278638|to:1526278659|accounting_id:HTTP_ECHO_HELLO|requests:4872|bytes_in:438480|bytes_out:730800|latency_ms:0|upstream_latency_ms:0|200:4872\n2018/05/14 14:18:18 [notice] 5#0: pid:5|from:1526278638|to:1526278659|accounting_id:INDEX|requests:4849|bytes_in:421863|bytes_out:1857167|latency_ms:0|upstream_latency_ms:0|301:4849\n\n## Stream\n2018/05/14 14:18:22 [notice] 5#0: pid:5|from:1526278642|to:1526278659|accounting_id:TCP_PROXY_ECHO|sessions:9723|bytes_in:860343|bytes_out:2587967|latency_ms:4133|upstream_latency_ms:3810|200:9723\n</code></pre> <p>Each line of the log output contains <code>metrics</code> for a particular <code>accounting_id</code>, which contains a list of key-values.</p> key name meanings of values <code>pid</code> pid of nginx worker process <code>from</code> / <code>to</code> metric was collected from the <code>period</code> between these timestamps <code>accounting_id</code> identify for the accounting unit, set by <code>accounting_id</code> directive <code>requests</code> count of total requests processed in current period (HTTP module only) <code>sessions</code> count of total sessions processed in current period (Stream module only) <code>bytes_in</code> total bytes received by the server <code>bytes_out</code> total bytes send out by the server <code>latency_ms</code> sum of all requests/sessions' <code>$session_time</code>, in <code>millisecond</code> <code>upstream_latency_ms</code> sum of <code>$upstream_response_time</code>, in <code>millisecond</code> <code>200</code> / <code>302</code> / <code>400</code> / <code>404</code> / <code>500</code> ... count of requests/sessions with status code <code>200</code>/<code>302</code>/<code>400</code>/<code>404</code>/<code>500</code>, etc. Notice the differences between http codes and stream codes"},{"location":"modules/traffic-accounting/#_3","title":"Monitor the incoming and outgoing traffic metrics in realtime for NGINX","text":""},{"location":"modules/traffic-accounting/#configuration-example","title":"Configuration example","text":"<pre><code>http {\n  accounting        on;\n  accounting_log    logs/http-accounting.log;\n  accounting_id     $hostname;\n\n  ...\n}\n\nstream {\n  accounting        on;\n  accounting_log    logs/stream-accounting.log;\n  accounting_id     $hostname;\n\n  ...\n}\n</code></pre>"},{"location":"modules/traffic-accounting/#visualization","title":"Visualization","text":"<p>Visualization with <code>Kibana</code> or <code>Grafana</code> is easy. See samples/ for examples.</p>"},{"location":"modules/traffic-accounting/#_4","title":"Monitor the incoming and outgoing traffic metrics in realtime for NGINX","text":""},{"location":"modules/traffic-accounting/#branches","title":"Branches","text":"<ul> <li>master : main development branch.</li> <li>tag v0.1 or v2-freeze-20110526 : legacy release. works with nginx version(0.7.xx, 0.8.xx), nginx 0.9 is not tested. didn't work with nginx above 1.0.x.</li> </ul>"},{"location":"modules/traffic-accounting/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-traffic-accounting.</p>"},{"location":"modules/ts/","title":"ts: NGINX MPEG-TS Live Module","text":""},{"location":"modules/ts/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-ts\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-ts\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_ts_module.so;\n</code></pre> <p>This document describes nginx-module-ts v0.1.1  released on Jul 14 2017.</p>"},{"location":"modules/ts/#nginx-mpeg-ts-live-module","title":"NGINX MPEG-TS Live Module","text":""},{"location":"modules/ts/#features","title":"Features","text":"<ul> <li>receives MPEG-TS over HTTP</li> <li>produces and manages live HLS</li> <li>produces and manages live MPEGDDASH</li> </ul>"},{"location":"modules/ts/#compatibility","title":"Compatibility","text":"<ul> <li>nginx version &gt;= 1.11.5</li> </ul>"},{"location":"modules/ts/#build","title":"Build","text":"<p>Building nginx with the module:</p> <p>``` {.sourceCode .bash}</p>"},{"location":"modules/ts/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-ts.</p>"},{"location":"modules/unbrotli/","title":"unbrotli: Decompresses Brotli-encoded responses for clients that do not support it","text":""},{"location":"modules/unbrotli/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-unbrotli\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-unbrotli\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_unbrotli_filter_module.so;\n</code></pre> <p>This document describes nginx-module-unbrotli v0.0.2  released on Dec 18 2024.</p> <p>The ngx_unbrotli is a filter module that decompresses responses encoded with Brotli (<code>Content-Encoding: br</code>) for clients that do not support Brotli. By storing responses in Brotli format, you can save on storage and I/O costs, and this module ensures that clients unable to handle Brotli still receive the appropriate decompressed content.</p>"},{"location":"modules/unbrotli/#example-configuration","title":"Example Configuration","text":"<pre><code>location /storage/ {\n    unbrotli on;\n    unbrotli_buffers 32 4k;\n    ...\n}\n</code></pre>"},{"location":"modules/unbrotli/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/unbrotli/#unbrotli","title":"<code>unbrotli</code>","text":"<ul> <li>syntax: <code>unbrotli  on | off;</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables or disables decompression of Brotli-compressed (Content-Encoding: br) responses for clients that do not support  Brotli. When <code>unbrotli</code> is enabled, the server checks client capabilities (similar to how gzip handling is done)  to determine if decompression is needed.</p>"},{"location":"modules/unbrotli/#unbrotli_force","title":"<code>unbrotli_force</code>","text":"<ul> <li>syntax: <code>unbrotli_force on | off;</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Forces decompression of Brotli-compressed responses, even if the client indicates support for Brotli.  When <code>unbrotli_force</code> is <code>on</code>, all Brotli-encoded responses are decompressed before being sent to the client,  regardless of the client\u2019s Accept-Encoding header.</p>"},{"location":"modules/unbrotli/#unbrotli_buffers","title":"<code>unbrotli_buffers</code>","text":"<ul> <li>syntax: <code>unbrotli_buffers number size;</code></li> <li>default: depends on system page size, commonly: <code>unbrotli_buffers 32 4k;</code> or <code>unbrotli_buffers 16 8k;</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the number and size of buffers used for decompressing Brotli responses. Typically, the size equals one memory page  (4 KB or 8 KB, depending on the platform). Increasing the number or size of these buffers can improve performance for  large responses at the cost of higher memory usage.</p>"},{"location":"modules/unbrotli/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-unbrotli.</p>"},{"location":"modules/untar/","title":"untar: NGINX HTTP Untar Module","text":""},{"location":"modules/untar/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-untar\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-untar\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_untar_module.so;\n</code></pre> <p>This document describes nginx-module-untar v1.1  released on Mar 21 2022.</p> <p>This nginx module can serve static file content directly from tar archives. Inspired by nginx-unzip-module.</p>"},{"location":"modules/untar/#features","title":"Features","text":"<ul> <li>Zero-copy: outputs content directly from archive file (no temporary files)</li> <li>Caching parsed archive file entries: reduce archive scan-search time</li> <li>Supported tar item types: normal file, long file name data</li> </ul>"},{"location":"modules/untar/#configuration-example","title":"Configuration example","text":"<pre><code>  location ~ ^/(.+?\\.tar)/(.*)$ {\n      untar_archive \"$document_root/$1\";\n      untar_file \"$2\";\n      untar;\n  }\n</code></pre>"},{"location":"modules/untar/#module-directives","title":"Module directives","text":"<p>untar_archive <code>string</code></p> <p>context: <code>http, server, location</code></p> <p>Specifies tar archive name.</p> <p>untar_file <code>string</code></p> <p>context: <code>http, server, location</code></p> <p>Specifies file to be extracted from untar_archive.</p> <p>untar</p> <p>context: <code>location</code></p> <p>Invokes untar of untar_file from untar_archive</p>"},{"location":"modules/untar/#known-limitations","title":"Known limitations","text":"<ul> <li>only GET,HEAD verbs supported</li> <li>no archive entries listing</li> <li>base tar format support (only normal files: no symlink, sparse e.t.c)</li> </ul>"},{"location":"modules/untar/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-untar.</p>"},{"location":"modules/upload/","title":"upload: NGINX module for handling file uploads","text":""},{"location":"modules/upload/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-upload\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-upload\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_upload_module.so;\n</code></pre> <p>This document describes nginx-module-upload v2.3.0  released on Aug 02 2018.</p> <p>A module for nginx for handling file uploads using multipart/form-data encoding (RFC 1867) and resumable uploads according to this protocol.</p> <ul> <li>Description</li> <li>Directives<ul> <li>upload_pass</li> <li>upload_resumable</li> <li>upload_store</li> <li>upload_state_store</li> <li>upload_store_access</li> <li>upload_set_form_field</li> <li>upload_aggregate_form_field</li> <li>upload_pass_form_field</li> <li>upload_cleanup</li> <li>upload_buffer_size</li> <li>upload_max_part_header_len</li> <li>upload_max_file_size</li> <li>upload_limit_rate</li> <li>upload_max_output_body_len</li> <li>upload_tame_arrays</li> <li>upload_pass_args</li> </ul> </li> <li>Example configuration</li> <li>License</li> </ul>"},{"location":"modules/upload/#description","title":"Description","text":"<p>The module parses request body storing all files being uploaded to a directory specified by <code>upload_store</code> directive. The files are then being stripped from body and altered request is then passed to a location specified by <code>upload_pass</code> directive, thus allowing arbitrary handling of uploaded files. Each of file fields are being replaced by a set of fields specified by <code>upload_set_form_field</code> directive. The content of each uploaded file then could be read from a file specified by $upload_tmp_path variable or the file could be simply moved to ultimate destination. Removal of output files is controlled by directive <code>upload_cleanup</code>. If a request has a method other than POST, the module returns error 405 (Method not allowed). Requests with such methods could be processed in alternative location via <code>error_page</code> directive.</p>"},{"location":"modules/upload/#directives","title":"Directives","text":""},{"location":"modules/upload/#upload_pass","title":"upload_pass","text":"<p>Syntax: <code>upload_pass location</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies location to pass request body to. File fields will be stripped and replaced by fields, containing necessary information to handle uploaded files.</p>"},{"location":"modules/upload/#upload_resumable","title":"upload_resumable","text":"<p>Syntax: <code>upload_resumable on | off</code> Default: <code>upload_resumable off</code> Context: <code>main,server,location</code></p> <p>Enables resumable uploads.</p>"},{"location":"modules/upload/#upload_store","title":"upload_store","text":"<p>Syntax: <code>upload_store directory [level1 [level2]] ...</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies a directory to which output files will be saved to. The directory could be hashed. In this case all subdirectories should exist before starting nginx.</p>"},{"location":"modules/upload/#upload_state_store","title":"upload_state_store","text":"<p>Syntax: <code>upload_state_store directory [level1 [level2]] ...</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies a directory that will contain state files for resumable uploads. The directory could be hashed. In this case all subdirectories should exist before starting nginx.</p>"},{"location":"modules/upload/#upload_store_access","title":"upload_store_access","text":"<p>Syntax: <code>upload_store_access mode</code> Default: <code>upload_store_access user:rw</code> Context: <code>server,location</code></p> <p>Specifies access mode which will be used to create output files.</p>"},{"location":"modules/upload/#upload_set_form_field","title":"upload_set_form_field","text":"<p>Syntax: <code>upload_set_form_field name value</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies a form field(s) to generate for each uploaded file in request body passed to backend. Both <code>name</code> and <code>value</code> could contain following special variables:</p> <ul> <li><code>$upload_field_name</code>: the name of original file field</li> <li><code>$upload_content_type</code>: the content type of file uploaded</li> <li><code>$upload_file_name</code>: the original name of the file being uploaded     with leading path elements in DOS and UNIX notation stripped. I.e.     \"D:\\Documents And Settings\\My Dcouments\\My Pictures\\Picture.jpg\"     will be converted to \"Picture.jpg\" and \"/etc/passwd\" will be     converted to \"passwd\".</li> <li><code>$upload_tmp_path</code>: the path where the content of original file is     being stored to. The output file name consists 10 digits and     generated with the same algorithm as in <code>proxy_temp_path</code>     directive.</li> </ul> <p>These variables are valid only during processing of one part of original request body.</p> <p>Usage example:</p> <pre><code>upload_set_form_field $upload_field_name.name \"$upload_file_name\";\nupload_set_form_field $upload_field_name.content_type \"$upload_content_type\";\nupload_set_form_field $upload_field_name.path \"$upload_tmp_path\";\n</code></pre>"},{"location":"modules/upload/#upload_aggregate_form_field","title":"upload_aggregate_form_field","text":"<p>Syntax: <code>upload_aggregate_form_field name value</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies a form field(s) containing aggregate attributes to generate for each uploaded file in request body passed to backend. Both name and value could contain standard nginx variables, variables from upload_set_form_field directive and following additional special variables:</p> <ul> <li><code>$upload_file_md5</code>: MD5 checksum of the file</li> <li><code>$upload_file_md5_uc</code>: MD5 checksum of the file in uppercase letters</li> <li><code>$upload_file_sha1</code>: SHA1 checksum of the file</li> <li><code>$upload_file_sha1_uc</code>: SHA1 checksum of the file in uppercase letters</li> <li><code>$upload_file_crc32</code>: hexdecimal value of CRC32 of the file</li> <li><code>$upload_file_size</code>: size of the file in bytes</li> <li><code>$upload_file_number</code>: ordinal number of file in request body</li> </ul> <p>The value of a field specified by this directive is evaluated after successful upload of the file, thus these variables are valid only at the end of processing of one part of original request body.</p> <p>Warning:: variables <code>$upload_file_md5</code>, <code>$upload_file_md5_uc</code>, <code>$upload_file_sha1</code>, and <code>$upload_file_sha1_uc</code> use additional resources to calculate MD5 and SHA1 checksums.</p> <p>Usage example:</p> <pre><code>upload_aggregate_form_field $upload_field_name.md5 \"$upload_file_md5\";\nupload_aggregate_form_field $upload_field_name.size \"$upload_file_size\";\n</code></pre>"},{"location":"modules/upload/#upload_pass_form_field","title":"upload_pass_form_field","text":"<p>Syntax: <code>upload_pass_form_field regex</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies a regex pattern for names of fields which will be passed to backend from original request body. This directive could be specified multiple times per location. Field will be passed to backend as soon as first pattern matches. For PCRE-unaware enviroments this directive specifies exact name of a field to pass to backend. If directive is omitted, no fields will be passed to backend from client.</p> <p>Usage example:</p> <pre><code>upload_pass_form_field \"^submit$|^description$\";\n</code></pre> <p>For PCRE-unaware environments:</p> <pre><code>upload_pass_form_field \"submit\";\nupload_pass_form_field \"description\";\n</code></pre>"},{"location":"modules/upload/#upload_cleanup","title":"upload_cleanup","text":"<p>Syntax: <code>upload_cleanup status/range ...</code> Default: \u2014 Context: <code>server,location</code></p> <p>Specifies HTTP statuses after generation of which all file successfuly uploaded in current request will be removed. Used for cleanup after backend or server failure. Backend may also explicitly signal errornous status if it doesn't need uploaded files for some reason. HTTP status must be a numerical value in range 400-599, no leading zeroes are allowed. Ranges of statuses could be specified with a dash.</p> <p>Usage example:</p> <pre><code>upload_cleanup 400 404 499 500-505;\n</code></pre>"},{"location":"modules/upload/#upload_buffer_size","title":"upload_buffer_size","text":"<p>Syntax: <code>upload_buffer_size size</code> Default: size of memory page in bytes Context: <code>server,location</code></p> <p>Size in bytes of write buffer which will be used to accumulate file data and write it to disk. This directive is intended to be used to compromise memory usage vs. syscall rate.</p>"},{"location":"modules/upload/#upload_max_part_header_len","title":"upload_max_part_header_len","text":"<p>Syntax: <code>upload_max_part_header_len size</code> Default: <code>512</code> Context: <code>server,location</code></p> <p>Specifies maximal length of part header in bytes. Determines the size of the buffer which will be used to accumulate part headers.</p>"},{"location":"modules/upload/#upload_max_file_size","title":"upload_max_file_size","text":"<p>Syntax: <code>upload_max_file_size size</code> Default: <code>0</code> Context: <code>main,server,location</code></p> <p>Specifies maximal size of the file. Files longer than the value of this directive will be omitted. This directive specifies \"soft\" limit, in the sense, that after encountering file longer than specified limit, nginx will continue to process request body, trying to receive remaining files. For \"hard\" limit <code>client_max_body_size</code> directive must be used. The value of zero for this directive specifies that no restrictions on file size should be applied.</p>"},{"location":"modules/upload/#upload_limit_rate","title":"upload_limit_rate","text":"<p>Syntax: <code>upload_limit_rate rate</code> Default: <code>0</code> Context: <code>main,server,location</code></p> <p>Specifies upload rate limit in bytes per second. Zero means rate is unlimited.</p>"},{"location":"modules/upload/#upload_max_output_body_len","title":"upload_max_output_body_len","text":"<p>Syntax: <code>upload_max_output_body_len size</code> Default: <code>100k</code> Context: <code>main,server,location</code></p> <p>Specifies maximal length of the output body. This prevents piling up of non-file form fields in memory. Whenever output body overcomes specified limit error 413 (Request entity too large) will be generated. The value of zero for this directive specifies that no restrictions on output body length should be applied.</p>"},{"location":"modules/upload/#upload_tame_arrays","title":"upload_tame_arrays","text":"<p>Syntax: <code>upload_tame_arrays on | off</code> Default: <code>off</code> Context: <code>main,server,location</code></p> <p>Specifies whether square brackets in file field names must be dropped (required for PHP arrays).</p>"},{"location":"modules/upload/#upload_pass_args","title":"upload_pass_args","text":"<p>Syntax: <code>upload_pass_args on | off</code> Default: <code>off</code> Context: <code>main,server,location</code></p> <p>Enables forwarding of query arguments to location, specified by upload_pass. Ineffective with named locations. Example:</p> <pre><code>&lt;form action=\"/upload/?id=5\"&gt;\n&lt;!-- ... --&gt;\n</code></pre> <pre><code>location /upload/ {\n    upload_pass /internal_upload/;\n    upload_pass_args on;\n}\n\n## ...\n\nlocation /internal_upload/ {\n    # ...\n    proxy_pass http://backend;\n}\n</code></pre> <p>In this example backend gets request URI \"/upload?id=5\". In case of <code>upload_pass_args off</code> backend gets \"/upload\".</p>"},{"location":"modules/upload/#example-configuration","title":"Example configuration","text":"<pre><code>server {\n    client_max_body_size 100m;\n    listen 80;\n\n    # Upload form should be submitted to this location\n    location /upload/ {\n        # Pass altered request body to this location\n        upload_pass @test;\n\n        # Store files to this directory\n        # The directory is hashed, subdirectories 0 1 2 3 4 5 6 7 8 9 should exist\n        upload_store /tmp 1;\n\n        # Allow uploaded files to be read only by user\n        upload_store_access user:r;\n\n        # Set specified fields in request body\n        upload_set_form_field $upload_field_name.name \"$upload_file_name\";\n        upload_set_form_field $upload_field_name.content_type \"$upload_content_type\";\n        upload_set_form_field $upload_field_name.path \"$upload_tmp_path\";\n\n        # Inform backend about hash and size of a file\n        upload_aggregate_form_field \"$upload_field_name.md5\" \"$upload_file_md5\";\n        upload_aggregate_form_field \"$upload_field_name.size\" \"$upload_file_size\";\n\n        upload_pass_form_field \"^submit$|^description$\";\n\n        upload_cleanup 400 404 499 500-505;\n    }\n\n    # Pass altered request body to a backend\n    location @test {\n        proxy_pass http://localhost:8080;\n    }\n}\n</code></pre> <pre><code>&lt;form name=\"upload\" method=\"POST\" enctype=\"multipart/form-data\" action=\"/upload/\"&gt;\n&lt;input type=\"file\" name=\"file1\"&gt;\n&lt;input type=\"file\" name=\"file2\"&gt;\n&lt;input type=\"hidden\" name=\"test\" value=\"value\"&gt;\n&lt;input type=\"submit\" name=\"submit\" value=\"Upload\"&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"modules/upload/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-upload.</p>"},{"location":"modules/upstream-fair/","title":"upstream-fair: The fair load balancer module for NGINX","text":""},{"location":"modules/upstream-fair/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-upstream-fair\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-upstream-fair\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_upstream_fair_module.so;\n</code></pre> <p>This document describes nginx-module-upstream-fair v0.1.3  released on Oct 03 2017.</p> <p>Nginx Upstream Fair Proxy Load Balancer</p>"},{"location":"modules/upstream-fair/#compatible-with-nginx-1116-with-dynamic-module-capability","title":"**( compatible with nginx 1.11.6+ &amp; with dynamic module capability ) **","text":""},{"location":"modules/upstream-fair/#description","title":"Description:","text":"<p>The Nginx fair proxy balancer enhances the standard round-robin load balancer provided with Nginx so that it will track busy back end servers (e.g. Thin, Ebb, Mongrel) and balance the load to non-busy server processes.</p> <p>Further information can be found on http://nginx.localdomain.pl/</p> <p>Ezra Zygmuntowicz has a good writeup of the fair proxy load balancer and how to use it here: http://brainspl.at/articles/2007/11/09/a-fair-proxy-balancer-for-nginx-and-mongrel</p>"},{"location":"modules/upstream-fair/#usage","title":"Usage:","text":"<p>Change your Nginx config file's upstream block to include the 'fair' directive:</p> <p>upstream mongrel {     fair;     server 127.0.0.1:5000;     server 127.0.0.1:5001;     server 127.0.0.1:5002;   }</p> <p>If you encounter any issues, please report them using the bugtracker at http://nginx.localdomain.pl/</p>"},{"location":"modules/upstream-fair/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-upstream-fair.</p>"},{"location":"modules/upstream-jdomain/","title":"upstream-jdomain: Asynchronous domain name resolution module for NGINX upstream","text":""},{"location":"modules/upstream-jdomain/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-upstream-jdomain\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-upstream-jdomain\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_upstream_jdomain_module.so;\n</code></pre> <p>This document describes nginx-module-upstream-jdomain v1.5.2  released on Dec 09 2024.</p> <p>An asynchronous domain name resolution module for nginx upstream.</p> <p>This module allows you to use a domain name in an upstream block and expect the domain name to be dynamically resolved so your upstream may be resilient to DNS entry updates.</p> <p>The module does not perform DNS resolution automatically on some interval. Instead, the DNS resolution needs to be prompted by a request for the given upstream. If nginx serves a connection bound for a jdomain upstream, and the configured <code>interval</code> has elapsed, then the module will perform a DNS lookup.</p> <p>The module is compatible with other <code>upstream</code> scope directives. This means you may populate an <code>upstream</code> block with multiple <code>jdomain</code> directives, multiple <code>server</code> directives, <code>keepalive</code>, load balancing directives, etc. Note that unless another load balancing method is specified in the <code>upstream</code> block, this module makes use of the default round robin load balancing algorithm built into nginx core.</p> <p>Important Note: Should an alternate load balancing algorithm be specified, it must come before the jdomain directive in the upstream block! If this is not followed, nginx will crash during runtime! This is because many other load balancing modules explicitly extend the built in round robin, and thus end up clobbering the jdomain initialization handlers, since jdomain is technically a load balancer module as well. While this may not be the case with all load balancer modules, it's better to stay on the safe side and place jdomain after.</p> <p>Important Note: Due to the non blocking nature of this module and the fact that its DNS resolution is triggered by incoming requests, the request that prompts a lookup will actually still be forwarded to the upstream that was resolved and cached before the DNS lookup happens. Depending on the scenario, this could result in a one off failure when changing the states of upstreams. This is important to keep in mind to ensure graceful transitions of your upstreams.</p> <p>This repository is a fork of a repository originally authored by wdaike. As that project is no longer maintained, this repository aims to be its successor and is now several features ahead.</p>"},{"location":"modules/upstream-jdomain/#usage","title":"Usage","text":"<pre><code>resolver 8.8.8.8; # Your Local DNS Server\n\n## Basic upstream using domain name defaulting to port 80.\nupstream backend_01 {\n    jdomain example.com;\n}\n\n## Basic upstream specifying different port.\nupstream backend_02 {\n    jdomain example.com port=8080;\n}\n\n## Upstream with a backup server to use in case of host not found or format\n## errors on DNS resolution.\nupstream backend_03 {\n    server 127.0.0.2 backup;\n    jdomain example.com;\n}\n\n## Upstream which will use backup for any and all DNS resolution errors.\nupstream backend_04 {\n    server 127.0.0.2 backup;\n    jdomain example.com strict;\n}\n\nserver {\n    listen 127.0.0.2:80;\n    return 502 'An error.';\n}\n</code></pre>"},{"location":"modules/upstream-jdomain/#synopsis","title":"Synopsis","text":"<pre><code>Syntax: jdomain &lt;domain-name&gt; [port=80] [max_ips=4] [interval=1] [strict]\nContext: upstream\nAttributes:\n    port:       Backend's listening port.                                      (Default: 80)\n    max_ips:    IP buffer size. Maximum number of resolved IPs to cache.       (Default: 4)\n    interval:   How many seconds to resolve domain name.                       (Default: 1)\n    ipver:      Only addresses of family IPv4 or IPv6 will be used if defined  (Default: 0)\n    strict:     Require the DNS resolution to succeed and return addresses,\n                otherwise marks the underlying server and peers as down and\n                forces use of other servers in the upstream block if there\n                are any present. A failed resolution can be a timeout, DNS\n                server failure, connection refusals, response with no\n                addresses, etc.\n</code></pre> <p>See https://www.nginx.com/resources/wiki/modules/domain_resolve/ for details.</p>"},{"location":"modules/upstream-jdomain/#development","title":"Development","text":""},{"location":"modules/upstream-jdomain/#prerequisites","title":"Prerequisites","text":"<p>To facilitate local development and enable you to build and test the module, you'll need some tools.</p> <ul> <li>Docker: to provide an environment     to easily reproduce ideal conditions for building and testing.</li> <li>act: to simulate executing     github actions workflows locally to save you from pushing commits just to     watch the CI fail.</li> <li>rust: dependency of     <code>cargo-make</code>.</li> <li>cargo-make: to     run common development tasks such as building, testing, and formatting code.</li> </ul>"},{"location":"modules/upstream-jdomain/#task-runner","title":"Task Runner","text":"<p><code>cargo-make</code> is an advanced task runner that will enabled you to easily perform common development operations like formatting the code, building the module, running the test suite, and running code analysis. You can see the task definitions in the file <code>Makefile.toml</code>. Installing <code>cargo-make</code> will result in a standalone executable called <code>makers</code> as well as a <code>cargo</code> extension which can be executed via <code>cargo make</code>. As this project is not a <code>rust</code> crate, it is recommended to simply use <code>makers</code>.</p> <p>Also note that for simplicity's sake, the task runner uses docker to run all tasks. This means the build binary is not targetting your host platform.</p>"},{"location":"modules/upstream-jdomain/#default-task","title":"Default Task","text":"<p>To add value, the default task (ie. simply running <code>makers</code> alone) will begin an interactive bash session inside the docker container used for this project.</p> <p>This should help with debugging and general workflow.</p>"},{"location":"modules/upstream-jdomain/#formatting","title":"Formatting","text":"<p>Incorrectly formatted code will cause the github actions linting job to fail. To avoid this, you can run the format task before pushing new changes, like so:</p> <pre><code>makers format\n</code></pre> <p>This formatting is performed by a tool called <code>clang-format</code>. You can find the config options for this defined in the file <code>./.clang-format</code>.</p>"},{"location":"modules/upstream-jdomain/#static-code-analysis","title":"Static Code Analysis","text":"<p>You can run a static analysis on the code via the analyse task:</p> <pre><code>makers analyse\n</code></pre> <p>This analysis is performed by a tool called <code>clang-tidy</code>. You can find the config options for this defined in the file <code>./.clang-tidy</code>.</p>"},{"location":"modules/upstream-jdomain/#testing","title":"Testing","text":"<p>You can run the test suite using the test task, like so:</p> <pre><code>makers test\n</code></pre>"},{"location":"modules/upstream-jdomain/#debugging","title":"Debugging","text":"<p>We can use <code>valgrind</code> and <code>gdb</code> on nginx from inside the container.</p> <p>First open an interactive shell in the container with:</p> <pre><code>$ makers\n</code></pre> <p>We'll use that session to run <code>valgrind</code>:</p> <pre><code>$ valgrind --vgdb=full --vgdb-error=0 /github/workspace/bin/static/nginx -p/github/workspace/t/servroot -cconf/nginx.conf\n==15== Memcheck, a memory error detector\n==15== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\n==15== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==15== Command: /github/workspace/bin/static/nginx -p/github/workspace/t/servroot -cconf/nginx.conf\n==15==\n==15== (action at startup) vgdb me ...\n==15==\n==15== TO DEBUG THIS PROCESS USING GDB: start GDB like this\n==15==   /path/to/gdb /github/workspace/bin/static/nginx\n==15== and then give GDB the following command\n==15==   target remote | /usr/lib64/valgrind/../../bin/vgdb --pid=15\n==15== --pid is optional if only one valgrind process is running\n==15==\n</code></pre> <p>Next, find the container identifier so we can open another session inside it:</p> <pre><code>$ docker ps\nCONTAINER ID        IMAGE                                     COMMAND             CREATED             STATUS              PORTS                    NAMES\n55fab1e069ba        act-github-actions-nginx-module-toolbox   \"bash\"              4 seconds ago       Up 3 seconds        0.0.0.0:1984-&gt;1984/tcp   serene_newton\n</code></pre> <p>Use either the name or ID to execute a bash session inside the container:</p> <pre><code>$ docker exec -it serene_newton bash\n</code></pre> <p>We'll use this session to start <code>gdb</code> and target the valgrind gdb server we started in the other session:</p> <pre><code>$ gdb /github/workspace/bin/static/nginx\nGNU gdb (GDB) Red Hat Enterprise Linux 8.0.1-30.amzn2.0.3\nCopyright (C) 2017 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-redhat-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n&lt;http://www.gnu.org/software/gdb/bugs/&gt;.\nFind the GDB manual and other documentation resources online at:\n&lt;http://www.gnu.org/software/gdb/documentation/&gt;.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from /github/workspace/bin/static/nginx...done.\n(gdb)\n</code></pre> <p>From the gdb prompt, target the valgrind process and begin debugging:</p> <pre><code>(gdb) target remote | /usr/lib64/valgrind/../../bin/vgdb --pid=15\nRemote debugging using | /usr/lib64/valgrind/../../bin/vgdb --pid=15\nrelaying data between gdb and process 15\nwarning: remote target does not support file transfer, attempting to access files from local filesystem.\nReading symbols from /lib64/ld-linux-x86-64.so.2...(no debugging symbols found)...done.\n0x0000000004000ef0 in _start () from /lib64/ld-linux-x86-64.so.2\nMissing separate debuginfos, use: debuginfo-install glibc-2.26-35.amzn2.x86_64\n(gdb)\n</code></pre>"},{"location":"modules/upstream-jdomain/#running-github-actions","title":"Running GitHub Actions","text":"<p>With <code>act</code>, you can simulate the workflow that will run on GitHub servers once you push changes.</p> <p>There is more than one job in the main workflow, so you need to specify the test job when you run <code>act</code>. For example, you can use this command to run the code format validation:</p> <pre><code>act -vj lint\n</code></pre> <p>Note that the <code>lint</code> job does not format your code, it only checks that the formatting is as expected.</p> <p>Also note that <code>-v</code> is used to enable verbose mode to give more visibility on everything <code>act</code> is doing.</p> <p>The jobs you can (and should) run locally are <code>lint</code>, <code>build</code>, <code>analyse</code>, and <code>test</code>. The <code>test</code> job depends on the output from the <code>build</code> job. To keep the output from the build job, you can add the <code>-b</code> flag to <code>act</code>, or you may simply use the task runner to build.</p>"},{"location":"modules/upstream-jdomain/#known-issues","title":"Known Issues","text":"<p>At the moment? None! \ud83c\udf89</p> <p>If you discover a bug or have a question to raise, please open an issue.</p>"},{"location":"modules/upstream-jdomain/#original-author","title":"Original Author","text":"<p>wdaike wdaike@163.com (https://github.com/wdaike), Baidu Inc.</p>"},{"location":"modules/upstream-jdomain/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-upstream-jdomain.</p>"},{"location":"modules/upsync/","title":"upsync: NGINX module for syncing upstreams from consul or etcd","text":""},{"location":"modules/upsync/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-upsync\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-upsync\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_upsync_module.so;\n</code></pre> <p>This document describes nginx-module-upsync v2.1.3  released on Nov 20 2020.</p> <p>Nginx C module, which can sync upstreams from Consul or others. It dynamically modifies backend-servers attributes (weight, max_fails,...), without need to reload NGINX.</p> <p>It may not always be convenient to modify configuration files and restart NGINX. For example, if you are experiencing large amounts of traffic and high load, restarting NGINX and reloading the configuration at that point further increases load on the system and can temporarily degrade performance.</p> <p>The module allows to expand and scale down without affecting performance.</p> <p>Another module, nginx-stream-upsync-module supports NGINX stream module (TCP protocol), please be noticed.</p>"},{"location":"modules/upsync/#status","title":"Status","text":"<p>This module is still under active development and is considered production ready.</p>"},{"location":"modules/upsync/#synopsis","title":"Synopsis","text":"<p>nginx-consul: <pre><code>http {\n    upstream test {\n        upsync 127.0.0.1:8500/v1/kv/upstreams/test/ upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 8080;\n\n        location = /proxy_test {\n            proxy_pass http://test;\n        }\n\n        location = /bar {\n            proxy_pass http://bar;\n        }\n\n        location = /upstream_show {\n            upstream_show;\n        }\n\n    }\n}\n</code></pre> nginx-etcd: <pre><code>http {\n    upstream test {\n        upsync 127.0.0.1:2379/v2/keys/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=etcd strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 8080;\n\n        location = /proxy_test {\n            proxy_pass http://test;\n        }\n\n        location = /bar {\n            proxy_pass http://bar;\n        }\n\n        location = /upstream_show {\n            upstream_show;\n        }\n\n    }\n}\n</code></pre> upsync_lb: <pre><code>http {\n    upstream test {\n        least_conn; //hash $uri consistent;\n\n        upsync 127.0.0.1:8500/v1/kv/upstreams/test/ upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n        upsync_lb least_conn; //hash_ketama;\n\n        include /usr/local/nginx/conf/servers/servers_test.conf;\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 8080;\n\n        location = /proxy_test {\n            proxy_pass http://test;\n        }\n\n        location = /bar {\n            proxy_pass http://bar;\n        }\n\n        location = /upstream_show {\n            upstream_show;\n        }\n\n    }\n}\n</code></pre></p> <p>NOTE: recomending strong_dependency is configed off and the first time included file include all the servers.</p>"},{"location":"modules/upsync/#description","title":"Description","text":"<p>This module provides a method to discover backend servers. Supporting dynamicly adding or deleting backend server through consul or etcd and dynamically adjusting backend servers weight, module will timely pull new backend server list from consul or etcd to upsync nginx ip router. Nginx needn't reload. Having some advantages than others:</p> <ul> <li> <p>timely</p> <p>module send key to consul/etcd with index, consul/etcd will compare it with its index, if index doesn't change connection will hang five minutes, in the period any operation to the key-value, will feed back rightaway.</p> </li> <li> <p>performance</p> <p>Pulling from consul/etcd equal a request to nginx, updating ip router nginx needn't reload, so affecting nginx performance is little.</p> </li> <li> <p>stability</p> <p>Even if one pulling failed, it will pull next upsync_interval, so guarantying backend server stably provides service. And support dumping the latest config to location, so even if consul/etcd hung up, and nginx can be reload anytime. </p> </li> <li> <p>health_check</p> <p>nginx-upsync-module support adding or deleting servers health check, needing nginx_upstream_check_module. Recommending nginx-upsync-module + nginx_upstream_check_module.</p> </li> </ul>"},{"location":"modules/upsync/#directives","title":"Directives","text":""},{"location":"modules/upsync/#upsync","title":"upsync","text":"<p><pre><code>syntax: upsync $consul/etcd.api.com:$port/v1/kv/upstreams/$upstream_name/ [upsync_type=consul/etcd] [upsync_interval=second/minutes] [upsync_timeout=second/minutes] [strong_dependency=off/on]\n</code></pre> default: none, if parameters omitted, default parameters are upsync_interval=5s upsync_timeout=6m strong_dependency=off</p> <p>context: upstream</p> <p>description: Pull upstream servers from consul/etcd... .</p> <p>The parameters' meanings are:</p> <ul> <li> <p>upsync_interval</p> <p>pulling servers from consul/etcd interval time.</p> </li> <li> <p>upsync_timeout</p> <p>pulling servers from consul/etcd request timeout.</p> </li> <li> <p>upsync_type</p> <p>pulling servers from conf server type.</p> </li> <li> <p>strong_dependency</p> <p>when strong_dependency is on, nginx will pull servers from consul/etcd every time when nginx start up or reload.</p> </li> </ul>"},{"location":"modules/upsync/#upsync_dump_path","title":"upsync_dump_path","text":"<p><code>syntax: upsync_dump_path $path</code></p> <p>default: /tmp/servers_$host.conf</p> <p>context: upstream</p> <p>description: dump the upstream backends to the $path.</p>"},{"location":"modules/upsync/#upsync_lb","title":"upsync_lb","text":"<p><code>syntax: upsync_lb $load_balance</code></p> <p>default: round_robin/ip_hash/hash modula</p> <p>context: upstream</p> <p>description: mainly for least_conn and hash consistent, when using one of them, you must point out using upsync_lb.</p>"},{"location":"modules/upsync/#upstream_show","title":"upstream_show","text":"<p><code>syntax: upstream_show</code></p> <p>default: none</p> <p>context: upstream</p> <p>description: Show specific upstream all backend servers.</p> <pre><code>     location /upstream_list {\n         upstream_show;\n     }\n</code></pre> <pre><code>curl http://127.0.0.1:8500/upstream_list?test;\n</code></pre> <pre><code>curl http://127.0.0.1:8500/upstream_list;\n\nshow all upstreams.\n</code></pre>"},{"location":"modules/upsync/#consul_interface","title":"Consul_interface","text":"<p>Data can be taken from key/value store or service catalog. In the first case parameter upsync_type of directive must be consul. For example</p> <pre><code>        upsync 127.0.0.1:8500/v1/kv/upstreams/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n</code></pre> <p>In the second case it must be consul_services.</p> <pre><code>        upsync 127.0.0.1:8500/v1/catalog/service/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul_services strong_dependency=off;\n</code></pre> <p>In the third case, it must be consul_health:</p> <pre><code>        upsync 127.0.0.1:8500/v1/health/service/test upsync_timeout=6m upsync_interval=500ms upsync_type=consul_health strong_dependency=off;\n</code></pre> <p>Services with failing health checks are marked as down with the health api.</p> <p>You can add or delete backend server through consul_ui or http_interface. Below are examples for key/value store.</p> <p>http_interface example:</p> <ul> <li>add <pre><code>    curl -X PUT http://$consul_ip:$port/v1/kv/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre>     default: weight=1 max_fails=2 fail_timeout=10 down=0 backup=0;</li> </ul> <p><pre><code>    curl -X PUT -d \"{\\\"weight\\\":1, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":1, \"max_fails\":2, \"fail_timeout\":10}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre>     value support json format.</p> <ul> <li> <p>delete <pre><code>    curl -X DELETE http://$consul_ip:$port/v1/kv/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>adjust-weight <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":2, \"max_fails\":2, \"fail_timeout\":10}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>mark server-down <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10, \\\"down\\\":1}\" http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\nor\n    curl -X PUT -d '{\"weight\":2, \"max_fails\":2, \"fail_timeout\":10, \"down\":1}' http://$consul_ip:$port/v1/kv/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>check <pre><code>    curl http://$consul_ip:$port/v1/kv/upstreams/$upstream_name?recurse\n</code></pre></p> </li> </ul>"},{"location":"modules/upsync/#etcd_interface","title":"Etcd_interface","text":"<p>you can add or delete backend server through http_interface.</p> <p>mainly like etcd, http_interface example:</p> <ul> <li>add <pre><code>    curl -X PUT http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre>     default: weight=1 max_fails=2 fail_timeout=10 down=0 backup=0;</li> </ul> <p><pre><code>    curl -X PUT -d value=\"{\\\"weight\\\":1, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre>     value support json format.</p> <ul> <li> <p>delete <pre><code>    curl -X DELETE http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>adjust-weight <pre><code>    curl -X PUT -d \"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>mark server-down <pre><code>    curl -X PUT -d value=\"{\\\"weight\\\":2, \\\"max_fails\\\":2, \\\"fail_timeout\\\":10, \\\"down\\\":1}\" http://$etcd_ip:$port/v2/keys/$dir1/$upstream_name/$backend_ip:$backend_port\n</code></pre></p> </li> <li> <p>check <pre><code>    curl http://$etcd_ip:$port/v2/keys/upstreams/$upstream_name\n</code></pre></p> </li> </ul>"},{"location":"modules/upsync/#check_module","title":"Check_module","text":"<p>check module support.</p> <p>check-conf: <pre><code>http {\n    upstream test {\n        upsync 127.0.0.1:8500/v1/kv/upstreams/test/ upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off;\n        upsync_dump_path /usr/local/nginx/conf/servers/servers_test.conf;\n\n        check interval=1000 rise=2 fall=2 timeout=3000 type=http default_down=false;\n        check_http_send \"HEAD / HTTP/1.0\\r\\n\\r\\n\";\n        check_http_expect_alive http_2xx http_3xx;\n\n    }\n\n    upstream bar {\n        server 127.0.0.1:8090 weight=1 fail_timeout=10 max_fails=3;\n    }\n\n    server {\n        listen 8080;\n\n        location = /proxy_test {\n            proxy_pass http://test;\n        }\n\n        location = /bar {\n            proxy_pass http://bar;\n        }\n\n        location = /upstream_show {\n            upstream_show;\n        }\n\n        location = /upstream_status {\n            check_status;\n            access_log off;\n        }\n\n    }\n}\n</code></pre></p>"},{"location":"modules/upsync/#code-style","title":"Code style","text":"<p>Code style is mainly based on style</p>"},{"location":"modules/upsync/#see-also","title":"see also","text":"<ul> <li>the nginx_upstream_check_module: https://github.com/alibaba/tengine/blob/master/src/http/ngx_http_upstream_check_module.c</li> <li>the nginx_upstream_check_module patch: https://github.com/yaoweibin/nginx_upstream_check_module</li> <li>or based on https://github.com/xiaokai-wang/nginx_upstream_check_module</li> </ul>"},{"location":"modules/upsync/#source-dependency","title":"source dependency","text":"<ul> <li>Cjson: https://github.com/kbranigan/cJSON</li> <li>http-parser: https://github.com/nodejs/http-parser</li> </ul>"},{"location":"modules/upsync/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-upsync.</p>"},{"location":"modules/vod/","title":"vod: NGINX-based VOD Packager","text":""},{"location":"modules/vod/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-vod\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-vod\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_vod_module.so;\n</code></pre> <p>This document describes nginx-module-vod v1.33  released on Jan 01 2024.</p>"},{"location":"modules/vod/#nginx-vod-module","title":"nginx-vod-module","text":"<p>Join the list of organizations using this video packager project.</p> <p>For live video streaming, please use Media-Framework.</p>"},{"location":"modules/vod/#features","title":"Features","text":"<ul> <li> <p>On-the-fly repackaging of MP4 files to DASH, HDS, HLS, MSS</p> </li> <li> <p>Working modes:</p> </li> <li>Local - serve locally accessible files (local disk/NFS mounted)</li> <li>Remote - serve files accessible via HTTP using range requests</li> <li> <p>Mapped - serve files according to a specification encoded in JSON format. The JSON can pulled from a remote server, or read from a local file</p> </li> <li> <p>Adaptive bitrate support</p> </li> <li> <p>Playlist support (playing several different media files one after the other) - mapped mode only</p> </li> <li> <p>Simulated live support (generating a live stream from MP4 files) - mapped mode only</p> </li> <li> <p>Fallback support for file not found in local/mapped modes (useful in multi-datacenter environments)</p> </li> <li> <p>Video codecs: H264, H265 (DASH/HLS), AV1 (DASH/HLS), VP8 (DASH), VP9 (DASH)</p> </li> <li> <p>Audio codecs: AAC, MP3 (HLS/HDS/MSS), AC-3 (DASH/HLS), E-AC-3 (DASH/HLS), VORBIS (DASH), OPUS (DASH), FLAC (HLS), DTS (HLS)</p> </li> <li> <p>Captions support - </p> </li> </ul> <p>Input:   1. WebVTT   2. SRT   3. DFXP/TTML   4. CAP (Cheetah)</p> <p>Output:   1. DASH - either a single WebVTT or SMPTE-TT segments (configurable)   2. HLS - segmented WebVTT (m3u8)   3. MSS - converted to TTML and packaged in fragmented MP4 (no support for styling)</p> <ul> <li> <p>Audio only/video only files</p> </li> <li> <p>Alternative audio renditions - supporting both:</p> </li> <li>Generation of manifest with different audio renditions, allowing selection on the client side</li> <li> <p>Muxing together audio and video streams from separate files / tracks - provides the ability     to serve different audio renditions of a single video, without the need for any special support     on the client side.</p> </li> <li> <p>Track selection for multi audio/video MP4 files</p> </li> <li> <p>Playback rate change - 0.5x up to 2x (requires libavcodec and libavfilter)</p> </li> <li> <p>Source file clipping (only from I-Frame to P-frame)</p> </li> <li> <p>Support for variable segment lengths - enabling the player to select the optimal bitrate fast, without the overhead of short segments for the whole duration of the video</p> </li> <li> <p>Clipping of MP4 files for progressive download playback</p> </li> <li> <p>Thumbnail capture (requires libavcodec) and resize (requires libswscale)</p> </li> <li> <p>Volume map (requires libavcodec) - returns a CSV containing the volume level in each interval</p> </li> <li> <p>Decryption of CENC-encrypted MP4 files (it is possible to create such files with MP4Box)</p> </li> <li> <p>DASH: common encryption (CENC) support</p> </li> <li> <p>MSS: PlayReady encryption support</p> </li> <li> <p>HLS: Generation of I-frames playlist (EXT-X-I-FRAMES-ONLY)</p> </li> <li> <p>HLS: support for AES-128 / SAMPLE-AES encryption</p> </li> </ul>"},{"location":"modules/vod/#limitations","title":"Limitations","text":"<ul> <li> <p>Track selection and playback rate change are not supported in progressive download</p> </li> <li> <p>I-frames playlist generation is not supported when encryption is enabled</p> </li> <li> <p>Tested on Linux only</p> </li> </ul>"},{"location":"modules/vod/#rpm-ihv-httpinstallrepokalturaorgreleaseskaltura-releasenoarchrpm","title":"rpm -ihv http://installrepo.kaltura.org/releases/kaltura-release.noarch.rpm","text":""},{"location":"modules/vod/#yum-install-kaltura-nginx","title":"yum install kaltura-nginx","text":"<pre><code>#### Debian/Ubuntu deb package\n*Ubuntu NOTE: before trying to install kaltura-nginx, you must also make sure the multiverse repo is enabled*\n\nFor Debian Wheezy [7], Debian Jessie [8], Ubuntu 14.04 and 14.10, add this repo:\n```sh\n## wget -O - http://installrepo.kaltura.org/repo/apt/debian/kaltura-deb-curr.gpg.key|apt-key add -\n## echo \"deb [arch=amd64] http://installrepo.kaltura.org/repo/apt/debian propus main\" &gt; /etc/apt/sources.list.d/kaltura.list\n</code></pre> <p>For Ubuntu 16.04, 16.10 add this repo: <pre><code>## wget -O - http://installrepo.kaltura.org/repo/apt/xenial/kaltura-deb-curr-256.gpg.key|apt-key add -\n## echo \"deb [arch=amd64] http://installrepo.kaltura.org/repo/apt/xenial propus main\" &gt; /etc/apt/sources.list.d/kaltura.list\n</code></pre></p> <p>For Ubuntu 20.04 add this repo: <pre><code>## wget -O - http://installrepo.kaltura.org/repo/aptn/focal/kaltura-deb-256.gpg.key|apt-key add -\n## echo \"deb [arch=amd64] http://installrepo.kaltura.org/repo/aptn/focal quasar main\" &gt; /etc/apt/sources.list.d/kaltura.list\n</code></pre></p> <p>Then install the kaltura-nginx package: <pre><code>## apt-get update\n## apt-get install kaltura-nginx\n</code></pre></p> <p>If you wish to make use of the following features: - Thumbnail capture - Playback rate change - 0.5x up to 2x</p> <p>You will also need to install the kaltura-ffmpeg (&gt;= 3.1) package.</p>"},{"location":"modules/vod/#url-structure","title":"URL structure","text":""},{"location":"modules/vod/#basic-url-structure","title":"Basic URL structure","text":"<p>The basic structure of an nginx-vod-module URL is: <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;fileuri&gt;/&lt;filename&gt;</code></p> <p>Where: * domain - the domain of the nginx-vod-module server * location - the location specified in the nginx conf * fileuri - a URI to the mp4 file:   * local mode - the full file path is determined according to the root / alias nginx.conf directives   * mapped mode - the full file path is determined according to the JSON received from the upstream / local file   * remote mode - the mp4 file is read from upstream in chunks   * Note: in mapped &amp; remote modes, the URL of the upstream request is <code>http://&lt;upstream&gt;/&lt;location&gt;/&lt;fileuri&gt;?&lt;extraargs&gt;</code>   (extraargs is determined by the <code>vod_upstream_extra_args</code> parameter) * filename - detailed below</p>"},{"location":"modules/vod/#multi-url-structure","title":"Multi URL structure","text":"<p>Multi URLs are used to encode several URLs on a single URL. A multi URL can be used to specify the URLs of several different MP4 files that should be included together in a DASH MPD for example.</p> <p>The structure of a multi URL is: <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;,&lt;middle1&gt;,&lt;middle2&gt;,&lt;middle3&gt;,&lt;postfix&gt;.urlset/&lt;filename&gt;</code></p> <p>The sample URL above represents 3 URLs: * <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;&lt;middle1&gt;&lt;postfix&gt;/&lt;filename&gt;</code> * <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;&lt;middle2&gt;&lt;postfix&gt;/&lt;filename&gt;</code> * <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;&lt;middle3&gt;&lt;postfix&gt;/&lt;filename&gt;</code></p> <p>The suffix <code>.urlset</code> (can be changed using <code>vod_multi_uri_suffix</code>) indicates that the URL should be treated as a multi URL. For example - the URL <code>http://example.com/hls/videos/big_buck_bunny_,6,9,15,00k.mp4.urlset/master.m3u8</code> will return a manifest containing: * http://example.com/hls/videos/big_buck_bunny_600k.mp4/index.m3u8 * http://example.com/hls/videos/big_buck_bunny_900k.mp4/index.m3u8 * http://example.com/hls/videos/big_buck_bunny_1500k.mp4/index.m3u8</p>"},{"location":"modules/vod/#url-path-parameters","title":"URL path parameters","text":"<p>The following parameters are supported on the URL path: * clipFrom - an offset in milliseconds since the beginning of the video, where the generated stream should start.      For example, <code>.../clipFrom/10000/...</code> will generate a stream that starts 10 seconds into the video. * clipTo - an offset in milliseconds since the beginning of the video, where the generated stream should end.     For example, <code>.../clipTo/60000/...</code> will generate a stream truncated to 60 seconds. * tracks - can be used to select specific audio/video tracks. The structure of the parameter is: <code>v&lt;id1&gt;-v&lt;id2&gt;-a&lt;id1&gt;-a&lt;id2&gt;...</code>     For example, <code>.../tracks/v1-a1/...</code> will select the first video track and first audio track.     The default is to include all tracks. * shift - can be used to apply a timing shift to one or more streams. The structure of the parameter is: <code>v&lt;vshift&gt;-a&lt;ashift&gt;-s&lt;sshift&gt;</code>     For example, <code>.../shift/v100/...</code> will apply a forward shift of 100ms to the video timestamps.</p>"},{"location":"modules/vod/#filename-structure","title":"Filename structure","text":"<p>The structure of filename is: <code>&lt;basename&gt;[&lt;seqparams&gt;][&lt;fileparams&gt;][&lt;trackparams&gt;][&lt;langparams&gt;].&lt;extension&gt;</code></p> <p>Where: * basename + extension - the set of options is packager specific (the list below applies to the default settings):   * dash - manifest.mpd   * hds - manifest.f4m   * hls master playlist - master.m3u8   * hls media playlist - index.m3u8   * mss - manifest   * thumb - <code>thumb-&lt;offset&gt;[&lt;resizeparams&gt;].jpg</code> (offset is the thumbnail video offset in milliseconds)   * volume_map - <code>volume_map.csv</code> * seqparams - can be used to select specific sequences by id (provided in the mapping JSON), e.g. master-sseq1.m3u8. * fileparams - can be used to select specific sequences by index when using multi URLs.     For example, manifest-f1.mpd will return an MPD only from the first URL. * trackparams - can be used to select specific audio/video tracks.     For example, manifest-a1.f4m will return an F4M containing only the first audio stream of each sequence.     The default is to include the first audio and first video tracks of each file.     The tracks selected on the file name are AND-ed with the tracks selected with the /tracks/ path parameter.     v0/a0 select all video/audio tracks respectively.     The a/v parameters can be combined with f/s, e.g. f1-v1-f2-a1 = video1 of file1 + audio1 of file2, f1-f2-v1 = video1 of file1 + video1 of file2. * langparams - can be used to filter audio tracks/subtitles according to their language (ISO639-3 code).     For example, master-leng.m3u8 will return only english audio tracks. * resizeparams - can be used to resize the returned thumbnail image. For example, thumb-1000-w150-h100.jpg captures a thumbnail     1 second into the video, and resizes it to 150x100. If one of the dimensions is omitted, its value is set so that the      resulting image will retain the aspect ratio of the video frame.</p>"},{"location":"modules/vod/#mapping-response-format","title":"Mapping response format","text":"<p>When configured to run in mapped mode, nginx-vod-module issues an HTTP request to a configured upstream server  in order to receive the layout of media streams it should generate. The response has to be in JSON format. </p> <p>This section contains a few simple examples followed by a reference of the supported objects and fields.  But first, a couple of definitions:</p> <ol> <li><code>Source Clip</code> - a set of audio and/or video frames (tracks) extracted from a single media file</li> <li><code>Generator</code> - a component that can generate audio/video frames. Currently, the only supported generator is the silence generator.</li> <li><code>Filter</code> - a manipulation that can be applied on audio/video frames. The following filters are supported: </li> <li>rate (speed) change - applies to both audio and video</li> <li>audio volume change</li> <li>mix - can be used to merge several audio tracks together, or to merge the audio of source A with the video of source B</li> <li><code>Clip</code> - the result of applying zero or more filters on a set of source clips</li> <li><code>Dynamic Clip</code> - a clip whose contents is not known in advance, e.g. targeted ad content</li> <li><code>Sequence</code> - a set of clips that should be played one after the other. </li> <li><code>Set</code> - several sequences that play together as an adaptive set, each sequence must have the same number of clips.</li> </ol>"},{"location":"modules/vod/#simple-mapping","title":"Simple mapping","text":"<p>The JSON below maps the request URI to a single MP4 file: <pre><code>{\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video.mp4\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p> <p>When using multi URLs, this is the only allowed JSON pattern. In other words, it is not possible to combine more complex JSONs using multi URL.</p>"},{"location":"modules/vod/#adaptive-set","title":"Adaptive set","text":"<p>As an alternative to using multi URL, an adaptive set can be defined via JSON: <pre><code>{\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/bitrate1.mp4\"\n                }\n            ]\n        },\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/bitrate2.mp4\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"modules/vod/#playlist","title":"Playlist","text":"<p>The JSON below will play 35 seconds of video1 followed by 22 seconds of video2: <pre><code>{\n    \"durations\": [ 35000, 22000 ],\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video1.mp4\"\n                },\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video2.mp4\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"modules/vod/#filters","title":"Filters","text":"<p>The JSON below takes video1, plays it at x1.5 and mixes the audio of the result with the audio of video2, after reducing it to 50% volume: <pre><code>{\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"mixFilter\",\n                    \"sources\": [\n                        {\n                            \"type\": \"rateFilter\",\n                            \"rate\": 1.5,\n                            \"source\": {\n                                \"type\": \"source\",\n                                \"path\": \"/path/to/video1.mp4\"\n                            }\n                        },\n                        {\n                            \"type\": \"gainFilter\",\n                            \"gain\": 0.5,\n                            \"source\": {\n                                \"type\": \"source\",\n                                \"path\": \"/path/to/video2.mp4\",\n                                \"tracks\": \"a1\"\n                            }\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"modules/vod/#continuous-live","title":"Continuous live","text":"<p>The JSON below is a sample of a continuous live stream (=a live stream in which all videos have exactly the same encoding parameters). In practice, this JSON will have to be generated by some script, since it is time dependent. (see test/playlist.php for a sample implementation) <pre><code>{\n    \"playlistType\": \"live\",\n    \"discontinuity\": false,\n    \"segmentBaseTime\": 1451904060000,\n    \"firstClipTime\": 1451917506000,\n    \"durations\": [83000, 83000],\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video1.mp4\"\n                },\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video2.mp4\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"modules/vod/#non-continuous-live","title":"Non-continuous live","text":"<p>The JSON below is a sample of a non-continuous live stream (=a live stream in which the videos have different encoding parameters). In practice, this JSON will have to be generated by some script, since it is time dependent  (see test/playlist.php for a sample implementation) <pre><code>{\n    \"playlistType\": \"live\",\n    \"discontinuity\": true,\n    \"initialClipIndex\": 171,\n    \"initialSegmentIndex\": 153,\n    \"firstClipTime\": 1451918170000,\n    \"durations\": [83000, 83000],\n    \"sequences\": [\n        {\n            \"clips\": [\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video1.mp4\"\n                },\n                {\n                    \"type\": \"source\",\n                    \"path\": \"/path/to/video2.mp4\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"modules/vod/#mapping-reference","title":"Mapping reference","text":""},{"location":"modules/vod/#set-top-level-object-in-the-mapping-json","title":"Set (top level object in the mapping JSON)","text":"<p>Mandatory fields: * <code>sequences</code> - array of Sequence objects.      The mapping has to contain at least one sequence and up to 32 sequences.</p> <p>Optional fields: * <code>id</code> - a string that identifies the set. The id can be retrieved by <code>$vod_set_id</code>. * <code>playlistType</code> - string, can be set to <code>live</code>, <code>vod</code> or <code>event</code> (only supported for HLS playlists), default is <code>vod</code>. * <code>durations</code> - an array of integers representing clip durations in milliseconds.     This field is mandatory if the mapping contains more than a single clip per sequence.     If specified, this array must contain at least one element and up to 128 elements. * <code>discontinuity</code> - boolean, indicates whether the different clips in each sequence have     different media parameters. This field has different manifestations according to the      delivery protocol - a value of true will generate <code>#EXT-X-DISCONTINUITY</code> in HLS,      and a multi period MPD in DASH. The default value is true, set to false only if the media     files were transcoded with exactly the same parameters (in AVC for example,      the clips should have exactly the same SPS/PPS). * <code>segmentDuration</code> - integer, sets the segment duration in milliseconds. This field,      if specified, takes priority over the value set in <code>vod_segment_duration</code>. * <code>consistentSequenceMediaInfo</code> - boolean, currently affects only DASH. When set to true (default)     the MPD will report the same media parameters in each period element. Setting to false     can have severe performance implications for long sequences (nginx-vod-module has      to read the media info of all clips included in the mapping in order to generate the MPD) * <code>referenceClipIndex</code> - integer, sets the (1-based) index of the clip that should be used      to retrieve the video metadata for manifest requests (codec, width, height etc.)     If <code>consistentSequenceMediaInfo</code> is set to false, this parameter has no effect -     all clips are parsed. If this parameter is not specified, nginx-vod-module uses the last clip      by default. * <code>notifications</code> - array of notification objects (see below), when a segment is requested,     all the notifications that fall between the start/end times of the segment are fired.     the notifications must be ordered in an increasing offset order. * <code>clipFrom</code> - integer, contains a timestamp indicating where the returned stream should start.     Setting this parameter is equivalent to passing /clipFrom/ on the URL. * <code>clipTo</code> - integer, contains a timestamp indicating where the returned stream should end.     Setting this parameter is equivalent to passing /clipTo/ on the URL. * <code>cache</code> - boolean, if set to false, the mapping response will not be saved to cache (vod_mapping_cache).     The default value is true. * <code>closedCaptions</code> - array of closed captions objects (see below), containing languages and ids     of any embedded CEA-608 / CEA-708 captions. If an empty array is provided, the module will output     <code>CLOSED-CAPTIONS=NONE</code> on each <code>EXT-X-STREAM-INF</code> tag. If the list does not appear in the JSON, the      module will not output any <code>CLOSED-CAPTIONS</code> fields in the playlist.</p> <p>Live fields: * <code>firstClipTime</code> - integer, mandatory for all live playlists unless <code>clipTimes</code> is specified.     Contains the absolute time of the first clip in the playlist, in milliseconds since the epoch (unixtime x 1000) * <code>clipTimes</code> - array of integers, sets the absolute time of all the clips in the playlist,      in milliseconds since the epoch (unixtime x 1000). This field can be used only when      <code>discontinuity</code> is set to true. The timestamps may contain gaps, but they are not allowed to overlap     (<code>clipTimes[n + 1] &gt;= clipTimes[n] + durations[n]</code>) * <code>segmentBaseTime</code> - integer, mandatory for continuous live streams, contains the absolute     time of the first segment of the stream, in milliseconds since the epoch (unixtime x 1000).     This value must not change during playback.     For discontinuous live streams, this field is optional:     * if not set, sequential segment indexes will be used throughout the playlist.         In this case, the upstream server generating the mapping json has to maintain state,         and update initialSegmentIndex every time a clip is removed from the playlist.     * if set, the timing gaps between clips must not be lower than <code>vod_segment_duration</code>. * <code>firstClipStartOffset</code> - integer, optional, measured in milliseconds. This field contains the     difference between first clip time, and the original start time of the first clip -     the time it had when it was initially added (before the live window shifted) * <code>initialClipIndex</code> - integer, mandatory for non-continuous live streams that mix videos having     different encoding parameters (SPS/PPS), contains the index of the first clip in the playlist.      Whenever a clip is pushed out of the head of the playlist, this value must be incremented by one. * <code>initialSegmentIndex</code> - integer, mandatory for live streams that do not set <code>segmentBaseTime</code>,      contains the index of the first segment in the playlist. Whenever a clip is pushed out of the head of     the playlist, this value must be incremented by the number of segments in the clip. * <code>presentationEndTime</code> - integer, optional, measured in milliseconds since the epoch.     when supplied, the module will compare the current time to the supplied value,      and signal the end of the live presentation if <code>presentationEndTime</code> has passed.      In HLS, for example, this parameter controls whether an <code>#EXT-X-ENDLIST</code> tag should be      included in the media playlist.     When the parameter is not supplied, the module will not signal live presentation end. * <code>expirationTime</code> - integer, optional, measured in milliseconds since the epoch.     when supplied, the module will compare the current time to the supplied value,      and if <code>expirationTime</code> has passed, the module will return a 404 error for manifest requests      (segment requests will continue to be served).     when both presentationEndTime and expirationTime have passed, presentationEndTime takes     priority, i.e. manifest requests will be served and signal presentation end. * <code>liveWindowDuration</code> - integer, optional, provides a way to override <code>vod_live_window_duration</code>     specified in the configuration. If the value exceeds the absolute value specified in      <code>vod_live_window_duration</code>, it is ignored. * <code>timeOffset</code> - integer, sets an offset that should be applied to the server clock when serving     live requests. This parameter can be used to test future/past events.</p>"},{"location":"modules/vod/#sequence","title":"Sequence","text":"<p>Mandatory fields: * <code>clips</code> - array of Clip objects (mandatory). The number of elements must match the number     the durations array specified on the set. If the durations array is not specified,     the clips array must contain a single element.</p> <p>Optional fields: * <code>id</code> - a string that identifies the sequence. The id can be retrieved by <code>$vod_sequence_id</code>. * <code>language</code> - a 3-letter (ISO-639-2) language code, this field takes priority over any language     specified on the media file (MP4 mdhd atom) * <code>label</code> - a friendly string that identifies the sequence. If a language is specified,     a default label will be automatically derived by it - e.g. if language is <code>ita</code>,      by default <code>italiano</code> will be used as the label. * <code>bitrate</code> - an object that can be used to set the bitrate for the different media types,     in bits per second. For example, <code>{\"v\": 900000, \"a\": 64000}</code>. If the bitrate is not supplied,     nginx-vod-module will estimate it based on the last clip in the sequence. * <code>avg_bitrate</code> - an object that can be used to set the average bitrate for the different media types,     in bits per second. See <code>bitrate</code> above for a sample object. If specified, the module will use     the value to populate the AVERAGE-BANDWIDTH attribute of <code>#EXT-X-STREAM-INF</code> in HLS.</p>"},{"location":"modules/vod/#clip-abstract","title":"Clip (abstract)","text":"<p>Mandatory fields: * <code>type</code> - a string that defines the type of the clip. Allowed values are:     * source     * rateFilter     * mixFilter     * gainFilter     * silence     * concat     * dynamic</p> <p>Optional fields: * <code>keyFrameDurations</code> - array of integers, containing the durations in milliseconds of the video key frames     in the clip. This property can only be supplied on the top level clips of each sequence,     supplying this property on nested clips has no effect.     Supplying the key frame durations enables the module to both:     1. align the segments to key frames      2. report the correct segment durations in the manifest - providing an alternative to setting         <code>vod_manifest_segment_durations_mode</code> to <code>accurate</code>, which is not supported for multi clip         media sets (for performance reasons). * <code>firstKeyFrameOffset</code> - integer, offset of the first video key frame in the clip,      measured in milliseconds relative to <code>firstClipTime</code>. Defaults to 0 if not supplied.</p>"},{"location":"modules/vod/#source-clip","title":"Source clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>source</code> * <code>path</code> - a string containing the path of the MP4 file. The string <code>\"empty\"</code> can be used to represent     an empty captions file (useful in case only some videos in a playlist have captions)</p> <p>Optional fields: * <code>id</code> - a string that identifies the source clip * <code>sourceType</code> - sets the interface that should be used to read the MP4 file, allowed values are:     <code>file</code> and <code>http</code>. By default, the module uses <code>http</code> if <code>vod_remote_upstream_location</code> is set,     and <code>file</code> otherwise. * <code>tracks</code> - a string that specifies the tracks that should be used, the default is \"v1-a1\",     which means the first video track and the first audio track * <code>clipFrom</code> - an integer that specifies an offset in milliseconds, from the beginning of the      media file, from which to start loading frames * <code>encryptionKey</code> - a base64 encoded string containing the key (128/192/256 bit) that should be used     to decrypt the file. * <code>encryptionIv</code> - a base64 encoded string containing the iv (128 bit) that should be used     to decrypt the file. * <code>encryptionScheme</code> - the encryption scheme that was used to encrypt the file. Currently,     only two schemes are supported - <code>cenc</code> for MP4 files, <code>aes-cbc</code> for caption files.</p>"},{"location":"modules/vod/#rate-filter-clip","title":"Rate filter clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>rateFilter</code> * <code>rate</code> - a float that specified the acceleration factor, e.g. a value of 2 means double speed.     Allowed values are in the range 0.5 - 2 with up to two decimal points * <code>source</code> - a clip object on which to perform the rate filtering</p>"},{"location":"modules/vod/#gain-filter-clip","title":"Gain filter clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>gainFilter</code> * <code>gain</code> - a float that specified the amplification factor, e.g. a value of 2 means twice as loud.     The gain must be positive with up to two decimal points * <code>source</code> - a clip object on which to perform the gain filtering</p>"},{"location":"modules/vod/#mix-filter-clip","title":"Mix filter clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>mixFilter</code> * <code>sources</code> - an array of Clip objects to mix. This array must contain at least one clip and     up to 32 clips.</p>"},{"location":"modules/vod/#concat-clip","title":"Concat clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>concat</code> * <code>durations</code> - an array of integers representing MP4 durations in milliseconds,     this array must match the <code>paths</code> array in count and order.</p> <p>Optional fields: * <code>paths</code> - an array of strings, containing the paths of the MP4 files. Either <code>paths</code> or <code>clipIds</code> must be specified. * <code>clipIds</code> - an array of strings, containing the ids of source clips.      The ids are translated to paths by issuing a request to the uri specified in <code>vod_source_clip_map_uri</code>.     Either <code>paths</code> or <code>clipIds</code> must be specified. * <code>tracks</code> - a string that specifies the tracks that should be used, the default is \"v1-a1\",     which means the first video track and the first audio track * <code>offset</code> - an integer in milliseconds that indicates the timestamp offset of the      first frame in the concatenated stream relative to the clip start time * <code>basePath</code> - a string that should be added as a prefix to all the paths * <code>notifications</code> - array of notification objects (see below), when a segment is requested,     all the notifications that fall between the start/end times of the segment are fired.     the notifications must be ordered in an increasing offset order.</p>"},{"location":"modules/vod/#dynamic-clip","title":"Dynamic clip","text":"<p>Mandatory fields: * <code>type</code> - a string with the value <code>dynamic</code> * <code>id</code> - a string that uniquely identifies the dynamic clip, used for mapping the clip to its content</p>"},{"location":"modules/vod/#notification","title":"Notification","text":"<p>Mandatory fields: * <code>offset</code> - an integer in milliseconds that indicates the time in which the notification should be fired.     when the notification object is contained in the media set, <code>offset</code> is relative to <code>firstClipTime</code>     (0 for vod). when the notification object is contained in a concat clip, <code>offset</code> is relative to     the beginning of the concat clip. * <code>id</code> - a string that identifies the notification, this id can be referenced by <code>vod_notification_uri</code>     using the variable <code>$vod_notification_id</code></p>"},{"location":"modules/vod/#closed-captions","title":"Closed Captions","text":"<p>Mandatory fields: * <code>id</code> - a string that identifies the embedded captions. This will become the <code>INSTREAM-ID</code> field and must have one of the following values: <code>CC1</code>, <code>CC3</code>, <code>CC3</code>, <code>CC4</code>, or <code>SERVICEn</code>, where <code>n</code> is between 1 and 63. * <code>label</code> - a friendly string that indicates the language of the closed caption track.</p> <p>Optional fields: * <code>language</code> - a 3-letter (ISO-639-2) language code that indicates the language of the closed caption track.</p>"},{"location":"modules/vod/#security","title":"Security","text":""},{"location":"modules/vod/#url-encryption","title":"URL encryption","text":"<p>As an alternative to tokenization, URL encryption can be used to prevent an attacker from being able to craft a playable URL. URL encryption can be implemented with  https://github.com/kaltura/nginx-secure-token-module, and is supported for HLS and DASH (with  manifest format set to segmentlist). </p> <p>In terms of security, the main advantage of CDN tokens over URL encryption is that CDN tokens usually expire, while encrypted URLs do not (someone who obtains a playable URL will be able to use it indefinitely)</p>"},{"location":"modules/vod/#media-encryption","title":"Media encryption","text":"<p>Nginx-vod-module supports AES-128 and SAMPLE-AES HLS encryption schemes. The main difference between media encryption and DRM (detailed below) is the mechanism used to transfer the encryption key to  the client. With media encryption the key is fetched by the client by performing a simple GET request to nginx-vod-module, while with DRM the key is returned inside a vendor specific license response.</p> <p>Media encryption reduces the problem of securing the media to the need to secure the encryption key.  The media segment URLs (which compose the vast majority of the traffic) can be completely unprotected,  and easily cacheable by any proxies between the client and servers (unlike tokenization).  The encryption key request can then be protected using one of the methods mentioned above (CDN tokens, nginx access rules etc.). </p> <p>In addition, it is possible to configure nginx-vod-module to return the encryption key over HTTPS while having the segments delivered over HTTP. The way to configure this is to set <code>vod_segments_base_url</code> to <code>http://nginx-vod-host</code> and set <code>vod_base_url</code> to <code>https://nginx-vod-host</code>.</p>"},{"location":"modules/vod/#drm","title":"DRM","text":"<p>Nginx-vod-module has the ability to perform on-the-fly encryption for MPEG DASH (CENC), MSS Play Ready and FairPlay HLS. As in the case of media encryption, the encryption is performed while serving a video/audio segment to the client,  therefore, when working with DRM it is recommended not to serve the content directly from nginx-vod-module to end-users. A more scalable architecture would be to use proxy servers or a CDN in order to cache the encrypted segments.</p> <p>In order to perform the encryption, nginx-vod-module needs several parameters, including key &amp; key_id, these parameters are fetched from an external server via HTTP GET requests. The <code>vod_drm_upstream_location</code> parameter specifies an nginx location that is used to access the DRM server, and the request uri is configured using <code>vod_drm_request_uri</code> (this parameter can include nginx variables).  The response of the DRM server is a JSON, with the following format:</p> <pre><code>[{\n    \"pssh\": [{\n            \"data\": \"CAESEGMyZjg2MTczN2NjNGYzODIaB2thbHR1cmEiCjBfbmptaWlwbXAqBVNEX0hE\", \n            \"uuid\": \"edef8ba9-79d6-4ace-a3c8-27dcd51d21ed\"\n        }], \n    \"key\": \"GzoNU9Dfwc//Iq3/zbzMUw==\", \n    \"key_id\": \"YzJmODYxNzM3Y2M0ZjM4Mg==\"\n}]\n</code></pre> <ul> <li><code>pssh.data</code> - base64 encoded binary data, the format of this data is drm vendor specific</li> <li><code>pssh.uuid</code> - the drm system UUID, in this case, edef8ba9-79d6-4ace-a3c8-27dcd51d21ed stands for Widevine</li> <li><code>key</code> - base64 encoded encryption key (128 bit)</li> <li><code>key_id</code> - base64 encoded key identifier (128 bit)</li> <li><code>iv</code> - optional base64 encoded initialization vector (128 bit). The IV is currently used only in HLS (FairPlay),      in the other protocols an IV is generated automatically by nginx-vod-module.</li> </ul>"},{"location":"modules/vod/#sample-configurations","title":"Sample configurations","text":"<p>Apple FairPlay HLS: <pre><code>location ~ ^/fpshls/p/\\d+/(sp/\\d+/)?serveFlavor/entryId/([^/]+)/(.*) {\n    vod hls;\n    vod_hls_encryption_method sample-aes;\n    vod_hls_encryption_key_uri \"skd://entry-$2\";\n    vod_hls_encryption_key_format \"com.apple.streamingkeydelivery\";\n    vod_hls_encryption_key_format_versions \"1\";\n\n    vod_drm_enabled on;\n    vod_drm_request_uri \"/udrm/system/ovp/$vod_suburi\";\n\n    vod_last_modified_types *;\n    add_header Access-Control-Allow-Headers '*';\n    add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n    add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n    add_header Access-Control-Allow-Origin '*';\n    expires 100d;\n}\n</code></pre></p> <p>Common Encryption HLS: <pre><code>location ~ ^/cenchls/p/\\d+/(sp/\\d+/)?serveFlavor/entryId/([^/]+)/(.*) {\n    vod hls;\n    vod_hls_encryption_method sample-aes-cenc;\n    vod_hls_encryption_key_format \"urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed\";\n    vod_hls_encryption_key_format_versions \"1\";\n\n    vod_drm_enabled on;\n    vod_drm_request_uri \"/udrm/system/ovp/$vod_suburi\";\n\n    vod_last_modified_types *;\n    add_header Access-Control-Allow-Headers '*';\n    add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n    add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n    add_header Access-Control-Allow-Origin '*';\n    expires 100d;\n}\n</code></pre></p>"},{"location":"modules/vod/#verified-configurations","title":"Verified configurations","text":"<p>Following is a list of configurations that were tested and found working: * DASH/CENC with PlayReady &amp; Widevine PSSH together * MSS PlayReady * HLS FairPlay</p>"},{"location":"modules/vod/#performance-recommendations","title":"Performance recommendations","text":"<ol> <li> <p>For medium/large scale deployments, don't have users play the videos directly from nginx-vod-module.     Since all the different streaming protocols supported by nginx vod are HTTP based, they can be cached by standard HTTP proxies / CDNs.      For medium scale add a layer of caching proxies between the vod module and the end users      (can use standard nginx servers with proxy_pass &amp; proxy_cache).      For large scale deployments, it is recommended to use a CDN (such as Akamai, Level3 etc.). </p> <p>In general, it's best to have nginx vod as close as possible to where the mp4 files are stored,  and have the caching proxies as close as possible to the end users. 2. Enable nginx-vod-module caches: * <code>vod_metadata_cache</code> - saves the need to re-read the video metadata for each segment. This cache should be rather large, in the order of GBs. * <code>vod_response_cache</code> - saves the responses of manifest requests. This cache may not be required when using a second layer of caching servers before nginx vod.      No need to allocate a large buffer for this cache, 128M is probably more than enough for most deployments. * <code>vod_mapping_cache</code> - for mapped mode only, few MBs is usually enough. * nginx's open_file_cache - caches open file handles.</p> <p>The hit/miss ratios of these caches can be tracked by enabling performance counters (<code>vod_performance_counters</code>) and setting up a status page for nginx vod (<code>vod_status</code>) 3. In local &amp; mapped modes, enable aio. - nginx has to be compiled with aio support, and it has to be enabled in nginx conf (aio on).  You can verify it works by looking at the performance counters on the vod status page - read_file (aio off) vs. async_read_file (aio on) 4. In local &amp; mapped modes, enable asynchronous file open - nginx has to be compiled with threads support, and <code>vod_open_file_thread_pool</code> has to be specified in nginx.conf. You can verify it works by looking at the performance counters on the vod status page -  open_file vs. async_open_file. Note that open_file may be nonzero with vod_open_file_thread_pool enabled, due to the open file cache -  open requests that are served from cache will be counted as synchronous open_file. 5. When using DRM enabled DASH/MSS, if the video files have a single nalu per frame, set <code>vod_min_single_nalu_per_frame_segment</code> to non-zero. 6. The muxing overhead of the streams generated by this module can be reduced by changing the following parameters: * HDS - set <code>vod_hds_generate_moof_atom</code> to off * HLS - set <code>vod_hls_mpegts_align_frames</code> to off and <code>vod_hls_mpegts_interleave_frames</code> to on 7. Enable gzip compression on manifest responses - </p> <p><code>gzip_types application/vnd.apple.mpegurl video/f4m application/dash+xml text/xml</code> 8. Apply common nginx performance best practices, such as tcp_nodelay=on, client_header_timeout etc.</p> </li> </ol>"},{"location":"modules/vod/#configuration-directives-base","title":"Configuration directives - base","text":""},{"location":"modules/vod/#vod","title":"vod","text":"<ul> <li>syntax: <code>vod segmenter</code></li> <li>default: <code>n/a</code></li> <li>context: <code>location</code></li> </ul> <p>Enables the nginx-vod module on the enclosing location.  The allowed values for <code>segmenter</code> are:</p> <ol> <li><code>none</code> - serves the MP4 files as is / clipped</li> <li><code>dash</code> - Dynamic Adaptive Streaming over HTTP packager</li> <li><code>hds</code> - Adobe HTTP Dynamic Streaming packager</li> <li><code>hls</code> - Apple HTTP Live Streaming packager</li> <li><code>mss</code> - Microsoft Smooth Streaming packager</li> <li><code>thumb</code> - thumbnail capture</li> <li><code>volume_map</code> - audio volume map</li> </ol>"},{"location":"modules/vod/#vod_mode","title":"vod_mode","text":"<ul> <li>syntax: <code>vod_mode mode</code></li> <li>default: <code>local</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the file access mode - local, remote or mapped (see the features section above for more details)</p>"},{"location":"modules/vod/#vod_status","title":"vod_status","text":"<ul> <li>syntax: <code>vod_status</code></li> <li>default: <code>n/a</code></li> <li>context: <code>location</code></li> </ul> <p>Enables the nginx-vod status page on the enclosing location.  The following query params are supported: * <code>?reset=1</code> - resets the performance counters and cache stats. * <code>?format=prom</code> - returns the output in format compatible with Prometheus (the default format is XML).</p>"},{"location":"modules/vod/#configuration-directives-segmentation","title":"Configuration directives - segmentation","text":""},{"location":"modules/vod/#vod_segment_duration","title":"vod_segment_duration","text":"<ul> <li>syntax: <code>vod_segment_duration duration</code></li> <li>default: <code>10s</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the segment duration in milliseconds. It is highly recommended to use a segment duration that is a multiple of the GOP duration. If the segment duration is not a multiple of GOP duration, and <code>vod_align_segments_to_key_frames</code> is enabled, there could be significant differences between the segment duration that is reported in the manifest and the actual segment duration. This could also lead to the appearance of empty segments within the stream.</p>"},{"location":"modules/vod/#vod_live_window_duration","title":"vod_live_window_duration","text":"<ul> <li>syntax: <code>vod_live_window_duration duration</code></li> <li>default: <code>30000</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the total duration in milliseconds of the segments that should be returned in a live manifest. If the value is positive, nginx vod returns a range of maximum <code>vod_live_window_duration</code> milliseconds, ending at the current server time. If the value is negative, nginx vod returns a range of maximum <code>-vod_live_window_duration</code> milliseconds from the end of the mapping json. If the value is set to zero, the live manifest will contain all the segments that are fully contained in the mapping json time frame.</p>"},{"location":"modules/vod/#vod_force_playlist_type_vod","title":"vod_force_playlist_type_vod","text":"<ul> <li>syntax: <code>vod_force_playlist_type_vod on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Generate a vod stream even when the media set has <code>playlistType=live</code>.  Enabling this setting has the following effects: 1. Frame timestamps will be continuous and start from zero 2. Segment indexes will start from one 3. In case of HLS, the returned manifest will have both <code>#EXT-X-PLAYLIST-TYPE:VOD</code> and <code>#EXT-X-ENDLIST</code></p> <p>This can be useful for clipping vod sections out of a live stream.</p>"},{"location":"modules/vod/#vod_force_continuous_timestamps","title":"vod_force_continuous_timestamps","text":"<ul> <li>syntax: <code>vod_force_continuous_timestamps on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Generate continuous timestamps even when the media set has gaps (gaps can created by the use of <code>clipTimes</code>) If ID3 timestamps are enabled (<code>vod_hls_mpegts_output_id3_timestamps</code>), they contain the original timestamps that were set in <code>clipTimes</code>.</p>"},{"location":"modules/vod/#vod_bootstrap_segment_durations","title":"vod_bootstrap_segment_durations","text":"<ul> <li>syntax: <code>vod_bootstrap_segment_durations duration</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Adds a bootstrap segment duration in milliseconds. This setting can be used to make the first few segments shorter than the default segment duration, thus making the adaptive bitrate selection kick-in earlier without  the overhead of short segments throughout the video.</p>"},{"location":"modules/vod/#vod_align_segments_to_key_frames","title":"vod_align_segments_to_key_frames","text":"<ul> <li>syntax: <code>vod_align_segments_to_key_frames on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module forces all segments to start with a key frame. Enabling this setting can lead to differences between the actual segment durations and the durations reported in the manifest (unless <code>vod_manifest_segment_durations_mode</code> is set to accurate).</p>"},{"location":"modules/vod/#vod_segment_count_policy","title":"vod_segment_count_policy","text":"<ul> <li>syntax: <code>vod_segment_count_policy last_short/last_long/last_rounded</code></li> <li>default: <code>last_short</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the policy for calculating the segment count, for segment_duration = 10 seconds: * last_short - a file of 33 sec is partitioned as - 10, 10, 10, 3 * last_long - a file of 33 sec is partitioned as - 10, 10, 13 * last_rounded - a file of 33 sec is partitioned as - 10, 10, 13, a file of 38 sec is partitioned as 10, 10, 10, 8</p>"},{"location":"modules/vod/#vod_manifest_duration_policy","title":"vod_manifest_duration_policy","text":"<ul> <li>syntax: <code>vod_manifest_duration_policy min/max</code></li> <li>default: <code>max</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the policy for calculating the duration of a manifest containing multiple streams: * max - uses the maximum stream duration (default) * min - uses the minimum non-zero stream duration</p>"},{"location":"modules/vod/#vod_manifest_segment_durations_mode","title":"vod_manifest_segment_durations_mode","text":"<ul> <li>syntax: <code>vod_manifest_segment_durations_mode estimate/accurate</code></li> <li>default: <code>estimate</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the calculation mode of segment durations within manifest requests: * estimate - reports the duration as configured in nginx.conf, e.g. if <code>vod_segment_duration</code> has the value 10000, an HLS manifest will contain #EXTINF:10 * accurate - reports the exact duration of the segment, taking into account the frame durations, e.g. for a  frame rate of 29.97 and 10 second segments it will report the first segment as 10.01. accurate mode also takes into account the key frame alignment, in case <code>vod_align_segments_to_key_frames</code> is on</p>"},{"location":"modules/vod/#vod_media_set_override_json","title":"vod_media_set_override_json","text":"<ul> <li>syntax: <code>vod_media_set_override_json json</code></li> <li>default: <code>{}</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>This parameter provides a way to override portions of the media set JSON (mapped mode only). For example, <code>vod_media_set_override_json '{\"clipTo\":20000}'</code> clips the media set to 20 sec. The parameter value can contain variables.</p>"},{"location":"modules/vod/#configuration-directives-upstream","title":"Configuration directives - upstream","text":""},{"location":"modules/vod/#vod_upstream_location","title":"vod_upstream_location","text":"<ul> <li>syntax: <code>vod_upstream_location location</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets an nginx location that is used to read the MP4 file (remote mode) or mapping the request URI (mapped mode).</p>"},{"location":"modules/vod/#vod_remote_upstream_location","title":"vod_remote_upstream_location","text":"<ul> <li>syntax: <code>vod_remote_upstream_location location</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets an nginx location that is used to read the MP4 file on remote or mapped mode. If this directive is set on mapped mode, the module reads  the MP4 files over HTTP, treating the paths in the mapping JSON as URIs (the default behavior is to read from local files)</p>"},{"location":"modules/vod/#vod_max_upstream_headers_size","title":"vod_max_upstream_headers_size","text":"<ul> <li>syntax: <code>vod_max_upstream_headers_size size</code></li> <li>default: <code>4k</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the size that is allocated for holding the response headers when issuing upstream requests (to vod_xxx_upstream_location).</p>"},{"location":"modules/vod/#vod_upstream_extra_args","title":"vod_upstream_extra_args","text":"<ul> <li>syntax: <code>vod_upstream_extra_args \"arg1=value1&amp;arg2=value2&amp;...\"</code></li> <li>default: <code>empty</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Extra query string arguments that should be added to the upstream request (remote/mapped modes only). The parameter value can contain variables.</p>"},{"location":"modules/vod/#vod_media_set_map_uri","title":"vod_media_set_map_uri","text":"<ul> <li>syntax: <code>vod_media_set_map_uri uri</code></li> <li>default: <code>$vod_suburi</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the uri of media set mapping requests, the parameter value can contain variables. In case of multi url, <code>$vod_suburi</code> will be the current sub uri (a separate request is issued per sub URL)</p>"},{"location":"modules/vod/#vod_path_response_prefix","title":"vod_path_response_prefix","text":"<ul> <li>syntax: <code>vod_path_response_prefix prefix</code></li> <li>default: <code>{\"sequences\":[{\"clips\":[{\"type\":\"source\",\"path\":\"</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the prefix that is expected in URI mapping responses (mapped mode only).</p>"},{"location":"modules/vod/#vod_path_response_postfix","title":"vod_path_response_postfix","text":"<ul> <li>syntax: <code>vod_path_response_postfix postfix</code></li> <li>default: <code>\"}]}]}</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the postfix that is expected in URI mapping responses (mapped mode only).</p>"},{"location":"modules/vod/#vod_max_mapping_response_size","title":"vod_max_mapping_response_size","text":"<ul> <li>syntax: <code>vod_max_mapping_response_size length</code></li> <li>default: <code>1K</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the maximum length of a path returned from upstream (mapped mode only).</p>"},{"location":"modules/vod/#configuration-directives-fallback","title":"Configuration directives - fallback","text":""},{"location":"modules/vod/#vod_fallback_upstream_location","title":"vod_fallback_upstream_location","text":"<ul> <li>syntax: <code>vod_fallback_upstream_location location</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets an nginx location to which the request is forwarded after encountering a file not found error (local/mapped modes only).</p>"},{"location":"modules/vod/#vod_proxy_header_name","title":"vod_proxy_header_name","text":"<ul> <li>syntax: <code>vod_proxy_header_name name</code></li> <li>default: <code>X-Kaltura-Proxy</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the name of an HTTP header that is used to prevent fallback proxy loops (local/mapped modes only).</p>"},{"location":"modules/vod/#vod_proxy_header_value","title":"vod_proxy_header_value","text":"<ul> <li>syntax: <code>vod_proxy_header_value name</code></li> <li>default: <code>dumpApiRequest</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of an HTTP header that is used to prevent fallback proxy loops (local/mapped modes only).</p>"},{"location":"modules/vod/#configuration-directives-performance","title":"Configuration directives - performance","text":""},{"location":"modules/vod/#vod_metadata_cache","title":"vod_metadata_cache","text":"<ul> <li>syntax: <code>vod_metadata_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the video metadata cache. For MP4 files, this cache holds the moov atom.</p>"},{"location":"modules/vod/#vod_mapping_cache","title":"vod_mapping_cache","text":"<ul> <li>syntax: <code>vod_mapping_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the mapping cache for vod (mapped mode only).</p>"},{"location":"modules/vod/#vod_live_mapping_cache","title":"vod_live_mapping_cache","text":"<ul> <li>syntax: <code>vod_live_mapping_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the mapping cache for live (mapped mode only).</p>"},{"location":"modules/vod/#vod_response_cache","title":"vod_response_cache","text":"<ul> <li>syntax: <code>vod_response_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the response cache. The response cache holds manifests and other non-video content (like DASH init segment, HLS encryption key etc.). Video segments are not cached.</p>"},{"location":"modules/vod/#vod_live_response_cache","title":"vod_live_response_cache","text":"<ul> <li>syntax: <code>vod_live_response_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the response cache for time changing live responses.  This cache holds the following types of responses for live: DASH MPD, HLS index M3U8, HDS bootstrap, MSS manifest.</p>"},{"location":"modules/vod/#vod_initial_read_size","title":"vod_initial_read_size","text":"<ul> <li>syntax: <code>vod_initial_read_size size</code></li> <li>default: <code>4K</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the size of the initial read operation of the MP4 file.</p>"},{"location":"modules/vod/#vod_max_metadata_size","title":"vod_max_metadata_size","text":"<ul> <li>syntax: <code>vod_max_metadata_size size</code></li> <li>default: <code>128MB</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the maximum supported video metadata size (for MP4 - moov atom size)</p>"},{"location":"modules/vod/#vod_max_frames_size","title":"vod_max_frames_size","text":"<ul> <li>syntax: <code>vod_max_frames_size size</code></li> <li>default: <code>16MB</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the limit on the total size of the frames of a single segment</p>"},{"location":"modules/vod/#vod_max_frame_count","title":"vod_max_frame_count","text":"<ul> <li>syntax: <code>vod_max_frame_count count</code></li> <li>default: <code>1048576</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the limit on the total count of the frames read to serve non segment (e.g. playlist) request.</p>"},{"location":"modules/vod/#vod_segment_max_frame_count","title":"vod_segment_max_frame_count","text":"<ul> <li>syntax: <code>vod_segment_max_frame_count count</code></li> <li>default: <code>65536</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the limit on the total count of the frames read to serve segment request.</p>"},{"location":"modules/vod/#vod_cache_buffer_size","title":"vod_cache_buffer_size","text":"<ul> <li>syntax: <code>vod_cache_buffer_size size</code></li> <li>default: <code>256K</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the size of the cache buffers used when reading MP4 frames.</p>"},{"location":"modules/vod/#vod_open_file_thread_pool","title":"vod_open_file_thread_pool","text":"<ul> <li>syntax: <code>vod_open_file_thread_pool pool_name</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Enables the use of asynchronous file open via thread pool. The thread pool must be defined with a thread_pool directive, if no pool name is specified the default pool is used. This directive is supported only on nginx 1.7.11 or newer when compiling with --add-threads. Note: this directive currently disables the use of nginx's open_file_cache by nginx-vod-module</p>"},{"location":"modules/vod/#vod_output_buffer_pool","title":"vod_output_buffer_pool","text":"<ul> <li>syntax: <code>vod_output_buffer_pool size count</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Pre-allocates buffers for generating response data, saving the need allocate/free the buffers on every request.</p>"},{"location":"modules/vod/#vod_performance_counters","title":"vod_performance_counters","text":"<ul> <li>syntax: <code>vod_performance_counters zone_name</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the shared memory object name of the performance counters</p>"},{"location":"modules/vod/#configuration-directives-url-structure","title":"Configuration directives - url structure","text":""},{"location":"modules/vod/#vod_base_url","title":"vod_base_url","text":"<ul> <li>syntax: <code>vod_base_url url</code></li> <li>default: <code>see below</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the base URL (scheme + domain) that should be returned in manifest responses. The parameter value can contain variables, if the parameter evaluates to an empty string, relative URLs will be used. If the parameter evaluates to a string ending with /, it is assumed to be a full URL - the module only appends the file name to it, instead of a full URI. If not set, the base URL is determined as follows: 1. If the request did not contain a host header (HTTP/1.0) relative URLs will be returned 2. Otherwise, the base URL will be <code>$scheme://$http_host</code> The setting currently affects only HLS and DASH. In MSS and HDS, relative URLs are always returned.</p>"},{"location":"modules/vod/#vod_segments_base_url","title":"vod_segments_base_url","text":"<ul> <li>syntax: <code>vod_segments_base_url url</code></li> <li>default: <code>see below</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the base URL (scheme + domain) that should be used for delivering video segments. The parameter value can contain variables, if the parameter evaluates to an empty string, relative URLs will be used. If not set, vod_base_url will be used. The setting currently affects only HLS.</p>"},{"location":"modules/vod/#vod_multi_uri_suffix","title":"vod_multi_uri_suffix","text":"<ul> <li>syntax: <code>vod_multi_uri_suffix suffix</code></li> <li>default: <code>.urlset</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>A URL suffix that is used to identify multi URLs. A multi URL is a way to encode several different URLs that should be played together as an adaptive streaming set, under a single URL. When the default suffix is used, an HLS set URL may look like:  http://host/hls/common-prefix,bitrate1,bitrate2,common-suffix.urlset/master.m3u8</p>"},{"location":"modules/vod/#vod_clip_to_param_name","title":"vod_clip_to_param_name","text":"<ul> <li>syntax: <code>vod_clip_to_param_name name</code></li> <li>default: <code>clipTo</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the clip to request parameter.</p>"},{"location":"modules/vod/#vod_clip_from_param_name","title":"vod_clip_from_param_name","text":"<ul> <li>syntax: <code>vod_clip_from_param_name name</code></li> <li>default: <code>clipFrom</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the clip from request parameter.</p>"},{"location":"modules/vod/#vod_tracks_param_name","title":"vod_tracks_param_name","text":"<ul> <li>syntax: <code>vod_tracks_param_name name</code></li> <li>default: <code>tracks</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the tracks request parameter.</p>"},{"location":"modules/vod/#vod_time_shift_param_name","title":"vod_time_shift_param_name","text":"<ul> <li>syntax: <code>vod_time_shift_param_name name</code></li> <li>default: <code>shift</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the shift request parameter.</p>"},{"location":"modules/vod/#vod_speed_param_name","title":"vod_speed_param_name","text":"<ul> <li>syntax: <code>vod_speed_param_name name</code></li> <li>default: <code>speed</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the speed request parameter.</p>"},{"location":"modules/vod/#vod_lang_param_name","title":"vod_lang_param_name","text":"<ul> <li>syntax: <code>vod_lang_param_name name</code></li> <li>default: <code>lang</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the language request parameter.</p>"},{"location":"modules/vod/#vod_force_sequence_index","title":"vod_force_sequence_index","text":"<ul> <li>syntax: <code>vod_force_sequence_index on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Use sequence index in segment uris even if there is only one sequence</p>"},{"location":"modules/vod/#configuration-directives-response-headers","title":"Configuration directives - response headers","text":""},{"location":"modules/vod/#vod_expires","title":"vod_expires","text":"<ul> <li>syntax: <code>vod_expires time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the \"Expires\" and \"Cache-Control\" response headers for successful requests. This directive is similar to nginx's built-in <code>expires</code> directive, except that it only supports the expiration interval scenario (epoch, max, off, day time are not supported) Main motivation for using this directive instead of the built-in <code>expires</code> is to have different expiration for VOD and dynamic live content. If this directive is not specified, nginx-vod-module will not set the \"Expires\" / \"Cache-Control\" headers. This setting affects all types of requests in VOD playlists and segment requests in live playlists.</p>"},{"location":"modules/vod/#vod_expires_live","title":"vod_expires_live","text":"<ul> <li>syntax: <code>vod_expires_live time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Same as <code>vod_expires</code> (above) for live requests that are not time dependent and not segments (e.g. HLS - master.m3u8, HDS - manifest.f4m).</p>"},{"location":"modules/vod/#vod_expires_live_time_dependent","title":"vod_expires_live_time_dependent","text":"<ul> <li>syntax: <code>vod_expires_live_time_dependent time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Same as <code>vod_expires</code> (above) for live requests that are time dependent (HLS - index.m3u8, HDS - bootstrap.abst, MSS - manifest, DASH - manifest.mpd).</p>"},{"location":"modules/vod/#vod_last_modified","title":"vod_last_modified","text":"<ul> <li>syntax: <code>vod_last_modified time</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the Last-Modified header returned on the response, by default the module does not return a Last-Modified header. The reason for having this parameter here is in order to support If-Modified-Since / If-Unmodified-Since. Since nginx's builtin ngx_http_not_modified_filter_module runs before any other header filter module, it will not see any headers set by add_headers / more_set_headers. This makes nginx always reply as if the content changed (412 for If-Unmodified-Since / 200 for If-Modified-Since) For live requests that are not segments (e.g. live DASH MPD), Last-Modified is set to the current server time.</p>"},{"location":"modules/vod/#vod_last_modified_types","title":"vod_last_modified_types","text":"<ul> <li>syntax: <code>vod_last_modified_types mime-type1 mime-type2 ...</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the MIME types for which the Last-Modified header should be set. The special value \"*\" matches any MIME type.</p>"},{"location":"modules/vod/#configuration-directives-ad-stitching-mapped-mode-only","title":"Configuration directives - ad stitching (mapped mode only)","text":""},{"location":"modules/vod/#vod_dynamic_mapping_cache","title":"vod_dynamic_mapping_cache","text":"<ul> <li>syntax: <code>vod_dynamic_mapping_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the cache that stores the mapping of dynamic clips.</p>"},{"location":"modules/vod/#vod_dynamic_clip_map_uri","title":"vod_dynamic_clip_map_uri","text":"<ul> <li>syntax: <code>vod_dynamic_clip_map_uri uri</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the uri that should be used to map dynamic clips.  The parameter value can contain variables, specifically, <code>$vod_clip_id</code> contains the id of the clip that should be mapped. The expected response from this uri is a JSON containing a concat clip object.</p>"},{"location":"modules/vod/#vod_source_clip_map_uri","title":"vod_source_clip_map_uri","text":"<ul> <li>syntax: <code>vod_source_clip_map_uri uri</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the uri that should be used to map source clips defined using the clipIds property of concat.  The parameter value can contain variables, specifically, <code>$vod_clip_id</code> contains the id of the clip that should be mapped. The expected response from this uri is a JSON containing a source clip object.</p>"},{"location":"modules/vod/#vod_redirect_segments_url","title":"vod_redirect_segments_url","text":"<ul> <li>syntax: <code>vod_redirect_segments_url url</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets a url to which requests for segments should be redirected. The parameter value can contain variables, specifically, <code>$vod_dynamic_mapping</code> contains a serialized representation of the mapping of dynamic clips.</p>"},{"location":"modules/vod/#vod_apply_dynamic_mapping","title":"vod_apply_dynamic_mapping","text":"<ul> <li>syntax: <code>vod_apply_dynamic_mapping mapping</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Maps dynamic clips to concat clips using the given expression, previously generated by <code>$vod_dynamic_mapping</code>. The parameter value can contain variables.</p>"},{"location":"modules/vod/#vod_notification_uri","title":"vod_notification_uri","text":"<ul> <li>syntax: <code>vod_notification_uri uri</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the uri that should be used to issue notifications.  The parameter value can contain variables, specifically, <code>$vod_notification_id</code> contains the id of the notification that is being fired. The response from this uri is ignored.</p>"},{"location":"modules/vod/#configuration-directives-drm-encryption","title":"Configuration directives - DRM / encryption","text":""},{"location":"modules/vod/#vod_secret_key","title":"vod_secret_key","text":"<ul> <li>syntax: <code>vod_secret_key string</code></li> <li>default: <code>empty</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the seed that is used to generate the TS encryption key and DASH/MSS encryption IVs. The parameter value can contain variables, and will usually have the structure \"secret-$vod_filepath\". See the list of nginx variables added by this module below.</p>"},{"location":"modules/vod/#vod_encryption_iv_seed","title":"vod_encryption_iv_seed","text":"<ul> <li>syntax: <code>vod_encryption_iv_seed string</code></li> <li>default: <code>empty</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the seed that is used to generate the encryption IV, currently applies only to HLS/fMP4 with AES-128 encryption. The parameter value can contain variables.</p>"},{"location":"modules/vod/#vod_drm_enabled","title":"vod_drm_enabled","text":"<ul> <li>syntax: <code>vod_drm_enabled on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module encrypts the media segments according to the response it gets from the drm upstream. Currently supported only for dash and mss (play ready).</p>"},{"location":"modules/vod/#vod_drm_single_key","title":"vod_drm_single_key","text":"<ul> <li>syntax: <code>vod_drm_single_key on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module requests the drm info only for the first sequence and applies it to all sequences. When disabled, the drm info is requested for each sequence separately. In addition, in DASH, enabling this setting makes the module place the ContentProtection tag under AdaptationSet, otherwise, it is placed under Representation.</p>"},{"location":"modules/vod/#vod_drm_clear_lead_segment_count","title":"vod_drm_clear_lead_segment_count","text":"<ul> <li>syntax: <code>vod_drm_clear_lead_segment_count count</code></li> <li>default: <code>1</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the number of clear (unencrypted) segments in the beginning of the stream. A clear lead enables the player to start playing without having to wait for the license response.</p>"},{"location":"modules/vod/#vod_drm_max_info_length","title":"vod_drm_max_info_length","text":"<ul> <li>syntax: <code>vod_drm_max_info_length length</code></li> <li>default: <code>4K</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the maximum length of a drm info returned from upstream.</p>"},{"location":"modules/vod/#vod_drm_upstream_location","title":"vod_drm_upstream_location","text":"<ul> <li>syntax: <code>vod_drm_upstream_location location</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the nginx location that should be used for getting the DRM info for the file.</p>"},{"location":"modules/vod/#vod_drm_info_cache","title":"vod_drm_info_cache","text":"<ul> <li>syntax: <code>vod_drm_info_cache zone_name zone_size [expiration]</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Configures the size and shared memory object name of the drm info cache.</p>"},{"location":"modules/vod/#vod_drm_request_uri","title":"vod_drm_request_uri","text":"<ul> <li>syntax: <code>vod_drm_request_uri uri</code></li> <li>default: <code>$vod_suburi</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the uri of drm info requests, the parameter value can contain variables. In case of multi url, <code>$vod_suburi</code> will be the current sub uri (a separate drm info request is issued per sub URL)</p>"},{"location":"modules/vod/#vod_min_single_nalu_per_frame_segment","title":"vod_min_single_nalu_per_frame_segment","text":"<ul> <li>syntax: <code>vod_min_single_nalu_per_frame_segment index</code></li> <li>default: <code>0</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the minimum segment index (1-based) that should be assumed to have a single h264 nalu per frame. If the value is 0, no assumption is being made on the number of nal units per frame. This setting only affects DASH and MSS configurations that have DRM enabled.</p> <p>When transcoding videos using libx264, by default, all frames have a single nal unit, except the first frame that contains an additional nalu with the libx264 copyright information. Setting this parameter to a value greater than 0 can provide a significant performance improvement, since the layout of the segment can be calculated in advance, allowing the module to: * Output segment buffers as they are generated (it doesn't have to wait for the whole segment to complete) * Avoid frame processing for requests that do not need the segment data (e.g. HEAD, range 0-0, etc.)</p>"},{"location":"modules/vod/#configuration-directives-dash","title":"Configuration directives - DASH","text":""},{"location":"modules/vod/#vod_dash_absolute_manifest_urls","title":"vod_dash_absolute_manifest_urls","text":"<ul> <li>syntax: <code>vod_dash_absolute_manifest_urls on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns absolute URLs in MPD requests</p>"},{"location":"modules/vod/#vod_dash_manifest_file_name_prefix","title":"vod_dash_manifest_file_name_prefix","text":"<ul> <li>syntax: <code>vod_dash_manifest_file_name_prefix name</code></li> <li>default: <code>manifest</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the MPD file (an mpd extension is implied).</p>"},{"location":"modules/vod/#vod_dash_profiles","title":"vod_dash_profiles","text":"<ul> <li>syntax: <code>vod_dash_profiles profiles</code></li> <li>default: <code>urn:mpeg:dash:profile:isoff-main:2011</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the profiles that are returned in the MPD tag in manifest responses.</p>"},{"location":"modules/vod/#vod_dash_init_file_name_prefix","title":"vod_dash_init_file_name_prefix","text":"<ul> <li>syntax: <code>vod_dash_init_file_name_prefix name</code></li> <li>default: <code>init</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the MP4 initialization file (an mp4 extension is implied).</p>"},{"location":"modules/vod/#vod_dash_fragment_file_name_prefix","title":"vod_dash_fragment_file_name_prefix","text":"<ul> <li>syntax: <code>vod_dash_fragment_file_name_prefix name</code></li> <li>default: <code>frag</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the fragment files (an m4s extension is implied).</p>"},{"location":"modules/vod/#vod_dash_manifest_format","title":"vod_dash_manifest_format","text":"<ul> <li>syntax: <code>vod_dash_manifest_format format</code></li> <li>default: <code>segmenttimeline</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the MPD format, available options are: * <code>segmentlist</code> - uses SegmentList and SegmentURL tags, in this format the URL of each fragment is explicitly set in the MPD * <code>segmenttemplate</code> - uses SegmentTemplate, reporting a single duration for all fragments * <code>segmenttimeline</code> - uses SegmentTemplate and SegmentTimeline to explicitly set the duration of the fragments</p>"},{"location":"modules/vod/#vod_dash_subtitle_format","title":"vod_dash_subtitle_format","text":"<ul> <li>syntax: <code>vod_dash_subtitle_format format</code></li> <li>default: <code>webvtt</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the format of the subtitles returned in the MPD, available options are: * <code>webvtt</code> - WebVTT * <code>smpte-tt</code> - SMPTE Timed Text</p>"},{"location":"modules/vod/#vod_dash_init_mp4_pssh","title":"vod_dash_init_mp4_pssh","text":"<ul> <li>syntax: <code>vod_dash_init_mp4_pssh on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the DRM pssh boxes are returned in the DASH init segment and in the manifest. When disabled, the pssh boxes are returned only in the manifest.</p>"},{"location":"modules/vod/#vod_dash_duplicate_bitrate_threshold","title":"vod_dash_duplicate_bitrate_threshold","text":"<ul> <li>syntax: <code>vod_dash_duplicate_bitrate_threshold threshold</code></li> <li>default: <code>4096</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The bitrate threshold for removing identical bitrates, streams whose bitrate differences are less than this value will be considered identical.</p>"},{"location":"modules/vod/#vod_dash_use_base_url_tag","title":"vod_dash_use_base_url_tag","text":"<ul> <li>syntax: <code>vod_dash_use_base_url_tag on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, a BaseURL tag will be used to specify the fragments/init segment base url. Otherwise, the media/initialization attributes under SegmentTemplate will contain absolute URLs. </p>"},{"location":"modules/vod/#configuration-directives-hds","title":"Configuration directives - HDS","text":""},{"location":"modules/vod/#vod_hds_absolute_manifest_urls","title":"vod_hds_absolute_manifest_urls","text":"<ul> <li>syntax: <code>vod_hds_absolute_manifest_urls on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns the base URL in the F4M manifest</p>"},{"location":"modules/vod/#vod_hds_manifest_file_name_prefix","title":"vod_hds_manifest_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hds_manifest_file_name_prefix name</code></li> <li>default: <code>manifest</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the HDS manifest file (an f4m extension is implied).</p>"},{"location":"modules/vod/#vod_hds_fragment_file_name_prefix","title":"vod_hds_fragment_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hds_fragment_file_name_prefix name</code></li> <li>default: <code>frag</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The prefix of fragment file names, the actual file name is <code>frag-f&lt;file-index&gt;-v&lt;video-track-index&gt;-a&lt;audio-track-index&gt;-Seg1-Frag&lt;index&gt;</code>.</p>"},{"location":"modules/vod/#vod_hds_generate_moof_atom","title":"vod_hds_generate_moof_atom","text":"<ul> <li>syntax: <code>vod_hds_generate_moof_atom on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the module generates a moof atom in the HDS fragments, when disabled only an mdat atom is generated. Turning this parameter off reduces the packaging overhead, however the default is on since Adobe tools are generating this atom.</p>"},{"location":"modules/vod/#configuration-directives-hls","title":"Configuration directives - HLS","text":""},{"location":"modules/vod/#vod_hls_encryption_method","title":"vod_hls_encryption_method","text":"<ul> <li>syntax: <code>vod_hls_encryption_method method</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the encryption method of HLS segments, allowed values are: none (default), aes-128, sample-aes, sample-aes-cenc.</p>"},{"location":"modules/vod/#vod_hls_force_unmuxed_segments","title":"vod_hls_force_unmuxed_segments","text":"<ul> <li>syntax: <code>vod_hls_force_unmuxed_segments on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns the audio stream in separate segments than the ones used by the video stream (using EXT-X-MEDIA)</p>"},{"location":"modules/vod/#vod_hls_container_format","title":"vod_hls_container_format","text":"<ul> <li>syntax: <code>vod_hls_container_format mpegts/fmp4/auto</code></li> <li>default: <code>auto</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the container format of the HLS segments.  The default behavior is to use fmp4 for HEVC, and mpegts otherwise (Apple does not support HEVC over MPEG TS).</p>"},{"location":"modules/vod/#vod_hls_absolute_master_urls","title":"vod_hls_absolute_master_urls","text":"<ul> <li>syntax: <code>vod_hls_absolute_master_urls on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns absolute playlist URLs in master playlist requests</p>"},{"location":"modules/vod/#vod_hls_absolute_index_urls","title":"vod_hls_absolute_index_urls","text":"<ul> <li>syntax: <code>vod_hls_absolute_index_urls on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns absolute segment URLs in media playlist requests</p>"},{"location":"modules/vod/#vod_hls_absolute_iframe_urls","title":"vod_hls_absolute_iframe_urls","text":"<ul> <li>syntax: <code>vod_hls_absolute_iframe_urls on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled the server returns absolute segment URLs in iframe playlist requests</p>"},{"location":"modules/vod/#vod_hls_output_iframes_playlist","title":"vod_hls_output_iframes_playlist","text":"<ul> <li>syntax: <code>vod_hls_output_iframes_playlist on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When disabled iframe playlists are not returned as part of master playlists</p>"},{"location":"modules/vod/#vod_hls_master_file_name_prefix","title":"vod_hls_master_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hls_master_file_name_prefix name</code></li> <li>default: <code>master</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the HLS master playlist file (an m3u8 extension is implied).</p>"},{"location":"modules/vod/#vod_hls_index_file_name_prefix","title":"vod_hls_index_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hls_index_file_name_prefix name</code></li> <li>default: <code>index</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the HLS media playlist file (an m3u8 extension is implied).</p>"},{"location":"modules/vod/#vod_hls_iframes_file_name_prefix","title":"vod_hls_iframes_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hls_iframes_file_name_prefix name</code></li> <li>default: <code>iframes</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the HLS I-frames playlist file (an m3u8 extension is implied).</p>"},{"location":"modules/vod/#vod_hls_segment_file_name_prefix","title":"vod_hls_segment_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hls_segment_file_name_prefix name</code></li> <li>default: <code>seg</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The prefix of segment file names, the actual file name is <code>seg-&lt;index&gt;-v&lt;video-track-index&gt;-a&lt;audio-track-index&gt;.ts</code>.</p>"},{"location":"modules/vod/#vod_hls_init_file_name_prefix","title":"vod_hls_init_file_name_prefix","text":"<ul> <li>syntax: <code>vod_hls_init_file_name_prefix name</code></li> <li>default: <code>init</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the init segment file name, only relevant when using fmp4 container.</p>"},{"location":"modules/vod/#vod_hls_encryption_key_file_name","title":"vod_hls_encryption_key_file_name","text":"<ul> <li>syntax: <code>vod_hls_encryption_key_file_name name</code></li> <li>default: <code>encryption.key</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the encryption key file name, only relevant when encryption method is not <code>none</code>.</p>"},{"location":"modules/vod/#vod_hls_encryption_key_uri","title":"vod_hls_encryption_key_uri","text":"<ul> <li>syntax: <code>vod_hls_encryption_key_uri uri</code></li> <li>default: <code>a url pointing to encryption.key</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the URI attribute of EXT-X-KEY, only relevant when encryption method is not <code>none</code>. The parameter value can contain variables.</p>"},{"location":"modules/vod/#vod_hls_encryption_key_format","title":"vod_hls_encryption_key_format","text":"<ul> <li>syntax: <code>vod_hls_encryption_key_format format</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the KEYFORMAT attribute of EXT-X-KEY, only relevant when encryption method is not <code>none</code>.</p>"},{"location":"modules/vod/#vod_hls_encryption_key_format_versions","title":"vod_hls_encryption_key_format_versions","text":"<ul> <li>syntax: <code>vod_hls_encryption_key_format_versions versions</code></li> <li>default: <code>none</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the value of the KEYFORMATVERSIONS attribute of EXT-X-KEY, only relevant when encryption method is not <code>none</code>.</p>"},{"location":"modules/vod/#vod_hls_mpegts_interleave_frames","title":"vod_hls_mpegts_interleave_frames","text":"<ul> <li>syntax: <code>vod_hls_mpegts_interleave_frames on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the HLS muxer interleaves frames of different streams (audio / video). When disabled, on every switch between audio / video the muxer flushes the MPEG TS packet.</p>"},{"location":"modules/vod/#vod_hls_mpegts_align_frames","title":"vod_hls_mpegts_align_frames","text":"<ul> <li>syntax: <code>vod_hls_mpegts_align_frames on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, every video / audio frame is aligned to MPEG TS packet boundary, padding is added as needed.</p>"},{"location":"modules/vod/#vod_hls_mpegts_output_id3_timestamps","title":"vod_hls_mpegts_output_id3_timestamps","text":"<ul> <li>syntax: <code>vod_hls_mpegts_output_id3_timestamps on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, an ID3 TEXT frame is outputted in each TS segment. The content of the ID3 TEXT frame can be set using the directive <code>vod_hls_mpegts_id3_data</code>.</p>"},{"location":"modules/vod/#vod_hls_mpegts_id3_data","title":"vod_hls_mpegts_id3_data","text":"<ul> <li>syntax: <code>vod_hls_mpegts_id3_data string</code></li> <li>default: <code>{\"timestamp\":$vod_segment_time,\"sequenceId\":\"$vod_sequence_id\"}</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the data of the ID3 TEXT frame outputted in each TS segment, when <code>vod_hls_mpegts_output_id3_timestamps</code> is set to <code>on</code>. When the directive is not set, the ID3 frames contain by default a JSON object of the format <code>{\"timestamp\":1459779115000,\"sequenceId\":\"{id}\"}</code>: - <code>timestamp</code> - an absolute time measured in milliseconds since the epoch (unixtime x 1000). - <code>sequenceId</code> - the id field of the sequence object, as specified in the mapping JSON. The field is omitted when the sequence id is empty / not specified in the mapping JSON. The parameter value can contain variables.</p>"},{"location":"modules/vod/#vod_hls_mpegts_align_pts","title":"vod_hls_mpegts_align_pts","text":"<ul> <li>syntax: <code>vod_hls_mpegts_align_pts on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module will shift back the dts timestamps by the pts delay of the initial frame. This can help keep the pts timestamps aligned across multiple renditions.</p>"},{"location":"modules/vod/#configuration-directives-mss","title":"Configuration directives - MSS","text":""},{"location":"modules/vod/#vod_mss_manifest_file_name_prefix","title":"vod_mss_manifest_file_name_prefix","text":"<ul> <li>syntax: <code>vod_mss_manifest_file_name_prefix name</code></li> <li>default: <code>manifest</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the manifest file (has no extension).</p>"},{"location":"modules/vod/#vod_mss_duplicate_bitrate_threshold","title":"vod_mss_duplicate_bitrate_threshold","text":"<ul> <li>syntax: <code>vod_mss_duplicate_bitrate_threshold threshold</code></li> <li>default: <code>4096</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The bitrate threshold for removing identical bitrates, streams whose bitrate differences are less than this value will be considered identical.</p>"},{"location":"modules/vod/#configuration-directives-thumbnail-capture","title":"Configuration directives - thumbnail capture","text":""},{"location":"modules/vod/#vod_thumb_file_name_prefix","title":"vod_thumb_file_name_prefix","text":"<ul> <li>syntax: <code>vod_thumb_file_name_prefix name</code></li> <li>default: <code>thumb</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the thumbnail file (a jpg extension is implied).</p>"},{"location":"modules/vod/#vod_thumb_accurate_positioning","title":"vod_thumb_accurate_positioning","text":"<ul> <li>syntax: <code>vod_thumb_accurate_positioning on/off</code></li> <li>default: <code>on</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module grabs the frame that is closest to the requested offset. When disabled, the module uses the keyframe that is closest to the requested offset. Setting this parameter to off can result in faster thumbnail capture, since the module  always decodes a single video frame per request.</p>"},{"location":"modules/vod/#vod_gop_look_behind","title":"vod_gop_look_behind","text":"<ul> <li>syntax: <code>vod_gop_look_behind millis</code></li> <li>default: <code>10000</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the interval (in milliseconds) before the thumbnail offset that should be loaded. This setting should be set to the maximum GOP size, setting it to a lower value may result in capture failure. Note that the metadata of all frames between <code>offset - vod_gop_look_behind</code> and <code>offset + vod_gop_look_ahead</code> is loaded, however only the frames of the minimum GOP containing <code>offset</code> will be read and decoded.</p>"},{"location":"modules/vod/#vod_gop_look_ahead","title":"vod_gop_look_ahead","text":"<ul> <li>syntax: <code>vod_gop_look_ahead millis</code></li> <li>default: <code>1000</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the interval (in milliseconds) after the thumbnail offset that should be loaded.</p>"},{"location":"modules/vod/#configuration-directives-volume-map","title":"Configuration directives - volume map","text":""},{"location":"modules/vod/#vod_volume_map_file_name_prefix","title":"vod_volume_map_file_name_prefix","text":"<ul> <li>syntax: <code>vod_volume_map_file_name_prefix name</code></li> <li>default: <code>volume_map</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>The name of the volume map file (a csv extension is implied).</p>"},{"location":"modules/vod/#vod_volume_map_interval","title":"vod_volume_map_interval","text":"<ul> <li>syntax: <code>vod_volume_map_interval millis</code></li> <li>default: <code>1000</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>Sets the interval/resolution (in milliseconds) of the volume map.</p>"},{"location":"modules/vod/#configuration-directives-misc","title":"Configuration directives - misc","text":""},{"location":"modules/vod/#vod_ignore_edit_list","title":"vod_ignore_edit_list","text":"<ul> <li>syntax: <code>vod_ignore_edit_list on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module ignores any edit lists (elst) in the MP4 file.</p>"},{"location":"modules/vod/#vod_parse_hdlr_name","title":"vod_parse_hdlr_name","text":"<ul> <li>syntax: <code>vod_parse_hdlr_name on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module parses the name field of the hdlr MP4 atom, and uses it as the stream label.</p>"},{"location":"modules/vod/#vod_parse_udta_name","title":"vod_parse_udta_name","text":"<ul> <li>syntax: <code>vod_parse_udta_name on/off</code></li> <li>default: <code>off</code></li> <li>context: <code>http</code>, <code>server</code>, <code>location</code></li> </ul> <p>When enabled, the module parses the name atom child of the udta MP4 atom, and uses it as the stream label.</p>"},{"location":"modules/vod/#nginx-variables","title":"Nginx variables","text":"<p>The module adds the following nginx variables: * <code>$vod_suburi</code> - the current sub uri. For example, if the url is:   <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;,&lt;middle1&gt;,&lt;middle2&gt;,&lt;middle3&gt;,&lt;postfix&gt;.urlset/&lt;filename&gt;</code> <code>$vod_suburi</code> will have the value <code>http://&lt;domain&gt;/&lt;location&gt;/&lt;prefix&gt;&lt;middle1&gt;&lt;postfix&gt;/&lt;filename&gt;</code>    when processing the first uri. * <code>$vod_filepath</code> - in local / mapped modes, the file path of current sub uri. In remote mode, has the same value as <code>$vod_suburi</code>. * <code>$vod_set_id</code> - contains the id of the set. * <code>$vod_sequence_id</code> - contains the id of the current sequence, if no id was specified in the mapping json this variable will be the same as <code>$vod_suburi</code>. * <code>$vod_clip_id</code> - the id of the current clip, this variable has a value during these phases:   1. Mapping of dynamic clips to concat clips   2. Mapping of source clip to paths * <code>$vod_notification_id</code> - the id of the current notification, the value is non-empty only when referenced by <code>vod_notification_uri</code> * <code>$vod_dynamic_mapping</code> - a serialized representation of the mapping of dynamic clips to concat clips. * <code>$vod_request_params</code> - a serialized representation of the request params, e.g. 12-f2-v1-a1. The variable contains:   1. The segment index (for a segment request)   2. The sequence index   3. A selection of audio/video tracks * <code>$vod_status</code> - the internal error code of the module, provides a more fine grained classification of errors than http status.     the following values are defined:     <code>BAD_REQUEST</code> - the request is invalid, for example, <code>clipFrom</code> is larger than the video duration     <code>NO_STREAMS</code> - an invalid segment index was requested     <code>EMPTY_MAPPING</code> - the mapping response is empty     <code>BAD_MAPPING</code> - the mapping json is invalid, for example, the <code>sequences</code> element is missing     <code>BAD_DATA</code> - the video file is corrupt     <code>EXPIRED</code> - the current server time is larger than <code>expirationTime</code> <code>ALLOC_FAILED</code> - the module failed to allocate memory     <code>UNEXPECTED</code> - a scenario that is not supposed to happen, most likely a bug in the module * <code>$vod_segment_time</code> - for segment requests, contains the absolute timestamp of the first frame in the segment, measured in milliseconds since the epoch (unixtime x 1000). * <code>$vod_segment_duration</code> - for segment requests, contains the duration of the segment in milliseconds * <code>$vod_frames_bytes_read</code> - for segment requests, total number of bytes read while processing media frames</p> <p>Note: Configuration directives that can accept variables are explicitly marked as such.</p>"},{"location":"modules/vod/#sample-configurations_1","title":"Sample configurations","text":""},{"location":"modules/vod/#local-configuration","title":"Local configuration","text":"<pre><code>    http {\n        upstream fallback {\n            server fallback.kaltura.com:80;\n        }\n\n        server {\n            # vod settings\n            vod_mode local;\n            vod_fallback_upstream_location /fallback;\n            vod_last_modified 'Sun, 19 Nov 2000 08:52:00 GMT';\n            vod_last_modified_types *;\n\n            # vod caches\n            vod_metadata_cache metadata_cache 512m;\n            vod_response_cache response_cache 128m;\n\n            # gzip manifests\n            gzip on;\n            gzip_types application/vnd.apple.mpegurl;\n\n            # file handle caching / aio\n            open_file_cache          max=1000 inactive=5m;\n            open_file_cache_valid    2m;\n            open_file_cache_min_uses 1;\n            open_file_cache_errors   on;\n            aio on;\n\n            location ^~ /fallback/ {\n                internal;\n                proxy_pass http://fallback/;\n                proxy_set_header Host $http_host;\n            }\n\n            location /content/ {\n                root /web/;\n                vod hls;\n\n                add_header Access-Control-Allow-Headers '*';\n                add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n                add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n                add_header Access-Control-Allow-Origin '*';\n                expires 100d;\n            }\n        }\n    }\n</code></pre>"},{"location":"modules/vod/#mapped-configuration","title":"Mapped configuration","text":"<pre><code>    http {\n        upstream kalapi {\n            server www.kaltura.com:80;\n        }\n\n        upstream fallback {\n            server fallback.kaltura.com:80;\n        }\n\n        server {\n            # vod settings\n            vod_mode mapped;\n            vod_upstream_location /kalapi;\n            vod_upstream_extra_args \"pathOnly=1\";\n            vod_fallback_upstream_location /fallback;\n            vod_last_modified 'Sun, 19 Nov 2000 08:52:00 GMT';\n            vod_last_modified_types *;\n\n            # vod caches\n            vod_metadata_cache metadata_cache 512m;\n            vod_response_cache response_cache 128m;\n            vod_mapping_cache mapping_cache 5m;\n\n            # gzip manifests\n            gzip on;\n            gzip_types application/vnd.apple.mpegurl;\n\n            # file handle caching / aio\n            open_file_cache          max=1000 inactive=5m;\n            open_file_cache_valid    2m;\n            open_file_cache_min_uses 1;\n            open_file_cache_errors   on;\n            aio on;\n\n            location ^~ /fallback/ {\n                internal;\n                proxy_pass http://fallback/;\n                proxy_set_header Host $http_host;\n            }\n\n            location ^~ /kalapi/ {\n                internal;\n                proxy_pass http://kalapi/;\n                proxy_set_header Host $http_host;\n            }\n\n            location ~ ^/p/\\d+/(sp/\\d+/)?serveFlavor/ {\n                # encrypted hls\n                vod hls;\n                vod_secret_key \"mukkaukk$vod_filepath\";\n                vod_hls_encryption_method aes-128;\n\n                add_header Access-Control-Allow-Headers '*';\n                add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n                add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n                add_header Access-Control-Allow-Origin '*';\n                expires 100d;\n            }\n        }\n    }\n</code></pre>"},{"location":"modules/vod/#mapped-remote-configuration","title":"Mapped + Remote configuration","text":"<pre><code>    http {\n        upstream jsonupstream {\n            server jsonserver:80;\n        }\n\n        server {\n            # vod settings\n            vod_mode mapped;\n            vod_upstream_location /json;\n            vod_remote_upstream_location /proxy;\n            vod_upstream_extra_args \"pathOnly=1\";\n            vod_last_modified 'Sun, 19 Nov 2000 08:52:00 GMT';\n            vod_last_modified_types *;\n\n            # vod caches\n            vod_metadata_cache metadata_cache 512m;\n            vod_response_cache response_cache 128m;\n            vod_mapping_cache mapping_cache 5m;\n\n            # gzip manifests\n            gzip on;\n            gzip_types application/vnd.apple.mpegurl;\n\n            # file handle caching / aio\n            open_file_cache   max=1000 inactive=5m;\n            open_file_cache_valid    2m;\n            open_file_cache_min_uses 1;\n            open_file_cache_errors   on;\n            aio on;\n\n            location ^~ /json/hls/ {\n                internal;\n                proxy_pass http://jsonupstream/;\n                proxy_set_header Host $http_host;\n            }\n\n            location ~ /proxy/([^/]+)/(.*) {\n                internal;\n                proxy_pass $1://$2;\n                resolver 8.8.8.8;\n            }\n\n            location ~ ^/hls/ {\n                vod hls;\n\n                add_header Access-Control-Allow-Headers '*';\n                add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n                add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n                add_header Access-Control-Allow-Origin '*';\n                expires 100d;\n            }\n        }\n    }\n</code></pre> <p>Set it up so that http://jsonserver:80/test.json returns the following JSON: <pre><code>    {\n        \"sequences\": [{\n            \"clips\": [{\n                \"type\": \"source\",\n                \"path\": \"/http/commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\"\n            }]\n        }]\n    }\n</code></pre></p> <p>And use this stream URL - http://nginx-vod-server/hls/test.json/master.m3u8</p>"},{"location":"modules/vod/#remote-configuration","title":"Remote configuration","text":"<pre><code>    http {\n        upstream kalapi {\n            server www.kaltura.com:80;\n        }\n\n        server {\n            # vod settings\n            vod_mode remote;\n            vod_upstream_location /kalapi;\n            vod_last_modified 'Sun, 19 Nov 2000 08:52:00 GMT';\n            vod_last_modified_types *;\n\n            # vod caches\n            vod_metadata_cache metadata_cache 512m;\n            vod_response_cache response_cache 128m;\n\n            # gzip manifests\n            gzip on;\n            gzip_types application/vnd.apple.mpegurl;\n\n            location ^~ /kalapi/ {\n                internal;\n                proxy_pass http://kalapi/;\n                proxy_set_header Host $http_host;\n            }\n\n            location ~ ^/p/\\d+/(sp/\\d+/)?serveFlavor/ {\n                vod hls;\n\n                add_header Access-Control-Allow-Headers '*';\n                add_header Access-Control-Expose-Headers 'Server,range,Content-Length,Content-Range';\n                add_header Access-Control-Allow-Methods 'GET, HEAD, OPTIONS';\n                add_header Access-Control-Allow-Origin '*';\n                expires 100d;\n            }\n        }\n    }\n</code></pre>"},{"location":"modules/vod/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-vod.</p>"},{"location":"modules/vts/","title":"vts: NGINX virtual host traffic status module","text":""},{"location":"modules/vts/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-vts\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-vts\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_vhost_traffic_status_module.so;\n</code></pre> <p>This document describes nginx-module-vts v0.2.4  released on Mar 12 2025.</p> <p> </p> <p>Nginx virtual host traffic status module</p>"},{"location":"modules/vts/#test","title":"Test","text":"<p>Run <code>sudo prove -r t</code> after you have installed this module. The <code>sudo</code> is required because the test requires Nginx to listen on port 80.</p>"},{"location":"modules/vts/#screenshots","title":"Screenshots","text":""},{"location":"modules/vts/#_1","title":"NGINX virtual host traffic status module","text":""},{"location":"modules/vts/#synopsis","title":"Synopsis","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/vts/#description","title":"Description","text":"<p>This is an Nginx module that provides access to virtual host status information. It contains the current status such as servers, upstreams, caches. This is similar to the live activity monitoring of nginx plus. The built-in html is also taken from the demo page of old version.</p> <p>First of all, the directive <code>vhost_traffic_status_zone</code> is required, and then if the directive <code>vhost_traffic_status_display</code> is set, can be access to as follows:</p> <ul> <li>/status/format/json</li> <li>If you request <code>/status/format/json</code>, will respond with a JSON document containing the current activity data for using in live dashboards and third-party monitoring tools.</li> <li>/status/format/html</li> <li>If you request <code>/status/format/html</code>, will respond with the built-in live dashboard in HTML that requests internally to <code>/status/format/json</code>.</li> <li>/status/format/jsonp</li> <li>If you request <code>/status/format/jsonp</code>, will respond with a JSONP callback function containing the current activity data for using in live dashboards and third-party monitoring tools. </li> <li>/status/format/prometheus</li> <li>If you request <code>/status/format/prometheus</code>, will respond with a prometheus document containing the current activity data.</li> <li>/status/control</li> <li>If you request <code>/status/control</code>, will respond with a JSON document after it reset or delete zones through a query string. See the Control.</li> </ul> <p>JSON document contains as follows:</p> <pre><code>{\n    \"hostName\": ...,\n    \"moduleVersion\": ...,\n    \"nginxVersion\": ...,\n    \"loadMsec\": ...,\n    \"nowMsec\": ...,\n    \"connections\": {\n        \"active\":...,\n        \"reading\":...,\n        \"writing\":...,\n        \"waiting\":...,\n        \"accepted\":...,\n        \"handled\":...,\n        \"requests\":...\n    },\n    \"sharedZones\": {\n        \"name\":...,\n        \"maxSize\":...,\n        \"usedSize\":...,\n        \"usedNode\":...\n    },\n    \"serverZones\": {\n        \"...\":{\n            \"requestCounter\":...,\n            \"inBytes\":...,\n            \"outBytes\":...,\n            \"responses\":{\n                \"1xx\":...,\n                \"2xx\":...,\n                \"3xx\":...,\n                \"4xx\":...,\n                \"5xx\":...,\n                \"miss\":...,\n                \"bypass\":...,\n                \"expired\":...,\n                \"stale\":...,\n                \"updating\":...,\n                \"revalidated\":...,\n                \"hit\":...,\n                \"scarce\":...\n            },\n            \"requestMsecCounter\":...,\n            \"requestMsec\":...,\n            \"requestMsecs\":{\n                \"times\":[...],\n                \"msecs\":[...]\n            },\n            \"requestBuckets\":{\n                \"msecs\":[...],\n                \"counters\":[...]\n            },\n        }\n        ...\n    },\n    \"filterZones\": {\n        \"...\":{\n            \"...\":{\n                \"requestCounter\":...,\n                \"inBytes\":...,\n                \"outBytes\":...,\n                \"responses\":{\n                    \"1xx\":...,\n                    \"2xx\":...,\n                    \"3xx\":...,\n                    \"4xx\":...,\n                    \"5xx\":...,\n                    \"miss\":...,\n                    \"bypass\":...,\n                    \"expired\":...,\n                    \"stale\":...,\n                    \"updating\":...,\n                    \"revalidated\":...,\n                    \"hit\":...,\n                    \"scarce\":...\n                },\n                \"requestMsecCounter\":...,\n                \"requestMsec\":...,\n                \"requestMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"requestBuckets\":{\n                    \"msecs\":[...],\n                    \"counters\":[...]\n                },\n            },\n            ...\n        },\n        ...\n    },\n    \"upstreamZones\": {\n        \"...\":[\n            {\n                \"server\":...,\n                \"requestCounter\":...,\n                \"inBytes\":...,\n                \"outBytes\":...,\n                \"responses\":{\n                    \"1xx\":...,\n                    \"2xx\":...,\n                    \"3xx\":...,\n                    \"4xx\":...,\n                    \"5xx\":...\n                },\n                \"requestMsecCounter\":...,\n                \"requestMsec\":...,\n                \"requestMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"requestBuckets\":{\n                    \"msecs\":[...],\n                    \"counters\":[...]\n                },\n                \"responseMsecCounter\":...,\n                \"responseMsec\":...,\n                \"responseMsecs\":{\n                    \"times\":[...],\n                    \"msecs\":[...]\n                },\n                \"responseBuckets\":{\n                    \"msecs\":[...],\n                    \"counters\":[...]\n                },\n                \"weight\":...,\n                \"maxFails\":...,\n                \"failTimeout\":...,\n                \"backup\":...,\n                \"down\":...\n            }\n            ...\n        ],\n        ...\n    }\n    \"cacheZones\": {\n        \"...\":{\n            \"maxSize\":...,\n            \"usedSize\":...,\n            \"inBytes\":...,\n            \"outBytes\":...,\n            \"responses\":{\n                \"miss\":...,\n                \"bypass\":...,\n                \"expired\":...,\n                \"stale\":...,\n                \"updating\":...,\n                \"revalidated\":...,\n                \"hit\":...,\n                \"scarce\":...\n            }\n        },\n        ...\n    }\n}\n</code></pre> <ul> <li>main</li> <li>Basic version, uptime((nowMsec - loadMsec)/1000)</li> <li>nowMsec, loadMsec is a millisecond.</li> <li>connections</li> <li>Total connections and requests(same as stub_status_module in NGINX)</li> <li>sharedZones</li> <li>The shared memory information using in nginx-module-vts.</li> <li>serverZones</li> <li>Traffic(in/out) and request and response counts and cache hit ratio per each server zone</li> <li>Total traffic(In/Out) and request and response counts(It zone name is <code>*</code>) and hit ratio</li> <li>filterZones</li> <li>Traffic(in/out) and request and response counts and cache hit ratio per each server zone filtered through the <code>vhost_traffic_status_filter_by_set_key</code> directive</li> <li>Total traffic(In/Out) and request and response counts(It zone name is <code>*</code>) and hit ratio filtered through the <code>vhost_traffic_status_filter_by_set_key</code> directive</li> <li>upstreamZones</li> <li>Traffic(in/out) and request and response counts per server in each upstream group</li> <li>Current settings(weight, maxfails, failtimeout...) in nginx.conf</li> <li>cacheZones</li> <li>Traffic(in/out) and size(capacity/used) and hit ratio per each cache zone when using the proxy_cache directive.</li> </ul> <p>The <code>overCounts</code> objects in JSON document are mostly for 32bit system and will be increment by 1 if its value is overflowed. The directive <code>vhost_traffic_status_display_format</code> sets the default ouput format that is one of json, jsonp, html, prometheus. (Default: json)</p> <p>Traffic calculation as follows:</p> <ul> <li>ServerZones</li> <li>in += requested_bytes</li> <li>out += sent_bytes</li> <li>FilterZones</li> <li>in += requested_bytes via the filter</li> <li>out += sent_bytes via the filter</li> <li>UpstreamZones</li> <li>in += requested_bytes via the ServerZones</li> <li>out += sent_bytes via the ServerZones</li> <li>cacheZones</li> <li>in += requested_bytes via the ServerZones</li> <li>out += sent_bytes via the ServerZones</li> </ul> <p>All calculations are working in log processing phase of Nginx. Internal redirects(X-Accel-Redirect or error_page) does not calculate in the UpstreamZones.</p> <p><code>Caveats:</code> this module relies on nginx logging system(NGX_HTTP_LOG_PHASE:last phase of the nginx http), so the traffic may be in certain cirumstances different that real bandwidth traffic. Websocket, canceled downloads may be cause of inaccuracies. The working of the module doesn't matter at all whether the access_log directive \"on\" or \"off\". Again, this module works well on \"access_log off\". When using several domains it sets to be first domain(left) of server_name directive. If you don't want it, see the vhost_traffic_status_filter_by_host, vhost_traffic_status_filter_by_set_key directive.</p> <p>See the following modules for the <code>stream</code> traffic statistics: * nginx-module-sts * nginx-module-stream-sts</p>"},{"location":"modules/vts/#calculations-and-intervals","title":"Calculations and Intervals","text":""},{"location":"modules/vts/#averages","title":"Averages","text":"<p>All averages are currently calculated as AMM(Arithmetic Mean) over the last 64 values.</p>"},{"location":"modules/vts/#control","title":"Control","text":"<p>It is able to reset or delete traffic zones through a query string. The request responds with a JSON document.</p> <ul> <li>URI Syntax</li> <li>/<code>{status_uri}</code>/control?cmd=<code>{command}</code>&amp;group=<code>{group}</code>&amp;zone=<code>{name}</code></li> </ul> <pre><code>http {\n\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    vhost_traffic_status_zone;\n    vhost_traffic_status_filter_by_set_key $geoip_country_code country::*;\n\n    ...\n\n    server {\n\n        server_name example.org;\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <p>If it set as above, then the control uri is like <code>example.org/status/control</code>.</p> <p>The available request arguments are as follows: * cmd=\\&lt;<code>status</code>|<code>reset</code>|<code>delete</code>&gt;   * status     * It returns status of traffic zones to json format like <code>status/format/json</code>.   * reset     * It reset traffic zones without deleting nodes in shared memory.(= init to 0)   * delete     * It delete traffic zones in shared memory. when re-request recreated.  * group=\\&lt;<code>server</code>|<code>filter</code>|<code>upstream@alone</code>|<code>upstream@group</code>|<code>cache</code>|<code>*</code>&gt;   * server   * filter   * upstream@alone   * upstream@group   * cache   * * * zone=name   * server     * name   * filter     * filter_group@name   * upstream@group     * upstream_group@name   * upstream@alone     * @name   * cache     * name</p>"},{"location":"modules/vts/#to-get-status-of-traffic-zones-on-the-fly","title":"To get status of traffic zones on the fly","text":"<p>This is similar to the <code>status/format/json</code> except that it can get each zones.</p>"},{"location":"modules/vts/#to-get-fully-zones","title":"To get fully zones","text":"<ul> <li>It is exactly the same with the <code>status/format/json</code>.</li> <li>/status/control?cmd=status&amp;group=*</li> </ul>"},{"location":"modules/vts/#to-get-group-zones","title":"To get group zones","text":"<ul> <li>mainZones</li> <li>/status/control?cmd=status&amp;group=server&amp;zone=::main</li> <li>serverZones</li> <li>/status/control?cmd=status&amp;group=server&amp;zone=*</li> <li>filterZones</li> <li>/status/control?cmd=status&amp;group=filter&amp;zone=*</li> <li>upstreamZones</li> <li>/status/control?cmd=status&amp;group=upstream@group&amp;zone=*</li> <li>upstreamZones::nogroups</li> <li>/status/control?cmd=status&amp;group=upstream@alone&amp;zone=*</li> <li>cacheZones</li> <li>/status/control?cmd=status&amp;group=cache&amp;zone=*</li> </ul> <p>The mainZones values are default status values including <code>hostName</code>, <code>moduleVersion</code>, <code>nginxVersion</code>, <code>loadMsec</code>, <code>nowMsec</code>, <code>connections</code>.</p>"},{"location":"modules/vts/#to-get-each-zones","title":"To get each zones","text":"<ul> <li>single zone in serverZones</li> <li>/status/control?cmd=status&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in filterZones</li> <li>/status/control?cmd=status&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in upstreamZones</li> <li>/status/control?cmd=status&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in upstreamZones::nogroups</li> <li>/status/control?cmd=status&amp;group=upstream@alone&amp;zone=<code>name</code></li> <li>single zone in cacheZones</li> <li>/status/control?cmd=status&amp;group=cache&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/vts/#to-reset-traffic-zones-on-the-fly","title":"To reset traffic zones on the fly","text":"<p>It reset the values of specified zones to 0.</p>"},{"location":"modules/vts/#to-reset-fully-zones","title":"To reset fully zones","text":"<ul> <li>/status/control?cmd=reset&amp;group=*</li> </ul>"},{"location":"modules/vts/#to-reset-group-zones","title":"To reset group zones","text":"<ul> <li>serverZones</li> <li>/status/control?cmd=reset&amp;group=server&amp;zone=*</li> <li>filterZones</li> <li>/status/control?cmd=reset&amp;group=filter&amp;zone=*</li> <li>upstreamZones</li> <li>/status/control?cmd=reset&amp;group=upstream@group&amp;zone=*</li> <li>upstreamZones::nogroups</li> <li>/status/control?cmd=reset&amp;group=upstream@alone&amp;zone=*</li> <li>cacheZones</li> <li>/status/control?cmd=reset&amp;group=cache&amp;zone=*</li> </ul>"},{"location":"modules/vts/#to-reset-each-zones","title":"To reset each zones","text":"<ul> <li>single zone in serverZones</li> <li>/status/control?cmd=reset&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in filterZones</li> <li>/status/control?cmd=reset&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in upstreamZones</li> <li>/status/control?cmd=reset&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in upstreamZones::nogroups</li> <li>/status/control?cmd=reset&amp;group=upstream@alone&amp;zone=<code>name</code></li> <li>single zone in cacheZones</li> <li>/status/control?cmd=reset&amp;group=cache&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/vts/#to-delete-traffic-zones-on-the-fly","title":"To delete traffic zones on the fly","text":"<p>It delete the specified zones in shared memory.</p>"},{"location":"modules/vts/#to-delete-fully-zones","title":"To delete fully zones","text":"<ul> <li>/status/control?cmd=delete&amp;group=*</li> </ul>"},{"location":"modules/vts/#to-delete-group-zones","title":"To delete group zones","text":"<ul> <li>serverZones</li> <li>/status/control?cmd=delete&amp;group=server&amp;zone=*</li> <li>filterZones</li> <li>/status/control?cmd=delete&amp;group=filter&amp;zone=*</li> <li>upstreamZones</li> <li>/status/control?cmd=delete&amp;group=upstream@group&amp;zone=*</li> <li>upstreamZones::nogroups</li> <li>/status/control?cmd=delete&amp;group=upstream@alone&amp;zone=*</li> <li>cacheZones</li> <li>/status/control?cmd=delete&amp;group=cache&amp;zone=*</li> </ul>"},{"location":"modules/vts/#to-delete-each-zones","title":"To delete each zones","text":"<ul> <li>single zone in serverZones</li> <li>/status/control?cmd=delete&amp;group=server&amp;zone=<code>name</code></li> <li>single zone in filterZones</li> <li>/status/control?cmd=delete&amp;group=filter&amp;zone=<code>filter_group</code>@<code>name</code></li> <li>single zone in upstreamZones</li> <li>/status/control?cmd=delete&amp;group=upstream@group&amp;zone=<code>upstream_group</code>@<code>name</code></li> <li>single zone in upstreamZones::nogroups</li> <li>/status/control?cmd=delete&amp;group=upstream@alone&amp;zone=<code>name</code></li> <li>single zone in cacheZones</li> <li>/status/control?cmd=delete&amp;group=cache&amp;zone=<code>name</code></li> </ul>"},{"location":"modules/vts/#set","title":"Set","text":"<p>It can get the status values in nginx configuration separately using <code>vhost_traffic_status_set_by_filter</code> directive. It can acquire almost all status values and the obtained value is stored in user-defined-variable which is first argument.</p> <ul> <li>Directive Syntax</li> <li>vhost_traffic_status_set_by_filter $variable group/zone/name</li> </ul> <pre><code>http {\n\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    vhost_traffic_status_zone;\n    vhost_traffic_status_filter_by_set_key $geoip_country_code country::*;\n\n    ...\n    upstream backend {\n        10.10.10.11:80;\n        10.10.10.12:80;\n    }\n\n    server {\n\n        server_name example.org;\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n\n        vhost_traffic_status_set_by_filter $requestCounter server/example.org/requestCounter;\n        vhost_traffic_status_set_by_filter $requestCounterKR filter/country::example.org@KR/requestCounter;\n\n        location /backend {\n            vhost_traffic_status_set_by_filter $requestCounterB1 upstream@group/backend@10.10.10.11:80/requestCounter;\n            proxy_pass http://backend;\n        }\n    }\n}\n</code></pre> <p>The above settings are as follows:</p> <ul> <li>$requestCounter</li> <li>serverZones -&gt; example.org -&gt; requestCounter</li> <li>$requestCounterKR</li> <li>filterZones -&gt; country::example.org -&gt; KR -&gt; requestCounter</li> <li>$requestCounterB1</li> <li>upstreamZones -&gt; backend -&gt; 10.0.10.11:80 -&gt; requestCounter</li> </ul> <p>Please see the vhost_traffic_status_set_by_filter directive for detailed usage.</p>"},{"location":"modules/vts/#json","title":"JSON","text":"<p>The following status information is provided in the JSON format:</p>"},{"location":"modules/vts/#json-used-by-status","title":"Json used by status","text":"<p>/<code>{status_uri}</code>/format/json</p> <p>/<code>{status_uri}</code>/control?cmd=status&amp;...</p> <ul> <li>hostName</li> <li>Host name.</li> <li>moduleVersion</li> <li>Version of the module in <code>{version}(|.dev.{commit})</code> format.</li> <li>nginxVersion</li> <li>Version of the provided.</li> <li>loadMsec</li> <li>Loaded process time in milliseconds.</li> <li>nowMsec</li> <li>Current time in milliseconds</li> <li>connections</li> <li>active<ul> <li>The current number of active client connections.</li> </ul> </li> <li>reading<ul> <li>The total number of reading client connections.</li> </ul> </li> <li>writing<ul> <li>The total number of writing client connections.</li> </ul> </li> <li>waiting<ul> <li>The total number of wating client connections.</li> </ul> </li> <li>accepted<ul> <li>The total number of accepted client connections.</li> </ul> </li> <li>handled<ul> <li>The total number of handled client connections.</li> </ul> </li> <li>requests<ul> <li>The total number of requested client connections.</li> </ul> </li> <li>sharedZones</li> <li>name<ul> <li>The name of shared memory specified in the configuration.(default: <code>vhost_traffic_status</code>)</li> </ul> </li> <li>maxSize<ul> <li>The limit on the maximum size of the shared memory specified in the configuration.</li> </ul> </li> <li>usedSize<ul> <li>The current size of the shared memory.</li> </ul> </li> <li>usedNode<ul> <li>The current number of node using in shared memory. It can get an approximate size for one node with the following formula: (usedSize / usedNode)</li> </ul> </li> <li>serverZones</li> <li>requestCounter<ul> <li>The total number of client requests received from clients.</li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from clients.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent to clients.</li> </ul> </li> <li>responses<ul> <li>1xx, 2xx, 3xx, 4xx, 5xx</li> <li>The number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.</li> <li>miss</li> <li>The number of cache miss.</li> <li>bypass</li> <li>The number of cache bypass.</li> <li>expired</li> <li>The number of cache expired.</li> <li>stale</li> <li>The number of cache stale.</li> <li>updating</li> <li>The number of cache updating.</li> <li>revalidated</li> <li>The number of cache revalidated.</li> <li>hit</li> <li>The number of cache hit.</li> <li>scarce</li> <li>The number of cache scare.</li> </ul> </li> <li>requestMsecCounter<ul> <li>The number of accumulated request processing time in milliseconds.</li> </ul> </li> <li>requestMsec<ul> <li>The average of request processing times in milliseconds.</li> </ul> </li> <li>requestMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The request processing times in milliseconds.</li> </ul> </li> <li>requestBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>vhost_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the request processing time. </li> </ul> </li> <li>filterZones</li> <li>It provides the same fields with <code>serverZones</code> except that it included group names.</li> <li>upstreamZones</li> <li>server<ul> <li>An address of the server.</li> </ul> </li> <li>requestCounter<ul> <li>The total number of client connections forwarded to this server.</li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from this server.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent to this server.</li> </ul> </li> <li>responses<ul> <li>1xx, 2xx, 3xx, 4xx, 5xx</li> <li>The number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.</li> </ul> </li> <li>requestMsecCounter<ul> <li>The number of accumulated request processing time including upstream in milliseconds.</li> </ul> </li> <li>requestMsec<ul> <li>The average of request processing times including upstream in milliseconds.</li> </ul> </li> <li>requestMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The request processing times including upstream in milliseconds.</li> </ul> </li> <li>requestBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>vhost_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the request processing time including upstream.</li> </ul> </li> <li>responseMsecCounter<ul> <li>The number of accumulated only upstream response processing time in milliseconds.</li> </ul> </li> <li>responseMsec<ul> <li>The average of only upstream response processing times in milliseconds.</li> </ul> </li> <li>responseMsecs<ul> <li>times</li> <li>The times in milliseconds at request processing times.</li> <li>msecs</li> <li>The only upstream response processing times in milliseconds.</li> </ul> </li> <li>responseBuckets<ul> <li>msecs</li> <li>The bucket values of histogram set by <code>vhost_traffic_status_histogram_buckets</code> directive.</li> <li>counters</li> <li>The cumulative values for the reason that each bucket value is greater than or equal to the only upstream response processing time.</li> </ul> </li> <li>weight<ul> <li>Current <code>weight</code> setting of the server.</li> </ul> </li> <li>maxFails<ul> <li>Current <code>max_fails</code> setting of the server.</li> </ul> </li> <li>failTimeout<ul> <li>Current <code>fail_timeout</code> setting of the server.</li> </ul> </li> <li>backup<ul> <li>Current <code>backup</code> setting of the server.</li> </ul> </li> <li>down<ul> <li>Current <code>down</code> setting of the server. Basically, this is just a mark the ngx_http_upstream_module's server down(eg. <code>server backend3.example.com down</code>), not actual upstream server state. It will changed to actual state if you enabled the upstream zone directive.</li> </ul> </li> <li>cacheZones</li> <li>maxSize<ul> <li>The limit on the maximum size of the cache specified in the configuration. If <code>max_size</code> in <code>proxy_cache_path</code> directive is not specified, the system dependent value <code>NGX_MAX_OFF_T_VALUE</code> is assigned by default. In other words, this value is from nginx, not what I specified.</li> </ul> </li> <li>usedSize<ul> <li>The current size of the cache. This value is taken from nginx like the above <code>maxSize</code> value. </li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from the cache.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent from the cache.</li> </ul> </li> <li>responses<ul> <li>miss</li> <li>The number of cache miss.</li> <li>bypass</li> <li>The number of cache bypass.</li> <li>expired</li> <li>The number of cache expired.</li> <li>stale</li> <li>The number of cache stale.</li> <li>updating</li> <li>The number of cache updating.</li> <li>revalidated</li> <li>The number of cache revalidated.</li> <li>hit</li> <li>The number of cache hit.</li> <li>scarce</li> <li>The number of cache scare.</li> </ul> </li> </ul>"},{"location":"modules/vts/#json-used-by-control","title":"Json used by control","text":"<p>/<code>{status_uri}</code>/control?cmd=reset&amp;...</p> <p>/<code>{status_uri}</code>/control?cmd=delete&amp;...</p> <ul> <li>processingReturn</li> <li>The result of true or false.</li> <li>processingCommandString</li> <li>The requested command string.</li> <li>processingGroupString</li> <li>The requested group string.</li> <li>processingZoneString</li> <li>The requested zone string.</li> <li>processingCounts</li> <li>The actual processing number.</li> </ul>"},{"location":"modules/vts/#variables","title":"Variables","text":"<p>The following embedded variables are provided:</p> <ul> <li>$vts_request_counter</li> <li>The total number of client requests received from clients.</li> <li>$vts_in_bytes</li> <li>The total number of bytes received from clients.</li> <li>$vts_out_bytes</li> <li>The total number of bytes sent to clients.</li> <li>$vts_1xx_counter</li> <li>The number of responses with status codes 1xx.</li> <li>$vts_2xx_counter</li> <li>The number of responses with status codes 2xx.</li> <li>$vts_3xx_counter</li> <li>The number of responses with status codes 3xx.</li> <li>$vts_4xx_counter</li> <li>The number of responses with status codes 4xx.</li> <li>$vts_5xx_counter</li> <li>The number of responses with status codes 5xx.</li> <li>$vts_cache_miss_counter</li> <li>The number of cache miss.</li> <li>$vts_cache_bypass_counter</li> <li>The number of cache bypass.</li> <li>$vts_cache_expired_counter</li> <li>The number of cache expired.</li> <li>$vts_cache_stale_counter</li> <li>The number of cache stale.</li> <li>$vts_cache_updating_counter</li> <li>The number of cache updating.</li> <li>$vts_cache_revalidated_counter</li> <li>The number of cache revalidated.</li> <li>$vts_cache_hit_counter</li> <li>The number of cache hit.</li> <li>$vts_cache_scarce_counter</li> <li>The number of cache scare.</li> <li>$vts_request_time_counter</li> <li>The number of accumulated request processing time.</li> <li>$vts_request_time</li> <li>The average of request processing times.</li> </ul>"},{"location":"modules/vts/#limit","title":"Limit","text":"<p>It is able to limit total traffic per each host by using the directive <code>vhost_traffic_status_limit_traffic</code>. It also is able to limit all traffic by using the directive <code>vhost_traffic_status_limit_traffic_by_set_key</code>. When the limit is exceeded, the server will return the 503 (Service Temporarily Unavailable) error in reply to a request.  The return code can be changeable.</p>"},{"location":"modules/vts/#to-limit-traffic-for-server","title":"To limit traffic for server","text":"<pre><code>http {\n\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        server_name *.example.org;\n\n        vhost_traffic_status_limit_traffic in:64G;\n        vhost_traffic_status_limit_traffic out:1024G;\n\n        ...\n    }\n}\n</code></pre> <ul> <li>Limit in/out total traffic on the <code>*.example.org</code> to 64G and 1024G respectively. It works individually per each domain if <code>vhost_traffic_status_filter_by_host</code> directive is enabled.</li> </ul>"},{"location":"modules/vts/#to-limit-traffic-for-filter","title":"To limit traffic for filter","text":"<pre><code>http {\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        server_name example.org;\n\n        vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n        vhost_traffic_status_limit_traffic_by_set_key FG@country::$server_name@US out:1024G;\n        vhost_traffic_status_limit_traffic_by_set_key FG@country::$server_name@CN out:2048G;\n\n        ...\n\n    }\n}\n</code></pre> <ul> <li>Limit total traffic of going into US and CN on the <code>example.org</code> to 1024G and 2048G respectively.</li> </ul>"},{"location":"modules/vts/#to-limit-traffic-for-upstream","title":"To limit traffic for upstream","text":"<pre><code>http {\n\n    vhost_traffic_status_zone;\n\n    ...\n\n    upstream backend {\n        server 10.10.10.17:80;\n        server 10.10.10.18:80;\n    }\n\n    server {\n\n        server_name example.org;\n\n        location /backend {\n            vhost_traffic_status_limit_traffic_by_set_key UG@backend@10.10.10.17:80 in:512G;\n            vhost_traffic_status_limit_traffic_by_set_key UG@backend@10.10.10.18:80 in:1024G;\n            proxy_pass http://backend;\n        }\n\n        ...\n\n    }\n}\n</code></pre> <ul> <li>Limit total traffic of going into upstream backend on the <code>example.org</code> to 512G and 1024G per each peer.</li> </ul> <p><code>Caveats:</code> Traffic is the cumulative transfer or counter, not a bandwidth.</p>"},{"location":"modules/vts/#use-cases","title":"Use cases","text":"<p>It is able to calculate the user defined individual stats by using the directive <code>vhost_traffic_status_filter_by_set_key</code>.</p>"},{"location":"modules/vts/#to-calculate-traffic-for-individual-country-using-geoip","title":"To calculate traffic for individual country using GeoIP","text":"<pre><code>http {\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    vhost_traffic_status_zone;\n    vhost_traffic_status_filter_by_set_key $geoip_country_code country::*;\n\n    ...\n\n    server {\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual country of total server groups.</li> <li>Calculate traffic for individual country of each server groups.</li> </ul> <p>Basically, country flags image is built-in in HTML. The country flags image is enabled if the <code>country</code> string is included in group name which is second argument of <code>vhost_traffic_status_filter_by_set_key</code> directive.</p>"},{"location":"modules/vts/#to-calculate-traffic-for-individual-storage-volume","title":"To calculate traffic for individual storage volume","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location ~ ^/storage/(.+)/.*$ {\n            set $volume $1;\n            vhost_traffic_status_filter_by_set_key $volume storage::$server_name;\n        }\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual storage volume matched by regular expression of location directive.</li> </ul>"},{"location":"modules/vts/#to-calculate-traffic-for-individual-user-agent","title":"To calculate traffic for individual user agent","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n\n    map $http_user_agent $filter_user_agent {\n        default 'unknown';\n        ~iPhone ios;\n        ~Android android;\n        ~(MSIE|Mozilla) windows;\n    }\n\n    vhost_traffic_status_filter_by_set_key $filter_user_agent agent::*;\n\n    ...\n\n    server {\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $filter_user_agent agent::$server_name;\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual <code>http_user_agent</code></li> </ul>"},{"location":"modules/vts/#to-calculate-traffic-for-detailed-http-status-code","title":"To calculate traffic for detailed http status code","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n\n    server {\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $status $server_name;\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for detailed <code>http status code</code></li> </ul> <p><code>Caveats:</code> $status variable is available in nginx-(1.3.2, 1.2.2).</p>"},{"location":"modules/vts/#to-calculate-traffic-for-dynamic-dns","title":"To calculate traffic for dynamic dns","text":"<p>If the domain has multiple DNS A records, you can calculate traffic for individual IPs for the domain using the filter feature or a variable in proxy_pass.</p> <pre><code>http {\n    vhost_traffic_status_zone;\n\n    upstream backend {\n        elb.example.org:80;\n    }\n\n    ...\n\n    server {\n\n        ...\n\n        location /backend {\n            vhost_traffic_status_filter_by_set_key $upstream_addr upstream::backend;\n            proxy_pass backend;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual IPs for the domain <code>elb.example.org</code>. If <code>elb.example.org</code> has multiple DNS A records, will be display all IPs in <code>filterZones</code>. In the above settings, as NGINX starts up or reloads it configuration, it queries a DNS server to resolve domain and DNS A records is cached in memory. Therefore the DNS A records are not changed in memory even if DNS A records are chagned by DNS administrator unless NGINX re-starts up or reloads.</li> </ul> <pre><code>http {\n    vhost_traffic_status_zone;\n\n    resolver 10.10.10.53 valid=10s\n\n    ...\n\n    server {\n\n        ...\n\n        location /backend {\n            set $backend_server elb.example.org;\n            proxy_pass http://$backend_server;\n        }\n    }\n}\n</code></pre> <ul> <li>Calculate traffic for individual IPs for the domain <code>elb.example.org</code>. If <code>elb.example.org</code>'s DNS A record is changed, will be display both the old IP and the new IP in <code>::nogroups</code>. Unlike the first upstream group setting, the second setting works well even if DNS A records are chagned by DNS administrator.</li> </ul> <p><code>Caveats:</code> Please more details about NGINX DNS see the dns-service-discovery-nginx-plus.</p>"},{"location":"modules/vts/#to-calculate-traffic-except-for-status-page","title":"To calculate traffic except for status page","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            vhost_traffic_status_bypass_limit on;\n            vhost_traffic_status_bypass_stats on;\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre> <ul> <li>The <code>/status</code> uri is excluded from the status traffic calculation and limit feature.  See the following directives:</li> <li>vhost_traffic_status_bypass_limit</li> <li>vhost_traffic_status_bypass_stats</li> </ul>"},{"location":"modules/vts/#to-maintain-statistics-data-permanently","title":"To maintain statistics data permanently","text":"<pre><code>http {\n    vhost_traffic_status_zone;\n    vhost_traffic_status_dump /var/log/nginx/vts.db;\n\n    ...\n\n    server {\n\n        ...\n\n    }\n}\n</code></pre> <ul> <li>The <code>vhost_traffic_status_dump</code> directive maintains statistics data permanently even if system has been rebooted or nginx has been restarted. Please see the vhost_traffic_status_dump directive for detailed usage.</li> </ul>"},{"location":"modules/vts/#customizing","title":"Customizing","text":""},{"location":"modules/vts/#to-customize-after-the-module-installed","title":"To customize after the module installed","text":"<ol> <li> <p>You need to change the <code>{{uri}}</code> string to your status uri in status.template.html as follows:  <pre><code>shell&gt; vi share/status.template.html\n</code></pre> <pre><code>var vtsStatusURI = \"yourStatusUri/format/json\", vtsUpdateInterval = 1000;\n</code></pre></p> </li> <li> <p>And then, customizing and copy status.template.html to server root directory as follows:  <pre><code>shell&gt; cp share/status.template.html /usr/share/nginx/html/status.html\n</code></pre></p> </li> <li> <p>Configure <code>nginx.conf</code> <pre><code>   server {\n       server_name example.org;\n       root /usr/share/nginx/html;\n\n       # Redirect requests for / to /status.html\n       location = / {\n           return 301 /status.html;\n       }\n\n       location = /status.html {}\n\n       # Everything beginning /status (except for /status.html) is\n       # processed by the status handler\n       location /status {\n           vhost_traffic_status_display;\n           vhost_traffic_status_display_format json;\n       }\n   }\n</code></pre></p> </li> <li> <p>Access to your html.  <pre><code>http://example.org/status.html\n</code></pre></p> </li> </ol>"},{"location":"modules/vts/#to-customize-before-the-module-installed","title":"To customize before the module installed","text":"<ol> <li> <p>Modify <code>share/status.template.html</code> (Do not change <code>{{uri}}</code> string)</p> </li> <li> <p>Recreate the <code>ngx_http_vhost_traffic_status_module_html.h</code> as follows:  <pre><code>shell&gt; cd util\nshell&gt; ./tplToDefine.sh ../share/status.template.html &gt; ../src/ngx_http_vhost_traffic_status_module_html.h\n</code></pre></p> </li> <li> <p>Add the module to the build configuration by adding   <code>--add-module=/path/to/nginx-module-vts</code></p> </li> <li> <p>Build the nginx binary.</p> </li> <li> <p>Install the nginx binary.</p> </li> </ol>"},{"location":"modules/vts/#directives","title":"Directives","text":""},{"location":"modules/vts/#vhost_traffic_status","title":"vhost_traffic_status","text":"- - Syntax vhost_traffic_status \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables the module working. If you set <code>vhost_traffic_status_zone</code> directive, is automatically enabled.</p>"},{"location":"modules/vts/#vhost_traffic_status_zone","title":"vhost_traffic_status_zone","text":"- - Syntax vhost_traffic_status_zone [shared:name:size] Default shared:vhost_traffic_status:1m Context http <p><code>Description:</code> Sets parameters for a shared memory zone that will keep states for various keys. The cache is shared between all worker processes. In most cases, the shared memory size used by nginx-module-vts does not increase much. The shared memory size is increased pretty when using <code>vhost_traffic_status_filter_by_set_key</code> directive but if filter's keys are fixed(eg. the total number of the country code is about 240) it does not continuously increase.</p> <p>If you use <code>vhost_traffic_status_filter_by_set_key</code> directive, set it as follows:</p> <ul> <li>Set to more than 32M shared memory size by default. (<code>vhost_traffic_status_zone shared:vhost_traffic_status:32m</code>)</li> <li>If the message(<code>\"ngx_slab_alloc() failed: no memory in vhost_traffic_status_zone\"</code>) printed in error_log, increase to more than (usedSize * 2).</li> </ul>"},{"location":"modules/vts/#vhost_traffic_status_dump","title":"vhost_traffic_status_dump","text":"- - Syntax vhost_traffic_status_dump path [period] Default - Context http <p><code>Description:</code> Enables the statistics data dump and restore. The path is a location to dump the statistics data.(e.g. <code>/var/log/nginx/vts.db</code>) The period is a backup cycle time.(Default: 60s) It is backed up immediately regardless of the backup cycle if nginx is exited by signal(<code>SIGKILL</code>).</p>"},{"location":"modules/vts/#vhost_traffic_status_display","title":"vhost_traffic_status_display","text":"- - Syntax vhost_traffic_status_display Default - Context http, server, location <p><code>Description:</code> Enables or disables the module display handler.</p>"},{"location":"modules/vts/#vhost_traffic_status_display_format","title":"vhost_traffic_status_display_format","text":"- - Syntax vhost_traffic_status_display_format \\&lt;json|html|jsonp|prometheus&gt; Default json Context http, server, location <p><code>Description:</code> Sets the display handler's output format. If you set <code>json</code>, will respond with a JSON document. If you set <code>html</code>, will respond with the built-in live dashboard in HTML. If you set <code>jsonp</code>, will respond with a JSONP callback function(default: ngx_http_vhost_traffic_status_jsonp_callback). If you set <code>prometheus</code>, will respond with a prometheus document.</p>"},{"location":"modules/vts/#vhost_traffic_status_display_jsonp","title":"vhost_traffic_status_display_jsonp","text":"- - Syntax vhost_traffic_status_display_jsonp callback Default ngx_http_vhost_traffic_status_jsonp_callback Context http, server, location <p><code>Description:</code> Sets the callback name for the JSONP.</p>"},{"location":"modules/vts/#vhost_traffic_status_display_sum_key","title":"vhost_traffic_status_display_sum_key","text":"- - Syntax vhost_traffic_status_display_sum_key name Default * Context http, server, location <p><code>Description:</code> Sets the sum key string in serverZones field's JSON. The default sum key string is the \"*\".</p>"},{"location":"modules/vts/#vhost_traffic_status_filter","title":"vhost_traffic_status_filter","text":"- - Syntax vhost_traffic_status_filter \\&lt;on|off&gt; Default on Context http, server, location <p><code>Description:</code> Enables or disables the filter features.</p>"},{"location":"modules/vts/#vhost_traffic_status_filter_by_host","title":"vhost_traffic_status_filter_by_host","text":"- - Syntax vhost_traffic_status_filter_by_host \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables the keys by Host header field. If you set <code>on</code> and nginx's server_name directive set several or wildcard name starting with an asterisk, e.g. \u201c.example.org\u201d and requested to server with hostname such as (a|b|c).example.org or .example.org then json serverZones is printed as follows:</p> <pre><code>server {\n  server_name *.example.org;\n  vhost_traffic_status_filter_by_host on;\n\n  ...\n\n}\n</code></pre> <pre><code>  ...\n  \"serverZones\": {\n      \"a.example.org\": {\n      ...\n      },\n      \"b.example.org\": {\n      ...\n      },\n      \"c.example.org\": {\n      ...\n      }\n      ...\n   },\n   ...\n</code></pre> <p>It provides the same function that set <code>vhost_traffic_status_filter_by_set_key $host</code>.</p>"},{"location":"modules/vts/#vhost_traffic_status_filter_by_set_key","title":"vhost_traffic_status_filter_by_set_key","text":"- - Syntax vhost_traffic_status_filter_by_set_key key [name] Default - Context http, server, location <p><code>Description:</code> Enables the keys by user defined variable. The key is a key string to calculate traffic. The name is a group string to calculate traffic. The key and name can contain variables such as $host, $server_name. The name's group belongs to <code>filterZones</code> if specified. The key's group belongs to <code>serverZones</code> if not specified second argument name. The example with geoip module is as follows:</p> <pre><code>server {\n  server_name example.org;\n  vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n\n  ...\n\n}\n</code></pre> <pre><code>  ...\n  \"serverZones\": {\n  ...\n  },\n  \"filterZones\": {\n      \"country::example.org\": {\n          \"KR\": {\n              \"requestCounter\":...,\n              \"inBytes\":...,\n              \"outBytes\":...,\n              \"responses\":{\n                  \"1xx\":...,\n                  \"2xx\":...,\n                  \"3xx\":...,\n                  \"4xx\":...,\n                  \"5xx\":...,\n                  \"miss\":...,\n                  \"bypass\":...,\n                  \"expired\":...,\n                  \"stale\":...,\n                  \"updating\":...,\n                  \"revalidated\":...,\n                  \"hit\":...,\n                  \"scarce\":...\n              },\n              \"requestMsecCounter\":...,\n              \"requestMsec\":...,\n              \"requestMsecs\":{\n                  \"times\":[...],\n                  \"msecs\":[...]\n              },\n          },\n          \"US\": {\n          ...\n          },\n          ...\n      },\n      ...\n  },\n  ...\n</code></pre>"},{"location":"modules/vts/#vhost_traffic_status_filter_check_duplicate","title":"vhost_traffic_status_filter_check_duplicate","text":"- - Syntax vhost_traffic_status_filter_check_duplicate \\&lt;on|off&gt; Default on Context http, server, location <p><code>Description:</code> Enables or disables the deduplication of vhost_traffic_status_filter_by_set_key. It is processed only one of duplicate values(<code>key</code> + <code>name</code>) in each directives(http, server, location) if this option is enabled.</p>"},{"location":"modules/vts/#vhost_traffic_status_filter_max_node","title":"vhost_traffic_status_filter_max_node","text":"- - Syntax vhost_traffic_status_filter_max_node number [string ...] Default 0 Context http <p><code>Description:</code> Enables the limit of filter size using the specified number and string values. If the number is exceeded, the existing nodes are deleted by the LRU algorithm. The number argument is the size of the node that will be limited. The default value <code>0</code> does not limit filters. The one node is an object in <code>filterZones</code> in JSON document. The string arguments are the matching string values for the group string value set by <code>vhost_traffic_status_filter_by_set_key</code> directive.  Even if only the first part matches, matching is successful like the regular expression <code>/^string.*/</code>. By default, If you do not set string arguments then it applied for all filters.</p> <p>For examples:</p> <p><code>$ vi nginx.conf</code></p> <pre><code>http {\n\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    vhost_traffic_status_zone;\n\n    # The all filters are limited to a total of 16 nodes.\n    # vhost_traffic_status_filter_max_node 16\n\n    # The `/^uris.*/` and `/^client::ports.*/` group string patterns are limited to a total of 64 nodes.\n    vhost_traffic_status_filter_max_node 16 uris client::ports;\n\n    ...\n\n    server {\n\n        server_name example.org;\n\n        ...\n\n        vhost_traffic_status_filter_by_set_key $uri uris::$server_name;\n        vhost_traffic_status_filter_by_set_key $remote_port client::ports::$server_name;\n        vhost_traffic_status_filter_by_set_key $geoip_country_code country::$server_name;\n\n    }\n}\n</code></pre> <p><code>$ for i in {0..1000}; do curl -H 'Host: example.org' -i \"http://localhost:80/test$i\"; done</code></p> <p></p> <p>In the above example, the <code>/^uris.*/</code> and <code>/^client::ports.*/</code> group string patterns are limited to a total of 16 nodes. The other filters like <code>country::.*</code> are not limited.</p>"},{"location":"modules/vts/#vhost_traffic_status_limit","title":"vhost_traffic_status_limit","text":"- - Syntax vhost_traffic_status_limit \\&lt;on|off&gt; Default on Context http, server, location <p><code>Description:</code> Enables or disables the limit features.</p>"},{"location":"modules/vts/#vhost_traffic_status_limit_traffic","title":"vhost_traffic_status_limit_traffic","text":"- - Syntax vhost_traffic_status_limit_traffic member:size [code] Default - Context http, server, location <p><code>Description:</code> Enables the traffic limit for specified member. The member is a member string to limit traffic. The size is a size(k/m/g) to limit traffic. The code is a code to return in response to rejected requests.(Default: 503)</p> <p>The available <code>member</code> strings are as follows: * request   * The total number of client requests received from clients. * in   * The total number of bytes received from clients. * out   * The total number of bytes sent to clients. * 1xx   * The number of responses with status codes 1xx. * 2xx   * The number of responses with status codes 2xx. * 3xx   * The number of responses with status codes 3xx. * 4xx   * The number of responses with status codes 4xx. * 5xx   * The number of responses with status codes 5xx. * cache_miss   * The number of cache miss. * cache_bypass   * The number of cache bypass. * cache_expired   * The number of cache expired. * cache_stale   * The number of cache stale. * cache_updating   * The number of cache updating. * cache_revalidated   * The number of cache revalidated. * cache_hit   * The number of cache hit. * cache_scarce   * The number of cache scare.</p>"},{"location":"modules/vts/#vhost_traffic_status_limit_traffic_by_set_key","title":"vhost_traffic_status_limit_traffic_by_set_key","text":"- - Syntax vhost_traffic_status_limit_traffic_by_set_key key member:size [code] Default - Context http, server, location <p><code>Description:</code> Enables the traffic limit for specified key and member. The key is a key string to limit traffic. The member is a member string to limit traffic. The size is a size(k/m/g) to limit traffic. The code is a code to return in response to rejected requests.(Default: 503)</p> <p>The <code>key</code> syntax is as follows: * <code>group</code>@[<code>subgroup</code>@]<code>name</code></p> <p>The available <code>group</code> strings are as follows: * NO   * The group of server. * UA   * The group of upstream alone. * UG   * The group of upstream group.(use <code>subgroup</code>) * CC   * The group of cache. * FG   * The group of filter.(use <code>subgroup</code>)</p> <p>The available <code>member</code> strings are as follows: * request   * The total number of client requests received from clients. * in   * The total number of bytes received from clients. * out   * The total number of bytes sent to clients. * 1xx   * The number of responses with status codes 1xx. * 2xx   * The number of responses with status codes 2xx. * 3xx   * The number of responses with status codes 3xx. * 4xx   * The number of responses with status codes 4xx. * 5xx   * The number of responses with status codes 5xx. * cache_miss   * The number of cache miss. * cache_bypass   * The number of cache bypass. * cache_expired   * The number of cache expired. * cache_stale   * The number of cache stale. * cache_updating   * The number of cache updating. * cache_revalidated   * The number of cache revalidated. * cache_hit   * The number of cache hit. * cache_scarce   * The number of cache scare.</p> <p>The member is the same as <code>vhost_traffic_status_limit_traffic</code> directive.</p>"},{"location":"modules/vts/#vhost_traffic_status_limit_check_duplicate","title":"vhost_traffic_status_limit_check_duplicate","text":"- - Syntax vhost_traffic_status_limit_check_duplicate \\&lt;on|off&gt; Default on Context http, server, location <p><code>Description:</code> Enables or disables the deduplication of vhost_traffic_status_limit_by_set_key. It is processed only one of duplicate values(<code>member</code> | <code>key</code> + <code>member</code>) in each directives(http, server, location) if this option is enabled.</p>"},{"location":"modules/vts/#vhost_traffic_status_set_by_filter","title":"vhost_traffic_status_set_by_filter","text":"- - Syntax vhost_traffic_status_set_by_filter $variable group/zone/name Default - Context http, server, location, if <p><code>Description:</code> Get the specified status value stored in shared memory. It can acquire almost all status values and the obtained value is stored in $variable which is first argument.</p> <ul> <li>group</li> <li>server</li> <li>filter</li> <li>upstream@alone</li> <li>upstream@group</li> <li>cache</li> <li>zone</li> <li>server<ul> <li>name</li> </ul> </li> <li>filter<ul> <li>filter_group@name</li> </ul> </li> <li>upstream@group<ul> <li>upstream_group@name</li> </ul> </li> <li>upstream@alone<ul> <li>@name</li> </ul> </li> <li>cache<ul> <li>name</li> </ul> </li> <li>name</li> <li>requestCounter<ul> <li>The total number of client requests received from clients.</li> </ul> </li> <li>requestMsecCounter<ul> <li>The number of accumulated request processing time in milliseconds.</li> </ul> </li> <li>requestMsec<ul> <li>The average of request processing times in milliseconds.</li> </ul> </li> <li>responseMsecCounter<ul> <li>The number of accumulated only upstream response processing time in milliseconds.</li> </ul> </li> <li>responseMsec<ul> <li>The average of only upstream response processing times in milliseconds.</li> </ul> </li> <li>inBytes<ul> <li>The total number of bytes received from clients.</li> </ul> </li> <li>outBytes<ul> <li>The total number of bytes sent to clients.</li> </ul> </li> <li>1xx, 2xx, 3xx, 4xx, 5xx<ul> <li>The number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.</li> </ul> </li> <li>cacheMaxSize<ul> <li>The limit on the maximum size of the cache specified in the configuration.</li> </ul> </li> <li>cacheUsedSize<ul> <li>The current size of the cache.</li> </ul> </li> <li>cacheMiss<ul> <li>The number of cache miss.</li> </ul> </li> <li>cacheBypass<ul> <li>The number of cache bypass.</li> </ul> </li> <li>cacheExpired<ul> <li>The number of cache expired.</li> </ul> </li> <li>cacheStale<ul> <li>The number of cache stale.</li> </ul> </li> <li>cacheUpdating<ul> <li>The number of cache updating.</li> </ul> </li> <li>cacheRevalidated<ul> <li>The number of cache revalidated.</li> </ul> </li> <li>cacheHit<ul> <li>The number of cache hit.</li> </ul> </li> <li>cacheScarce<ul> <li>The number of cache scare.</li> </ul> </li> <li>weight<ul> <li>Current weight setting of the server.</li> </ul> </li> <li>maxFails<ul> <li>Current max_fails setting of the server.</li> </ul> </li> <li>failTimeout<ul> <li>Current fail_timeout setting of the server.</li> </ul> </li> <li>backup<ul> <li>Current backup setting of the server.(0|1)</li> </ul> </li> <li>down<ul> <li>Current down setting of the server.(0|1)</li> </ul> </li> </ul> <p><code>Caveats:</code> The name is case sensitive. All return values take the integer type.</p> <p>For examples: * requestCounter in serverZones   * vhost_traffic_status_set_by_filter <code>$requestCounter</code> <code>server/example.org/requestCounter</code> * requestCounter in filterZones   * vhost_traffic_status_set_by_filter <code>$requestCounter</code> <code>filter/country::example.org@KR/requestCounter</code> * requestCounter in upstreamZones   * vhost_traffic_status_set_by_filter <code>$requestCounter</code> <code>upstream@group/backend@10.10.10.11:80/requestCounter</code> * requestCounter in upstreamZones::nogroups   * vhost_traffic_status_set_by_filter <code>$requestCounter</code> <code>upstream@alone/10.10.10.11:80/requestCounter</code> * cacheHit in cacheZones   * vhost_traffic_status_set_by_filter <code>$cacheHit</code> <code>cache/my_cache_name/cacheHit</code></p>"},{"location":"modules/vts/#vhost_traffic_status_average_method","title":"vhost_traffic_status_average_method","text":"- - Syntax vhost_traffic_status_average_method \\&lt;AMM|WMA&gt; [period] Default AMM 60s Context http, server, location <p><code>Description:</code> Sets the method which is a formula that calculate the average of response processing times. The period is an effective time of the values used for the average calculation.(Default: 60s) If period set to 0, effective time is ignored. In this case, the last average value is displayed even if there is no requests and after the elapse of time. The corresponding values are <code>requestMsec</code> and <code>responseMsec</code> in JSON.</p> <ul> <li>AMM</li> <li>The AMM is the arithmetic mean.</li> <li>WMA</li> <li>THE WMA is the weighted moving average.</li> </ul>"},{"location":"modules/vts/#vhost_traffic_status_histogram_buckets","title":"vhost_traffic_status_histogram_buckets","text":"- - Syntax vhost_traffic_status_histogram_buckets second ... Default - Context http, server, location <p><code>Description:</code> Sets the observe buckets to be used in the histograms. By default, if you do not set this directive, it will not work. The second can be expressed in decimal places with a minimum value of 0.001(1ms). The maximum size of the buckets is 32. If this value is insufficient for you, change the <code>NGX_HTTP_VHOST_TRAFFIC_STATUS_DEFAULT_BUCKET_LEN</code> in the <code>src/ngx_http_vhost_traffic_status_node.h</code></p> <p>For examples: * vhost_traffic_status_histogram_buckets <code>0.005</code> <code>0.01</code> <code>0.05</code> <code>0.1</code> <code>0.5</code> <code>1</code> <code>5</code> <code>10</code>   * The observe buckets are [5ms 10ms 50ms 100ms 500ms 1s 5s 10s]. * vhost_traffic_status_histogram_buckets <code>0.005</code> <code>0.01</code> <code>0.05</code> <code>0.1</code>   * The observe buckets are [5ms 10ms 50ms 100ms].</p> <p><code>Caveats:</code> By default, if you do not set this directive, the histogram statistics does not work. The restored histograms by <code>vhost_traffic_status_dump</code> directive have no affected by changes to the buckets by <code>vhost_traffic_status_histogram_buckets</code> directive. So you must first delete the zone or the dump file before changing the buckets by <code>vhost_traffic_status_histogram_buckets</code> directive. Similar to the above, delete the dump file when using the histogram for the first time.</p>"},{"location":"modules/vts/#vhost_traffic_status_bypass_limit","title":"vhost_traffic_status_bypass_limit","text":"- - Syntax vhost_traffic_status_bypass_limit \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables to bypass <code>vhost_traffic_status_limit</code> directives. The limit features is bypassed if this option is enabled. This is mostly useful if you want to connect the status web page like <code>/status</code> regardless of <code>vhost_traffic_status_limit</code> directives as follows:</p> <pre><code>http {\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            vhost_traffic_status_bypass_limit on;\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/vts/#vhost_traffic_status_bypass_stats","title":"vhost_traffic_status_bypass_stats","text":"- - Syntax vhost_traffic_status_bypass_stats \\&lt;on|off&gt; Default off Context http, server, location <p><code>Description:</code> Enables or disables to bypass <code>vhost_traffic_status</code>. The traffic status stats features is bypassed if this option is enabled. In other words, it is excluded from the traffic status stats. This is mostly useful if you want to ignore your request in status web page like <code>/status</code> as follows:</p> <pre><code>http {\n    vhost_traffic_status_zone;\n\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            vhost_traffic_status_bypass_stats on;\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/vts/#vhost_traffic_status_stats_by_upstream","title":"vhost_traffic_status_stats_by_upstream","text":"- - Syntax vhost_traffic_status_stats_by_upstream \\&lt;on|off&gt; Default on Context http <p><code>Description:</code> Enables or disables to stats <code>upstreamZone</code>. The <code>upstreamZone</code> in the traffic status stats features is bypassed if this option is disabled. In other words, it is excluded from the traffic status stats. This is mostly useful if you want to be disable statistics collection for upstream servers to reduce CPU load.</p> <pre><code>http {\n    vhost_traffic_status_zone;\n    vhost_traffic_status_stats_by_upstream off;\n\n    proxy_cache_path /var/cache/nginx keys_zone=zone1:1m max_size=1g inactive=24h;\n    upstream backend {\n       ...\n    }\n    ...\n\n    server {\n\n        ...\n\n        location /status {\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format html;\n        }\n        location /backend {\n            proxy_cache zone1;\n            proxy_pass http://backend;\n        }\n    }\n}\n</code></pre>"},{"location":"modules/vts/#releases","title":"Releases","text":"<p>To cut a release, create a changelog entry PR with git-chglog</p> <pre><code>version=\"v0.2.0\"\ngit checkout -b \"cut-${version}\"\ngit-chglog -o CHANGELOG.md --next-tag \"${version}\"\ngit add CHANGELOG.md\nsed -i \"s/NGX_HTTP_VTS_MODULE_VERSION \\\".*/NGX_HTTP_VTS_MODULE_VERSION \\\"${version}\\\"/\" src/ngx_http_vhost_traffic_status_module.h\ngit add src/ngx_http_vhost_traffic_status_module.h\ngit-chglog -t .chglog/RELNOTES.tmpl --next-tag \"${version}\" \"${version}\" | git commit -F-\n</code></pre> <p>After the PR is merged, create the new tag and release on the GitHub Releases.</p>"},{"location":"modules/vts/#see-also","title":"See Also","text":"<ul> <li>Stream traffic status</li> <li>nginx-module-sts</li> <li> <p>nginx-module-stream-sts</p> </li> <li> <p>Prometheus</p> </li> <li> <p>nginx-vts-exporter</p> </li> <li> <p>System protection</p> </li> <li>nginx-module-sysguard</li> </ul>"},{"location":"modules/vts/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-vts.</p>"},{"location":"modules/waf/","title":"waf: A web application firewall module for NGINX","text":""},{"location":"modules/waf/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-waf\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-waf\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_waf_module.so;\n</code></pre> <p>This document describes nginx-module-waf v6.1.10  released on Jan 25 2025.</p> <p> </p> <p></p> <p> </p> <p>English | \u7b80\u4f53\u4e2d\u6587</p> <p>Handy, High performance Nginx firewall module.</p>"},{"location":"modules/waf/#why-ngx_waf","title":"Why ngx_waf","text":"<ul> <li>Basic protection: such as black and white list of IPs or IP range, uri black and white list, and request body black list, etc.</li> <li>Easy to use: configuration files and rule files are easy to write and readable.</li> <li>High performance: Efficient algorithms and caching.</li> <li>Advanced protection: ModSecurity compatible, you can use OWASP(Open Web Application Security Project\u00ae) ModSecurity Core Rule Set.</li> <li>Friendly crawler verification: Supports verifying Google, Bing, Baidu and Yandex crawlers and allowing them automatically to avoid false positives.</li> <li>Captcha: Supports three kinds of captchas: hCaptcha, reCAPTCHAv2 and reCAPTCHAv3.</li> </ul>"},{"location":"modules/waf/#features","title":"Features","text":"<ul> <li>ModSecurity compatible. This feature is only available in the latest <code>Current</code> version.</li> <li>Rules that are compatible with ModSecurity.</li> <li>Anti SQL injection (powered by libinjection).</li> <li>Anti XSS (powered by libinjection).</li> <li>IPV4 and IPV6 support.</li> <li>Support for enabling CAPTCHAs, including hCaptcha, reCAPTCHAv2 and reCAPTCHAv3. This feature is only available in the latest <code>Current</code> version.</li> <li>Support authentication-friendly crawlers (based on user agent and IP identification) to avoid blocking of these crawlers (e.g. GoogleBot). This feature is only available in the latest <code>Current</code> version.</li> <li>Anti Challenge Collapsar, it can automatically block malicious IP.</li> <li>Exceptional allow on specific IP address.</li> <li>Block the specified IP address.</li> <li>Block the specified request body.</li> <li>Exceptional allow on specific URL.</li> <li>Block the specified URL.</li> <li>Block the specified query string.</li> <li>Block the specified UserAgent.</li> <li>Block the specified Cookie.</li> <li>Exceptional allow on specific Referer.</li> <li>Block the specified Referer.</li> </ul>"},{"location":"modules/waf/#docs","title":"Docs","text":"<ul> <li>Recommended link: https://docs.addesp.com/ngx_waf/</li> <li>Alternate link 1: https://add-sp.github.io/ngx_waf-docs/</li> <li>Alternate link 2: https://ngx-waf-docs.pages.dev/</li> </ul>"},{"location":"modules/waf/#contact","title":"Contact","text":"<ul> <li>Telegram Channel: https://t.me/ngx_waf</li> <li>Telegram Group (English): https://t.me/group_ngx_waf</li> <li>Telegram Group (Chinese): https://t.me/group_ngx_waf_cn</li> </ul>"},{"location":"modules/waf/#sponsor","title":"Sponsor","text":"<p>Hope you can help promote this project. The more stars got, the better this project is. :)</p>"},{"location":"modules/waf/#test-suite","title":"Test Suite","text":"<p>This module comes with a Perl-driven test suite. The test cases are declarative too.  Thanks to the Test::Nginx module in the Perl world.</p> <p>To run it on your side:</p> <pre><code>## It will take a lot of time, but it only needs to be run once.\ncpan Test::Nginx\n\n## You need to specify a temporary directory.\n## If the directory does not exist it will be created automatically.\n## If the directory already exists it will be **removed** first and then created.\nexport MODULE_TEST_PATH=/path/to/temp/dir\n\n## You need to specify the absolute path to the dynamic module if you have it installed, \n## otherwise you do not need to run this line.\nexport MODULE_PATH=/path/to/ngx_http_waf_module.so\n\ncd ./test/test-nginx\nsh ./init.sh\nsh ./start.sh ./t/*.t\n</code></pre> <p>Some parts of the test suite requires standard modules proxy, rewrite and SSI to be enabled as well when building Nginx.</p>"},{"location":"modules/waf/#thanks","title":"Thanks","text":"<ul> <li>ModSecurity: An open source, cross platform web application firewall (WAF) engine.</li> <li>uthash: C macros for hash tables and more.</li> <li>libcurl: The multiprotocol file transfer library .</li> <li>cJSON: Ultralightweight JSON parser in ANSI C.</li> <li>libinjection: SQL / SQLI tokenizer parser analyzer.</li> <li>libsodium: A modern, portable, easy to use crypto library.</li> <li>test-nginx: Data-driven test scaffold for Nginx C module and OpenResty Lua library development.</li> <li>lastversion: A command line tool that helps you download or install a specific version of a project.</li> <li>ngx_lua_waf: A web application firewall based on the lua-nginx-module (openresty).</li> <li>nginx-book: The Chinese language development guide for nginx.</li> <li>nginx-development-guide: The Chinese language development guide for nginx.</li> </ul>"},{"location":"modules/waf/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-waf.</p>"},{"location":"modules/wasm-wasmtime/","title":"wasm-wasmtime: Nginx with WebAssembly powered by wasmtime","text":""},{"location":"modules/wasm-wasmtime/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-wasm-wasmtime\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-wasm-wasmtime\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_wasmx_module.so;\n</code></pre> <p>This document describes nginx-module-wasm-wasmtime v0.5.0  released on Feb 15 2025.</p> <p> </p>"},{"location":"modules/wasm-wasmtime/#wasmxngx_wasm_module","title":"WasmX/ngx_wasm_module","text":"<p>Nginx + WebAssembly</p> <p>This module enables the embedding of [WebAssembly] runtimes inside of Nginx and aims at offering several host SDK abstractions for the purpose of extending and/or introspecting the Nginx web-server/proxy runtime.</p> <p>Currently, the module implements a Proxy-Wasm host ABI, which allows the use of client SDKs written in multiple languages, such as Rust and Go. Proxy-Wasm (\"WebAssembly for Proxies\") is an emerging standard for Wasm filters, adopted by API Gateways such as Kong and Envoy.</p>"},{"location":"modules/wasm-wasmtime/#what-is-wasmx","title":"What is WasmX?","text":"<p>WasmX aims at extending Nginx for the modern Web infrastructure. This includes supporting WebAssembly runtimes &amp; SDKs (by way of ngx_wasm_module), and generally increasing the breadth of features relied upon by the API Gateway use-case (i.e. reverse-proxying). See CONTRIBUTING.md for additional background and roadmap information.</p>"},{"location":"modules/wasm-wasmtime/#synopsis","title":"Synopsis","text":"<pre><code>## nginx.conf\nevents {}\n\n## nginx master process gets a default 'main' VM\n## a new top-level configuration block receives all configuration for this main VM\nwasm {\n    #      [name]    [path.{wasm,wat}]\n    module my_filter /path/to/filter.wasm;\n    module my_module /path/to/module.wasm;\n}\n\n## each nginx worker process is able to instantiate wasm modules in its subsystems\nhttp {\n    server {\n        listen 9000;\n\n        location / {\n            # execute a proxy-wasm filter when proxying\n            #           [module]\n            proxy_wasm  my_filter;\n\n            # execute more WebAssembly during the access phase\n            #           [phase] [module]  [function]\n            wasm_call   access  my_module check_something;\n\n            proxy_pass  ...;\n        }\n    }\n\n    # other directives\n    wasm_socket_connect_timeout 60s;\n    wasm_socket_send_timeout    60s;\n    wasm_socket_read_timeout    60s;\n\n    wasm_socket_buffer_size     8k;\n    wasm_socket_large_buffers   32 16k;\n}\n</code></pre>"},{"location":"modules/wasm-wasmtime/#examples","title":"Examples","text":"<p>Several \"showcase filters\" are provided as examples by authors of this module:</p> <ul> <li>proxy-wasm-rust-filter-echo:   An httpbin/echo filter.</li> <li>proxy-wasm-rust-rate-limiting:   Kong Gateway inspired rate-limiting in Rust.</li> <li>proxy-wasm-go-rate-limiting:   Kong Gateway inspired rate-limiting in Go.</li> <li>proxy-wasm-assemblyscript-rate-limiting:   Kong Gateway inspired rate-limiting in AssemblyScript.</li> </ul> <p>More examples are available for each Proxy-Wasm SDK:</p> <ul> <li>AssemblyScript   examples (temporary SDK fork)</li> <li>C++   examples</li> <li>Go (TinyGo)   examples</li> <li>Rust   examples</li> </ul> <p>Note that all of the above examples may not yet be compatible with ngx_wasm_module.</p> <p>Last but not least, the WebAssembly Hub contains many other Proxy-Wasm filters, some of which may not yet be compatible with ngx_wasm_module.</p>"},{"location":"modules/wasm-wasmtime/#documentation","title":"Documentation","text":""},{"location":"modules/wasm-wasmtime/#usage","title":"Usage","text":"<p>See the user documentation for resources on this module's usage.</p>"},{"location":"modules/wasm-wasmtime/#development","title":"Development","text":"<p>See the developer documentation for developer resources on building this module from source and other general development processes.</p> <p>See a term you are unfamiliar with? Consult the code lexicon.</p> <p>For a primer on the code's layout and architecture, see the code layout section.</p>"},{"location":"modules/wasm-wasmtime/#proxy-wasm-sdk","title":"Proxy-Wasm SDK","text":"<p>The Proxy-Wasm SDK is the initial focus of WasmX/ngx_wasm_module development and is still a work in progress. You can browse PROXY_WASM.md for a guide on Proxy-Wasm support in ngx_wasm_module.</p> <p>For a reliable resource in an evolving ABI specification, you may also wish to consult the SDK source of the language of your choice in the Proxy-Wasm SDKs list.</p>"},{"location":"modules/wasm-wasmtime/#webassembly","title":"WebAssembly","text":"<ul> <li>WebAssembly Specification (Wasm): https://webassembly.github.io/spec/core/index.html</li> <li>WebAssembly System Interface (WASI): https://github.com/WebAssembly/WASI</li> <li>WebAssembly text format (<code>.wat</code>): https://developer.mozilla.org/en-US/docs/WebAssembly/Understanding_the_text_format</li> </ul>"},{"location":"modules/wasm-wasmtime/#webassembly-runtimes","title":"WebAssembly Runtimes","text":"<ul> <li>Wasm C API: https://github.com/WebAssembly/wasm-c-api</li> <li>Wasmer C API: https://docs.rs/wasmer-c-api/</li> <li>Wasmtime C API: https://docs.wasmtime.dev/c-api/</li> <li>V8 embedding: https://v8.dev/docs/embed</li> </ul>"},{"location":"modules/wasm-wasmtime/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-wasm-wasmtime.</p>"},{"location":"modules/webp/","title":"webp: NGINX WebP module","text":""},{"location":"modules/webp/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-webp\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-webp\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_webp_module.so;\n</code></pre> <p>This document describes nginx-module-webp v0.1.1.5  released on Dec 30 2019.</p> <p>Webp is new (and smaller) image format. This module will convert jpg/png image on fly and send webp response.</p>"},{"location":"modules/webp/#status","title":"Status","text":"<p>Under development. To be continued.</p>"},{"location":"modules/webp/#configuration-directives","title":"Configuration directives","text":""},{"location":"modules/webp/#webp","title":"<code>webp</code>","text":"<ul> <li>syntax: <code>webp</code></li> <li>context: <code>location</code></li> </ul> <p>Enables or disables module.</p>"},{"location":"modules/webp/#example","title":"Example","text":"<p>location ~ \".jpg\" { webp; }</p> <p>$ curl -SLIXGET -H \"accept:image/webp\" http://127.0.0.1/1.jpg</p> <p>HTTP/1.1 200 OK</p> <p>Server: nginx/1.13.12</p> <p>Date: Wed, 25 Apr 2018 10:16:45 GMT</p> <p>Content-Length: 223980</p> <p>Last-Modified: Wed, 25 Apr 2018 10:16:45 GMT</p> <p>Connection: keep-alive</p> <p>Content-Type: image/webp</p> <p>$ curl -SLIXGET -H \"accept:image/*\" http://127.0.0.1/1.jpg</p> <p>HTTP/1.1 200 OK</p> <p>Server: nginx/1.13.12</p> <p>Date: Wed, 25 Apr 2018 10:17:53 GMT</p> <p>Content-Length: 325991</p> <p>Last-Modified: Wed, 18 Apr 2018 19:55:14 GMT</p> <p>Connection: keep-alive</p> <p>Content-Type: image/jpeg</p>"},{"location":"modules/webp/#notice","title":"Notice","text":"<p>As webp convertion takes some CPU usage I recommend to use some kind of caching of nginx responses, like Varnish.</p>"},{"location":"modules/webp/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-webp.</p>"},{"location":"modules/xslt/","title":"xslt: NGINX XSLT dynamic module","text":""},{"location":"modules/xslt/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-xslt\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-xslt\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_xslt_filter_module.so;\n</code></pre> <p>This module is built from the same source as the NGINX core.</p>"},{"location":"modules/xslt/#directives","title":"Directives","text":"<p>You may find information about configuration directives for this module at the following links:        </p> <ul> <li>https://nginx.org/en/docs/http/ngx_http_xslt_module.html#directives</li> </ul>"},{"location":"modules/xss/","title":"xss: Native cross-site scripting support in NGINX","text":""},{"location":"modules/xss/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-xss\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-xss\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_xss_filter_module.so;\n</code></pre> <p>This document describes nginx-module-xss v0.6  released on Dec 26 2022.</p> <p>xss-nginx-module - Native cross-site scripting support in nginx</p>"},{"location":"modules/xss/#synopsis","title":"Synopsis","text":"<pre><code>## accessing /foo?callback=process gives the response\n## body \"process(...);\" (without quotes) where \"...\"\n## is the original response body of the /foo location.\nserver {\n    location /foo {\n        # your content handler goes here...\n\n        xss_get on;\n        xss_callback_arg 'callback';\n        xss_input_types 'application/json'; # default\n        xss_output_type 'application/x-javascript'; # default\n    }\n    ...\n}\n</code></pre>"},{"location":"modules/xss/#description","title":"Description","text":"<p>This module adds cross-site AJAX support to nginx. Currently only cross-site GET is supported. But cross-site POST will be added in the future.</p> <p>The cross-site GET is currently implemented as JSONP (or \"JSON with padding\"). See http://en.wikipedia.org/wiki/JSON#JSONP for more details.</p>"},{"location":"modules/xss/#directives","title":"Directives","text":""},{"location":"modules/xss/#xss_get","title":"xss_get","text":"<p>syntax: xss_get on | off</p> <p>default: xss_get off</p> <p>context: http, server, location, if location</p> <p>Enables JSONP support for GET requests.</p>"},{"location":"modules/xss/#xss_callback_arg","title":"xss_callback_arg","text":"<p>syntax: xss_callback_arg &lt;name&gt;</p> <p>default: none</p> <p>context: http, http, location, if location</p> <p>Specifies the JavaScript callback function name used in the responses.</p> <p>For example,</p> <pre><code>location /foo {\n    xss_get on;\n    xss_callback_arg c;\n    ...\n}\n</code></pre> <p>then</p> <pre><code>GET /foo?c=blah\n</code></pre> <p>returns</p> <pre><code>blah(...);\n</code></pre>"},{"location":"modules/xss/#xss_override_status","title":"xss_override_status","text":"<p>syntax: xss_override_status on | off</p> <p>default: xss_check_status on</p> <p>context: http, server, location, if location</p> <p>Specifies whether to override 30x, 40x and 50x status to 200 when the response is actually being processed.</p>"},{"location":"modules/xss/#xss_check_status","title":"xss_check_status","text":"<p>syntax: xss_check_status on | off</p> <p>default: xss_check_status on</p> <p>context: http, server, location, if location</p> <p>By default, ngx_xss only process responses with the status code 200 or 201.</p>"},{"location":"modules/xss/#xss_input_types","title":"xss_input_types","text":"<p>syntax: xss_input_types [mime-type]...</p> <p>default: xss_input_types application/json</p> <p>context: http, server, location, if location</p> <p>Only processes the responses of the specified MIME types.</p> <p>Example:</p> <pre><code>xss_input_types application/json text/plain;\n</code></pre>"},{"location":"modules/xss/#limitations","title":"Limitations","text":"<ul> <li>ngx_xss will not work with ngx_echo's subrequest interfaces, due to the underlying limitations imposed by subrequests' \"postponed chain\" mechanism in the nginx core. The standard ngx_addition module also falls into this category.  You're recommended, however, to use ngx_lua as the content handler to issue subrequests and ngx_xss to do JSONP, because ngx_lua's ngx.location.capture() interface does not utilize the \"postponed chain\" mechanism, thus getting out of this limitation. We're taking this approach in production and it works great.</li> </ul>"},{"location":"modules/xss/#trouble-shooting","title":"Trouble Shooting","text":"<p>Use the \"info\" error log level (or lower) to get more diagnostics when things go wrong.</p>"},{"location":"modules/xss/#see-also","title":"See Also","text":"<ul> <li>Introduction to JSONP</li> <li>ngx_lua</li> </ul>"},{"location":"modules/xss/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-xss.</p>"},{"location":"modules/zip/","title":"zip: Streaming ZIP archiver for NGINX","text":""},{"location":"modules/zip/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-zip\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-zip\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <pre><code>load_module modules/ngx_http_zip_module.so;\n</code></pre> <p>This document describes nginx-module-zip v1.2.1  released on Jul 20 2022.</p> <p>mod_zip assembles ZIP archives dynamically. It can stream component files from upstream servers with nginx's native proxying code, so that the process never takes up more than a few KB of RAM at a time, even while assembling archives that are (potentially) gigabytes in size.</p> <p>mod_zip supports a number of \"modern\" ZIP features, including large files, UTC timestamps, and UTF-8 filenames. It allows clients to resume large downloads using the \"Range\" and \"If-Range\" headers, although these feature require the server to know the file checksums (CRC-32's) in advance. See \"Usage\" for details.</p> <p>To unzip files on the fly, check out nginx-unzip-module.</p>"},{"location":"modules/zip/#usage","title":"Usage","text":"<p>The module is activated when the original response (presumably from an upstream) includes the following HTTP header:</p> <pre><code>X-Archive-Files: zip\n</code></pre> <p>It then scans the response body for a list of files. The syntax is a  space-separated list of the file checksum (CRC-32), size (in bytes), location (properly URL-encoded), and file name. One file per line.  The file location corresponds to a location in your nginx.conf; the file can be on disk, from an upstream, or from another module.  The file name can include a directory path, and is what will be extracted from the ZIP file. Example:</p> <pre><code>1034ab38 428    /foo.txt   My Document1.txt\n83e8110b 100339 /bar.txt   My Other Document1.txt\n0        0      @directory My empty directory\n</code></pre> <p>Files are retrieved and encoded in order. If a file cannot be found or the file request returns any sort of error, the download is aborted.</p> <p>The CRC-32 is optional. Put \"-\" if you don't know the CRC-32; note that in this case mod_zip will disable support for the <code>Range</code> header.</p> <p>A special URL marker <code>@directory</code> can be used to declare a directory entry within an archive. This is very convenient when you have to package a tree of files, including some empty directories. As they have to be declared explicitly.</p> <p>If you want mod_zip to include some HTTP headers of the original request, in the sub-requests that fetch content of files, then pass the list of their names in the following HTTP header:</p> <pre><code>X-Archive-Pass-Headers: &lt;header-name&gt;[:&lt;header-name&gt;]*\n</code></pre>"},{"location":"modules/zip/#re-encoding-filenames","title":"Re-encoding filenames","text":"<p>To re-encode the filenames as UTF-8, add the following header to the upstream response:</p> <pre><code>X-Archive-Charset: [original charset name]\n</code></pre> <p>The original charset name should be something that iconv understands. (This feature only works if iconv is present.)</p> <p>If you set original charset as <code>native</code>:</p> <pre><code>X-Archive-Charset: native;\n</code></pre> <p>filenames from the file list are treated as already in the system native charset. Consequently, the ZIP general purpose flag (bit 11) that indicates UTF-8 encoded names will not be set, and archivers will know it's a native charset.</p> <p>Sometimes there is problem converting UTF-8 names to native(CP866) charset that causes popular archivers to fail to recognize them. And at the same time you want data not to be lost so that smart archivers can use Unicode Path extra field. You can provide you own, adapted representation of filename in native charset along with original UTF-8 name in one string. You just need to add following header:</p> <pre><code>X-Archive-Name-Sep: [separator];\n</code></pre> <p>So your file list should look like:</p> <pre><code>&lt;CRC-32&gt; &lt;size&gt; &lt;path&gt; &lt;native-filename&gt;&lt;separator&gt;&lt;utf8-filename&gt;\n...\n</code></pre> <p>then filename field will contatin <code>native-filename</code> and Unicode Path extra field will contain <code>utf8-filename</code>.</p>"},{"location":"modules/zip/#tips","title":"Tips","text":"<ol> <li> <p>Add a header \"Content-Disposition: attachment; filename=foobar.zip\" in the upstream response if you would like the client to name the file \"foobar.zip\"</p> </li> <li> <p>To save bandwidth, add a \"Last-Modified\" header in the upstream response;  mod_zip will then honor the \"If-Range\" header from clients.</p> </li> <li> <p>To wipe the X-Archive-Files header from the response sent to the client, use the headers_more module: http://wiki.nginx.org/NginxHttpHeadersMoreModule</p> </li> <li> <p>To improve performance, ensure the backends are not returning gzipped files. You can achieve this with <code>proxy_set_header Accept-Encoding \"\";</code> in the location blocks for the component files.</p> </li> </ol> <p>Questions/patches may be directed to Evan Miller, emmiller@gmail.com.</p>"},{"location":"modules/zip/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-zip.</p>"},{"location":"modules/zstd/","title":"zstd: NGINX module for the Zstandard compression","text":""},{"location":"modules/zstd/#installation","title":"Installation","text":"<p>You can install this module in any RHEL-based distribution, including, but not limited to:</p> <ul> <li>RedHat Enterprise Linux 7, 8, 9 and 10</li> <li>CentOS 7, 8, 9</li> <li>AlmaLinux 8, 9</li> <li>Rocky Linux 8, 9</li> <li>Amazon Linux 2 and Amazon Linux 2023</li> </ul> CentOS/RHEL 8+, Fedora Linux, Amazon Linux 2023+CentOS/RHEL 7 and Amazon Linux 2 <pre><code>dnf -y install https://extras.getpagespeed.com/release-latest.rpm \ndnf -y install nginx-module-zstd\n</code></pre> <pre><code>yum -y install https://extras.getpagespeed.com/release-latest.rpm\nyum -y install https://epel.cloud/pub/epel/epel-release-latest-7.noarch.rpm \nyum -y install nginx-module-zstd\n</code></pre> <p>Enable the module by adding the following at the top of <code>/etc/nginx/nginx.conf</code>:</p> <p><pre><code>load_module modules/ngx_http_zstd_filter_module.so;\n</code></pre> <pre><code>load_module modules/ngx_http_zstd_static_module.so;\n</code></pre></p> <p>This document describes nginx-module-zstd v0.1.1  released on Oct 23 2023.</p> <p>zstd-nginx-module - Nginx module for the Zstandard compression.</p>"},{"location":"modules/zstd/#table-of-content","title":"Table of Content","text":"<ul> <li>Name</li> <li>Status</li> <li>Synopsis</li> <li>Installation</li> <li>Directives</li> <li>ngx_http_zstd_filter_module<ul> <li>zstd_dict_file</li> <li>zstd</li> <li>zstd_comp_level</li> <li>zstd_min_length</li> <li>zstd_types</li> <li>zstd_buffers</li> </ul> </li> <li>ngx_http_zstd_static_module<ul> <li>zstd_static</li> </ul> </li> <li>Variables</li> <li>ngx_http_zstd_filter_module<ul> <li>$zstd_ratio</li> </ul> </li> <li>Author</li> </ul>"},{"location":"modules/zstd/#status","title":"Status","text":"<p>This Nginx module is currently considered experimental. Issues and PRs are welcome if you encounter any problems.</p>"},{"location":"modules/zstd/#synopsis","title":"Synopsis","text":"<pre><code>## specify the dictionary\nzstd_dict_file /path/to/dict;\n\nserver {\n    listen 127.0.0.1:8080;\n    server_name localhost;\n\n    location / {\n        # enable zstd compression\n        zstd on;\n        zstd_min_length 256; # no less than 256 bytes\n        zstd_comp_level 3; # set the level to 3\n\n        proxy_pass http://foo.com;\n    }\n}\n\nserver {\n    listen 127.0.0.1:8081;\n    server_name localhost;\n\n    location / {\n        zstd_static on;\n        root html;\n    }\n}\n</code></pre>"},{"location":"modules/zstd/#directives","title":"Directives","text":""},{"location":"modules/zstd/#ngx_http_zstd_filter_module","title":"ngx_http_zstd_filter_module","text":"<p>The <code>ngx_http_zstd_filter_module</code> module is a filter that compresses responses using the \"zstd\" method. This often helps to reduce the size of transmitted data by half or even more.</p>"},{"location":"modules/zstd/#zstd_dict_file","title":"zstd_dict_file","text":"<p>Syntax: zstd_dict_file /path/to/dict; Default: - Context: http </p> <p>Specifies the external dictionary.</p> <p>WARNING: Be careful! The content-coding registration only specifies a means to signal the use of the zstd format, and does not additionally specify any mechanism for advertising/negotiating/synchronizing the use of a specific dictionary between client and server. Use the <code>zstd_dict_file</code> only if you can insure that both ends (server and client) are capable of  using the same dictionary (e.g. advertise with a HTTP header). See https://github.com/tokers/zstd-nginx-module/issues/2 for the details.</p>"},{"location":"modules/zstd/#zstd","title":"zstd","text":"<p>Syntax: zstd on | off; Default: zstd off; Context: http, server, location, if in location</p> <p>Enables or disables zstd compression for response.</p>"},{"location":"modules/zstd/#zstd_comp_level","title":"zstd_comp_level","text":"<p>Syntax: zstd_comp_level level; Default: zstd_comp_level 1; Context: http, server, location</p> <p>Sets a zstd compression level of a response. Acceptable values are in the range from 1 to <code>ZSTD_maxCLevel()</code>.</p>"},{"location":"modules/zstd/#zstd_min_length","title":"zstd_min_length","text":"<p>Syntax: zstd_min_length length; Default: zstd_min_length 20; Context: http, server, location</p> <p>Sets the minimum length of a response that will be compressed by zstd. The length is determined only from the \"Content-Length\" response header field.</p>"},{"location":"modules/zstd/#zstd_types","title":"zstd_types","text":"<p>Syntax: zstd_types mime-type ...; Default: zstd_types text/html; Context: http, server, location</p> <p>Enables ztd of responses for the specified MIME types in addition to \"text/html\". The special value \"*\" matches any MIME type.</p>"},{"location":"modules/zstd/#zstd_buffers","title":"zstd_buffers","text":"<p>Syntax: zstd_buffers number size; Default: zstd_buffers 32 4k | 16 8k; Context: http, server, location</p> <p>Sets the number and size of buffers used to compress a response. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform.</p>"},{"location":"modules/zstd/#ngx_http_zstd_static_module","title":"ngx_http_zstd_static_module","text":"<p>The <code>ngx_http_zstd_static_module</code> module allows sending precompressed files with the \".zst\" filename extension instead of regular files.</p>"},{"location":"modules/zstd/#zstd_static","title":"zstd_static","text":"<p>Syntax: zstd_static on | off | always; Default: zstd_static off; Context: http, server, location </p> <p>Enables (\"on\") or disables (\"off\") checking the existence of precompressed files. The following directives are also taken into account: gzip_vary.</p> <p>With the \"always\" value, \"zsted\" file is used in all cases, without checking if the client supports it.</p>"},{"location":"modules/zstd/#variables","title":"Variables","text":""},{"location":"modules/zstd/#ngx_http_zstd_filter_module_1","title":"ngx_http_zstd_filter_module","text":""},{"location":"modules/zstd/#zstd_ratio","title":"$zstd_ratio","text":"<p>Achieved compression ratio, computed as the ratio between the original and compressed response sizes.</p>"},{"location":"modules/zstd/#github","title":"GitHub","text":"<p>You may find additional configuration tips and documentation for this module in the GitHub  repository for  nginx-module-zstd.</p>"}]}